{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: *Using linguistic cues, is it possible to detect when betrayal will happen?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains two parts and each part we are using different feature extraction method.\n",
    "First part we are training 3 simple models:\n",
    "   - Logistic Regression\n",
    "   - Random Forest Classifier\n",
    "   - Gradient Boosting Classifier\n",
    "   \n",
    "For the second part we are training same models that are shown above as well as a Fully Connected Linear Network for predicting which season a Diplomacy game will end with betrayal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import random\n",
    "import sklearn\n",
    "import imblearn\n",
    "import numpy as np\n",
    "from io import open\n",
    "from helpers import *\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from itertools import product\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import matthews_corrcoef,f1_score\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the diplomacy data and setting the random seed so that the notebook can be reproducable.\n",
    "random.seed(5)\n",
    "with open(\"data/diplomacy_data.json\", \"r\") as f:\n",
    "    diplomacy = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***FIRST PART***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***FEATURE EXTRACTION***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features are extracted from all the seasons before the last support season and  games are eliminated if they have less than 4 seasons until last support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our main feature for our first part in this notebook\n",
    "#We only consider games which end in a betrayal\n",
    "betrayal = [entry for entry in diplomacy if entry[\"betrayal\"]==True]\n",
    "labels = np.empty((0))\n",
    "victim_items = np.empty((0,12))\n",
    "betrayer_items = np.empty((0,12))\n",
    "\n",
    "victim_items_e = np.empty((0,14))\n",
    "betrayer_items_e = np.empty((0,14))\n",
    "for who in [\"victim\",\"betrayer\"]:\n",
    "    for i,j in zip([0,-3,-2,-1],[-3,-2,-1,None]):\n",
    "        #We exctract all the features\n",
    "        item_e = extract_features(betrayal,who,i,j,True)\n",
    "        #We delete the Claim and Temporal Rest fields\n",
    "        item = np.delete(item_e, (8,13),axis=0)\n",
    "        \n",
    "       \n",
    "        item = np.transpose(item)\n",
    "        item_e = np.transpose(item_e)\n",
    "        \n",
    "        #Place the features in their corresponding arrays\n",
    "        if who == \"victim\":\n",
    "            victim_items = np.concatenate((victim_items, item), axis=0)\n",
    "            victim_items_e = np.concatenate((victim_items_e, item_e), axis=0)\n",
    "        else:\n",
    "            betrayer_items = np.concatenate((betrayer_items, item), axis=0)\n",
    "            betrayer_items_e = np.concatenate((betrayer_items_e, item_e), axis=0)\n",
    "            \n",
    "        #Create labels for the 4 classes\n",
    "        if who == \"victim\":    \n",
    "            if i == 0:\n",
    "                labels = np.concatenate((labels, np.repeat(3,item.shape[0])), axis=0) \n",
    "            if i == -3:\n",
    "                labels = np.concatenate((labels, np.repeat(2,item.shape[0])), axis=0)\n",
    "            if i == -2:\n",
    "                labels = np.concatenate((labels, np.repeat(1,item.shape[0])), axis=0)\n",
    "            if i == -1:\n",
    "                labels = np.concatenate((labels, np.repeat(0,item.shape[0])), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By getting difference between betrayer and victim features we are getting the inbalance features.\n",
    "#Normalizing the inbalance feateures using scale.\n",
    "X_train_s = preprocessing.scale(betrayer_items - victim_items)\n",
    "X_train_e = preprocessing.scale(betrayer_items_e - victim_items_e)\n",
    "y_train = labels\n",
    "#Shuffling the dataset\n",
    "rand_idx = np.random.permutation(len(X_train_s))\n",
    "X_train_s = X_train_s[rand_idx]\n",
    "X_train_e = X_train_e[rand_idx]\n",
    "y_train = y_train[rand_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ploting the how many features that each class has.\n",
    "before_1 = Counter(y_train)[0]\n",
    "before_2 = Counter(y_train)[1]\n",
    "before_3 = Counter(y_train)[2]\n",
    "before_4 = Counter(y_train)[3]\n",
    "x = [0,0.25,0.50,0.75]\n",
    "y_values = [before_1,before_2,before_3,before_4]\n",
    "ax = [0,0,0,0]\n",
    "width=0\n",
    "for j,y in enumerate(y_values):\n",
    "    ax[j]=plt.bar(width, y, label='No Betrayal',width=0.2,color='orange',edgecolor=\"black\")\n",
    "    width+=0.25\n",
    "\n",
    "plt.xticks(x, ('0', '1','2','3'))\n",
    "for i in range(4):\n",
    "    plt.text(ax[i][0].get_x() + ax[i][0].get_width()/2., ax[i][0].get_height()/2,'%d' % int(ax[i][0].get_height()),ha='center', va='bottom')\n",
    "    \n",
    "plt.title('Distribution of labels')\n",
    "plt.xlabel(\"Labels\")\n",
    "plt.ylabel(\"Count of seasons\")\n",
    "plt.savefig(\"qB_imbalance_part1.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Form the plot we can see that dataset unbalanced so that while training the models we will balance the data using smote(This library oversample the data at the end we will have same number of each classes and mean and the standard deviation of the class distributions will be the same.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***BASIC MODELS***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the basic models everything, except model, will be the same. We used 5 fold cross-validation for the each model and  at the begining of the each cross-validation we used grid search for the finding best parameters with 5-fold cross-validation. So we used nested cross-validations. Moreover we are repeating the same experiment for both including the all features and excluding claim and temporal rest features.\n",
    "\n",
    "Note: We are not tuning any parameters for the logistic regression so we are not using grid search for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With feature set 1\n",
      "-------------------------------\n",
      "i:0, matthews_corrcoef:0.16240532485281473, f1_score:0.25641025641025644, RMSE:1.5886502207249789, MAE:1.2476190476190476, bet_detection:[0.25641026 0.2962963  0.25       0.26086957]\n",
      "i:1, matthews_corrcoef:-0.18301143487743313, f1_score:0.08333333333333333, RMSE:1.8631032838127484, MAE:1.5480769230769231, bet_detection:[0.08333333 0.07142857 0.19607843 0.24691358]\n",
      "i:2, matthews_corrcoef:-0.04052204492365539, f1_score:0.14285714285714288, RMSE:1.781313257986063, MAE:1.4615384615384615, bet_detection:[0.14285714 0.25       0.16       0.23684211]\n",
      "i:3, matthews_corrcoef:0.06154574548966637, f1_score:0.2380952380952381, RMSE:1.8527526299245423, MAE:1.5288461538461537, bet_detection:[0.23809524 0.2        0.22857143 0.17283951]\n",
      "i:4, matthews_corrcoef:0.049882551800475974, f1_score:0.22727272727272724, RMSE:1.7893918176081718, MAE:1.4326923076923077, bet_detection:[0.22727273 0.25       0.3255814  0.19178082]\n",
      "Best results:\n",
      " matthews_corrcoef =0.16240532485281473 in i=0,\n",
      " f1_score=0.25641025641025644 in i=0,\n",
      " RMSE=1.5886502207249789 in i=0,\n",
      " MAE=1.2476190476190476 in i=0\n",
      "With feature set 2\n",
      "-------------------------------\n",
      "i:0, matthews_corrcoef:0.017277162218384545, f1_score:0.15384615384615385, RMSE:1.701539918790651, MAE:1.3714285714285714, bet_detection:[0.15384615 0.25454545 0.25531915 0.23188406]\n",
      "i:1, matthews_corrcoef:-0.0015422289352610965, f1_score:0.23076923076923078, RMSE:1.7840101758937104, MAE:1.4519230769230769, bet_detection:[0.23076923 0.125      0.15686275 0.19178082]\n",
      "i:2, matthews_corrcoef:-0.09832102880166933, f1_score:0.0975609756097561, RMSE:1.786703022974913, MAE:1.4807692307692308, bet_detection:[0.09756098 0.19047619 0.16326531 0.23684211]\n",
      "i:3, matthews_corrcoef:-0.05418800739686293, f1_score:0.11764705882352941, RMSE:1.8134115744809667, MAE:1.4615384615384615, bet_detection:[0.11764706 0.24       0.23529412 0.31111111]\n",
      "i:4, matthews_corrcoef:0.040661268204403286, f1_score:0.2222222222222222, RMSE:1.7759071354792608, MAE:1.4615384615384615, bet_detection:[0.22222222 0.16326531 0.18604651 0.16901408]\n",
      "Best results:\n",
      " matthews_corrcoef =0.040661268204403286 in i=4,\n",
      " f1_score=0.23076923076923078 in i=1,\n",
      " RMSE=1.701539918790651 in i=0,\n",
      " MAE=1.3714285714285714 in i=0\n"
     ]
    }
   ],
   "source": [
    "# for 5 fold CV with LogisticRegression\n",
    "#iterate over with and without claim and temporal rest features\n",
    "for idx,(X_train,y_train)  in enumerate(zip([X_train_s,X_train_e],[y_train,y_train])):\n",
    "    print(f'With feature set {idx+1}\\n-------------------------------')\n",
    "    #Setting N to 5 means 5-fold cross-validation\n",
    "    N = 5\n",
    "    r = np.zeros(N)\n",
    "    accuracy = np.zeros(N)\n",
    "    RMSE = np.zeros(N)\n",
    "    MAE=np.zeros(N)\n",
    "    \n",
    "    bet_detection=np.empty((0,4))\n",
    "\n",
    "    kf = KFold(n_splits=N)\n",
    "    i=0\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        #Seperating data as train and validation\n",
    "        X_tr_fold, X_te_fold = X_train[train_index], X_train[test_index]\n",
    "        y_tr_fold, y_te_fold = y_train[train_index], y_train[test_index]\n",
    "        #balancing the training dataset using smote\n",
    "        oversample = SMOTE()\n",
    "        X_tr_fold, y_tr_fold = oversample.fit_sample(X_tr_fold, y_tr_fold)\n",
    "        #shuffling the balanced data\n",
    "        rand_idx=np.random.permutation(len(X_tr_fold))\n",
    "        X_tr_fold = X_tr_fold[rand_idx]\n",
    "        y_tr_fold = y_tr_fold[rand_idx]\n",
    "         #We are setting our model as logistic regression \n",
    "        regressor = LogisticRegression()\n",
    "        #fitting the data into the model\n",
    "        regressor.fit(X_tr_fold,np.ravel(y_tr_fold))\n",
    "        #prediction over the current validation set\n",
    "        y_predict = regressor.predict(X_te_fold)\n",
    "        #Calculate f1-score(each class separately)\n",
    "        bet_detection = np.concatenate((bet_detection,[f1_score(y_te_fold,y_predict,average=None)]),axis=0)\n",
    "        #Calculate Matthews correlation coefficient for the class 0\n",
    "        z_window_pred = np.copy(y_predict)\n",
    "        z_window_pred[z_window_pred !=0] = 1\n",
    "        z_window_true = np.copy(y_te_fold)\n",
    "        z_window_true[z_window_true !=0] = 1\n",
    "        r[i] = matthews_corrcoef(z_window_true, z_window_pred)\n",
    "        #Calculate rmse and mae for extra information and comparison between models\n",
    "        RMSE[i] = np.sqrt(sklearn.metrics.mean_squared_error(y_te_fold, y_predict))\n",
    "        MAE[i] = sklearn.metrics.mean_absolute_error(y_te_fold, y_predict)\n",
    "        print('i:{}, matthews_corrcoef:{}, f1_score:{}, RMSE:{}, MAE:{}, bet_detection:{}'.format(i, r[i],bet_detection[i,0],RMSE[i], MAE[i],bet_detection[i]))\n",
    "        i+=1\n",
    "    #After getting the all results we are printing the best overall result over 5 different fold.\n",
    "    print('Best results:')\n",
    "    print(' matthews_corrcoef ={} in i={},\\n f1_score={} in i={},\\n RMSE={} in i={},\\n MAE={} in i={}'.format(np.amax(r), np.argmax(r), np.amax(bet_detection[:,0]), np.argmax(bet_detection[:,0]), np.amin(RMSE), np.argmin(RMSE), np.amin(MAE), np.argmin(MAE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With feature set 1\n",
      "-------------------------------\n",
      "Best Parameters for 0 fold: {'max_depth': 18, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "i:0, matthews_corrcoef:0.075052056099763, f1_score:0.17391304347826086, RMSE:1.4896468101693163, MAE:1.0952380952380953, bet_detection:[0.17391304 0.15789474 0.11111111 0.53097345]\n",
      "Best Parameters for 1 fold: {'max_depth': 18, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "i:1, matthews_corrcoef:0.08921633931048109, f1_score:0.23529411764705882, RMSE:1.745874257521693, MAE:1.3173076923076923, bet_detection:[0.23529412 0.06451613 0.08695652 0.5       ]\n",
      "Best Parameters for 2 fold: {'max_depth': 72, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "i:2, matthews_corrcoef:-0.04550157551932901, f1_score:0.08, RMSE:1.5597090458455087, MAE:1.1634615384615385, bet_detection:[0.08       0.07692308 0.2173913  0.48648649]\n",
      "Best Parameters for 3 fold: {'max_depth': 72, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 600}\n",
      "i:3, matthews_corrcoef:0.22252289995819016, f1_score:0.3076923076923077, RMSE:1.4741359920566768, MAE:1.0192307692307692, bet_detection:[0.30769231 0.125      0.13333333 0.61666667]\n",
      "Best Parameters for 4 fold: {'max_depth': 18, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 600}\n",
      "i:4, matthews_corrcoef:0.02306390612937763, f1_score:0.14814814814814814, RMSE:1.6172150801252798, MAE:1.2307692307692308, bet_detection:[0.14814815 0.06451613 0.05714286 0.50434783]\n",
      "Best results:\n",
      " matthews_corrcoef =0.22252289995819016 in i=3,\n",
      " f1_score=0.3076923076923077 in i=3,\n",
      " RMSE=1.4741359920566768 in i=3,\n",
      " MAE=1.0192307692307692 in i=3\n",
      "With feature set 2\n",
      "-------------------------------\n",
      "Best Parameters for 0 fold: {'max_depth': 36, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "i:0, matthews_corrcoef:0.033553079968086076, f1_score:0.14814814814814817, RMSE:1.508704900300412, MAE:1.0761904761904761, bet_detection:[0.14814815 0.17647059 0.125      0.58119658]\n",
      "Best Parameters for 1 fold: {'max_depth': 72, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 800}\n",
      "i:1, matthews_corrcoef:-0.027693436270228494, f1_score:0.07692307692307693, RMSE:1.695582495781317, MAE:1.2403846153846154, bet_detection:[0.07692308 0.13793103 0.08       0.546875  ]\n",
      "Best Parameters for 2 fold: {'max_depth': 36, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 800}\n",
      "i:2, matthews_corrcoef:0.014504945216194557, f1_score:0.1, RMSE:1.4935759876113537, MAE:1.0961538461538463, bet_detection:[0.1        0.06666667 0.         0.5625    ]\n",
      "Best Parameters for 3 fold: {'max_depth': 36, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 800}\n",
      "i:3, matthews_corrcoef:0.041723043742160654, f1_score:0.15384615384615385, RMSE:1.5032017112202156, MAE:1.0673076923076923, bet_detection:[0.15384615 0.11764706 0.14814815 0.59504132]\n",
      "Best Parameters for 4 fold: {'max_depth': 18, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "i:4, matthews_corrcoef:-0.06260203092259642, f1_score:0.07407407407407407, RMSE:1.5566235649883124, MAE:1.1346153846153846, bet_detection:[0.07407407 0.08333333 0.05714286 0.57377049]\n",
      "Best results:\n",
      " matthews_corrcoef =0.041723043742160654 in i=3,\n",
      " f1_score=0.15384615384615385 in i=3,\n",
      " RMSE=1.4935759876113537 in i=2,\n",
      " MAE=1.0673076923076923 in i=3\n"
     ]
    }
   ],
   "source": [
    "# for 5 fold CV for parameter tuning with RandomForest\n",
    "#iterate over with and without claim and temporal rest features\n",
    "for idx,(X_train,y_train)  in enumerate(zip([X_train_s,X_train_e],[y_train,y_train])):\n",
    "    print(f'With feature set {idx+1}\\n-------------------------------')\n",
    "    #setting the estimator as random forest classifier\n",
    "    estimator = RandomForestClassifier()\n",
    "    #setting the parameters which we will use them to tune the parameters and use them in the grid search\n",
    "    parameters =  {\n",
    "     'max_depth': [3, 6, 9, 18, 36,72],\n",
    "     'min_samples_leaf': [1, 2, 4],\n",
    "     'min_samples_split': [2, 5, 10],\n",
    "     'n_estimators': [100, 200, 400, 600, 800]}\n",
    "    #Setting N to 5 means 5-fold cross-validation\n",
    "    N = 5\n",
    "    r = np.zeros(N)\n",
    "    accuracy = np.zeros(N)\n",
    "    RMSE = np.zeros(N)\n",
    "    MAE=np.zeros(N)\n",
    "    bet_detection=np.empty((0,4))\n",
    "\n",
    "    kf = KFold(n_splits=N)\n",
    "    i=0\n",
    "\n",
    "\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        #Seperating data as train and validation\n",
    "        X_tr_fold, X_te_fold = X_train[train_index], X_train[test_index]\n",
    "        y_tr_fold, y_te_fold = y_train[train_index], y_train[test_index]\n",
    "        #balancing the training dataset using smote\n",
    "        oversample = SMOTE()\n",
    "        X_tr_fold, y_tr_fold = oversample.fit_sample(X_tr_fold, y_tr_fold)\n",
    "        #shuffling the balanced data\n",
    "        rand_idx=np.random.permutation(len(X_tr_fold))\n",
    "        X_tr_fold = X_tr_fold[rand_idx]\n",
    "        y_tr_fold = y_tr_fold[rand_idx]\n",
    "    \n",
    "        #We are setting the grid search(cv used for cross validation and set as 5 n_jobs=-1 so we will use the all processors available)\n",
    "        grid_search = GridSearchCV(estimator = estimator, param_grid = parameters, \n",
    "                              cv = N, n_jobs = -1)\n",
    "        #fitting the data into the all sets of parameters\n",
    "        grid_search.fit(X_tr_fold,np.ravel(y_tr_fold))\n",
    "        # We are printing the best parameters for the current training set.\n",
    "        print(\"Best Parameters for {} fold: {}\".format(i,grid_search.best_params_))\n",
    "        #We are getting the best estimator model\n",
    "        regressor = grid_search.best_estimator_\n",
    "        regressor.fit(X_tr_fold,np.ravel(y_tr_fold))# Actually this line is not needed since we are fitting all of the models but for just demosntration we are fitting anyway.\n",
    "        #prediction over the current validation set\n",
    "        y_predict = regressor.predict(X_te_fold)\n",
    "        #Calculate f1-score(each class separately)\n",
    "        bet_detection = np.concatenate((bet_detection,[f1_score(y_te_fold,y_predict,average=None)]),axis=0)\n",
    "        #Calculate Matthews correlation coefficient for the class 0\n",
    "        z_window_pred = np.copy(y_predict)\n",
    "        z_window_pred[z_window_pred !=0] = 1\n",
    "        z_window_true = np.copy(y_te_fold)\n",
    "        z_window_true[z_window_true !=0] = 1\n",
    "        r[i] = matthews_corrcoef(z_window_true, z_window_pred)\n",
    "        #Calculate rmse and mae for extra information and comparison between models\n",
    "        RMSE[i] = np.sqrt(sklearn.metrics.mean_squared_error(y_te_fold, y_predict))\n",
    "        MAE[i] = sklearn.metrics.mean_absolute_error(y_te_fold, y_predict)\n",
    "        print('i:{}, matthews_corrcoef:{}, f1_score:{}, RMSE:{}, MAE:{}, bet_detection:{}'.format(i, r[i],bet_detection[i,0],RMSE[i], MAE[i],bet_detection[i]))\n",
    "        i+=1\n",
    "    #After getting the all results we are printing the best overall result over 5 different fold.\n",
    "    print('Best results:')\n",
    "    print(' matthews_corrcoef ={} in i={},\\n f1_score={} in i={},\\n RMSE={} in i={},\\n MAE={} in i={}'.format(np.amax(r), np.argmax(r), np.amax(bet_detection[:,0]), np.argmax(bet_detection[:,0]), np.amin(RMSE), np.argmin(RMSE), np.amin(MAE), np.argmin(MAE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With feature set 1\n",
      "-------------------------------\n",
      "Best Parameters for 0 fold: {'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 400}\n",
      "i:0, matthews_corrcoef:0.10089692439079567, f1_score:0.1904761904761905, RMSE:1.5023790657297036, MAE:1.1333333333333333, bet_detection:[0.19047619 0.11428571 0.1        0.49122807]\n",
      "Best Parameters for 1 fold: {'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "i:1, matthews_corrcoef:-0.01497818518107938, f1_score:0.12903225806451615, RMSE:1.6727453252294333, MAE:1.2019230769230769, bet_detection:[0.12903226 0.13333333 0.16666667 0.58536585]\n",
      "Best Parameters for 2 fold: {'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 400}\n",
      "i:2, matthews_corrcoef:-0.11633501014942219, f1_score:0.0, RMSE:1.4411533842457842, MAE:1.0576923076923077, bet_detection:[0.         0.11428571 0.19047619 0.56880734]\n",
      "Best Parameters for 3 fold: {'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "i:3, matthews_corrcoef:0.07693218186208295, f1_score:0.16666666666666666, RMSE:1.5504341823651058, MAE:1.1346153846153846, bet_detection:[0.16666667 0.05555556 0.         0.59016393]\n",
      "Best Parameters for 4 fold: {'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "i:4, matthews_corrcoef:-0.07014463364036422, f1_score:0.1111111111111111, RMSE:1.7012438888151131, MAE:1.2980769230769231, bet_detection:[0.11111111 0.13333333 0.         0.49557522]\n",
      "Best results:\n",
      " matthews_corrcoef =0.10089692439079567 in i=0,\n",
      " f1_score=0.1904761904761905 in i=0,\n",
      " RMSE=1.4411533842457842 in i=2,\n",
      " MAE=1.0576923076923077 in i=2\n",
      "With feature set 2\n",
      "-------------------------------\n",
      "Best Parameters for 0 fold: {'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 400}\n",
      "i:0, matthews_corrcoef:0.075052056099763, f1_score:0.17391304347826086, RMSE:1.5275252316519468, MAE:1.1333333333333333, bet_detection:[0.17391304 0.05882353 0.16666667 0.52991453]\n",
      "Best Parameters for 1 fold: {'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 400}\n",
      "i:1, matthews_corrcoef:-0.07440934644141917, f1_score:0.1111111111111111, RMSE:1.7677669529663689, MAE:1.2788461538461537, bet_detection:[0.11111111 0.09090909 0.22222222 0.56910569]\n",
      "Best Parameters for 2 fold: {'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "i:2, matthews_corrcoef:-0.035451483867683334, f1_score:0.08333333333333334, RMSE:1.522270571320254, MAE:1.1057692307692308, bet_detection:[0.08333333 0.21428571 0.         0.55284553]\n",
      "Best Parameters for 3 fold: {'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "i:3, matthews_corrcoef:0.026663111822064236, f1_score:0.14814814814814814, RMSE:1.6142395208794855, MAE:1.2403846153846154, bet_detection:[0.14814815 0.         0.07692308 0.53448276]\n",
      "Best Parameters for 4 fold: {'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "i:4, matthews_corrcoef:-0.09063670411985018, f1_score:0.06666666666666667, RMSE:1.5962696899574718, MAE:1.1442307692307692, bet_detection:[0.06666667 0.08695652 0.17142857 0.56666667]\n",
      "Best results:\n",
      " matthews_corrcoef =0.075052056099763 in i=0,\n",
      " f1_score=0.17391304347826086 in i=0,\n",
      " RMSE=1.522270571320254 in i=2,\n",
      " MAE=1.1057692307692308 in i=2\n"
     ]
    }
   ],
   "source": [
    "# for 5 fold CV for parameter tuning with GBR\n",
    "#iterate over with and without claim and temporal rest features\n",
    "for idx,(X_train,y_train)  in enumerate(zip([X_train_s,X_train_e],[y_train,y_train])):\n",
    "    print(f'With feature set {idx+1}\\n-------------------------------')\n",
    "    #setting the estimator as gradient boosting classifier\n",
    "    estimator = GradientBoostingClassifier()\n",
    "    #setting the parameters which we will use them to tune the parameters and use them in the grid search\n",
    "    parameters =  {\n",
    "        'max_depth': [3, 6],\n",
    "        'min_samples_leaf': [1, 2],\n",
    "        'min_samples_split': [2, 4],\n",
    "        'learning_rate' : [0.1,0.01],\n",
    "        'n_estimators': [100, 200, 400]}\n",
    "    #Setting N to 5 means 5-fold cross-validation\n",
    "    N = 5\n",
    "    r = np.zeros(N)\n",
    "    accuracy = np.zeros(N)\n",
    "    RMSE = np.zeros(N)\n",
    "    MAE=np.zeros(N)\n",
    "    bet_detection=np.empty((0,4))\n",
    "\n",
    "    kf = KFold(n_splits=N)\n",
    "    i=0\n",
    "\n",
    "\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        #Seperating data as train and validation\n",
    "        X_tr_fold, X_te_fold = X_train[train_index], X_train[test_index]\n",
    "        y_tr_fold, y_te_fold = y_train[train_index], y_train[test_index]\n",
    "        #balancing the training dataset using smote\n",
    "        oversample = SMOTE()\n",
    "        X_tr_fold, y_tr_fold = oversample.fit_sample(X_tr_fold, y_tr_fold)\n",
    "        #shuffling the balanced data\n",
    "        rand_idx=np.random.permutation(len(X_tr_fold))\n",
    "        X_tr_fold = X_tr_fold[rand_idx]\n",
    "        y_tr_fold = y_tr_fold[rand_idx]\n",
    "\n",
    "        #We are setting the grid search(cv used for cross validation and set as 5 n_jobs=-1 so we will use the all processors available)\n",
    "        grid_search = GridSearchCV(estimator = estimator, param_grid = parameters, \n",
    "                              cv = N, n_jobs = -1)\n",
    "        #fitting the data into the all sets of parameters\n",
    "        grid_search.fit(X_tr_fold,np.ravel(y_tr_fold))\n",
    "        # We are printing the best parameters for the current training set.\n",
    "        print(\"Best Parameters for {} fold: {}\".format(i,grid_search.best_params_))\n",
    "        #We are getting the best estimator model\n",
    "        regressor = grid_search.best_estimator_\n",
    "        regressor.fit(X_tr_fold,np.ravel(y_tr_fold))# Actually this line is not needed since we are fitting all of the models but for just demosntration we are fitting anyway.\n",
    "        #prediction over the current validation set\n",
    "        y_predict = regressor.predict(X_te_fold)\n",
    "        #Calculate f1-score(each class separately)\n",
    "        bet_detection = np.concatenate((bet_detection,[f1_score(y_te_fold,y_predict,average=None)]),axis=0)\n",
    "        #Calculate Matthews correlation coefficient for the class 0\n",
    "        z_window_pred = np.copy(y_predict)\n",
    "        z_window_pred[z_window_pred !=0] = 1\n",
    "        z_window_true = np.copy(y_te_fold)\n",
    "        z_window_true[z_window_true !=0] = 1\n",
    "        r[i] = matthews_corrcoef(z_window_true, z_window_pred)\n",
    "        #Calculate rmse and mae for extra information and comparison between models\n",
    "        RMSE[i] = np.sqrt(sklearn.metrics.mean_squared_error(y_te_fold, y_predict))\n",
    "        MAE[i] = sklearn.metrics.mean_absolute_error(y_te_fold, y_predict)\n",
    "        print('i:{}, matthews_corrcoef:{}, f1_score:{}, RMSE:{}, MAE:{}, bet_detection:{}'.format(i, r[i],bet_detection[i,0],RMSE[i], MAE[i],bet_detection[i]))\n",
    "        i+=1\n",
    "    #After getting the all results we are printing the best overall result over 5 different fold.\n",
    "    print('Best results:')\n",
    "    print(' matthews_corrcoef ={} in i={},\\n f1_score={} in i={},\\n RMSE={} in i={},\\n MAE={} in i={}'.format(np.amax(r), np.argmax(r), np.amax(bet_detection[:,0]), np.argmax(bet_detection[:,0]), np.amin(RMSE), np.argmin(RMSE), np.amin(MAE), np.argmin(MAE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***SECOND PART***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This performs the main feature extraction of the notebook.\n",
    "items = []\n",
    "victim_items = []\n",
    "betrayer_items = []\n",
    "labels = []\n",
    "whole_items=[]\n",
    "\n",
    "\n",
    "victim_items_e = []\n",
    "betrayer_items_e = []\n",
    "labels = []\n",
    "whole_items_e=[]\n",
    "for entry in diplomacy:\n",
    "    #take the feature if and only if the game ends with betrayal\n",
    "    if not entry[\"betrayal\"]:\n",
    "        continue\n",
    "    before_betrayer = []\n",
    "    before_victim = []\n",
    "    \n",
    "    before_betrayer_e = []\n",
    "    before_victim_e = []\n",
    "    seasons = seasons_before_betrayal(entry)\n",
    "    #We only take games with more than 4 season into account\n",
    "    if len(seasons) < 4:\n",
    "        continue\n",
    "    for i,season in enumerate(seasons):\n",
    "        #We only consider a season valid if both players sent a message in that season\n",
    "        if len(season['messages']['victim']) == 0 or len(season['messages']['betrayer']) == 0:\n",
    "            continue\n",
    "        if len(seasons) == i+1:\n",
    "            label_item = 1\n",
    "        else:\n",
    "            label_item = 0\n",
    "        labels.append(label_item)\n",
    "        #Create the features for victim and the betrayer\n",
    "        for who in [\"victim\",\"betrayer\"]:\n",
    "            #politness\n",
    "            politness = [message[\"politeness\"] for message in season[\"messages\"][who]]           \n",
    "            politness_item = np.mean(politness) if len(politness)>=1 else 0\n",
    "            #sentiment\n",
    "            positive_sentiment = [message[\"sentiment\"][\"positive\"] for message in season[\"messages\"][who]]\n",
    "            negative_sentiment = [message[\"sentiment\"][\"negative\"] for message in season[\"messages\"][who]]\n",
    "            neutral_sentiment = [message[\"sentiment\"][\"neutral\"] for message in season[\"messages\"][who]]\n",
    "            positive_item = np.mean(positive_sentiment) if len(positive_sentiment)>=1 else 0\n",
    "            negative_item = np.mean(negative_sentiment) if len(negative_sentiment)>=1 else 0\n",
    "            neutral_item = np.mean(neutral_sentiment) if len(neutral_sentiment)>=1 else 0\n",
    "            #nb_requests\n",
    "            nb_requests = [message[\"n_requests\"] for message in season[\"messages\"][who]]\n",
    "            requests_item = np.mean(nb_requests) if len(nb_requests)>=1 else 0\n",
    "            #nb_words\n",
    "            nb_words = [message[\"n_words\"] for message in season[\"messages\"][who]]\n",
    "            words_item = np.mean(nb_words) if len(nb_words)>=1 else 0\n",
    "            #nb_sentences\n",
    "            nb_sentences = [message[\"n_sentences\"] for message in season[\"messages\"][who]]\n",
    "            sentences_item = np.mean(nb_sentences) if len(nb_sentences)>=1 else 0\n",
    "            #premise\n",
    "            premise = [len(message[\"lexicon_words\"][\"premise\"]) for message in season[\"messages\"][who] if \"premise\" in message[\"lexicon_words\"].keys()]\n",
    "            premise_item = np.mean(premise) if len(premise)>=1 else 0\n",
    "            #claim\n",
    "            claim = [len(message[\"lexicon_words\"][\"claim\"]) for message in season[\"messages\"][who] if \"claim\" in message[\"lexicon_words\"].keys()]\n",
    "            claim_item = np.mean(claim) if len(claim)>=1 else 0\n",
    "            #disc_comparison\n",
    "            disc_comparison = [len(message[\"lexicon_words\"][\"disc_comparison\"]) for message in season[\"messages\"][who] if \"disc_comparison\" in message[\"lexicon_words\"].keys()]\n",
    "            comparison_item = np.mean(disc_comparison) if len(disc_comparison)>=1 else 0\n",
    "            #disc_expansion\n",
    "            disc_expansion = [len(message[\"lexicon_words\"][\"disc_expansion\"]) for message in season[\"messages\"][who] if \"disc_expansion\" in message[\"lexicon_words\"].keys()]\n",
    "            expansion_item = np.mean(disc_expansion) if len(disc_expansion)>=1 else 0\n",
    "            #disc_contingency\n",
    "            disc_contingency = [len(message[\"lexicon_words\"][\"disc_contingency\"]) for message in season[\"messages\"][who] if \"disc_contingency\" in message[\"lexicon_words\"].keys()]\n",
    "            contingency_item = np.mean(disc_contingency) if len(disc_contingency)>=1 else 0\n",
    "            #disc_temporal_future\n",
    "            disc_temporal_future = [len(message[\"lexicon_words\"][\"disc_temporal_future\"]) for message in season[\"messages\"][who] if \"disc_temporal_future\" in message[\"lexicon_words\"].keys()]\n",
    "            temporal_future_item = np.mean(disc_temporal_future) if len(disc_temporal_future)>=1 else 0\n",
    "            #disc_temporal_rest\n",
    "            disc_temporal_rest = [len(message[\"lexicon_words\"][\"disc_temporal_rest\"]) for message in season[\"messages\"][who] if \"disc_temporal_rest\" in message[\"lexicon_words\"].keys()]\n",
    "            temporal_rest_item = np.mean(disc_temporal_rest) if len(disc_temporal_rest)>=1 else 0\n",
    "            \n",
    "            \n",
    "            item_e = [politness_item,positive_item,negative_item,neutral_item,requests_item,words_item,sentences_item,\\\n",
    "                premise_item,claim_item,comparison_item,expansion_item,contingency_item,temporal_future_item,temporal_rest_item]\n",
    "            \n",
    "            #we exclude Claim and Temporal rest for some of our models\n",
    "            item = np.delete(item_e, (8,13),axis=0)\n",
    "            \n",
    "            #We take the mean of each feature for each each\n",
    "            if who == \"victim\":\n",
    "                before_victim.append(item)\n",
    "                victim_items.append(np.mean(before_victim, axis = 0))\n",
    "                \n",
    "                before_victim_e.append(item_e)\n",
    "                victim_items_e.append(np.mean(before_victim_e, axis = 0))\n",
    "            else:\n",
    "                before_betrayer.append(item)\n",
    "                betrayer_items.append(np.mean(before_betrayer, axis = 0))\n",
    "                \n",
    "                before_betrayer_e.append(item_e)\n",
    "                betrayer_items_e.append(np.mean(before_betrayer_e, axis = 0))\n",
    "                \n",
    "        whole_items.append(np.sum([victim_items[-1],betrayer_items[-1]], axis = 0)/2)\n",
    "        whole_items_e.append(np.sum([victim_items_e[-1],betrayer_items_e[-1]], axis = 0)/2)\n",
    "                \n",
    "victim_items = np.array(victim_items)\n",
    "betrayer_items = np.array(betrayer_items)\n",
    "whole_items = np.array(whole_items)\n",
    "\n",
    "victim_items_e = np.array(victim_items_e)\n",
    "betrayer_items_e = np.array(betrayer_items_e)\n",
    "whole_items_e = np.array(whole_items_e)\n",
    "\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***BASIC MODELS***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the basic models everything, except model, will be the same. We used 5 fold cross-validation for the each model and  at the begining of the each cross-validation we used grid search for the finding best parameters with 5-fold cross-validation. So we used nested cross-validations. Moreover we are repeating the same experiment for both including the all features and excluding claim and temporal rest features.\n",
    "\n",
    "Note: We are not tuning any parameters for the logistic regression so we are not using grid search for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By getting difference between betrayer and victim features we are getting the inbalance features.\n",
    "#Normalizing the inbalance feateures using scale.\n",
    "X_train_s = preprocessing.scale(betrayer_items - victim_items)\n",
    "X_train_e = preprocessing.scale(betrayer_items_e - victim_items_e)\n",
    "y_train = labels\n",
    "#Shuffling the dataset\n",
    "rand_idx = np.random.permutation(len(X_train_s))\n",
    "X_train_s = X_train_s[rand_idx]\n",
    "X_train_e = X_train_e[rand_idx]\n",
    "y_train = y_train[rand_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ploting the how many features that each class has.\n",
    "width = 0.1\n",
    "x=[0,0.25]\n",
    "zeros = plt.bar(0, Counter(y_train)[0], label='No Betrayal',width=0.2,color='white',edgecolor=\"black\")\n",
    "ones = plt.bar(0.25,Counter(y_train)[1] , label='Betrayal',width=0.2,color='orange',edgecolor=\"black\")\n",
    "plt.text(zeros[0].get_x() + zeros[0].get_width()/2., zeros[0].get_height()/2,'%d' % int(zeros[0].get_height()),ha='center', va='bottom')\n",
    "plt.text(ones[0].get_x() + ones[0].get_width()/2., ones[0].get_height()/2,'%d' % int(ones[0].get_height()),ha='center', va='bottom')\n",
    "plt.xticks(x, ('0', '1'))\n",
    "\n",
    "plt.title('Distribution of labels')\n",
    "plt.xlabel(\"Labels\")\n",
    "plt.ylabel(\"Count of seasons\")\n",
    "plt.savefig(\"qB_imbalance_part2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With feature set 1\n",
      "-------------------------------\n",
      "i:0, matthews_corrcoef:0.06119900613621045, accuracy:0.5714285714285714, RMSE:0.6546536707079771, MAE:0.42857142857142855,f1_score:0.26229508196721313\n",
      "i:1, matthews_corrcoef:-0.08259308406823933, accuracy:0.5, RMSE:0.7071067811865476, MAE:0.5,f1_score:0.16129032258064516\n",
      "i:2, matthews_corrcoef:-0.02180967590080987, accuracy:0.5, RMSE:0.7071067811865476, MAE:0.5,f1_score:0.1875\n",
      "i:3, matthews_corrcoef:-0.050677591680696285, accuracy:0.5096153846153846, RMSE:0.7002746713858894, MAE:0.49038461538461536,f1_score:0.19047619047619047\n",
      "i:4, matthews_corrcoef:0.06715474916917052, accuracy:0.5576923076923077, RMSE:0.6650621717611762, MAE:0.4423076923076923,f1_score:0.25806451612903225\n",
      "Best results:\n",
      " matthews_corrcoef =0.06715474916917052 in i=4,\n",
      " accuracy=0.5714285714285714 in i=0,\n",
      " RMSE=0.6546536707079771 in i=0,\n",
      " MAE=0.42857142857142855 in i=0,\n",
      " f1_score=0.26229508196721313 in i=0 \n",
      "With feature set 2\n",
      "-------------------------------\n",
      "i:0, matthews_corrcoef:0.06119900613621045, accuracy:0.5714285714285714, RMSE:0.6546536707079771, MAE:0.42857142857142855,f1_score:0.26229508196721313\n",
      "i:1, matthews_corrcoef:0.03364550352617882, accuracy:0.49038461538461536, RMSE:0.713873507433484, MAE:0.5096153846153846,f1_score:0.23188405797101444\n",
      "i:2, matthews_corrcoef:-0.01454785934906616, accuracy:0.5096153846153846, RMSE:0.7002746713858894, MAE:0.49038461538461536,f1_score:0.19047619047619047\n",
      "i:3, matthews_corrcoef:-0.03497118833570246, accuracy:0.5288461538461539, RMSE:0.6864064729836441, MAE:0.47115384615384615,f1_score:0.19672131147540983\n",
      "i:4, matthews_corrcoef:0.0663663648395968, accuracy:0.5096153846153846, RMSE:0.7002746713858894, MAE:0.49038461538461536,f1_score:0.2608695652173913\n",
      "Best results:\n",
      " matthews_corrcoef =0.0663663648395968 in i=4,\n",
      " accuracy=0.5714285714285714 in i=0,\n",
      " RMSE=0.6546536707079771 in i=0,\n",
      " MAE=0.42857142857142855 in i=0,\n",
      " f1_score=0.26229508196721313 in i=0 \n"
     ]
    }
   ],
   "source": [
    "# for 5 fold CV with LogisticRegression\n",
    "#iterate over with and without claim and temporal rest features\n",
    "for idx,(X_train,y_train)  in enumerate(zip([X_train_s,X_train_e],[y_train,y_train])):\n",
    "    print(f'With feature set {idx+1}\\n-------------------------------')\n",
    "    #Setting N to 5 means 5-fold cross-validation\n",
    "    N = 5\n",
    "    r = np.zeros(N)\n",
    "    accuracy = np.zeros(N)\n",
    "    RMSE = np.zeros(N)\n",
    "    MAE=np.zeros(N)\n",
    "    f1_scores=np.zeros(N)\n",
    "\n",
    "    kf = KFold(n_splits=N)\n",
    "    i=0\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        #Seperating data as train and validation\n",
    "        X_tr_fold, X_te_fold = X_train[train_index], X_train[test_index]\n",
    "        y_tr_fold, y_te_fold = y_train[train_index], y_train[test_index]\n",
    "        #balancing the training dataset using smote\n",
    "        oversample = SMOTE()\n",
    "        X_tr_fold, y_tr_fold = oversample.fit_sample(X_tr_fold, y_tr_fold)\n",
    "        #shuffling the balanced data\n",
    "        rand_idx=np.random.permutation(len(X_tr_fold))\n",
    "        X_tr_fold = X_tr_fold[rand_idx]\n",
    "        y_tr_fold = y_tr_fold[rand_idx]\n",
    "        #We are setting our model as logistic regression \n",
    "        regressor = LogisticRegression()\n",
    "        #fitting the data into the model\n",
    "        regressor.fit(X_tr_fold,np.ravel(y_tr_fold))\n",
    "        #prediction over the current validation set\n",
    "        y_predict = regressor.predict(X_te_fold)\n",
    "        #Calculate f1-score, accuracy, Matthews correlation coefficient\n",
    "        f1_scores[i] = f1_score(y_te_fold,y_predict)\n",
    "        accuracy[i] = regressor.score(X_te_fold,y_te_fold)\n",
    "        r[i] = matthews_corrcoef(y_te_fold, y_predict)\n",
    "        #Calculate rmse and mae for extra information and comparison between models\n",
    "        RMSE[i] = np.sqrt(sklearn.metrics.mean_squared_error(y_te_fold, y_predict))\n",
    "        MAE[i] = sklearn.metrics.mean_absolute_error(y_te_fold, y_predict)\n",
    "        print('i:{}, matthews_corrcoef:{}, accuracy:{}, RMSE:{}, MAE:{},f1_score:{}'.format(i, r[i],accuracy[i],RMSE[i], MAE[i], f1_scores[i]))\n",
    "        i+=1\n",
    "    #After getting the all results we are printing the best overall result over 5 different fold.\n",
    "    print('Best results:')\n",
    "    print(' matthews_corrcoef ={} in i={},\\n accuracy={} in i={},\\n RMSE={} in i={},\\n MAE={} in i={},\\n f1_score={} in i={} '.format(np.amax(r), np.argmax(r), np.amax(accuracy), np.argmax(accuracy), np.amin(RMSE), np.argmin(RMSE), np.amin(MAE), np.argmin(MAE),np.amax(f1_scores), np.argmax(f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With feature set 1\n",
      "-------------------------------\n",
      "Best Parameters for 0 fold: {'max_depth': 18, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "i:0, matthews_corrcoef:-0.12254630365216752, accuracy:0.6952380952380952, RMSE:0.5520524474738834, MAE:0.3047619047619048,f1_score:0.058823529411764705\n",
      "Best Parameters for 1 fold: {'max_depth': 18, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "i:1, matthews_corrcoef:-0.03150517713606188, accuracy:0.7307692307692307, RMSE:0.5188745216627708, MAE:0.2692307692307692,f1_score:0.125\n",
      "Best Parameters for 2 fold: {'max_depth': 18, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "i:2, matthews_corrcoef:-0.009828039493309125, accuracy:0.75, RMSE:0.5, MAE:0.25,f1_score:0.13333333333333333\n",
      "Best Parameters for 3 fold: {'max_depth': 18, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "i:3, matthews_corrcoef:0.0651685393258427, accuracy:0.7692307692307693, RMSE:0.4803844614152614, MAE:0.23076923076923078,f1_score:0.20000000000000004\n",
      "Best Parameters for 4 fold: {'max_depth': 18, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 800}\n",
      "i:4, matthews_corrcoef:0.01580151543799924, accuracy:0.8173076923076923, RMSE:0.42742520713255516, MAE:0.18269230769230768,f1_score:0.09523809523809522\n",
      "Best results:\n",
      " matthews_corrcoef =0.0651685393258427 in i=3,\n",
      " accuracy=0.8173076923076923 in i=4,\n",
      " RMSE=0.42742520713255516 in i=4,\n",
      " MAE=0.18269230769230768 in i=4,\n",
      " f1_score=0.20000000000000004 in i=3 \n",
      "With feature set 2\n",
      "-------------------------------\n",
      "Best Parameters for 0 fold: {'max_depth': 18, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "i:0, matthews_corrcoef:0.054092790300989436, accuracy:0.7619047619047619, RMSE:0.4879500364742666, MAE:0.23809523809523808,f1_score:0.19354838709677422\n",
      "Best Parameters for 1 fold: {'max_depth': 18, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "i:1, matthews_corrcoef:-0.06388765649999399, accuracy:0.7596153846153846, RMSE:0.4902903378454601, MAE:0.2403846153846154,f1_score:0.07407407407407408\n",
      "Best Parameters for 2 fold: {'max_depth': 18, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 600}\n",
      "i:2, matthews_corrcoef:0.08058229640253803, accuracy:0.7788461538461539, RMSE:0.4702699715629801, MAE:0.22115384615384615,f1_score:0.20689655172413793\n",
      "Best Parameters for 3 fold: {'max_depth': 18, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "i:3, matthews_corrcoef:0.02306390612937763, accuracy:0.7788461538461539, RMSE:0.4702699715629801, MAE:0.22115384615384615,f1_score:0.14814814814814814\n",
      "Best Parameters for 4 fold: {'max_depth': 18, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 600}\n",
      "i:4, matthews_corrcoef:-0.0410632455447945, accuracy:0.7788461538461539, RMSE:0.4702699715629801, MAE:0.22115384615384615,f1_score:0.08\n",
      "Best results:\n",
      " matthews_corrcoef =0.08058229640253803 in i=2,\n",
      " accuracy=0.7788461538461539 in i=2,\n",
      " RMSE=0.4702699715629801 in i=2,\n",
      " MAE=0.22115384615384615 in i=2,\n",
      " f1_score=0.20689655172413793 in i=2 \n"
     ]
    }
   ],
   "source": [
    "# for 5 fold CV for parameter tuning with RandomForest\n",
    "#iterate over with and without claim and temporal rest features\n",
    "for idx,(X_train,y_train)  in enumerate(zip([X_train_s,X_train_e],[y_train,y_train])):\n",
    "    print(f'With feature set {idx+1}\\n-------------------------------')\n",
    "    #setting the estimator as random forest classifier\n",
    "    estimator = RandomForestClassifier()\n",
    "    #setting the parameters which we will use them to tune the parameters and use them in the grid search\n",
    "    parameters =  {\n",
    "        'max_depth': [3, 6, 9, 18],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'n_estimators': [100, 200, 400, 600, 800]}\n",
    "    #Setting N to 5 means 5-fold cross-validation\n",
    "    N = 5\n",
    "    r = np.zeros(N)\n",
    "    accuracy = np.zeros(N)\n",
    "    RMSE = np.zeros(N)\n",
    "    MAE=np.zeros(N)\n",
    "    f1_scores=np.zeros(N)\n",
    "\n",
    "\n",
    "    kf = KFold(n_splits=N)\n",
    "    i=0\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        #Seperating data as train and validation\n",
    "        X_tr_fold, X_te_fold = X_train[train_index], X_train[test_index]\n",
    "        y_tr_fold, y_te_fold = y_train[train_index], y_train[test_index]\n",
    "        #balancing the training dataset using smote\n",
    "        oversample = SMOTE()\n",
    "        X_tr_fold, y_tr_fold = oversample.fit_sample(X_tr_fold, y_tr_fold)\n",
    "        #shuffling the balanced data\n",
    "        rand_idx=np.random.permutation(len(X_tr_fold))\n",
    "        X_tr_fold = X_tr_fold[rand_idx]\n",
    "        y_tr_fold = y_tr_fold[rand_idx]\n",
    "        \n",
    "        #We are setting the grid search(cv used for cross validation and set as 5 n_jobs=-1 so we will use the all processors available)\n",
    "        grid_search = GridSearchCV(estimator = estimator, param_grid = parameters, \n",
    "                              cv = N, n_jobs = -1)\n",
    "        #fitting the data into the all sets of parameters\n",
    "        grid_search.fit(X_tr_fold,np.ravel(y_tr_fold))\n",
    "        # We are printing the best parameters for the current training set.\n",
    "        print(\"Best Parameters for {} fold: {}\".format(i,grid_search.best_params_))\n",
    "        #We are getting the best estimator model\n",
    "        regressor = grid_search.best_estimator_\n",
    "        regressor.fit(X_tr_fold,np.ravel(y_tr_fold)) # Actually this line is not needed since we are fitting all of the models but for just demosntration we are fitting anyway.\n",
    "        #prediction over the current validation set\n",
    "        y_predict = regressor.predict(X_te_fold)\n",
    "        #Calculate f1-score, accuracy, Matthews correlation coefficient\n",
    "        f1_scores[i] = f1_score(y_te_fold,y_predict)\n",
    "        accuracy[i] = regressor.score(X_te_fold,y_te_fold)\n",
    "        r[i] = matthews_corrcoef(y_te_fold, y_predict)\n",
    "        #Calculate rmse and mae for extra information and comparison between models\n",
    "        RMSE[i] = np.sqrt(sklearn.metrics.mean_squared_error(y_te_fold, y_predict))\n",
    "        MAE[i] = sklearn.metrics.mean_absolute_error(y_te_fold, y_predict)\n",
    "        print('i:{}, matthews_corrcoef:{}, accuracy:{}, RMSE:{}, MAE:{},f1_score:{}'.format(i, r[i],accuracy[i],RMSE[i], MAE[i], f1_scores[i]))\n",
    "        i+=1\n",
    "    #After getting the all results we are printing the best overall result over 5 different fold.\n",
    "    print('Best results:')\n",
    "    print(' matthews_corrcoef ={} in i={},\\n accuracy={} in i={},\\n RMSE={} in i={},\\n MAE={} in i={},\\n f1_score={} in i={} '.format(np.amax(r), np.argmax(r), np.amax(accuracy), np.argmax(accuracy), np.amin(RMSE), np.argmin(RMSE), np.amin(MAE), np.argmin(MAE),np.amax(f1_scores), np.argmax(f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With feature set 1\n",
      "-------------------------------\n",
      "Best Parameters for 0 fold: {'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "i:0, matthews_corrcoef:-0.010394134374075794, accuracy:0.7523809523809524, RMSE:0.4976133515281193, MAE:0.24761904761904763,f1_score:0.13333333333333333\n",
      "Best Parameters for 1 fold: {'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "i:1, matthews_corrcoef:-0.012012499502607453, accuracy:0.75, RMSE:0.5, MAE:0.25,f1_score:0.13333333333333333\n",
      "Best Parameters for 2 fold: {'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "i:2, matthews_corrcoef:-0.0192130139234745, accuracy:0.7403846153846154, RMSE:0.5095246653650681, MAE:0.25961538461538464,f1_score:0.12903225806451615\n",
      "Best Parameters for 3 fold: {'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "i:3, matthews_corrcoef:-0.1185113657849943, accuracy:0.7788461538461539, RMSE:0.4702699715629801, MAE:0.22115384615384615,f1_score:0.0\n",
      "Best Parameters for 4 fold: {'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 400}\n",
      "i:4, matthews_corrcoef:-0.06260203092259642, accuracy:0.7596153846153846, RMSE:0.4902903378454601, MAE:0.2403846153846154,f1_score:0.07407407407407407\n",
      "Best results:\n",
      " matthews_corrcoef =-0.010394134374075794 in i=0,\n",
      " accuracy=0.7788461538461539 in i=3,\n",
      " RMSE=0.4702699715629801 in i=3,\n",
      " MAE=0.22115384615384615 in i=3,\n",
      " f1_score=0.13333333333333333 in i=0 \n",
      "With feature set 2\n",
      "-------------------------------\n",
      "Best Parameters for 0 fold: {'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "i:0, matthews_corrcoef:0.17334037419817858, accuracy:0.780952380952381, RMSE:0.4680252333449758, MAE:0.21904761904761905,f1_score:0.30303030303030304\n",
      "Best Parameters for 1 fold: {'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "i:1, matthews_corrcoef:-0.06388765649999399, accuracy:0.7596153846153846, RMSE:0.4902903378454601, MAE:0.2403846153846154,f1_score:0.07407407407407408\n",
      "Best Parameters for 2 fold: {'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "i:2, matthews_corrcoef:0.01034452008423497, accuracy:0.7692307692307693, RMSE:0.4803844614152614, MAE:0.23076923076923078,f1_score:0.14285714285714288\n",
      "Best Parameters for 3 fold: {'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 400}\n",
      "i:3, matthews_corrcoef:-0.1074613339870406, accuracy:0.7115384615384616, RMSE:0.5370861555295746, MAE:0.28846153846153844,f1_score:0.0625\n",
      "Best Parameters for 4 fold: {'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "i:4, matthews_corrcoef:0.05177539655648002, accuracy:0.7980769230769231, RMSE:0.4493585171364586, MAE:0.20192307692307693,f1_score:0.16\n",
      "Best results:\n",
      " matthews_corrcoef =0.17334037419817858 in i=0,\n",
      " accuracy=0.7980769230769231 in i=4,\n",
      " RMSE=0.4493585171364586 in i=4,\n",
      " MAE=0.20192307692307693 in i=4,\n",
      " f1_score=0.30303030303030304 in i=0 \n"
     ]
    }
   ],
   "source": [
    "# for 5 fold CV for parameter tuning with GBR\n",
    "#iterate over with and without claim and temporal rest features\n",
    "for idx,(X_train,y_train)  in enumerate(zip([X_train_s,X_train_e],[y_train,y_train])):\n",
    "    print(f'With feature set {idx+1}\\n-------------------------------')\n",
    "    #setting the estimator as gradient boosting classifier\n",
    "    estimator = GradientBoostingClassifier()\n",
    "    #setting the parameters which we will use them to tune the parameters and use them in the grid search\n",
    "    parameters =  {\n",
    "        'max_depth': [3, 6],\n",
    "        'min_samples_leaf': [1, 2],\n",
    "        'min_samples_split': [2, 4],\n",
    "        'learning_rate' : [0.1,0.01],\n",
    "        'n_estimators': [100, 200, 400]}\n",
    "    #Setting N to 5 means 5-fold cross-validation\n",
    "    N = 5\n",
    "    r = np.zeros(N)\n",
    "    accuracy = np.zeros(N)\n",
    "    RMSE = np.zeros(N)\n",
    "    MAE=np.zeros(N)\n",
    "    f1_scores=np.zeros(N)\n",
    "\n",
    "    kf = KFold(n_splits=N)\n",
    "    i=0\n",
    "\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        #Seperating data as train and validation\n",
    "        X_tr_fold, X_te_fold = X_train[train_index], X_train[test_index]\n",
    "        y_tr_fold, y_te_fold = y_train[train_index], y_train[test_index]\n",
    "        #balancing the training dataset using smote\n",
    "        oversample = SMOTE()\n",
    "        X_tr_fold, y_tr_fold = oversample.fit_sample(X_tr_fold, y_tr_fold)\n",
    "        #shuffling the balanced data\n",
    "        rand_idx=np.random.permutation(len(X_tr_fold))\n",
    "        X_tr_fold = X_tr_fold[rand_idx]\n",
    "        y_tr_fold = y_tr_fold[rand_idx]\n",
    "\n",
    "        #We are setting the grid search(cv used for cross validation and set as 5 n_jobs=-1 so we will use the all processors available)\n",
    "        grid_search = GridSearchCV(estimator = estimator, param_grid = parameters, \n",
    "                              cv = N, n_jobs = -1)\n",
    "        #fitting the data into the all sets of parameters\n",
    "        grid_search.fit(X_tr_fold,np.ravel(y_tr_fold))\n",
    "        # We are printing the best parameters for the current training set.\n",
    "        print(\"Best Parameters for {} fold: {}\".format(i,grid_search.best_params_))\n",
    "        #We are getting the best estimator model\n",
    "        regressor = grid_search.best_estimator_\n",
    "        regressor.fit(X_tr_fold,np.ravel(y_tr_fold)) # Actually this line is not needed since we are fitting all of the models but for just demosntration we are fitting anyway.\n",
    "        #prediction over the current validation set\n",
    "        y_predict = regressor.predict(X_te_fold)\n",
    "        #Calculate f1-score, accuracy, Matthews correlation coefficient\n",
    "        f1_scores[i] = f1_score(y_te_fold,y_predict)\n",
    "        accuracy[i] = regressor.score(X_te_fold,y_te_fold)\n",
    "        r[i] = matthews_corrcoef(y_te_fold, y_predict)\n",
    "        #Calculate rmse and mae for extra information and comparison between models\n",
    "        RMSE[i] = np.sqrt(sklearn.metrics.mean_squared_error(y_te_fold, y_predict))\n",
    "        MAE[i] = sklearn.metrics.mean_absolute_error(y_te_fold, y_predict)\n",
    "        print('i:{}, matthews_corrcoef:{}, accuracy:{}, RMSE:{}, MAE:{},f1_score:{}'.format(i, r[i],accuracy[i],RMSE[i], MAE[i], f1_scores[i]))\n",
    "        i+=1\n",
    "    #After getting the all results we are printing the best overall result over 5 different fold.\n",
    "    print('Best results:')\n",
    "    print(' matthews_corrcoef ={} in i={},\\n accuracy={} in i={},\\n RMSE={} in i={},\\n MAE={} in i={},\\n f1_score={} in i={} '.format(np.amax(r), np.argmax(r), np.amax(accuracy), np.argmax(accuracy), np.amin(RMSE), np.argmin(RMSE), np.amin(MAE), np.argmin(MAE),np.amax(f1_scores), np.argmax(f1_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***NEURAL NETWORK***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_EPOCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create the input features required for the Neural Network model\n",
    "#For the nn we are using different features which is basically concatination of mean features of each game and mean inbalance vector of each game.\n",
    "features_s = np.concatenate((whole_items,np.absolute(betrayer_items - victim_items)), axis=1)\n",
    "features_e = np.concatenate((whole_items_e,np.absolute(betrayer_items_e - victim_items_e)), axis=1)\n",
    "labels =np.array(labels)\n",
    "#Suffle the data and labels\n",
    "rand_idx=np.random.permutation(len(features_s))\n",
    "features_s = features_s[rand_idx]\n",
    "features_e = features_e[rand_idx]\n",
    "labels = labels[rand_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For faster training we are checking if the cuda is avaliable for the current machine\n",
    "cuda_is_available = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform Grid search on batch size and learning rate parameters.\n",
    "\n",
    "Since we have very few samples, We use cross-validation in order to validate our traininig results.\n",
    "\n",
    "Then,we save the results into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    99] loss: 1.541036\n",
      "[1,   199] loss: 2.421468\n",
      "[1,   299] loss: 0.730566\n",
      "[1,   399] loss: 0.700716\n",
      "[1,   499] loss: 0.741626\n",
      "[1,   599] loss: 0.717288\n",
      "[1,   699] loss: 0.717369\n",
      "[2,    99] loss: 0.702786\n",
      "[2,   199] loss: 0.705621\n",
      "[2,   299] loss: 0.731958\n",
      "[2,   399] loss: 0.701078\n",
      "[2,   499] loss: 0.742166\n",
      "[2,   599] loss: 0.717555\n",
      "[2,   699] loss: 0.717918\n",
      "[3,    99] loss: 0.702692\n",
      "[3,   199] loss: 0.705785\n",
      "[3,   299] loss: 0.732138\n",
      "[3,   399] loss: 0.701140\n",
      "[3,   499] loss: 0.742277\n",
      "[3,   599] loss: 0.717621\n",
      "[3,   699] loss: 0.718063\n",
      "[4,    99] loss: 0.702666\n",
      "[4,   199] loss: 0.705836\n",
      "[4,   299] loss: 0.732197\n",
      "[4,   399] loss: 0.701161\n",
      "[4,   499] loss: 0.742317\n",
      "[4,   599] loss: 0.717645\n",
      "[4,   699] loss: 0.718119\n",
      "[5,    99] loss: 0.702656\n",
      "[5,   199] loss: 0.705856\n",
      "[5,   299] loss: 0.732222\n",
      "[5,   399] loss: 0.701170\n",
      "[5,   499] loss: 0.742334\n",
      "[5,   599] loss: 0.717656\n",
      "[5,   699] loss: 0.718143\n",
      "[6,    99] loss: 0.702651\n",
      "[6,   199] loss: 0.705865\n",
      "[6,   299] loss: 0.732233\n",
      "[6,   399] loss: 0.701174\n",
      "[6,   499] loss: 0.742342\n",
      "[6,   599] loss: 0.717661\n",
      "[6,   699] loss: 0.718154\n",
      "[7,    99] loss: 0.702649\n",
      "[7,   199] loss: 0.705870\n",
      "[7,   299] loss: 0.732238\n",
      "[7,   399] loss: 0.701176\n",
      "[7,   499] loss: 0.742346\n",
      "[7,   599] loss: 0.717663\n",
      "[7,   699] loss: 0.718159\n",
      "[8,    99] loss: 0.702648\n",
      "[8,   199] loss: 0.705872\n",
      "[8,   299] loss: 0.732241\n",
      "[8,   399] loss: 0.701176\n",
      "[8,   499] loss: 0.742347\n",
      "[8,   599] loss: 0.717664\n",
      "[8,   699] loss: 0.718162\n",
      "[9,    99] loss: 0.702648\n",
      "[9,   199] loss: 0.705873\n",
      "[9,   299] loss: 0.732242\n",
      "[9,   399] loss: 0.701177\n",
      "[9,   499] loss: 0.742348\n",
      "[9,   599] loss: 0.717665\n",
      "[9,   699] loss: 0.718163\n",
      "[10,    99] loss: 0.702647\n",
      "[10,   199] loss: 0.705873\n",
      "[10,   299] loss: 0.732242\n",
      "[10,   399] loss: 0.701177\n",
      "[10,   499] loss: 0.742348\n",
      "[10,   599] loss: 0.717665\n",
      "[10,   699] loss: 0.718163\n",
      "[11,    99] loss: 0.702647\n",
      "[11,   199] loss: 0.705873\n",
      "[11,   299] loss: 0.732243\n",
      "[11,   399] loss: 0.701177\n",
      "[11,   499] loss: 0.742349\n",
      "[11,   599] loss: 0.717665\n",
      "[11,   699] loss: 0.718164\n",
      "[12,    99] loss: 0.702647\n",
      "[12,   199] loss: 0.705873\n",
      "[12,   299] loss: 0.732243\n",
      "[12,   399] loss: 0.701177\n",
      "[12,   499] loss: 0.742349\n",
      "[12,   599] loss: 0.717665\n",
      "[12,   699] loss: 0.718164\n",
      "[13,    99] loss: 0.702647\n",
      "[13,   199] loss: 0.705873\n",
      "[13,   299] loss: 0.732243\n",
      "[13,   399] loss: 0.701177\n",
      "[13,   499] loss: 0.742349\n",
      "[13,   599] loss: 0.717665\n",
      "[13,   699] loss: 0.718164\n",
      "[14,    99] loss: 0.702647\n",
      "[14,   199] loss: 0.705873\n",
      "[14,   299] loss: 0.732243\n",
      "[14,   399] loss: 0.701177\n",
      "[14,   499] loss: 0.742349\n",
      "[14,   599] loss: 0.717665\n",
      "[14,   699] loss: 0.718164\n",
      "[15,    99] loss: 0.702647\n",
      "[15,   199] loss: 0.705873\n",
      "[15,   299] loss: 0.732243\n",
      "[15,   399] loss: 0.701177\n",
      "[15,   499] loss: 0.742349\n",
      "[15,   599] loss: 0.717665\n",
      "[15,   699] loss: 0.718164\n",
      "[16,    99] loss: 0.702647\n",
      "[16,   199] loss: 0.705873\n",
      "[16,   299] loss: 0.732243\n",
      "[16,   399] loss: 0.701177\n",
      "[16,   499] loss: 0.742349\n",
      "[16,   599] loss: 0.717665\n",
      "[16,   699] loss: 0.718164\n",
      "[17,    99] loss: 0.702647\n",
      "[17,   199] loss: 0.705873\n",
      "[17,   299] loss: 0.732243\n",
      "[17,   399] loss: 0.701177\n",
      "[17,   499] loss: 0.742349\n",
      "[17,   599] loss: 0.717665\n",
      "[17,   699] loss: 0.718164\n",
      "[18,    99] loss: 0.702647\n",
      "[18,   199] loss: 0.705873\n",
      "[18,   299] loss: 0.732243\n",
      "[18,   399] loss: 0.701177\n",
      "[18,   499] loss: 0.742349\n",
      "[18,   599] loss: 0.717665\n",
      "[18,   699] loss: 0.718164\n",
      "[19,    99] loss: 0.702647\n",
      "[19,   199] loss: 0.705873\n",
      "[19,   299] loss: 0.732243\n",
      "[19,   399] loss: 0.701177\n",
      "[19,   499] loss: 0.742349\n",
      "[19,   599] loss: 0.717665\n",
      "[19,   699] loss: 0.718164\n",
      "[20,    99] loss: 0.702647\n",
      "[20,   199] loss: 0.705873\n",
      "[20,   299] loss: 0.732243\n",
      "[20,   399] loss: 0.701177\n",
      "[20,   499] loss: 0.742349\n",
      "[20,   599] loss: 0.717665\n",
      "[20,   699] loss: 0.718164\n",
      "[21,    99] loss: 0.702647\n",
      "[21,   199] loss: 0.705873\n",
      "[21,   299] loss: 0.732243\n",
      "[21,   399] loss: 0.701177\n",
      "[21,   499] loss: 0.742349\n",
      "[21,   599] loss: 0.717665\n",
      "[21,   699] loss: 0.718164\n",
      "[22,    99] loss: 0.702647\n",
      "[22,   199] loss: 0.705873\n",
      "[22,   299] loss: 0.732243\n",
      "[22,   399] loss: 0.701177\n",
      "[22,   499] loss: 0.742349\n",
      "[22,   599] loss: 0.717665\n",
      "[22,   699] loss: 0.718164\n",
      "[23,    99] loss: 0.702647\n",
      "[23,   199] loss: 0.705873\n",
      "[23,   299] loss: 0.732243\n",
      "[23,   399] loss: 0.701177\n",
      "[23,   499] loss: 0.742349\n",
      "[23,   599] loss: 0.717665\n",
      "[23,   699] loss: 0.718164\n",
      "[24,    99] loss: 0.702647\n",
      "[24,   199] loss: 0.705873\n",
      "[24,   299] loss: 0.732243\n",
      "[24,   399] loss: 0.701177\n",
      "[24,   499] loss: 0.742349\n",
      "[24,   599] loss: 0.717665\n",
      "[24,   699] loss: 0.718164\n",
      "[25,    99] loss: 0.702647\n",
      "[25,   199] loss: 0.705873\n",
      "[25,   299] loss: 0.732243\n",
      "[25,   399] loss: 0.701177\n",
      "[25,   499] loss: 0.742349\n",
      "[25,   599] loss: 0.717665\n",
      "[25,   699] loss: 0.718164\n",
      "[26,    99] loss: 0.702647\n",
      "[26,   199] loss: 0.705873\n",
      "[26,   299] loss: 0.732243\n",
      "[26,   399] loss: 0.701177\n",
      "[26,   499] loss: 0.742349\n",
      "[26,   599] loss: 0.717665\n",
      "[26,   699] loss: 0.718164\n",
      "[27,    99] loss: 0.702647\n",
      "[27,   199] loss: 0.705873\n",
      "[27,   299] loss: 0.732243\n",
      "[27,   399] loss: 0.701177\n",
      "[27,   499] loss: 0.742349\n",
      "[27,   599] loss: 0.717665\n",
      "[27,   699] loss: 0.718164\n",
      "[28,    99] loss: 0.702647\n",
      "[28,   199] loss: 0.705873\n",
      "[28,   299] loss: 0.732243\n",
      "[28,   399] loss: 0.701177\n",
      "[28,   499] loss: 0.742349\n",
      "[28,   599] loss: 0.717665\n",
      "[28,   699] loss: 0.718164\n",
      "[29,    99] loss: 0.702647\n",
      "[29,   199] loss: 0.705873\n",
      "[29,   299] loss: 0.732243\n",
      "[29,   399] loss: 0.701177\n",
      "[29,   499] loss: 0.742349\n",
      "[29,   599] loss: 0.717665\n",
      "[29,   699] loss: 0.718164\n",
      "[30,    99] loss: 0.702647\n",
      "[30,   199] loss: 0.705873\n",
      "[30,   299] loss: 0.732243\n",
      "[30,   399] loss: 0.701177\n",
      "[30,   499] loss: 0.742349\n",
      "[30,   599] loss: 0.717665\n",
      "[30,   699] loss: 0.718164\n",
      "[31,    99] loss: 0.702647\n",
      "[31,   199] loss: 0.705873\n",
      "[31,   299] loss: 0.732243\n",
      "[31,   399] loss: 0.701177\n",
      "[31,   499] loss: 0.742349\n",
      "[31,   599] loss: 0.717665\n",
      "[31,   699] loss: 0.718164\n",
      "[32,    99] loss: 0.702647\n",
      "[32,   199] loss: 0.705873\n",
      "[32,   299] loss: 0.732243\n",
      "[32,   399] loss: 0.701177\n",
      "[32,   499] loss: 0.742349\n",
      "[32,   599] loss: 0.717665\n",
      "[32,   699] loss: 0.718164\n",
      "[33,    99] loss: 0.702647\n",
      "[33,   199] loss: 0.705873\n",
      "[33,   299] loss: 0.732243\n",
      "[33,   399] loss: 0.701177\n",
      "[33,   499] loss: 0.742349\n",
      "[33,   599] loss: 0.717665\n",
      "[33,   699] loss: 0.718164\n",
      "[34,    99] loss: 0.702647\n",
      "[34,   199] loss: 0.705873\n",
      "[34,   299] loss: 0.732243\n",
      "[34,   399] loss: 0.701177\n",
      "[34,   499] loss: 0.742349\n",
      "[34,   599] loss: 0.717665\n",
      "[34,   699] loss: 0.718164\n",
      "[35,    99] loss: 0.702647\n",
      "[35,   199] loss: 0.705873\n",
      "[35,   299] loss: 0.732243\n",
      "[35,   399] loss: 0.701177\n",
      "[35,   499] loss: 0.742349\n",
      "[35,   599] loss: 0.717665\n",
      "[35,   699] loss: 0.718164\n",
      "[36,    99] loss: 0.702647\n",
      "[36,   199] loss: 0.705873\n",
      "[36,   299] loss: 0.732243\n",
      "[36,   399] loss: 0.701177\n",
      "[36,   499] loss: 0.742349\n",
      "[36,   599] loss: 0.717665\n",
      "[36,   699] loss: 0.718164\n",
      "[37,    99] loss: 0.702647\n",
      "[37,   199] loss: 0.705873\n",
      "[37,   299] loss: 0.732243\n",
      "[37,   399] loss: 0.701177\n",
      "[37,   499] loss: 0.742349\n",
      "[37,   599] loss: 0.717665\n",
      "[37,   699] loss: 0.718164\n",
      "[38,    99] loss: 0.702647\n",
      "[38,   199] loss: 0.705873\n",
      "[38,   299] loss: 0.732243\n",
      "[38,   399] loss: 0.701177\n",
      "[38,   499] loss: 0.742349\n",
      "[38,   599] loss: 0.717665\n",
      "[38,   699] loss: 0.718164\n",
      "[39,    99] loss: 0.702647\n",
      "[39,   199] loss: 0.705873\n",
      "[39,   299] loss: 0.732243\n",
      "[39,   399] loss: 0.701177\n",
      "[39,   499] loss: 0.742349\n",
      "[39,   599] loss: 0.717665\n",
      "[39,   699] loss: 0.718164\n",
      "[40,    99] loss: 0.702647\n",
      "[40,   199] loss: 0.705873\n",
      "[40,   299] loss: 0.732243\n",
      "[40,   399] loss: 0.701177\n",
      "[40,   499] loss: 0.742349\n",
      "[40,   599] loss: 0.717665\n",
      "[40,   699] loss: 0.718164\n",
      "[41,    99] loss: 0.702647\n",
      "[41,   199] loss: 0.705873\n",
      "[41,   299] loss: 0.732243\n",
      "[41,   399] loss: 0.701177\n",
      "[41,   499] loss: 0.742349\n",
      "[41,   599] loss: 0.717665\n",
      "[41,   699] loss: 0.718164\n",
      "[42,    99] loss: 0.702647\n",
      "[42,   199] loss: 0.705873\n",
      "[42,   299] loss: 0.732243\n",
      "[42,   399] loss: 0.701177\n",
      "[42,   499] loss: 0.742349\n",
      "[42,   599] loss: 0.717665\n",
      "[42,   699] loss: 0.718164\n",
      "[43,    99] loss: 0.702647\n",
      "[43,   199] loss: 0.705873\n",
      "[43,   299] loss: 0.732243\n",
      "[43,   399] loss: 0.701177\n",
      "[43,   499] loss: 0.742349\n",
      "[43,   599] loss: 0.717665\n",
      "[43,   699] loss: 0.718164\n",
      "[44,    99] loss: 0.702647\n",
      "[44,   199] loss: 0.705873\n",
      "[44,   299] loss: 0.732243\n",
      "[44,   399] loss: 0.701177\n",
      "[44,   499] loss: 0.742349\n",
      "[44,   599] loss: 0.717665\n",
      "[44,   699] loss: 0.718164\n",
      "[45,    99] loss: 0.702647\n",
      "[45,   199] loss: 0.705873\n",
      "[45,   299] loss: 0.732243\n",
      "[45,   399] loss: 0.701177\n",
      "[45,   499] loss: 0.742349\n",
      "[45,   599] loss: 0.717665\n",
      "[45,   699] loss: 0.718164\n",
      "[46,    99] loss: 0.702647\n",
      "[46,   199] loss: 0.705873\n",
      "[46,   299] loss: 0.732243\n",
      "[46,   399] loss: 0.701177\n",
      "[46,   499] loss: 0.742349\n",
      "[46,   599] loss: 0.717665\n",
      "[46,   699] loss: 0.718164\n",
      "[47,    99] loss: 0.702647\n",
      "[47,   199] loss: 0.705873\n",
      "[47,   299] loss: 0.732243\n",
      "[47,   399] loss: 0.701177\n",
      "[47,   499] loss: 0.742349\n",
      "[47,   599] loss: 0.717665\n",
      "[47,   699] loss: 0.718164\n",
      "[48,    99] loss: 0.702647\n",
      "[48,   199] loss: 0.705873\n",
      "[48,   299] loss: 0.732243\n",
      "[48,   399] loss: 0.701177\n",
      "[48,   499] loss: 0.742349\n",
      "[48,   599] loss: 0.717665\n",
      "[48,   699] loss: 0.718164\n",
      "[49,    99] loss: 0.702647\n",
      "[49,   199] loss: 0.705873\n",
      "[49,   299] loss: 0.732243\n",
      "[49,   399] loss: 0.701177\n",
      "[49,   499] loss: 0.742349\n",
      "[49,   599] loss: 0.717665\n",
      "[49,   699] loss: 0.718164\n",
      "[50,    99] loss: 0.702647\n",
      "[50,   199] loss: 0.705873\n",
      "[50,   299] loss: 0.732243\n",
      "[50,   399] loss: 0.701177\n",
      "[50,   499] loss: 0.742349\n",
      "[50,   599] loss: 0.717665\n",
      "[50,   699] loss: 0.718164\n",
      "[51,    99] loss: 0.702647\n",
      "[51,   199] loss: 0.705873\n",
      "[51,   299] loss: 0.732243\n",
      "[51,   399] loss: 0.701177\n",
      "[51,   499] loss: 0.742349\n",
      "[51,   599] loss: 0.717665\n",
      "[51,   699] loss: 0.718164\n",
      "[52,    99] loss: 0.702647\n",
      "[52,   199] loss: 0.705873\n",
      "[52,   299] loss: 0.732243\n",
      "[52,   399] loss: 0.701177\n",
      "[52,   499] loss: 0.742349\n",
      "[52,   599] loss: 0.717665\n",
      "[52,   699] loss: 0.718164\n",
      "[53,    99] loss: 0.702647\n",
      "[53,   199] loss: 0.705873\n",
      "[53,   299] loss: 0.732243\n",
      "[53,   399] loss: 0.701177\n",
      "[53,   499] loss: 0.742349\n",
      "[53,   599] loss: 0.717665\n",
      "[53,   699] loss: 0.718164\n",
      "[54,    99] loss: 0.702647\n",
      "[54,   199] loss: 0.705873\n",
      "[54,   299] loss: 0.732243\n",
      "[54,   399] loss: 0.701177\n",
      "[54,   499] loss: 0.742349\n",
      "[54,   599] loss: 0.717665\n",
      "[54,   699] loss: 0.718164\n",
      "[55,    99] loss: 0.702647\n",
      "[55,   199] loss: 0.705873\n",
      "[55,   299] loss: 0.732243\n",
      "[55,   399] loss: 0.701177\n",
      "[55,   499] loss: 0.742349\n",
      "[55,   599] loss: 0.717665\n",
      "[55,   699] loss: 0.718164\n",
      "[56,    99] loss: 0.702647\n",
      "[56,   199] loss: 0.705873\n",
      "[56,   299] loss: 0.732243\n",
      "[56,   399] loss: 0.701177\n",
      "[56,   499] loss: 0.742349\n",
      "[56,   599] loss: 0.717665\n",
      "[56,   699] loss: 0.718164\n",
      "[57,    99] loss: 0.702647\n",
      "[57,   199] loss: 0.705873\n",
      "[57,   299] loss: 0.732243\n",
      "[57,   399] loss: 0.701177\n",
      "[57,   499] loss: 0.742349\n",
      "[57,   599] loss: 0.717665\n",
      "[57,   699] loss: 0.718164\n",
      "[58,    99] loss: 0.702647\n",
      "[58,   199] loss: 0.705873\n",
      "[58,   299] loss: 0.732243\n",
      "[58,   399] loss: 0.701177\n",
      "[58,   499] loss: 0.742349\n",
      "[58,   599] loss: 0.717665\n",
      "[58,   699] loss: 0.718164\n",
      "[59,    99] loss: 0.702647\n",
      "[59,   199] loss: 0.705873\n",
      "[59,   299] loss: 0.732243\n",
      "[59,   399] loss: 0.701177\n",
      "[59,   499] loss: 0.742349\n",
      "[59,   599] loss: 0.717665\n",
      "[59,   699] loss: 0.718164\n",
      "[60,    99] loss: 0.702647\n",
      "[60,   199] loss: 0.705873\n",
      "[60,   299] loss: 0.732243\n",
      "[60,   399] loss: 0.701177\n",
      "[60,   499] loss: 0.742349\n",
      "[60,   599] loss: 0.717665\n",
      "[60,   699] loss: 0.718164\n",
      "[61,    99] loss: 0.702647\n",
      "[61,   199] loss: 0.705873\n",
      "[61,   299] loss: 0.732243\n",
      "[61,   399] loss: 0.701177\n",
      "[61,   499] loss: 0.742349\n",
      "[61,   599] loss: 0.717665\n",
      "[61,   699] loss: 0.718164\n",
      "[62,    99] loss: 0.702647\n",
      "[62,   199] loss: 0.705873\n",
      "[62,   299] loss: 0.732243\n",
      "[62,   399] loss: 0.701177\n",
      "[62,   499] loss: 0.742349\n",
      "[62,   599] loss: 0.717665\n",
      "[62,   699] loss: 0.718164\n",
      "[63,    99] loss: 0.702647\n",
      "[63,   199] loss: 0.705873\n",
      "[63,   299] loss: 0.732243\n",
      "[63,   399] loss: 0.701177\n",
      "[63,   499] loss: 0.742349\n",
      "[63,   599] loss: 0.717665\n",
      "[63,   699] loss: 0.718164\n",
      "[64,    99] loss: 0.702647\n",
      "[64,   199] loss: 0.705873\n",
      "[64,   299] loss: 0.732243\n",
      "[64,   399] loss: 0.701177\n",
      "[64,   499] loss: 0.742349\n",
      "[64,   599] loss: 0.717665\n",
      "[64,   699] loss: 0.718164\n",
      "[65,    99] loss: 0.702647\n",
      "[65,   199] loss: 0.705873\n",
      "[65,   299] loss: 0.732243\n",
      "[65,   399] loss: 0.701177\n",
      "[65,   499] loss: 0.742349\n",
      "[65,   599] loss: 0.717665\n",
      "[65,   699] loss: 0.718164\n",
      "[66,    99] loss: 0.702647\n",
      "[66,   199] loss: 0.705873\n",
      "[66,   299] loss: 0.732243\n",
      "[66,   399] loss: 0.701177\n",
      "[66,   499] loss: 0.742349\n",
      "[66,   599] loss: 0.717665\n",
      "[66,   699] loss: 0.718164\n",
      "[67,    99] loss: 0.702647\n",
      "[67,   199] loss: 0.705873\n",
      "[67,   299] loss: 0.732243\n",
      "[67,   399] loss: 0.701177\n",
      "[67,   499] loss: 0.742349\n",
      "[67,   599] loss: 0.717665\n",
      "[67,   699] loss: 0.718164\n",
      "[68,    99] loss: 0.702647\n",
      "[68,   199] loss: 0.705873\n",
      "[68,   299] loss: 0.732243\n",
      "[68,   399] loss: 0.701177\n",
      "[68,   499] loss: 0.742349\n",
      "[68,   599] loss: 0.717665\n",
      "[68,   699] loss: 0.718164\n",
      "[69,    99] loss: 0.702647\n",
      "[69,   199] loss: 0.705873\n",
      "[69,   299] loss: 0.732243\n",
      "[69,   399] loss: 0.701177\n",
      "[69,   499] loss: 0.742349\n",
      "[69,   599] loss: 0.717665\n",
      "[69,   699] loss: 0.718164\n",
      "[70,    99] loss: 0.702647\n",
      "[70,   199] loss: 0.705873\n",
      "[70,   299] loss: 0.732243\n",
      "[70,   399] loss: 0.701177\n",
      "[70,   499] loss: 0.742349\n",
      "[70,   599] loss: 0.717665\n",
      "[70,   699] loss: 0.718164\n",
      "[71,    99] loss: 0.702647\n",
      "[71,   199] loss: 0.705873\n",
      "[71,   299] loss: 0.732243\n",
      "[71,   399] loss: 0.701177\n",
      "[71,   499] loss: 0.742349\n",
      "[71,   599] loss: 0.717665\n",
      "[71,   699] loss: 0.718164\n",
      "[72,    99] loss: 0.702647\n",
      "[72,   199] loss: 0.705873\n",
      "[72,   299] loss: 0.732243\n",
      "[72,   399] loss: 0.701177\n",
      "[72,   499] loss: 0.742349\n",
      "[72,   599] loss: 0.717665\n",
      "[72,   699] loss: 0.718164\n",
      "[73,    99] loss: 0.702647\n",
      "[73,   199] loss: 0.705873\n",
      "[73,   299] loss: 0.732243\n",
      "[73,   399] loss: 0.701177\n",
      "[73,   499] loss: 0.742349\n",
      "[73,   599] loss: 0.717665\n",
      "[73,   699] loss: 0.718164\n",
      "[74,    99] loss: 0.702647\n",
      "[74,   199] loss: 0.705873\n",
      "[74,   299] loss: 0.732243\n",
      "[74,   399] loss: 0.701177\n",
      "[74,   499] loss: 0.742349\n",
      "[74,   599] loss: 0.717665\n",
      "[74,   699] loss: 0.718164\n",
      "[75,    99] loss: 0.702647\n",
      "[75,   199] loss: 0.705873\n",
      "[75,   299] loss: 0.732243\n",
      "[75,   399] loss: 0.701177\n",
      "[75,   499] loss: 0.742349\n",
      "[75,   599] loss: 0.717665\n",
      "[75,   699] loss: 0.718164\n",
      "[76,    99] loss: 0.702647\n",
      "[76,   199] loss: 0.705873\n",
      "[76,   299] loss: 0.732243\n",
      "[76,   399] loss: 0.701177\n",
      "[76,   499] loss: 0.742349\n",
      "[76,   599] loss: 0.717665\n",
      "[76,   699] loss: 0.718164\n",
      "[77,    99] loss: 0.702647\n",
      "[77,   199] loss: 0.705873\n",
      "[77,   299] loss: 0.732243\n",
      "[77,   399] loss: 0.701177\n",
      "[77,   499] loss: 0.742349\n",
      "[77,   599] loss: 0.717665\n",
      "[77,   699] loss: 0.718164\n",
      "[78,    99] loss: 0.702647\n",
      "[78,   199] loss: 0.705873\n",
      "[78,   299] loss: 0.732243\n",
      "[78,   399] loss: 0.701177\n",
      "[78,   499] loss: 0.742349\n",
      "[78,   599] loss: 0.717665\n",
      "[78,   699] loss: 0.718164\n",
      "[79,    99] loss: 0.702647\n",
      "[79,   199] loss: 0.705873\n",
      "[79,   299] loss: 0.732243\n",
      "[79,   399] loss: 0.701177\n",
      "[79,   499] loss: 0.742349\n",
      "[79,   599] loss: 0.717665\n",
      "[79,   699] loss: 0.718164\n",
      "[80,    99] loss: 0.702647\n",
      "[80,   199] loss: 0.705873\n",
      "[80,   299] loss: 0.732243\n",
      "[80,   399] loss: 0.701177\n",
      "[80,   499] loss: 0.742349\n",
      "[80,   599] loss: 0.717665\n",
      "[80,   699] loss: 0.718164\n",
      "[81,    99] loss: 0.702647\n",
      "[81,   199] loss: 0.705873\n",
      "[81,   299] loss: 0.732243\n",
      "[81,   399] loss: 0.701177\n",
      "[81,   499] loss: 0.742349\n",
      "[81,   599] loss: 0.717665\n",
      "[81,   699] loss: 0.718164\n",
      "[82,    99] loss: 0.702647\n",
      "[82,   199] loss: 0.705873\n",
      "[82,   299] loss: 0.732243\n",
      "[82,   399] loss: 0.701177\n",
      "[82,   499] loss: 0.742349\n",
      "[82,   599] loss: 0.717665\n",
      "[82,   699] loss: 0.718164\n",
      "[83,    99] loss: 0.702647\n",
      "[83,   199] loss: 0.705873\n",
      "[83,   299] loss: 0.732243\n",
      "[83,   399] loss: 0.701177\n",
      "[83,   499] loss: 0.742349\n",
      "[83,   599] loss: 0.717665\n",
      "[83,   699] loss: 0.718164\n",
      "[84,    99] loss: 0.702647\n",
      "[84,   199] loss: 0.705873\n",
      "[84,   299] loss: 0.732243\n",
      "[84,   399] loss: 0.701177\n",
      "[84,   499] loss: 0.742349\n",
      "[84,   599] loss: 0.717665\n",
      "[84,   699] loss: 0.718164\n",
      "[85,    99] loss: 0.702647\n",
      "[85,   199] loss: 0.705873\n",
      "[85,   299] loss: 0.732243\n",
      "[85,   399] loss: 0.701177\n",
      "[85,   499] loss: 0.742349\n",
      "[85,   599] loss: 0.717665\n",
      "[85,   699] loss: 0.718164\n",
      "[86,    99] loss: 0.702647\n",
      "[86,   199] loss: 0.705873\n",
      "[86,   299] loss: 0.732243\n",
      "[86,   399] loss: 0.701177\n",
      "[86,   499] loss: 0.742349\n",
      "[86,   599] loss: 0.717665\n",
      "[86,   699] loss: 0.718164\n",
      "[87,    99] loss: 0.702647\n",
      "[87,   199] loss: 0.705873\n",
      "[87,   299] loss: 0.732243\n",
      "[87,   399] loss: 0.701177\n",
      "[87,   499] loss: 0.742349\n",
      "[87,   599] loss: 0.717665\n",
      "[87,   699] loss: 0.718164\n",
      "[88,    99] loss: 0.702647\n",
      "[88,   199] loss: 0.705873\n",
      "[88,   299] loss: 0.732243\n",
      "[88,   399] loss: 0.701177\n",
      "[88,   499] loss: 0.742349\n",
      "[88,   599] loss: 0.717665\n",
      "[88,   699] loss: 0.718164\n",
      "[89,    99] loss: 0.702647\n",
      "[89,   199] loss: 0.705873\n",
      "[89,   299] loss: 0.732243\n",
      "[89,   399] loss: 0.701177\n",
      "[89,   499] loss: 0.742349\n",
      "[89,   599] loss: 0.717665\n",
      "[89,   699] loss: 0.718164\n",
      "[90,    99] loss: 0.702647\n",
      "[90,   199] loss: 0.705873\n",
      "[90,   299] loss: 0.732243\n",
      "[90,   399] loss: 0.701177\n",
      "[90,   499] loss: 0.742349\n",
      "[90,   599] loss: 0.717665\n",
      "[90,   699] loss: 0.718164\n",
      "[91,    99] loss: 0.702647\n",
      "[91,   199] loss: 0.705873\n",
      "[91,   299] loss: 0.732243\n",
      "[91,   399] loss: 0.701177\n",
      "[91,   499] loss: 0.742349\n",
      "[91,   599] loss: 0.717665\n",
      "[91,   699] loss: 0.718164\n",
      "[92,    99] loss: 0.702647\n",
      "[92,   199] loss: 0.705873\n",
      "[92,   299] loss: 0.732243\n",
      "[92,   399] loss: 0.701177\n",
      "[92,   499] loss: 0.742349\n",
      "[92,   599] loss: 0.717665\n",
      "[92,   699] loss: 0.718164\n",
      "[93,    99] loss: 0.702647\n",
      "[93,   199] loss: 0.705873\n",
      "[93,   299] loss: 0.732243\n",
      "[93,   399] loss: 0.701177\n",
      "[93,   499] loss: 0.742349\n",
      "[93,   599] loss: 0.717665\n",
      "[93,   699] loss: 0.718164\n",
      "[94,    99] loss: 0.702647\n",
      "[94,   199] loss: 0.705873\n",
      "[94,   299] loss: 0.732243\n",
      "[94,   399] loss: 0.701177\n",
      "[94,   499] loss: 0.742349\n",
      "[94,   599] loss: 0.717665\n",
      "[94,   699] loss: 0.718164\n",
      "[95,    99] loss: 0.702647\n",
      "[95,   199] loss: 0.705873\n",
      "[95,   299] loss: 0.732243\n",
      "[95,   399] loss: 0.701177\n",
      "[95,   499] loss: 0.742349\n",
      "[95,   599] loss: 0.717665\n",
      "[95,   699] loss: 0.718164\n",
      "[96,    99] loss: 0.702647\n",
      "[96,   199] loss: 0.705873\n",
      "[96,   299] loss: 0.732243\n",
      "[96,   399] loss: 0.701177\n",
      "[96,   499] loss: 0.742349\n",
      "[96,   599] loss: 0.717665\n",
      "[96,   699] loss: 0.718164\n",
      "[97,    99] loss: 0.702647\n",
      "[97,   199] loss: 0.705873\n",
      "[97,   299] loss: 0.732243\n",
      "[97,   399] loss: 0.701177\n",
      "[97,   499] loss: 0.742349\n",
      "[97,   599] loss: 0.717665\n",
      "[97,   699] loss: 0.718164\n",
      "[98,    99] loss: 0.702647\n",
      "[98,   199] loss: 0.705873\n",
      "[98,   299] loss: 0.732243\n",
      "[98,   399] loss: 0.701177\n",
      "[98,   499] loss: 0.742349\n",
      "[98,   599] loss: 0.717665\n",
      "[98,   699] loss: 0.718164\n",
      "[99,    99] loss: 0.702647\n",
      "[99,   199] loss: 0.705873\n",
      "[99,   299] loss: 0.732243\n",
      "[99,   399] loss: 0.701177\n",
      "[99,   499] loss: 0.742349\n",
      "[99,   599] loss: 0.717665\n",
      "[99,   699] loss: 0.718164\n",
      "[100,    99] loss: 0.702647\n",
      "[100,   199] loss: 0.705873\n",
      "[100,   299] loss: 0.732243\n",
      "[100,   399] loss: 0.701177\n",
      "[100,   499] loss: 0.742349\n",
      "[100,   599] loss: 0.717665\n",
      "[100,   699] loss: 0.718164\n",
      "Finished Training\n",
      "[1,    99] loss: 3.410827\n",
      "[1,   199] loss: 0.723795\n",
      "[1,   299] loss: 0.694446\n",
      "[1,   399] loss: 0.684161\n",
      "[1,   499] loss: 0.721873\n",
      "[1,   599] loss: 0.724524\n",
      "[1,   699] loss: 0.732854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    99] loss: 0.710852\n",
      "[2,   199] loss: 0.720570\n",
      "[2,   299] loss: 0.694821\n",
      "[2,   399] loss: 0.684403\n",
      "[2,   499] loss: 0.721957\n",
      "[2,   599] loss: 0.724767\n",
      "[2,   699] loss: 0.733120\n",
      "[3,    99] loss: 0.710820\n",
      "[3,   199] loss: 0.720655\n",
      "[3,   299] loss: 0.694867\n",
      "[3,   399] loss: 0.684444\n",
      "[3,   499] loss: 0.721972\n",
      "[3,   599] loss: 0.724822\n",
      "[3,   699] loss: 0.733190\n",
      "[4,    99] loss: 0.710811\n",
      "[4,   199] loss: 0.720681\n",
      "[4,   299] loss: 0.694882\n",
      "[4,   399] loss: 0.684459\n",
      "[4,   499] loss: 0.721977\n",
      "[4,   599] loss: 0.724842\n",
      "[4,   699] loss: 0.733217\n",
      "[5,    99] loss: 0.710807\n",
      "[5,   199] loss: 0.720691\n",
      "[5,   299] loss: 0.694889\n",
      "[5,   399] loss: 0.684464\n",
      "[5,   499] loss: 0.721979\n",
      "[5,   599] loss: 0.724850\n",
      "[5,   699] loss: 0.733229\n",
      "[6,    99] loss: 0.710806\n",
      "[6,   199] loss: 0.720696\n",
      "[6,   299] loss: 0.694891\n",
      "[6,   399] loss: 0.684467\n",
      "[6,   499] loss: 0.721980\n",
      "[6,   599] loss: 0.724854\n",
      "[6,   699] loss: 0.733234\n",
      "[7,    99] loss: 0.710805\n",
      "[7,   199] loss: 0.720698\n",
      "[7,   299] loss: 0.694893\n",
      "[7,   399] loss: 0.684468\n",
      "[7,   499] loss: 0.721980\n",
      "[7,   599] loss: 0.724856\n",
      "[7,   699] loss: 0.733237\n",
      "[8,    99] loss: 0.710805\n",
      "[8,   199] loss: 0.720699\n",
      "[8,   299] loss: 0.694893\n",
      "[8,   399] loss: 0.684469\n",
      "[8,   499] loss: 0.721981\n",
      "[8,   599] loss: 0.724857\n",
      "[8,   699] loss: 0.733238\n",
      "[9,    99] loss: 0.710804\n",
      "[9,   199] loss: 0.720700\n",
      "[9,   299] loss: 0.694893\n",
      "[9,   399] loss: 0.684469\n",
      "[9,   499] loss: 0.721981\n",
      "[9,   599] loss: 0.724857\n",
      "[9,   699] loss: 0.733238\n",
      "[10,    99] loss: 0.710804\n",
      "[10,   199] loss: 0.720700\n",
      "[10,   299] loss: 0.694894\n",
      "[10,   399] loss: 0.684469\n",
      "[10,   499] loss: 0.721981\n",
      "[10,   599] loss: 0.724858\n",
      "[10,   699] loss: 0.733239\n",
      "[11,    99] loss: 0.710804\n",
      "[11,   199] loss: 0.720700\n",
      "[11,   299] loss: 0.694894\n",
      "[11,   399] loss: 0.684469\n",
      "[11,   499] loss: 0.721981\n",
      "[11,   599] loss: 0.724858\n",
      "[11,   699] loss: 0.733239\n",
      "[12,    99] loss: 0.710804\n",
      "[12,   199] loss: 0.720700\n",
      "[12,   299] loss: 0.694894\n",
      "[12,   399] loss: 0.684469\n",
      "[12,   499] loss: 0.721981\n",
      "[12,   599] loss: 0.724858\n",
      "[12,   699] loss: 0.733239\n",
      "[13,    99] loss: 0.710804\n",
      "[13,   199] loss: 0.720700\n",
      "[13,   299] loss: 0.694894\n",
      "[13,   399] loss: 0.684469\n",
      "[13,   499] loss: 0.721981\n",
      "[13,   599] loss: 0.724858\n",
      "[13,   699] loss: 0.733239\n",
      "[14,    99] loss: 0.710804\n",
      "[14,   199] loss: 0.720700\n",
      "[14,   299] loss: 0.694894\n",
      "[14,   399] loss: 0.684469\n",
      "[14,   499] loss: 0.721981\n",
      "[14,   599] loss: 0.724858\n",
      "[14,   699] loss: 0.733239\n",
      "[15,    99] loss: 0.710804\n",
      "[15,   199] loss: 0.720700\n",
      "[15,   299] loss: 0.694894\n",
      "[15,   399] loss: 0.684469\n",
      "[15,   499] loss: 0.721981\n",
      "[15,   599] loss: 0.724858\n",
      "[15,   699] loss: 0.733239\n",
      "[16,    99] loss: 0.710804\n",
      "[16,   199] loss: 0.720700\n",
      "[16,   299] loss: 0.694894\n",
      "[16,   399] loss: 0.684469\n",
      "[16,   499] loss: 0.721981\n",
      "[16,   599] loss: 0.724858\n",
      "[16,   699] loss: 0.733239\n",
      "[17,    99] loss: 0.710804\n",
      "[17,   199] loss: 0.720700\n",
      "[17,   299] loss: 0.694894\n",
      "[17,   399] loss: 0.684469\n",
      "[17,   499] loss: 0.721981\n",
      "[17,   599] loss: 0.724858\n",
      "[17,   699] loss: 0.733239\n",
      "[18,    99] loss: 0.710804\n",
      "[18,   199] loss: 0.720700\n",
      "[18,   299] loss: 0.694894\n",
      "[18,   399] loss: 0.684469\n",
      "[18,   499] loss: 0.721981\n",
      "[18,   599] loss: 0.724858\n",
      "[18,   699] loss: 0.733239\n",
      "[19,    99] loss: 0.710804\n",
      "[19,   199] loss: 0.720700\n",
      "[19,   299] loss: 0.694894\n",
      "[19,   399] loss: 0.684469\n",
      "[19,   499] loss: 0.721981\n",
      "[19,   599] loss: 0.724858\n",
      "[19,   699] loss: 0.733239\n",
      "[20,    99] loss: 0.710804\n",
      "[20,   199] loss: 0.720700\n",
      "[20,   299] loss: 0.694894\n",
      "[20,   399] loss: 0.684469\n",
      "[20,   499] loss: 0.721981\n",
      "[20,   599] loss: 0.724858\n",
      "[20,   699] loss: 0.733239\n",
      "[21,    99] loss: 0.710804\n",
      "[21,   199] loss: 0.720700\n",
      "[21,   299] loss: 0.694894\n",
      "[21,   399] loss: 0.684469\n",
      "[21,   499] loss: 0.721981\n",
      "[21,   599] loss: 0.724858\n",
      "[21,   699] loss: 0.733239\n",
      "[22,    99] loss: 0.710804\n",
      "[22,   199] loss: 0.720700\n",
      "[22,   299] loss: 0.694894\n",
      "[22,   399] loss: 0.684469\n",
      "[22,   499] loss: 0.721981\n",
      "[22,   599] loss: 0.724858\n",
      "[22,   699] loss: 0.733239\n",
      "[23,    99] loss: 0.710804\n",
      "[23,   199] loss: 0.720700\n",
      "[23,   299] loss: 0.694894\n",
      "[23,   399] loss: 0.684469\n",
      "[23,   499] loss: 0.721981\n",
      "[23,   599] loss: 0.724858\n",
      "[23,   699] loss: 0.733239\n",
      "[24,    99] loss: 0.710804\n",
      "[24,   199] loss: 0.720700\n",
      "[24,   299] loss: 0.694894\n",
      "[24,   399] loss: 0.684469\n",
      "[24,   499] loss: 0.721981\n",
      "[24,   599] loss: 0.724858\n",
      "[24,   699] loss: 0.733239\n",
      "[25,    99] loss: 0.710804\n",
      "[25,   199] loss: 0.720700\n",
      "[25,   299] loss: 0.694894\n",
      "[25,   399] loss: 0.684469\n",
      "[25,   499] loss: 0.721981\n",
      "[25,   599] loss: 0.724858\n",
      "[25,   699] loss: 0.733239\n",
      "[26,    99] loss: 0.710804\n",
      "[26,   199] loss: 0.720700\n",
      "[26,   299] loss: 0.694894\n",
      "[26,   399] loss: 0.684469\n",
      "[26,   499] loss: 0.721981\n",
      "[26,   599] loss: 0.724858\n",
      "[26,   699] loss: 0.733239\n",
      "[27,    99] loss: 0.710804\n",
      "[27,   199] loss: 0.720700\n",
      "[27,   299] loss: 0.694894\n",
      "[27,   399] loss: 0.684469\n",
      "[27,   499] loss: 0.721981\n",
      "[27,   599] loss: 0.724858\n",
      "[27,   699] loss: 0.733239\n",
      "[28,    99] loss: 0.710804\n",
      "[28,   199] loss: 0.720700\n",
      "[28,   299] loss: 0.694894\n",
      "[28,   399] loss: 0.684469\n",
      "[28,   499] loss: 0.721981\n",
      "[28,   599] loss: 0.724858\n",
      "[28,   699] loss: 0.733239\n",
      "[29,    99] loss: 0.710804\n",
      "[29,   199] loss: 0.720700\n",
      "[29,   299] loss: 0.694894\n",
      "[29,   399] loss: 0.684469\n",
      "[29,   499] loss: 0.721981\n",
      "[29,   599] loss: 0.724858\n",
      "[29,   699] loss: 0.733239\n",
      "[30,    99] loss: 0.710804\n",
      "[30,   199] loss: 0.720700\n",
      "[30,   299] loss: 0.694894\n",
      "[30,   399] loss: 0.684469\n",
      "[30,   499] loss: 0.721981\n",
      "[30,   599] loss: 0.724858\n",
      "[30,   699] loss: 0.733239\n",
      "[31,    99] loss: 0.710804\n",
      "[31,   199] loss: 0.720700\n",
      "[31,   299] loss: 0.694894\n",
      "[31,   399] loss: 0.684469\n",
      "[31,   499] loss: 0.721981\n",
      "[31,   599] loss: 0.724858\n",
      "[31,   699] loss: 0.733239\n",
      "[32,    99] loss: 0.710804\n",
      "[32,   199] loss: 0.720700\n",
      "[32,   299] loss: 0.694894\n",
      "[32,   399] loss: 0.684469\n",
      "[32,   499] loss: 0.721981\n",
      "[32,   599] loss: 0.724858\n",
      "[32,   699] loss: 0.733239\n",
      "[33,    99] loss: 0.710804\n",
      "[33,   199] loss: 0.720700\n",
      "[33,   299] loss: 0.694894\n",
      "[33,   399] loss: 0.684469\n",
      "[33,   499] loss: 0.721981\n",
      "[33,   599] loss: 0.724858\n",
      "[33,   699] loss: 0.733239\n",
      "[34,    99] loss: 0.710804\n",
      "[34,   199] loss: 0.720700\n",
      "[34,   299] loss: 0.694894\n",
      "[34,   399] loss: 0.684469\n",
      "[34,   499] loss: 0.721981\n",
      "[34,   599] loss: 0.724858\n",
      "[34,   699] loss: 0.733239\n",
      "[35,    99] loss: 0.710804\n",
      "[35,   199] loss: 0.720700\n",
      "[35,   299] loss: 0.694894\n",
      "[35,   399] loss: 0.684469\n",
      "[35,   499] loss: 0.721981\n",
      "[35,   599] loss: 0.724858\n",
      "[35,   699] loss: 0.733239\n",
      "[36,    99] loss: 0.710804\n",
      "[36,   199] loss: 0.720700\n",
      "[36,   299] loss: 0.694894\n",
      "[36,   399] loss: 0.684469\n",
      "[36,   499] loss: 0.721981\n",
      "[36,   599] loss: 0.724858\n",
      "[36,   699] loss: 0.733239\n",
      "[37,    99] loss: 0.710804\n",
      "[37,   199] loss: 0.720700\n",
      "[37,   299] loss: 0.694894\n",
      "[37,   399] loss: 0.684469\n",
      "[37,   499] loss: 0.721981\n",
      "[37,   599] loss: 0.724858\n",
      "[37,   699] loss: 0.733239\n",
      "[38,    99] loss: 0.710804\n",
      "[38,   199] loss: 0.720700\n",
      "[38,   299] loss: 0.694894\n",
      "[38,   399] loss: 0.684469\n",
      "[38,   499] loss: 0.721981\n",
      "[38,   599] loss: 0.724858\n",
      "[38,   699] loss: 0.733239\n",
      "[39,    99] loss: 0.710804\n",
      "[39,   199] loss: 0.720700\n",
      "[39,   299] loss: 0.694894\n",
      "[39,   399] loss: 0.684469\n",
      "[39,   499] loss: 0.721981\n",
      "[39,   599] loss: 0.724858\n",
      "[39,   699] loss: 0.733239\n",
      "[40,    99] loss: 0.710804\n",
      "[40,   199] loss: 0.720700\n",
      "[40,   299] loss: 0.694894\n",
      "[40,   399] loss: 0.684469\n",
      "[40,   499] loss: 0.721981\n",
      "[40,   599] loss: 0.724858\n",
      "[40,   699] loss: 0.733239\n",
      "[41,    99] loss: 0.710804\n",
      "[41,   199] loss: 0.720700\n",
      "[41,   299] loss: 0.694894\n",
      "[41,   399] loss: 0.684469\n",
      "[41,   499] loss: 0.721981\n",
      "[41,   599] loss: 0.724858\n",
      "[41,   699] loss: 0.733239\n",
      "[42,    99] loss: 0.710804\n",
      "[42,   199] loss: 0.720700\n",
      "[42,   299] loss: 0.694894\n",
      "[42,   399] loss: 0.684469\n",
      "[42,   499] loss: 0.721981\n",
      "[42,   599] loss: 0.724858\n",
      "[42,   699] loss: 0.733239\n",
      "[43,    99] loss: 0.710804\n",
      "[43,   199] loss: 0.720700\n",
      "[43,   299] loss: 0.694894\n",
      "[43,   399] loss: 0.684469\n",
      "[43,   499] loss: 0.721981\n",
      "[43,   599] loss: 0.724858\n",
      "[43,   699] loss: 0.733239\n",
      "[44,    99] loss: 0.710804\n",
      "[44,   199] loss: 0.720700\n",
      "[44,   299] loss: 0.694894\n",
      "[44,   399] loss: 0.684469\n",
      "[44,   499] loss: 0.721981\n",
      "[44,   599] loss: 0.724858\n",
      "[44,   699] loss: 0.733239\n",
      "[45,    99] loss: 0.710804\n",
      "[45,   199] loss: 0.720700\n",
      "[45,   299] loss: 0.694894\n",
      "[45,   399] loss: 0.684469\n",
      "[45,   499] loss: 0.721981\n",
      "[45,   599] loss: 0.724858\n",
      "[45,   699] loss: 0.733239\n",
      "[46,    99] loss: 0.710804\n",
      "[46,   199] loss: 0.720700\n",
      "[46,   299] loss: 0.694894\n",
      "[46,   399] loss: 0.684469\n",
      "[46,   499] loss: 0.721981\n",
      "[46,   599] loss: 0.724858\n",
      "[46,   699] loss: 0.733239\n",
      "[47,    99] loss: 0.710804\n",
      "[47,   199] loss: 0.720700\n",
      "[47,   299] loss: 0.694894\n",
      "[47,   399] loss: 0.684469\n",
      "[47,   499] loss: 0.721981\n",
      "[47,   599] loss: 0.724858\n",
      "[47,   699] loss: 0.733239\n",
      "[48,    99] loss: 0.710804\n",
      "[48,   199] loss: 0.720700\n",
      "[48,   299] loss: 0.694894\n",
      "[48,   399] loss: 0.684469\n",
      "[48,   499] loss: 0.721981\n",
      "[48,   599] loss: 0.724858\n",
      "[48,   699] loss: 0.733239\n",
      "[49,    99] loss: 0.710804\n",
      "[49,   199] loss: 0.720700\n",
      "[49,   299] loss: 0.694894\n",
      "[49,   399] loss: 0.684469\n",
      "[49,   499] loss: 0.721981\n",
      "[49,   599] loss: 0.724858\n",
      "[49,   699] loss: 0.733239\n",
      "[50,    99] loss: 0.710804\n",
      "[50,   199] loss: 0.720700\n",
      "[50,   299] loss: 0.694894\n",
      "[50,   399] loss: 0.684469\n",
      "[50,   499] loss: 0.721981\n",
      "[50,   599] loss: 0.724858\n",
      "[50,   699] loss: 0.733239\n",
      "[51,    99] loss: 0.710804\n",
      "[51,   199] loss: 0.720700\n",
      "[51,   299] loss: 0.694894\n",
      "[51,   399] loss: 0.684469\n",
      "[51,   499] loss: 0.721981\n",
      "[51,   599] loss: 0.724858\n",
      "[51,   699] loss: 0.733239\n",
      "[52,    99] loss: 0.710804\n",
      "[52,   199] loss: 0.720700\n",
      "[52,   299] loss: 0.694894\n",
      "[52,   399] loss: 0.684469\n",
      "[52,   499] loss: 0.721981\n",
      "[52,   599] loss: 0.724858\n",
      "[52,   699] loss: 0.733239\n",
      "[53,    99] loss: 0.710804\n",
      "[53,   199] loss: 0.720700\n",
      "[53,   299] loss: 0.694894\n",
      "[53,   399] loss: 0.684469\n",
      "[53,   499] loss: 0.721981\n",
      "[53,   599] loss: 0.724858\n",
      "[53,   699] loss: 0.733239\n",
      "[54,    99] loss: 0.710804\n",
      "[54,   199] loss: 0.720700\n",
      "[54,   299] loss: 0.694894\n",
      "[54,   399] loss: 0.684469\n",
      "[54,   499] loss: 0.721981\n",
      "[54,   599] loss: 0.724858\n",
      "[54,   699] loss: 0.733239\n",
      "[55,    99] loss: 0.710804\n",
      "[55,   199] loss: 0.720700\n",
      "[55,   299] loss: 0.694894\n",
      "[55,   399] loss: 0.684469\n",
      "[55,   499] loss: 0.721981\n",
      "[55,   599] loss: 0.724858\n",
      "[55,   699] loss: 0.733239\n",
      "[56,    99] loss: 0.710804\n",
      "[56,   199] loss: 0.720700\n",
      "[56,   299] loss: 0.694894\n",
      "[56,   399] loss: 0.684469\n",
      "[56,   499] loss: 0.721981\n",
      "[56,   599] loss: 0.724858\n",
      "[56,   699] loss: 0.733239\n",
      "[57,    99] loss: 0.710804\n",
      "[57,   199] loss: 0.720700\n",
      "[57,   299] loss: 0.694894\n",
      "[57,   399] loss: 0.684469\n",
      "[57,   499] loss: 0.721981\n",
      "[57,   599] loss: 0.724858\n",
      "[57,   699] loss: 0.733239\n",
      "[58,    99] loss: 0.710804\n",
      "[58,   199] loss: 0.720700\n",
      "[58,   299] loss: 0.694894\n",
      "[58,   399] loss: 0.684469\n",
      "[58,   499] loss: 0.721981\n",
      "[58,   599] loss: 0.724858\n",
      "[58,   699] loss: 0.733239\n",
      "[59,    99] loss: 0.710804\n",
      "[59,   199] loss: 0.720700\n",
      "[59,   299] loss: 0.694894\n",
      "[59,   399] loss: 0.684469\n",
      "[59,   499] loss: 0.721981\n",
      "[59,   599] loss: 0.724858\n",
      "[59,   699] loss: 0.733239\n",
      "[60,    99] loss: 0.710804\n",
      "[60,   199] loss: 0.720700\n",
      "[60,   299] loss: 0.694894\n",
      "[60,   399] loss: 0.684469\n",
      "[60,   499] loss: 0.721981\n",
      "[60,   599] loss: 0.724858\n",
      "[60,   699] loss: 0.733239\n",
      "[61,    99] loss: 0.710804\n",
      "[61,   199] loss: 0.720700\n",
      "[61,   299] loss: 0.694894\n",
      "[61,   399] loss: 0.684469\n",
      "[61,   499] loss: 0.721981\n",
      "[61,   599] loss: 0.724858\n",
      "[61,   699] loss: 0.733239\n",
      "[62,    99] loss: 0.710804\n",
      "[62,   199] loss: 0.720700\n",
      "[62,   299] loss: 0.694894\n",
      "[62,   399] loss: 0.684469\n",
      "[62,   499] loss: 0.721981\n",
      "[62,   599] loss: 0.724858\n",
      "[62,   699] loss: 0.733239\n",
      "[63,    99] loss: 0.710804\n",
      "[63,   199] loss: 0.720700\n",
      "[63,   299] loss: 0.694894\n",
      "[63,   399] loss: 0.684469\n",
      "[63,   499] loss: 0.721981\n",
      "[63,   599] loss: 0.724858\n",
      "[63,   699] loss: 0.733239\n",
      "[64,    99] loss: 0.710804\n",
      "[64,   199] loss: 0.720700\n",
      "[64,   299] loss: 0.694894\n",
      "[64,   399] loss: 0.684469\n",
      "[64,   499] loss: 0.721981\n",
      "[64,   599] loss: 0.724858\n",
      "[64,   699] loss: 0.733239\n",
      "[65,    99] loss: 0.710804\n",
      "[65,   199] loss: 0.720700\n",
      "[65,   299] loss: 0.694894\n",
      "[65,   399] loss: 0.684469\n",
      "[65,   499] loss: 0.721981\n",
      "[65,   599] loss: 0.724858\n",
      "[65,   699] loss: 0.733239\n",
      "[66,    99] loss: 0.710804\n",
      "[66,   199] loss: 0.720700\n",
      "[66,   299] loss: 0.694894\n",
      "[66,   399] loss: 0.684469\n",
      "[66,   499] loss: 0.721981\n",
      "[66,   599] loss: 0.724858\n",
      "[66,   699] loss: 0.733239\n",
      "[67,    99] loss: 0.710804\n",
      "[67,   199] loss: 0.720700\n",
      "[67,   299] loss: 0.694894\n",
      "[67,   399] loss: 0.684469\n",
      "[67,   499] loss: 0.721981\n",
      "[67,   599] loss: 0.724858\n",
      "[67,   699] loss: 0.733239\n",
      "[68,    99] loss: 0.710804\n",
      "[68,   199] loss: 0.720700\n",
      "[68,   299] loss: 0.694894\n",
      "[68,   399] loss: 0.684469\n",
      "[68,   499] loss: 0.721981\n",
      "[68,   599] loss: 0.724858\n",
      "[68,   699] loss: 0.733239\n",
      "[69,    99] loss: 0.710804\n",
      "[69,   199] loss: 0.720700\n",
      "[69,   299] loss: 0.694894\n",
      "[69,   399] loss: 0.684469\n",
      "[69,   499] loss: 0.721981\n",
      "[69,   599] loss: 0.724858\n",
      "[69,   699] loss: 0.733239\n",
      "[70,    99] loss: 0.710804\n",
      "[70,   199] loss: 0.720700\n",
      "[70,   299] loss: 0.694894\n",
      "[70,   399] loss: 0.684469\n",
      "[70,   499] loss: 0.721981\n",
      "[70,   599] loss: 0.724858\n",
      "[70,   699] loss: 0.733239\n",
      "[71,    99] loss: 0.710804\n",
      "[71,   199] loss: 0.720700\n",
      "[71,   299] loss: 0.694894\n",
      "[71,   399] loss: 0.684469\n",
      "[71,   499] loss: 0.721981\n",
      "[71,   599] loss: 0.724858\n",
      "[71,   699] loss: 0.733239\n",
      "[72,    99] loss: 0.710804\n",
      "[72,   199] loss: 0.720700\n",
      "[72,   299] loss: 0.694894\n",
      "[72,   399] loss: 0.684469\n",
      "[72,   499] loss: 0.721981\n",
      "[72,   599] loss: 0.724858\n",
      "[72,   699] loss: 0.733239\n",
      "[73,    99] loss: 0.710804\n",
      "[73,   199] loss: 0.720700\n",
      "[73,   299] loss: 0.694894\n",
      "[73,   399] loss: 0.684469\n",
      "[73,   499] loss: 0.721981\n",
      "[73,   599] loss: 0.724858\n",
      "[73,   699] loss: 0.733239\n",
      "[74,    99] loss: 0.710804\n",
      "[74,   199] loss: 0.720700\n",
      "[74,   299] loss: 0.694894\n",
      "[74,   399] loss: 0.684469\n",
      "[74,   499] loss: 0.721981\n",
      "[74,   599] loss: 0.724858\n",
      "[74,   699] loss: 0.733239\n",
      "[75,    99] loss: 0.710804\n",
      "[75,   199] loss: 0.720700\n",
      "[75,   299] loss: 0.694894\n",
      "[75,   399] loss: 0.684469\n",
      "[75,   499] loss: 0.721981\n",
      "[75,   599] loss: 0.724858\n",
      "[75,   699] loss: 0.733239\n",
      "[76,    99] loss: 0.710804\n",
      "[76,   199] loss: 0.720700\n",
      "[76,   299] loss: 0.694894\n",
      "[76,   399] loss: 0.684469\n",
      "[76,   499] loss: 0.721981\n",
      "[76,   599] loss: 0.724858\n",
      "[76,   699] loss: 0.733239\n",
      "[77,    99] loss: 0.710804\n",
      "[77,   199] loss: 0.720700\n",
      "[77,   299] loss: 0.694894\n",
      "[77,   399] loss: 0.684469\n",
      "[77,   499] loss: 0.721981\n",
      "[77,   599] loss: 0.724858\n",
      "[77,   699] loss: 0.733239\n",
      "[78,    99] loss: 0.710804\n",
      "[78,   199] loss: 0.720700\n",
      "[78,   299] loss: 0.694894\n",
      "[78,   399] loss: 0.684469\n",
      "[78,   499] loss: 0.721981\n",
      "[78,   599] loss: 0.724858\n",
      "[78,   699] loss: 0.733239\n",
      "[79,    99] loss: 0.710804\n",
      "[79,   199] loss: 0.720700\n",
      "[79,   299] loss: 0.694894\n",
      "[79,   399] loss: 0.684469\n",
      "[79,   499] loss: 0.721981\n",
      "[79,   599] loss: 0.724858\n",
      "[79,   699] loss: 0.733239\n",
      "[80,    99] loss: 0.710804\n",
      "[80,   199] loss: 0.720700\n",
      "[80,   299] loss: 0.694894\n",
      "[80,   399] loss: 0.684469\n",
      "[80,   499] loss: 0.721981\n",
      "[80,   599] loss: 0.724858\n",
      "[80,   699] loss: 0.733239\n",
      "[81,    99] loss: 0.710804\n",
      "[81,   199] loss: 0.720700\n",
      "[81,   299] loss: 0.694894\n",
      "[81,   399] loss: 0.684469\n",
      "[81,   499] loss: 0.721981\n",
      "[81,   599] loss: 0.724858\n",
      "[81,   699] loss: 0.733239\n",
      "[82,    99] loss: 0.710804\n",
      "[82,   199] loss: 0.720700\n",
      "[82,   299] loss: 0.694894\n",
      "[82,   399] loss: 0.684469\n",
      "[82,   499] loss: 0.721981\n",
      "[82,   599] loss: 0.724858\n",
      "[82,   699] loss: 0.733239\n",
      "[83,    99] loss: 0.710804\n",
      "[83,   199] loss: 0.720700\n",
      "[83,   299] loss: 0.694894\n",
      "[83,   399] loss: 0.684469\n",
      "[83,   499] loss: 0.721981\n",
      "[83,   599] loss: 0.724858\n",
      "[83,   699] loss: 0.733239\n",
      "[84,    99] loss: 0.710804\n",
      "[84,   199] loss: 0.720700\n",
      "[84,   299] loss: 0.694894\n",
      "[84,   399] loss: 0.684469\n",
      "[84,   499] loss: 0.721981\n",
      "[84,   599] loss: 0.724858\n",
      "[84,   699] loss: 0.733239\n",
      "[85,    99] loss: 0.710804\n",
      "[85,   199] loss: 0.720700\n",
      "[85,   299] loss: 0.694894\n",
      "[85,   399] loss: 0.684469\n",
      "[85,   499] loss: 0.721981\n",
      "[85,   599] loss: 0.724858\n",
      "[85,   699] loss: 0.733239\n",
      "[86,    99] loss: 0.710804\n",
      "[86,   199] loss: 0.720700\n",
      "[86,   299] loss: 0.694894\n",
      "[86,   399] loss: 0.684469\n",
      "[86,   499] loss: 0.721981\n",
      "[86,   599] loss: 0.724858\n",
      "[86,   699] loss: 0.733239\n",
      "[87,    99] loss: 0.710804\n",
      "[87,   199] loss: 0.720700\n",
      "[87,   299] loss: 0.694894\n",
      "[87,   399] loss: 0.684469\n",
      "[87,   499] loss: 0.721981\n",
      "[87,   599] loss: 0.724858\n",
      "[87,   699] loss: 0.733239\n",
      "[88,    99] loss: 0.710804\n",
      "[88,   199] loss: 0.720700\n",
      "[88,   299] loss: 0.694894\n",
      "[88,   399] loss: 0.684469\n",
      "[88,   499] loss: 0.721981\n",
      "[88,   599] loss: 0.724858\n",
      "[88,   699] loss: 0.733239\n",
      "[89,    99] loss: 0.710804\n",
      "[89,   199] loss: 0.720700\n",
      "[89,   299] loss: 0.694894\n",
      "[89,   399] loss: 0.684469\n",
      "[89,   499] loss: 0.721981\n",
      "[89,   599] loss: 0.724858\n",
      "[89,   699] loss: 0.733239\n",
      "[90,    99] loss: 0.710804\n",
      "[90,   199] loss: 0.720700\n",
      "[90,   299] loss: 0.694894\n",
      "[90,   399] loss: 0.684469\n",
      "[90,   499] loss: 0.721981\n",
      "[90,   599] loss: 0.724858\n",
      "[90,   699] loss: 0.733239\n",
      "[91,    99] loss: 0.710804\n",
      "[91,   199] loss: 0.720700\n",
      "[91,   299] loss: 0.694894\n",
      "[91,   399] loss: 0.684469\n",
      "[91,   499] loss: 0.721981\n",
      "[91,   599] loss: 0.724858\n",
      "[91,   699] loss: 0.733239\n",
      "[92,    99] loss: 0.710804\n",
      "[92,   199] loss: 0.720700\n",
      "[92,   299] loss: 0.694894\n",
      "[92,   399] loss: 0.684469\n",
      "[92,   499] loss: 0.721981\n",
      "[92,   599] loss: 0.724858\n",
      "[92,   699] loss: 0.733239\n",
      "[93,    99] loss: 0.710804\n",
      "[93,   199] loss: 0.720700\n",
      "[93,   299] loss: 0.694894\n",
      "[93,   399] loss: 0.684469\n",
      "[93,   499] loss: 0.721981\n",
      "[93,   599] loss: 0.724858\n",
      "[93,   699] loss: 0.733239\n",
      "[94,    99] loss: 0.710804\n",
      "[94,   199] loss: 0.720700\n",
      "[94,   299] loss: 0.694894\n",
      "[94,   399] loss: 0.684469\n",
      "[94,   499] loss: 0.721981\n",
      "[94,   599] loss: 0.724858\n",
      "[94,   699] loss: 0.733239\n",
      "[95,    99] loss: 0.710804\n",
      "[95,   199] loss: 0.720700\n",
      "[95,   299] loss: 0.694894\n",
      "[95,   399] loss: 0.684469\n",
      "[95,   499] loss: 0.721981\n",
      "[95,   599] loss: 0.724858\n",
      "[95,   699] loss: 0.733239\n",
      "[96,    99] loss: 0.710804\n",
      "[96,   199] loss: 0.720700\n",
      "[96,   299] loss: 0.694894\n",
      "[96,   399] loss: 0.684469\n",
      "[96,   499] loss: 0.721981\n",
      "[96,   599] loss: 0.724858\n",
      "[96,   699] loss: 0.733239\n",
      "[97,    99] loss: 0.710804\n",
      "[97,   199] loss: 0.720700\n",
      "[97,   299] loss: 0.694894\n",
      "[97,   399] loss: 0.684469\n",
      "[97,   499] loss: 0.721981\n",
      "[97,   599] loss: 0.724858\n",
      "[97,   699] loss: 0.733239\n",
      "[98,    99] loss: 0.710804\n",
      "[98,   199] loss: 0.720700\n",
      "[98,   299] loss: 0.694894\n",
      "[98,   399] loss: 0.684469\n",
      "[98,   499] loss: 0.721981\n",
      "[98,   599] loss: 0.724858\n",
      "[98,   699] loss: 0.733239\n",
      "[99,    99] loss: 0.710804\n",
      "[99,   199] loss: 0.720700\n",
      "[99,   299] loss: 0.694894\n",
      "[99,   399] loss: 0.684469\n",
      "[99,   499] loss: 0.721981\n",
      "[99,   599] loss: 0.724858\n",
      "[99,   699] loss: 0.733239\n",
      "[100,    99] loss: 0.710804\n",
      "[100,   199] loss: 0.720700\n",
      "[100,   299] loss: 0.694894\n",
      "[100,   399] loss: 0.684469\n",
      "[100,   499] loss: 0.721981\n",
      "[100,   599] loss: 0.724858\n",
      "[100,   699] loss: 0.733239\n",
      "Finished Training\n",
      "[1,    99] loss: 3.650241\n",
      "[1,   199] loss: 1.206461\n",
      "[1,   299] loss: 0.710109\n",
      "[1,   399] loss: 0.704784\n",
      "[1,   499] loss: 0.723561\n",
      "[1,   599] loss: 0.722470\n",
      "[1,   699] loss: 0.744257\n",
      "[2,    99] loss: 0.709481"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2,   199] loss: 0.737071\n",
      "[2,   299] loss: 0.713145\n",
      "[2,   399] loss: 0.703882\n",
      "[2,   499] loss: 0.723820\n",
      "[2,   599] loss: 0.722643\n",
      "[2,   699] loss: 0.744515\n",
      "[3,    99] loss: 0.709667\n",
      "[3,   199] loss: 0.737196\n",
      "[3,   299] loss: 0.713217\n",
      "[3,   399] loss: 0.703914\n",
      "[3,   499] loss: 0.723875\n",
      "[3,   599] loss: 0.722682\n",
      "[3,   699] loss: 0.744582\n",
      "[4,    99] loss: 0.709720\n",
      "[4,   199] loss: 0.737235\n",
      "[4,   299] loss: 0.713241\n",
      "[4,   399] loss: 0.703925\n",
      "[4,   499] loss: 0.723894\n",
      "[4,   599] loss: 0.722697\n",
      "[4,   699] loss: 0.744607\n",
      "[5,    99] loss: 0.709741\n",
      "[5,   199] loss: 0.737251\n",
      "[5,   299] loss: 0.713250\n",
      "[5,   399] loss: 0.703930\n",
      "[5,   499] loss: 0.723902\n",
      "[5,   599] loss: 0.722703\n",
      "[5,   699] loss: 0.744618\n",
      "[6,    99] loss: 0.709750\n",
      "[6,   199] loss: 0.737258\n",
      "[6,   299] loss: 0.713254\n",
      "[6,   399] loss: 0.703932\n",
      "[6,   499] loss: 0.723906\n",
      "[6,   599] loss: 0.722706\n",
      "[6,   699] loss: 0.744623\n",
      "[7,    99] loss: 0.709754\n",
      "[7,   199] loss: 0.737261\n",
      "[7,   299] loss: 0.713256\n",
      "[7,   399] loss: 0.703933\n",
      "[7,   499] loss: 0.723907\n",
      "[7,   599] loss: 0.722707\n",
      "[7,   699] loss: 0.744625\n",
      "[8,    99] loss: 0.709757\n",
      "[8,   199] loss: 0.737263\n",
      "[8,   299] loss: 0.713257\n",
      "[8,   399] loss: 0.703933\n",
      "[8,   499] loss: 0.723908\n",
      "[8,   599] loss: 0.722708\n",
      "[8,   699] loss: 0.744626\n",
      "[9,    99] loss: 0.709757\n",
      "[9,   199] loss: 0.737263\n",
      "[9,   299] loss: 0.713258\n",
      "[9,   399] loss: 0.703934\n",
      "[9,   499] loss: 0.723909\n",
      "[9,   599] loss: 0.722708\n",
      "[9,   699] loss: 0.744627\n",
      "[10,    99] loss: 0.709758\n",
      "[10,   199] loss: 0.737264\n",
      "[10,   299] loss: 0.713258\n",
      "[10,   399] loss: 0.703934\n",
      "[10,   499] loss: 0.723909\n",
      "[10,   599] loss: 0.722708\n",
      "[10,   699] loss: 0.744627\n",
      "[11,    99] loss: 0.709758\n",
      "[11,   199] loss: 0.737264\n",
      "[11,   299] loss: 0.713258\n",
      "[11,   399] loss: 0.703934\n",
      "[11,   499] loss: 0.723909\n",
      "[11,   599] loss: 0.722708\n",
      "[11,   699] loss: 0.744627\n",
      "[12,    99] loss: 0.709758\n",
      "[12,   199] loss: 0.737264\n",
      "[12,   299] loss: 0.713258\n",
      "[12,   399] loss: 0.703934\n",
      "[12,   499] loss: 0.723909\n",
      "[12,   599] loss: 0.722708\n",
      "[12,   699] loss: 0.744627\n",
      "[13,    99] loss: 0.709758\n",
      "[13,   199] loss: 0.737264\n",
      "[13,   299] loss: 0.713258\n",
      "[13,   399] loss: 0.703934\n",
      "[13,   499] loss: 0.723909\n",
      "[13,   599] loss: 0.722708\n",
      "[13,   699] loss: 0.744627\n",
      "[14,    99] loss: 0.709758\n",
      "[14,   199] loss: 0.737264\n",
      "[14,   299] loss: 0.713258\n",
      "[14,   399] loss: 0.703934\n",
      "[14,   499] loss: 0.723909\n",
      "[14,   599] loss: 0.722708\n",
      "[14,   699] loss: 0.744627\n",
      "[15,    99] loss: 0.709758\n",
      "[15,   199] loss: 0.737264\n",
      "[15,   299] loss: 0.713258\n",
      "[15,   399] loss: 0.703934\n",
      "[15,   499] loss: 0.723909\n",
      "[15,   599] loss: 0.722708\n",
      "[15,   699] loss: 0.744627\n",
      "[16,    99] loss: 0.709758\n",
      "[16,   199] loss: 0.737264\n",
      "[16,   299] loss: 0.713258\n",
      "[16,   399] loss: 0.703934\n",
      "[16,   499] loss: 0.723909\n",
      "[16,   599] loss: 0.722708\n",
      "[16,   699] loss: 0.744627\n",
      "[17,    99] loss: 0.709758\n",
      "[17,   199] loss: 0.737264\n",
      "[17,   299] loss: 0.713258\n",
      "[17,   399] loss: 0.703934\n",
      "[17,   499] loss: 0.723909\n",
      "[17,   599] loss: 0.722708\n",
      "[17,   699] loss: 0.744627\n",
      "[18,    99] loss: 0.709758\n",
      "[18,   199] loss: 0.737264\n",
      "[18,   299] loss: 0.713258\n",
      "[18,   399] loss: 0.703934\n",
      "[18,   499] loss: 0.723909\n",
      "[18,   599] loss: 0.722708\n",
      "[18,   699] loss: 0.744627\n",
      "[19,    99] loss: 0.709758\n",
      "[19,   199] loss: 0.737264\n",
      "[19,   299] loss: 0.713258\n",
      "[19,   399] loss: 0.703934\n",
      "[19,   499] loss: 0.723909\n",
      "[19,   599] loss: 0.722708\n",
      "[19,   699] loss: 0.744627\n",
      "[20,    99] loss: 0.709758\n",
      "[20,   199] loss: 0.737264\n",
      "[20,   299] loss: 0.713258\n",
      "[20,   399] loss: 0.703934\n",
      "[20,   499] loss: 0.723909\n",
      "[20,   599] loss: 0.722708\n",
      "[20,   699] loss: 0.744627\n",
      "[21,    99] loss: 0.709758\n",
      "[21,   199] loss: 0.737264\n",
      "[21,   299] loss: 0.713258\n",
      "[21,   399] loss: 0.703934\n",
      "[21,   499] loss: 0.723909\n",
      "[21,   599] loss: 0.722708\n",
      "[21,   699] loss: 0.744627\n",
      "[22,    99] loss: 0.709758\n",
      "[22,   199] loss: 0.737264\n",
      "[22,   299] loss: 0.713258\n",
      "[22,   399] loss: 0.703934\n",
      "[22,   499] loss: 0.723909\n",
      "[22,   599] loss: 0.722708\n",
      "[22,   699] loss: 0.744627\n",
      "[23,    99] loss: 0.709758\n",
      "[23,   199] loss: 0.737264\n",
      "[23,   299] loss: 0.713258\n",
      "[23,   399] loss: 0.703934\n",
      "[23,   499] loss: 0.723909\n",
      "[23,   599] loss: 0.722708\n",
      "[23,   699] loss: 0.744627\n",
      "[24,    99] loss: 0.709758\n",
      "[24,   199] loss: 0.737264\n",
      "[24,   299] loss: 0.713258\n",
      "[24,   399] loss: 0.703934\n",
      "[24,   499] loss: 0.723909\n",
      "[24,   599] loss: 0.722708\n",
      "[24,   699] loss: 0.744627\n",
      "[25,    99] loss: 0.709758\n",
      "[25,   199] loss: 0.737264\n",
      "[25,   299] loss: 0.713258\n",
      "[25,   399] loss: 0.703934\n",
      "[25,   499] loss: 0.723909\n",
      "[25,   599] loss: 0.722708\n",
      "[25,   699] loss: 0.744627\n",
      "[26,    99] loss: 0.709758\n",
      "[26,   199] loss: 0.737264\n",
      "[26,   299] loss: 0.713258\n",
      "[26,   399] loss: 0.703934\n",
      "[26,   499] loss: 0.723909\n",
      "[26,   599] loss: 0.722708\n",
      "[26,   699] loss: 0.744627\n",
      "[27,    99] loss: 0.709758\n",
      "[27,   199] loss: 0.737264\n",
      "[27,   299] loss: 0.713258\n",
      "[27,   399] loss: 0.703934\n",
      "[27,   499] loss: 0.723909\n",
      "[27,   599] loss: 0.722708\n",
      "[27,   699] loss: 0.744627\n",
      "[28,    99] loss: 0.709758\n",
      "[28,   199] loss: 0.737264\n",
      "[28,   299] loss: 0.713258\n",
      "[28,   399] loss: 0.703934\n",
      "[28,   499] loss: 0.723909\n",
      "[28,   599] loss: 0.722708\n",
      "[28,   699] loss: 0.744627\n",
      "[29,    99] loss: 0.709758\n",
      "[29,   199] loss: 0.737264\n",
      "[29,   299] loss: 0.713258\n",
      "[29,   399] loss: 0.703934\n",
      "[29,   499] loss: 0.723909\n",
      "[29,   599] loss: 0.722708\n",
      "[29,   699] loss: 0.744627\n",
      "[30,    99] loss: 0.709758\n",
      "[30,   199] loss: 0.737264\n",
      "[30,   299] loss: 0.713258\n",
      "[30,   399] loss: 0.703934\n",
      "[30,   499] loss: 0.723909\n",
      "[30,   599] loss: 0.722708\n",
      "[30,   699] loss: 0.744627\n",
      "[31,    99] loss: 0.709758\n",
      "[31,   199] loss: 0.737264\n",
      "[31,   299] loss: 0.713258\n",
      "[31,   399] loss: 0.703934\n",
      "[31,   499] loss: 0.723909\n",
      "[31,   599] loss: 0.722708\n",
      "[31,   699] loss: 0.744627\n",
      "[32,    99] loss: 0.709758\n",
      "[32,   199] loss: 0.737264\n",
      "[32,   299] loss: 0.713258\n",
      "[32,   399] loss: 0.703934\n",
      "[32,   499] loss: 0.723909\n",
      "[32,   599] loss: 0.722708\n",
      "[32,   699] loss: 0.744627\n",
      "[33,    99] loss: 0.709758\n",
      "[33,   199] loss: 0.737264\n",
      "[33,   299] loss: 0.713258\n",
      "[33,   399] loss: 0.703934\n",
      "[33,   499] loss: 0.723909\n",
      "[33,   599] loss: 0.722708\n",
      "[33,   699] loss: 0.744627\n",
      "[34,    99] loss: 0.709758\n",
      "[34,   199] loss: 0.737264\n",
      "[34,   299] loss: 0.713258\n",
      "[34,   399] loss: 0.703934\n",
      "[34,   499] loss: 0.723909\n",
      "[34,   599] loss: 0.722708\n",
      "[34,   699] loss: 0.744627\n",
      "[35,    99] loss: 0.709758\n",
      "[35,   199] loss: 0.737264\n",
      "[35,   299] loss: 0.713258\n",
      "[35,   399] loss: 0.703934\n",
      "[35,   499] loss: 0.723909\n",
      "[35,   599] loss: 0.722708\n",
      "[35,   699] loss: 0.744627\n",
      "[36,    99] loss: 0.709758\n",
      "[36,   199] loss: 0.737264\n",
      "[36,   299] loss: 0.713258\n",
      "[36,   399] loss: 0.703934\n",
      "[36,   499] loss: 0.723909\n",
      "[36,   599] loss: 0.722708\n",
      "[36,   699] loss: 0.744627\n",
      "[37,    99] loss: 0.709758\n",
      "[37,   199] loss: 0.737264\n",
      "[37,   299] loss: 0.713258\n",
      "[37,   399] loss: 0.703934\n",
      "[37,   499] loss: 0.723909\n",
      "[37,   599] loss: 0.722708\n",
      "[37,   699] loss: 0.744627\n",
      "[38,    99] loss: 0.709758\n",
      "[38,   199] loss: 0.737264\n",
      "[38,   299] loss: 0.713258\n",
      "[38,   399] loss: 0.703934\n",
      "[38,   499] loss: 0.723909\n",
      "[38,   599] loss: 0.722708\n",
      "[38,   699] loss: 0.744627\n",
      "[39,    99] loss: 0.709758\n",
      "[39,   199] loss: 0.737264\n",
      "[39,   299] loss: 0.713258\n",
      "[39,   399] loss: 0.703934\n",
      "[39,   499] loss: 0.723909\n",
      "[39,   599] loss: 0.722708\n",
      "[39,   699] loss: 0.744627\n",
      "[40,    99] loss: 0.709758\n",
      "[40,   199] loss: 0.737264\n",
      "[40,   299] loss: 0.713258\n",
      "[40,   399] loss: 0.703934\n",
      "[40,   499] loss: 0.723909\n",
      "[40,   599] loss: 0.722708\n",
      "[40,   699] loss: 0.744627\n",
      "[41,    99] loss: 0.709758\n",
      "[41,   199] loss: 0.737264\n",
      "[41,   299] loss: 0.713258\n",
      "[41,   399] loss: 0.703934\n",
      "[41,   499] loss: 0.723909\n",
      "[41,   599] loss: 0.722708\n",
      "[41,   699] loss: 0.744627\n",
      "[42,    99] loss: 0.709758\n",
      "[42,   199] loss: 0.737264\n",
      "[42,   299] loss: 0.713258\n",
      "[42,   399] loss: 0.703934\n",
      "[42,   499] loss: 0.723909\n",
      "[42,   599] loss: 0.722708\n",
      "[42,   699] loss: 0.744627\n",
      "[43,    99] loss: 0.709758\n",
      "[43,   199] loss: 0.737264\n",
      "[43,   299] loss: 0.713258\n",
      "[43,   399] loss: 0.703934\n",
      "[43,   499] loss: 0.723909\n",
      "[43,   599] loss: 0.722708\n",
      "[43,   699] loss: 0.744627\n",
      "[44,    99] loss: 0.709758\n",
      "[44,   199] loss: 0.737264\n",
      "[44,   299] loss: 0.713258\n",
      "[44,   399] loss: 0.703934\n",
      "[44,   499] loss: 0.723909\n",
      "[44,   599] loss: 0.722708\n",
      "[44,   699] loss: 0.744627\n",
      "[45,    99] loss: 0.709758\n",
      "[45,   199] loss: 0.737264\n",
      "[45,   299] loss: 0.713258\n",
      "[45,   399] loss: 0.703934\n",
      "[45,   499] loss: 0.723909\n",
      "[45,   599] loss: 0.722708\n",
      "[45,   699] loss: 0.744627\n",
      "[46,    99] loss: 0.709758\n",
      "[46,   199] loss: 0.737264\n",
      "[46,   299] loss: 0.713258\n",
      "[46,   399] loss: 0.703934\n",
      "[46,   499] loss: 0.723909\n",
      "[46,   599] loss: 0.722708\n",
      "[46,   699] loss: 0.744627\n",
      "[47,    99] loss: 0.709758\n",
      "[47,   199] loss: 0.737264\n",
      "[47,   299] loss: 0.713258\n",
      "[47,   399] loss: 0.703934\n",
      "[47,   499] loss: 0.723909\n",
      "[47,   599] loss: 0.722708\n",
      "[47,   699] loss: 0.744627\n",
      "[48,    99] loss: 0.709758\n",
      "[48,   199] loss: 0.737264\n",
      "[48,   299] loss: 0.713258\n",
      "[48,   399] loss: 0.703934\n",
      "[48,   499] loss: 0.723909\n",
      "[48,   599] loss: 0.722708\n",
      "[48,   699] loss: 0.744627\n",
      "[49,    99] loss: 0.709758\n",
      "[49,   199] loss: 0.737264\n",
      "[49,   299] loss: 0.713258\n",
      "[49,   399] loss: 0.703934\n",
      "[49,   499] loss: 0.723909\n",
      "[49,   599] loss: 0.722708\n",
      "[49,   699] loss: 0.744627\n",
      "[50,    99] loss: 0.709758\n",
      "[50,   199] loss: 0.737264\n",
      "[50,   299] loss: 0.713258\n",
      "[50,   399] loss: 0.703934\n",
      "[50,   499] loss: 0.723909\n",
      "[50,   599] loss: 0.722708\n",
      "[50,   699] loss: 0.744627\n",
      "[51,    99] loss: 0.709758\n",
      "[51,   199] loss: 0.737264\n",
      "[51,   299] loss: 0.713258\n",
      "[51,   399] loss: 0.703934\n",
      "[51,   499] loss: 0.723909\n",
      "[51,   599] loss: 0.722708\n",
      "[51,   699] loss: 0.744627\n",
      "[52,    99] loss: 0.709758\n",
      "[52,   199] loss: 0.737264\n",
      "[52,   299] loss: 0.713258\n",
      "[52,   399] loss: 0.703934\n",
      "[52,   499] loss: 0.723909\n",
      "[52,   599] loss: 0.722708\n",
      "[52,   699] loss: 0.744627\n",
      "[53,    99] loss: 0.709758\n",
      "[53,   199] loss: 0.737264\n",
      "[53,   299] loss: 0.713258\n",
      "[53,   399] loss: 0.703934\n",
      "[53,   499] loss: 0.723909\n",
      "[53,   599] loss: 0.722708\n",
      "[53,   699] loss: 0.744627\n",
      "[54,    99] loss: 0.709758\n",
      "[54,   199] loss: 0.737264\n",
      "[54,   299] loss: 0.713258\n",
      "[54,   399] loss: 0.703934\n",
      "[54,   499] loss: 0.723909\n",
      "[54,   599] loss: 0.722708\n",
      "[54,   699] loss: 0.744627\n",
      "[55,    99] loss: 0.709758\n",
      "[55,   199] loss: 0.737264\n",
      "[55,   299] loss: 0.713258\n",
      "[55,   399] loss: 0.703934\n",
      "[55,   499] loss: 0.723909\n",
      "[55,   599] loss: 0.722708\n",
      "[55,   699] loss: 0.744627\n",
      "[56,    99] loss: 0.709758\n",
      "[56,   199] loss: 0.737264\n",
      "[56,   299] loss: 0.713258\n",
      "[56,   399] loss: 0.703934\n",
      "[56,   499] loss: 0.723909\n",
      "[56,   599] loss: 0.722708\n",
      "[56,   699] loss: 0.744627\n",
      "[57,    99] loss: 0.709758\n",
      "[57,   199] loss: 0.737264\n",
      "[57,   299] loss: 0.713258\n",
      "[57,   399] loss: 0.703934\n",
      "[57,   499] loss: 0.723909\n",
      "[57,   599] loss: 0.722708\n",
      "[57,   699] loss: 0.744627\n",
      "[58,    99] loss: 0.709758\n",
      "[58,   199] loss: 0.737264\n",
      "[58,   299] loss: 0.713258\n",
      "[58,   399] loss: 0.703934\n",
      "[58,   499] loss: 0.723909\n",
      "[58,   599] loss: 0.722708\n",
      "[58,   699] loss: 0.744627\n",
      "[59,    99] loss: 0.709758\n",
      "[59,   199] loss: 0.737264\n",
      "[59,   299] loss: 0.713258\n",
      "[59,   399] loss: 0.703934\n",
      "[59,   499] loss: 0.723909\n",
      "[59,   599] loss: 0.722708\n",
      "[59,   699] loss: 0.744627\n",
      "[60,    99] loss: 0.709758\n",
      "[60,   199] loss: 0.737264\n",
      "[60,   299] loss: 0.713258\n",
      "[60,   399] loss: 0.703934\n",
      "[60,   499] loss: 0.723909\n",
      "[60,   599] loss: 0.722708\n",
      "[60,   699] loss: 0.744627\n",
      "[61,    99] loss: 0.709758\n",
      "[61,   199] loss: 0.737264\n",
      "[61,   299] loss: 0.713258\n",
      "[61,   399] loss: 0.703934\n",
      "[61,   499] loss: 0.723909\n",
      "[61,   599] loss: 0.722708\n",
      "[61,   699] loss: 0.744627\n",
      "[62,    99] loss: 0.709758\n",
      "[62,   199] loss: 0.737264\n",
      "[62,   299] loss: 0.713258\n",
      "[62,   399] loss: 0.703934\n",
      "[62,   499] loss: 0.723909\n",
      "[62,   599] loss: 0.722708\n",
      "[62,   699] loss: 0.744627\n",
      "[63,    99] loss: 0.709758\n",
      "[63,   199] loss: 0.737264\n",
      "[63,   299] loss: 0.713258\n",
      "[63,   399] loss: 0.703934\n",
      "[63,   499] loss: 0.723909\n",
      "[63,   599] loss: 0.722708\n",
      "[63,   699] loss: 0.744627\n",
      "[64,    99] loss: 0.709758\n",
      "[64,   199] loss: 0.737264\n",
      "[64,   299] loss: 0.713258\n",
      "[64,   399] loss: 0.703934\n",
      "[64,   499] loss: 0.723909\n",
      "[64,   599] loss: 0.722708\n",
      "[64,   699] loss: 0.744627\n",
      "[65,    99] loss: 0.709758\n",
      "[65,   199] loss: 0.737264\n",
      "[65,   299] loss: 0.713258\n",
      "[65,   399] loss: 0.703934\n",
      "[65,   499] loss: 0.723909\n",
      "[65,   599] loss: 0.722708\n",
      "[65,   699] loss: 0.744627\n",
      "[66,    99] loss: 0.709758\n",
      "[66,   199] loss: 0.737264\n",
      "[66,   299] loss: 0.713258\n",
      "[66,   399] loss: 0.703934\n",
      "[66,   499] loss: 0.723909\n",
      "[66,   599] loss: 0.722708\n",
      "[66,   699] loss: 0.744627\n",
      "[67,    99] loss: 0.709758\n",
      "[67,   199] loss: 0.737264\n",
      "[67,   299] loss: 0.713258\n",
      "[67,   399] loss: 0.703934\n",
      "[67,   499] loss: 0.723909\n",
      "[67,   599] loss: 0.722708\n",
      "[67,   699] loss: 0.744627\n",
      "[68,    99] loss: 0.709758\n",
      "[68,   199] loss: 0.737264\n",
      "[68,   299] loss: 0.713258\n",
      "[68,   399] loss: 0.703934\n",
      "[68,   499] loss: 0.723909\n",
      "[68,   599] loss: 0.722708\n",
      "[68,   699] loss: 0.744627\n",
      "[69,    99] loss: 0.709758\n",
      "[69,   199] loss: 0.737264\n",
      "[69,   299] loss: 0.713258\n",
      "[69,   399] loss: 0.703934\n",
      "[69,   499] loss: 0.723909\n",
      "[69,   599] loss: 0.722708\n",
      "[69,   699] loss: 0.744627\n",
      "[70,    99] loss: 0.709758\n",
      "[70,   199] loss: 0.737264\n",
      "[70,   299] loss: 0.713258\n",
      "[70,   399] loss: 0.703934\n",
      "[70,   499] loss: 0.723909\n",
      "[70,   599] loss: 0.722708\n",
      "[70,   699] loss: 0.744627\n",
      "[71,    99] loss: 0.709758\n",
      "[71,   199] loss: 0.737264\n",
      "[71,   299] loss: 0.713258\n",
      "[71,   399] loss: 0.703934\n",
      "[71,   499] loss: 0.723909\n",
      "[71,   599] loss: 0.722708\n",
      "[71,   699] loss: 0.744627\n",
      "[72,    99] loss: 0.709758\n",
      "[72,   199] loss: 0.737264\n",
      "[72,   299] loss: 0.713258\n",
      "[72,   399] loss: 0.703934\n",
      "[72,   499] loss: 0.723909\n",
      "[72,   599] loss: 0.722708\n",
      "[72,   699] loss: 0.744627\n",
      "[73,    99] loss: 0.709758\n",
      "[73,   199] loss: 0.737264\n",
      "[73,   299] loss: 0.713258\n",
      "[73,   399] loss: 0.703934\n",
      "[73,   499] loss: 0.723909\n",
      "[73,   599] loss: 0.722708\n",
      "[73,   699] loss: 0.744627\n",
      "[74,    99] loss: 0.709758\n",
      "[74,   199] loss: 0.737264\n",
      "[74,   299] loss: 0.713258\n",
      "[74,   399] loss: 0.703934\n",
      "[74,   499] loss: 0.723909\n",
      "[74,   599] loss: 0.722708\n",
      "[74,   699] loss: 0.744627\n",
      "[75,    99] loss: 0.709758\n",
      "[75,   199] loss: 0.737264\n",
      "[75,   299] loss: 0.713258\n",
      "[75,   399] loss: 0.703934\n",
      "[75,   499] loss: 0.723909\n",
      "[75,   599] loss: 0.722708\n",
      "[75,   699] loss: 0.744627\n",
      "[76,    99] loss: 0.709758\n",
      "[76,   199] loss: 0.737264\n",
      "[76,   299] loss: 0.713258\n",
      "[76,   399] loss: 0.703934\n",
      "[76,   499] loss: 0.723909\n",
      "[76,   599] loss: 0.722708\n",
      "[76,   699] loss: 0.744627\n",
      "[77,    99] loss: 0.709758\n",
      "[77,   199] loss: 0.737264\n",
      "[77,   299] loss: 0.713258\n",
      "[77,   399] loss: 0.703934\n",
      "[77,   499] loss: 0.723909\n",
      "[77,   599] loss: 0.722708\n",
      "[77,   699] loss: 0.744627\n",
      "[78,    99] loss: 0.709758\n",
      "[78,   199] loss: 0.737264\n",
      "[78,   299] loss: 0.713258\n",
      "[78,   399] loss: 0.703934\n",
      "[78,   499] loss: 0.723909\n",
      "[78,   599] loss: 0.722708\n",
      "[78,   699] loss: 0.744627\n",
      "[79,    99] loss: 0.709758\n",
      "[79,   199] loss: 0.737264\n",
      "[79,   299] loss: 0.713258\n",
      "[79,   399] loss: 0.703934\n",
      "[79,   499] loss: 0.723909\n",
      "[79,   599] loss: 0.722708\n",
      "[79,   699] loss: 0.744627\n",
      "[80,    99] loss: 0.709758\n",
      "[80,   199] loss: 0.737264\n",
      "[80,   299] loss: 0.713258\n",
      "[80,   399] loss: 0.703934\n",
      "[80,   499] loss: 0.723909\n",
      "[80,   599] loss: 0.722708\n",
      "[80,   699] loss: 0.744627\n",
      "[81,    99] loss: 0.709758\n",
      "[81,   199] loss: 0.737264\n",
      "[81,   299] loss: 0.713258\n",
      "[81,   399] loss: 0.703934\n",
      "[81,   499] loss: 0.723909\n",
      "[81,   599] loss: 0.722708\n",
      "[81,   699] loss: 0.744627\n",
      "[82,    99] loss: 0.709758\n",
      "[82,   199] loss: 0.737264\n",
      "[82,   299] loss: 0.713258\n",
      "[82,   399] loss: 0.703934\n",
      "[82,   499] loss: 0.723909\n",
      "[82,   599] loss: 0.722708\n",
      "[82,   699] loss: 0.744627\n",
      "[83,    99] loss: 0.709758\n",
      "[83,   199] loss: 0.737264\n",
      "[83,   299] loss: 0.713258\n",
      "[83,   399] loss: 0.703934\n",
      "[83,   499] loss: 0.723909\n",
      "[83,   599] loss: 0.722708\n",
      "[83,   699] loss: 0.744627\n",
      "[84,    99] loss: 0.709758\n",
      "[84,   199] loss: 0.737264\n",
      "[84,   299] loss: 0.713258\n",
      "[84,   399] loss: 0.703934\n",
      "[84,   499] loss: 0.723909\n",
      "[84,   599] loss: 0.722708\n",
      "[84,   699] loss: 0.744627\n",
      "[85,    99] loss: 0.709758\n",
      "[85,   199] loss: 0.737264\n",
      "[85,   299] loss: 0.713258\n",
      "[85,   399] loss: 0.703934\n",
      "[85,   499] loss: 0.723909\n",
      "[85,   599] loss: 0.722708\n",
      "[85,   699] loss: 0.744627\n",
      "[86,    99] loss: 0.709758\n",
      "[86,   199] loss: 0.737264\n",
      "[86,   299] loss: 0.713258\n",
      "[86,   399] loss: 0.703934\n",
      "[86,   499] loss: 0.723909\n",
      "[86,   599] loss: 0.722708\n",
      "[86,   699] loss: 0.744627\n",
      "[87,    99] loss: 0.709758\n",
      "[87,   199] loss: 0.737264\n",
      "[87,   299] loss: 0.713258\n",
      "[87,   399] loss: 0.703934\n",
      "[87,   499] loss: 0.723909\n",
      "[87,   599] loss: 0.722708\n",
      "[87,   699] loss: 0.744627\n",
      "[88,    99] loss: 0.709758\n",
      "[88,   199] loss: 0.737264\n",
      "[88,   299] loss: 0.713258\n",
      "[88,   399] loss: 0.703934\n",
      "[88,   499] loss: 0.723909\n",
      "[88,   599] loss: 0.722708\n",
      "[88,   699] loss: 0.744627\n",
      "[89,    99] loss: 0.709758\n",
      "[89,   199] loss: 0.737264\n",
      "[89,   299] loss: 0.713258\n",
      "[89,   399] loss: 0.703934\n",
      "[89,   499] loss: 0.723909\n",
      "[89,   599] loss: 0.722708\n",
      "[89,   699] loss: 0.744627\n",
      "[90,    99] loss: 0.709758\n",
      "[90,   199] loss: 0.737264\n",
      "[90,   299] loss: 0.713258\n",
      "[90,   399] loss: 0.703934\n",
      "[90,   499] loss: 0.723909\n",
      "[90,   599] loss: 0.722708\n",
      "[90,   699] loss: 0.744627\n",
      "[91,    99] loss: 0.709758\n",
      "[91,   199] loss: 0.737264\n",
      "[91,   299] loss: 0.713258\n",
      "[91,   399] loss: 0.703934\n",
      "[91,   499] loss: 0.723909\n",
      "[91,   599] loss: 0.722708\n",
      "[91,   699] loss: 0.744627\n",
      "[92,    99] loss: 0.709758\n",
      "[92,   199] loss: 0.737264\n",
      "[92,   299] loss: 0.713258\n",
      "[92,   399] loss: 0.703934\n",
      "[92,   499] loss: 0.723909\n",
      "[92,   599] loss: 0.722708\n",
      "[92,   699] loss: 0.744627\n",
      "[93,    99] loss: 0.709758\n",
      "[93,   199] loss: 0.737264\n",
      "[93,   299] loss: 0.713258\n",
      "[93,   399] loss: 0.703934\n",
      "[93,   499] loss: 0.723909\n",
      "[93,   599] loss: 0.722708\n",
      "[93,   699] loss: 0.744627\n",
      "[94,    99] loss: 0.709758\n",
      "[94,   199] loss: 0.737264\n",
      "[94,   299] loss: 0.713258\n",
      "[94,   399] loss: 0.703934\n",
      "[94,   499] loss: 0.723909\n",
      "[94,   599] loss: 0.722708\n",
      "[94,   699] loss: 0.744627\n",
      "[95,    99] loss: 0.709758\n",
      "[95,   199] loss: 0.737264\n",
      "[95,   299] loss: 0.713258\n",
      "[95,   399] loss: 0.703934\n",
      "[95,   499] loss: 0.723909\n",
      "[95,   599] loss: 0.722708\n",
      "[95,   699] loss: 0.744627\n",
      "[96,    99] loss: 0.709758\n",
      "[96,   199] loss: 0.737264\n",
      "[96,   299] loss: 0.713258\n",
      "[96,   399] loss: 0.703934\n",
      "[96,   499] loss: 0.723909\n",
      "[96,   599] loss: 0.722708\n",
      "[96,   699] loss: 0.744627\n",
      "[97,    99] loss: 0.709758\n",
      "[97,   199] loss: 0.737264\n",
      "[97,   299] loss: 0.713258\n",
      "[97,   399] loss: 0.703934\n",
      "[97,   499] loss: 0.723909\n",
      "[97,   599] loss: 0.722708\n",
      "[97,   699] loss: 0.744627\n",
      "[98,    99] loss: 0.709758\n",
      "[98,   199] loss: 0.737264\n",
      "[98,   299] loss: 0.713258\n",
      "[98,   399] loss: 0.703934\n",
      "[98,   499] loss: 0.723909\n",
      "[98,   599] loss: 0.722708\n",
      "[98,   699] loss: 0.744627\n",
      "[99,    99] loss: 0.709758\n",
      "[99,   199] loss: 0.737264\n",
      "[99,   299] loss: 0.713258\n",
      "[99,   399] loss: 0.703934\n",
      "[99,   499] loss: 0.723909\n",
      "[99,   599] loss: 0.722708\n",
      "[99,   699] loss: 0.744627\n",
      "[100,    99] loss: 0.709758\n",
      "[100,   199] loss: 0.737264\n",
      "[100,   299] loss: 0.713258\n",
      "[100,   399] loss: 0.703934\n",
      "[100,   499] loss: 0.723909\n",
      "[100,   599] loss: 0.722708\n",
      "[100,   699] loss: 0.744627\n",
      "Finished Training\n",
      "[1,    99] loss: 5.159720\n",
      "[1,   199] loss: 0.773904\n",
      "[1,   299] loss: 0.733163\n",
      "[1,   399] loss: 0.747814\n",
      "[1,   499] loss: 0.720651\n",
      "[1,   599] loss: 0.794786\n",
      "[1,   699] loss: 0.985431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    99] loss: 0.737613\n",
      "[2,   199] loss: 0.698509\n",
      "[2,   299] loss: 0.733332\n",
      "[2,   399] loss: 0.748668\n",
      "[2,   499] loss: 11.069885\n",
      "[2,   599] loss: 0.705443\n",
      "[2,   699] loss: 5.530346\n",
      "[3,    99] loss: 1.514289\n",
      "[3,   199] loss: 0.698509\n",
      "[3,   299] loss: 0.733228\n",
      "[3,   399] loss: 0.748460\n",
      "[3,   499] loss: 0.720922\n",
      "[3,   599] loss: 0.704795\n",
      "[3,   699] loss: 0.717068\n",
      "[4,    99] loss: 0.737897\n",
      "[4,   199] loss: 0.698564\n",
      "[4,   299] loss: 0.733440\n",
      "[4,   399] loss: 0.748876\n",
      "[4,   499] loss: 0.721130\n",
      "[4,   599] loss: 0.704927\n",
      "[4,   699] loss: 0.717156\n",
      "[5,    99] loss: 0.738029\n",
      "[5,   199] loss: 0.698603\n",
      "[5,   299] loss: 0.733531\n",
      "[5,   399] loss: 0.749050\n",
      "[5,   499] loss: 0.721218\n",
      "[5,   599] loss: 0.704984\n",
      "[5,   699] loss: 0.717193\n",
      "[6,    99] loss: 0.738085\n",
      "[6,   199] loss: 0.698620\n",
      "[6,   299] loss: 0.733572\n",
      "[6,   399] loss: 0.749127\n",
      "[6,   499] loss: 0.721257\n",
      "[6,   599] loss: 0.705009\n",
      "[6,   699] loss: 0.717210\n",
      "[7,    99] loss: 0.738111\n",
      "[7,   199] loss: 0.698628\n",
      "[7,   299] loss: 0.733591\n",
      "[7,   399] loss: 0.749162\n",
      "[7,   499] loss: 0.721275\n",
      "[7,   599] loss: 0.705021\n",
      "[7,   699] loss: 0.717218\n",
      "[8,    99] loss: 0.738123\n",
      "[8,   199] loss: 0.698632\n",
      "[8,   299] loss: 0.733599\n",
      "[8,   399] loss: 0.749179\n",
      "[8,   499] loss: 0.721284\n",
      "[8,   599] loss: 0.705026\n",
      "[8,   699] loss: 0.717222\n",
      "[9,    99] loss: 0.738129\n",
      "[9,   199] loss: 0.698634\n",
      "[9,   299] loss: 0.733603\n",
      "[9,   399] loss: 0.749187\n",
      "[9,   499] loss: 0.721288\n",
      "[9,   599] loss: 0.705029\n",
      "[9,   699] loss: 0.717224\n",
      "[10,    99] loss: 0.738131\n",
      "[10,   199] loss: 0.698635\n",
      "[10,   299] loss: 0.733605\n",
      "[10,   399] loss: 0.749190\n",
      "[10,   499] loss: 0.721290\n",
      "[10,   599] loss: 0.705030\n",
      "[10,   699] loss: 0.717224\n",
      "[11,    99] loss: 0.738133\n",
      "[11,   199] loss: 0.698635\n",
      "[11,   299] loss: 0.733606\n",
      "[11,   399] loss: 0.749192\n",
      "[11,   499] loss: 0.721291\n",
      "[11,   599] loss: 0.705031\n",
      "[11,   699] loss: 0.717225\n",
      "[12,    99] loss: 0.738133\n",
      "[12,   199] loss: 0.698635\n",
      "[12,   299] loss: 0.733606\n",
      "[12,   399] loss: 0.749193\n",
      "[12,   499] loss: 0.721291\n",
      "[12,   599] loss: 0.705031\n",
      "[12,   699] loss: 0.717225\n",
      "[13,    99] loss: 0.738134\n",
      "[13,   199] loss: 0.698635\n",
      "[13,   299] loss: 0.733607\n",
      "[13,   399] loss: 0.749193\n",
      "[13,   499] loss: 0.721291\n",
      "[13,   599] loss: 0.705031\n",
      "[13,   699] loss: 0.717225\n",
      "[14,    99] loss: 0.738134\n",
      "[14,   199] loss: 0.698635\n",
      "[14,   299] loss: 0.733607\n",
      "[14,   399] loss: 0.749194\n",
      "[14,   499] loss: 0.721291\n",
      "[14,   599] loss: 0.705031\n",
      "[14,   699] loss: 0.717225\n",
      "[15,    99] loss: 0.738134\n",
      "[15,   199] loss: 0.698635\n",
      "[15,   299] loss: 0.733607\n",
      "[15,   399] loss: 0.749194\n",
      "[15,   499] loss: 0.721291\n",
      "[15,   599] loss: 0.705031\n",
      "[15,   699] loss: 0.717225\n",
      "[16,    99] loss: 0.738134\n",
      "[16,   199] loss: 0.698635\n",
      "[16,   299] loss: 0.733607\n",
      "[16,   399] loss: 0.749194\n",
      "[16,   499] loss: 0.721291\n",
      "[16,   599] loss: 0.705031\n",
      "[16,   699] loss: 0.717225\n",
      "[17,    99] loss: 0.738134\n",
      "[17,   199] loss: 0.698635\n",
      "[17,   299] loss: 0.733607\n",
      "[17,   399] loss: 0.749194\n",
      "[17,   499] loss: 0.721291\n",
      "[17,   599] loss: 0.705031\n",
      "[17,   699] loss: 0.717225\n",
      "[18,    99] loss: 0.738134\n",
      "[18,   199] loss: 0.698635\n",
      "[18,   299] loss: 0.733607\n",
      "[18,   399] loss: 0.749194\n",
      "[18,   499] loss: 0.721291\n",
      "[18,   599] loss: 0.705031\n",
      "[18,   699] loss: 0.717225\n",
      "[19,    99] loss: 0.738134\n",
      "[19,   199] loss: 0.698635\n",
      "[19,   299] loss: 0.733607\n",
      "[19,   399] loss: 0.749194\n",
      "[19,   499] loss: 0.721291\n",
      "[19,   599] loss: 0.705031\n",
      "[19,   699] loss: 0.717225\n",
      "[20,    99] loss: 0.738134\n",
      "[20,   199] loss: 0.698635\n",
      "[20,   299] loss: 0.733607\n",
      "[20,   399] loss: 0.749194\n",
      "[20,   499] loss: 0.721291\n",
      "[20,   599] loss: 0.705031\n",
      "[20,   699] loss: 0.717225\n",
      "[21,    99] loss: 0.738134\n",
      "[21,   199] loss: 0.698635\n",
      "[21,   299] loss: 0.733607\n",
      "[21,   399] loss: 0.749194\n",
      "[21,   499] loss: 0.721291\n",
      "[21,   599] loss: 0.705031\n",
      "[21,   699] loss: 0.717225\n",
      "[22,    99] loss: 0.738134\n",
      "[22,   199] loss: 0.698635\n",
      "[22,   299] loss: 0.733607\n",
      "[22,   399] loss: 0.749194\n",
      "[22,   499] loss: 0.721291\n",
      "[22,   599] loss: 0.705031\n",
      "[22,   699] loss: 0.717225\n",
      "[23,    99] loss: 0.738134\n",
      "[23,   199] loss: 0.698635\n",
      "[23,   299] loss: 0.733607\n",
      "[23,   399] loss: 0.749194\n",
      "[23,   499] loss: 0.721291\n",
      "[23,   599] loss: 0.705031\n",
      "[23,   699] loss: 0.717225\n",
      "[24,    99] loss: 0.738134\n",
      "[24,   199] loss: 0.698635\n",
      "[24,   299] loss: 0.733607\n",
      "[24,   399] loss: 0.749194\n",
      "[24,   499] loss: 0.721291\n",
      "[24,   599] loss: 0.705031\n",
      "[24,   699] loss: 0.717225\n",
      "[25,    99] loss: 0.738134\n",
      "[25,   199] loss: 0.698635\n",
      "[25,   299] loss: 0.733607\n",
      "[25,   399] loss: 0.749194\n",
      "[25,   499] loss: 0.721291\n",
      "[25,   599] loss: 0.705031\n",
      "[25,   699] loss: 0.717225\n",
      "[26,    99] loss: 0.738134\n",
      "[26,   199] loss: 0.698635\n",
      "[26,   299] loss: 0.733607\n",
      "[26,   399] loss: 0.749194\n",
      "[26,   499] loss: 0.721291\n",
      "[26,   599] loss: 0.705031\n",
      "[26,   699] loss: 0.717225\n",
      "[27,    99] loss: 0.738134\n",
      "[27,   199] loss: 0.698635\n",
      "[27,   299] loss: 0.733607\n",
      "[27,   399] loss: 0.749194\n",
      "[27,   499] loss: 0.721291\n",
      "[27,   599] loss: 0.705031\n",
      "[27,   699] loss: 0.717225\n",
      "[28,    99] loss: 0.738134\n",
      "[28,   199] loss: 0.698635\n",
      "[28,   299] loss: 0.733607\n",
      "[28,   399] loss: 0.749194\n",
      "[28,   499] loss: 0.721291\n",
      "[28,   599] loss: 0.705031\n",
      "[28,   699] loss: 0.717225\n",
      "[29,    99] loss: 0.738134\n",
      "[29,   199] loss: 0.698635\n",
      "[29,   299] loss: 0.733607\n",
      "[29,   399] loss: 0.749194\n",
      "[29,   499] loss: 0.721291\n",
      "[29,   599] loss: 0.705031\n",
      "[29,   699] loss: 0.717225\n",
      "[30,    99] loss: 0.738134\n",
      "[30,   199] loss: 0.698635\n",
      "[30,   299] loss: 0.733607\n",
      "[30,   399] loss: 0.749194\n",
      "[30,   499] loss: 0.721291\n",
      "[30,   599] loss: 0.705031\n",
      "[30,   699] loss: 0.717225\n",
      "[31,    99] loss: 0.738134\n",
      "[31,   199] loss: 0.698635\n",
      "[31,   299] loss: 0.733607\n",
      "[31,   399] loss: 0.749194\n",
      "[31,   499] loss: 0.721291\n",
      "[31,   599] loss: 0.705031\n",
      "[31,   699] loss: 0.717225\n",
      "[32,    99] loss: 0.738134\n",
      "[32,   199] loss: 0.698635\n",
      "[32,   299] loss: 0.733607\n",
      "[32,   399] loss: 0.749194\n",
      "[32,   499] loss: 0.721291\n",
      "[32,   599] loss: 0.705031\n",
      "[32,   699] loss: 0.717225\n",
      "[33,    99] loss: 0.738134\n",
      "[33,   199] loss: 0.698635\n",
      "[33,   299] loss: 0.733607\n",
      "[33,   399] loss: 0.749194\n",
      "[33,   499] loss: 0.721291\n",
      "[33,   599] loss: 0.705031\n",
      "[33,   699] loss: 0.717225\n",
      "[34,    99] loss: 0.738134\n",
      "[34,   199] loss: 0.698635\n",
      "[34,   299] loss: 0.733607\n",
      "[34,   399] loss: 0.749194\n",
      "[34,   499] loss: 0.721291\n",
      "[34,   599] loss: 0.705031\n",
      "[34,   699] loss: 0.717225\n",
      "[35,    99] loss: 0.738134\n",
      "[35,   199] loss: 0.698635\n",
      "[35,   299] loss: 0.733607\n",
      "[35,   399] loss: 0.749194\n",
      "[35,   499] loss: 0.721291\n",
      "[35,   599] loss: 0.705031\n",
      "[35,   699] loss: 0.717225\n",
      "[36,    99] loss: 0.738134\n",
      "[36,   199] loss: 0.698635\n",
      "[36,   299] loss: 0.733607\n",
      "[36,   399] loss: 0.749194\n",
      "[36,   499] loss: 0.721291\n",
      "[36,   599] loss: 0.705031\n",
      "[36,   699] loss: 0.717225\n",
      "[37,    99] loss: 0.738134\n",
      "[37,   199] loss: 0.698635\n",
      "[37,   299] loss: 0.733607\n",
      "[37,   399] loss: 0.749194\n",
      "[37,   499] loss: 0.721291\n",
      "[37,   599] loss: 0.705031\n",
      "[37,   699] loss: 0.717225\n",
      "[38,    99] loss: 0.738134\n",
      "[38,   199] loss: 0.698635\n",
      "[38,   299] loss: 0.733607\n",
      "[38,   399] loss: 0.749194\n",
      "[38,   499] loss: 0.721291\n",
      "[38,   599] loss: 0.705031\n",
      "[38,   699] loss: 0.717225\n",
      "[39,    99] loss: 0.738134\n",
      "[39,   199] loss: 0.698635\n",
      "[39,   299] loss: 0.733607\n",
      "[39,   399] loss: 0.749194\n",
      "[39,   499] loss: 0.721291\n",
      "[39,   599] loss: 0.705031\n",
      "[39,   699] loss: 0.717225\n",
      "[40,    99] loss: 0.738134\n",
      "[40,   199] loss: 0.698635\n",
      "[40,   299] loss: 0.733607\n",
      "[40,   399] loss: 0.749194\n",
      "[40,   499] loss: 0.721291\n",
      "[40,   599] loss: 0.705031\n",
      "[40,   699] loss: 0.717225\n",
      "[41,    99] loss: 0.738134\n",
      "[41,   199] loss: 0.698635\n",
      "[41,   299] loss: 0.733607\n",
      "[41,   399] loss: 0.749194\n",
      "[41,   499] loss: 0.721291\n",
      "[41,   599] loss: 0.705031\n",
      "[41,   699] loss: 0.717225\n",
      "[42,    99] loss: 0.738134\n",
      "[42,   199] loss: 0.698635\n",
      "[42,   299] loss: 0.733607\n",
      "[42,   399] loss: 0.749194\n",
      "[42,   499] loss: 0.721291\n",
      "[42,   599] loss: 0.705031\n",
      "[42,   699] loss: 0.717225\n",
      "[43,    99] loss: 0.738134\n",
      "[43,   199] loss: 0.698635\n",
      "[43,   299] loss: 0.733607\n",
      "[43,   399] loss: 0.749194\n",
      "[43,   499] loss: 0.721291\n",
      "[43,   599] loss: 0.705031\n",
      "[43,   699] loss: 0.717225\n",
      "[44,    99] loss: 0.738134\n",
      "[44,   199] loss: 0.698635\n",
      "[44,   299] loss: 0.733607\n",
      "[44,   399] loss: 0.749194\n",
      "[44,   499] loss: 0.721291\n",
      "[44,   599] loss: 0.705031\n",
      "[44,   699] loss: 0.717225\n",
      "[45,    99] loss: 0.738134\n",
      "[45,   199] loss: 0.698635\n",
      "[45,   299] loss: 0.733607\n",
      "[45,   399] loss: 0.749194\n",
      "[45,   499] loss: 0.721291\n",
      "[45,   599] loss: 0.705031\n",
      "[45,   699] loss: 0.717225\n",
      "[46,    99] loss: 0.738134\n",
      "[46,   199] loss: 0.698635\n",
      "[46,   299] loss: 0.733607\n",
      "[46,   399] loss: 0.749194\n",
      "[46,   499] loss: 0.721291\n",
      "[46,   599] loss: 0.705031\n",
      "[46,   699] loss: 0.717225\n",
      "[47,    99] loss: 0.738134\n",
      "[47,   199] loss: 0.698635\n",
      "[47,   299] loss: 0.733607\n",
      "[47,   399] loss: 0.749194\n",
      "[47,   499] loss: 0.721291\n",
      "[47,   599] loss: 0.705031\n",
      "[47,   699] loss: 0.717225\n",
      "[48,    99] loss: 0.738134\n",
      "[48,   199] loss: 0.698635\n",
      "[48,   299] loss: 0.733607\n",
      "[48,   399] loss: 0.749194\n",
      "[48,   499] loss: 0.721291\n",
      "[48,   599] loss: 0.705031\n",
      "[48,   699] loss: 0.717225\n",
      "[49,    99] loss: 0.738134\n",
      "[49,   199] loss: 0.698635\n",
      "[49,   299] loss: 0.733607\n",
      "[49,   399] loss: 0.749194\n",
      "[49,   499] loss: 0.721291\n",
      "[49,   599] loss: 0.705031\n",
      "[49,   699] loss: 0.717225\n",
      "[50,    99] loss: 0.738134\n",
      "[50,   199] loss: 0.698635\n",
      "[50,   299] loss: 0.733607\n",
      "[50,   399] loss: 0.749194\n",
      "[50,   499] loss: 0.721291\n",
      "[50,   599] loss: 0.705031\n",
      "[50,   699] loss: 0.717225\n",
      "[51,    99] loss: 0.738134\n",
      "[51,   199] loss: 0.698635\n",
      "[51,   299] loss: 0.733607\n",
      "[51,   399] loss: 0.749194\n",
      "[51,   499] loss: 0.721291\n",
      "[51,   599] loss: 0.705031\n",
      "[51,   699] loss: 0.717225\n",
      "[52,    99] loss: 0.738134\n",
      "[52,   199] loss: 0.698635\n",
      "[52,   299] loss: 0.733607\n",
      "[52,   399] loss: 0.749194\n",
      "[52,   499] loss: 0.721291\n",
      "[52,   599] loss: 0.705031\n",
      "[52,   699] loss: 0.717225\n",
      "[53,    99] loss: 0.738134\n",
      "[53,   199] loss: 0.698635\n",
      "[53,   299] loss: 0.733607\n",
      "[53,   399] loss: 0.749194\n",
      "[53,   499] loss: 0.721291\n",
      "[53,   599] loss: 0.705031\n",
      "[53,   699] loss: 0.717225\n",
      "[54,    99] loss: 0.738134\n",
      "[54,   199] loss: 0.698635\n",
      "[54,   299] loss: 0.733607\n",
      "[54,   399] loss: 0.749194\n",
      "[54,   499] loss: 0.721291\n",
      "[54,   599] loss: 0.705031\n",
      "[54,   699] loss: 0.717225\n",
      "[55,    99] loss: 0.738134\n",
      "[55,   199] loss: 0.698635\n",
      "[55,   299] loss: 0.733607\n",
      "[55,   399] loss: 0.749194\n",
      "[55,   499] loss: 0.721291\n",
      "[55,   599] loss: 0.705031\n",
      "[55,   699] loss: 0.717225\n",
      "[56,    99] loss: 0.738134\n",
      "[56,   199] loss: 0.698635\n",
      "[56,   299] loss: 0.733607\n",
      "[56,   399] loss: 0.749194\n",
      "[56,   499] loss: 0.721291\n",
      "[56,   599] loss: 0.705031\n",
      "[56,   699] loss: 0.717225\n",
      "[57,    99] loss: 0.738134\n",
      "[57,   199] loss: 0.698635\n",
      "[57,   299] loss: 0.733607\n",
      "[57,   399] loss: 0.749194\n",
      "[57,   499] loss: 0.721291\n",
      "[57,   599] loss: 0.705031\n",
      "[57,   699] loss: 0.717225\n",
      "[58,    99] loss: 0.738134\n",
      "[58,   199] loss: 0.698635\n",
      "[58,   299] loss: 0.733607\n",
      "[58,   399] loss: 0.749194\n",
      "[58,   499] loss: 0.721291\n",
      "[58,   599] loss: 0.705031\n",
      "[58,   699] loss: 0.717225\n",
      "[59,    99] loss: 0.738134\n",
      "[59,   199] loss: 0.698635\n",
      "[59,   299] loss: 0.733607\n",
      "[59,   399] loss: 0.749194\n",
      "[59,   499] loss: 0.721291\n",
      "[59,   599] loss: 0.705031\n",
      "[59,   699] loss: 0.717225\n",
      "[60,    99] loss: 0.738134\n",
      "[60,   199] loss: 0.698635\n",
      "[60,   299] loss: 0.733607\n",
      "[60,   399] loss: 0.749194\n",
      "[60,   499] loss: 0.721291\n",
      "[60,   599] loss: 0.705031\n",
      "[60,   699] loss: 0.717225\n",
      "[61,    99] loss: 0.738134\n",
      "[61,   199] loss: 0.698635\n",
      "[61,   299] loss: 0.733607\n",
      "[61,   399] loss: 0.749194\n",
      "[61,   499] loss: 0.721291\n",
      "[61,   599] loss: 0.705031\n",
      "[61,   699] loss: 0.717225\n",
      "[62,    99] loss: 0.738134\n",
      "[62,   199] loss: 0.698635\n",
      "[62,   299] loss: 0.733607\n",
      "[62,   399] loss: 0.749194\n",
      "[62,   499] loss: 0.721291\n",
      "[62,   599] loss: 0.705031\n",
      "[62,   699] loss: 0.717225\n",
      "[63,    99] loss: 0.738134\n",
      "[63,   199] loss: 0.698635\n",
      "[63,   299] loss: 0.733607\n",
      "[63,   399] loss: 0.749194\n",
      "[63,   499] loss: 0.721291\n",
      "[63,   599] loss: 0.705031\n",
      "[63,   699] loss: 0.717225\n",
      "[64,    99] loss: 0.738134\n",
      "[64,   199] loss: 0.698635\n",
      "[64,   299] loss: 0.733607\n",
      "[64,   399] loss: 0.749194\n",
      "[64,   499] loss: 0.721291\n",
      "[64,   599] loss: 0.705031\n",
      "[64,   699] loss: 0.717225\n",
      "[65,    99] loss: 0.738134\n",
      "[65,   199] loss: 0.698635\n",
      "[65,   299] loss: 0.733607\n",
      "[65,   399] loss: 0.749194\n",
      "[65,   499] loss: 0.721291\n",
      "[65,   599] loss: 0.705031\n",
      "[65,   699] loss: 0.717225\n",
      "[66,    99] loss: 0.738134\n",
      "[66,   199] loss: 0.698635\n",
      "[66,   299] loss: 0.733607\n",
      "[66,   399] loss: 0.749194\n",
      "[66,   499] loss: 0.721291\n",
      "[66,   599] loss: 0.705031\n",
      "[66,   699] loss: 0.717225\n",
      "[67,    99] loss: 0.738134\n",
      "[67,   199] loss: 0.698635\n",
      "[67,   299] loss: 0.733607\n",
      "[67,   399] loss: 0.749194\n",
      "[67,   499] loss: 0.721291\n",
      "[67,   599] loss: 0.705031\n",
      "[67,   699] loss: 0.717225\n",
      "[68,    99] loss: 0.738134\n",
      "[68,   199] loss: 0.698635\n",
      "[68,   299] loss: 0.733607\n",
      "[68,   399] loss: 0.749194\n",
      "[68,   499] loss: 0.721291\n",
      "[68,   599] loss: 0.705031\n",
      "[68,   699] loss: 0.717225\n",
      "[69,    99] loss: 0.738134\n",
      "[69,   199] loss: 0.698635\n",
      "[69,   299] loss: 0.733607\n",
      "[69,   399] loss: 0.749194\n",
      "[69,   499] loss: 0.721291\n",
      "[69,   599] loss: 0.705031\n",
      "[69,   699] loss: 0.717225\n",
      "[70,    99] loss: 0.738134\n",
      "[70,   199] loss: 0.698635\n",
      "[70,   299] loss: 0.733607\n",
      "[70,   399] loss: 0.749194\n",
      "[70,   499] loss: 0.721291\n",
      "[70,   599] loss: 0.705031\n",
      "[70,   699] loss: 0.717225\n",
      "[71,    99] loss: 0.738134\n",
      "[71,   199] loss: 0.698635\n",
      "[71,   299] loss: 0.733607\n",
      "[71,   399] loss: 0.749194\n",
      "[71,   499] loss: 0.721291\n",
      "[71,   599] loss: 0.705031\n",
      "[71,   699] loss: 0.717225\n",
      "[72,    99] loss: 0.738134\n",
      "[72,   199] loss: 0.698635\n",
      "[72,   299] loss: 0.733607\n",
      "[72,   399] loss: 0.749194\n",
      "[72,   499] loss: 0.721291\n",
      "[72,   599] loss: 0.705031\n",
      "[72,   699] loss: 0.717225\n",
      "[73,    99] loss: 0.738134\n",
      "[73,   199] loss: 0.698635\n",
      "[73,   299] loss: 0.733607\n",
      "[73,   399] loss: 0.749194\n",
      "[73,   499] loss: 0.721291\n",
      "[73,   599] loss: 0.705031\n",
      "[73,   699] loss: 0.717225\n",
      "[74,    99] loss: 0.738134\n",
      "[74,   199] loss: 0.698635\n",
      "[74,   299] loss: 0.733607\n",
      "[74,   399] loss: 0.749194\n",
      "[74,   499] loss: 0.721291\n",
      "[74,   599] loss: 0.705031\n",
      "[74,   699] loss: 0.717225\n",
      "[75,    99] loss: 0.738134\n",
      "[75,   199] loss: 0.698635\n",
      "[75,   299] loss: 0.733607\n",
      "[75,   399] loss: 0.749194\n",
      "[75,   499] loss: 0.721291\n",
      "[75,   599] loss: 0.705031\n",
      "[75,   699] loss: 0.717225\n",
      "[76,    99] loss: 0.738134\n",
      "[76,   199] loss: 0.698635\n",
      "[76,   299] loss: 0.733607\n",
      "[76,   399] loss: 0.749194\n",
      "[76,   499] loss: 0.721291\n",
      "[76,   599] loss: 0.705031\n",
      "[76,   699] loss: 0.717225\n",
      "[77,    99] loss: 0.738134\n",
      "[77,   199] loss: 0.698635\n",
      "[77,   299] loss: 0.733607\n",
      "[77,   399] loss: 0.749194\n",
      "[77,   499] loss: 0.721291\n",
      "[77,   599] loss: 0.705031\n",
      "[77,   699] loss: 0.717225\n",
      "[78,    99] loss: 0.738134\n",
      "[78,   199] loss: 0.698635\n",
      "[78,   299] loss: 0.733607\n",
      "[78,   399] loss: 0.749194\n",
      "[78,   499] loss: 0.721291\n",
      "[78,   599] loss: 0.705031\n",
      "[78,   699] loss: 0.717225\n",
      "[79,    99] loss: 0.738134\n",
      "[79,   199] loss: 0.698635\n",
      "[79,   299] loss: 0.733607\n",
      "[79,   399] loss: 0.749194\n",
      "[79,   499] loss: 0.721291\n",
      "[79,   599] loss: 0.705031\n",
      "[79,   699] loss: 0.717225\n",
      "[80,    99] loss: 0.738134\n",
      "[80,   199] loss: 0.698635\n",
      "[80,   299] loss: 0.733607\n",
      "[80,   399] loss: 0.749194\n",
      "[80,   499] loss: 0.721291\n",
      "[80,   599] loss: 0.705031\n",
      "[80,   699] loss: 0.717225\n",
      "[81,    99] loss: 0.738134\n",
      "[81,   199] loss: 0.698635\n",
      "[81,   299] loss: 0.733607\n",
      "[81,   399] loss: 0.749194\n",
      "[81,   499] loss: 0.721291\n",
      "[81,   599] loss: 0.705031\n",
      "[81,   699] loss: 0.717225\n",
      "[82,    99] loss: 0.738134\n",
      "[82,   199] loss: 0.698635\n",
      "[82,   299] loss: 0.733607\n",
      "[82,   399] loss: 0.749194\n",
      "[82,   499] loss: 0.721291\n",
      "[82,   599] loss: 0.705031\n",
      "[82,   699] loss: 0.717225\n",
      "[83,    99] loss: 0.738134\n",
      "[83,   199] loss: 0.698635\n",
      "[83,   299] loss: 0.733607\n",
      "[83,   399] loss: 0.749194\n",
      "[83,   499] loss: 0.721291\n",
      "[83,   599] loss: 0.705031\n",
      "[83,   699] loss: 0.717225\n",
      "[84,    99] loss: 0.738134\n",
      "[84,   199] loss: 0.698635\n",
      "[84,   299] loss: 0.733607\n",
      "[84,   399] loss: 0.749194\n",
      "[84,   499] loss: 0.721291\n",
      "[84,   599] loss: 0.705031\n",
      "[84,   699] loss: 0.717225\n",
      "[85,    99] loss: 0.738134\n",
      "[85,   199] loss: 0.698635\n",
      "[85,   299] loss: 0.733607\n",
      "[85,   399] loss: 0.749194\n",
      "[85,   499] loss: 0.721291\n",
      "[85,   599] loss: 0.705031\n",
      "[85,   699] loss: 0.717225\n",
      "[86,    99] loss: 0.738134\n",
      "[86,   199] loss: 0.698635\n",
      "[86,   299] loss: 0.733607\n",
      "[86,   399] loss: 0.749194\n",
      "[86,   499] loss: 0.721291\n",
      "[86,   599] loss: 0.705031\n",
      "[86,   699] loss: 0.717225\n",
      "[87,    99] loss: 0.738134\n",
      "[87,   199] loss: 0.698635\n",
      "[87,   299] loss: 0.733607\n",
      "[87,   399] loss: 0.749194\n",
      "[87,   499] loss: 0.721291\n",
      "[87,   599] loss: 0.705031\n",
      "[87,   699] loss: 0.717225\n",
      "[88,    99] loss: 0.738134\n",
      "[88,   199] loss: 0.698635\n",
      "[88,   299] loss: 0.733607\n",
      "[88,   399] loss: 0.749194\n",
      "[88,   499] loss: 0.721291\n",
      "[88,   599] loss: 0.705031\n",
      "[88,   699] loss: 0.717225\n",
      "[89,    99] loss: 0.738134\n",
      "[89,   199] loss: 0.698635\n",
      "[89,   299] loss: 0.733607\n",
      "[89,   399] loss: 0.749194\n",
      "[89,   499] loss: 0.721291\n",
      "[89,   599] loss: 0.705031\n",
      "[89,   699] loss: 0.717225\n",
      "[90,    99] loss: 0.738134\n",
      "[90,   199] loss: 0.698635\n",
      "[90,   299] loss: 0.733607\n",
      "[90,   399] loss: 0.749194\n",
      "[90,   499] loss: 0.721291\n",
      "[90,   599] loss: 0.705031\n",
      "[90,   699] loss: 0.717225\n",
      "[91,    99] loss: 0.738134\n",
      "[91,   199] loss: 0.698635\n",
      "[91,   299] loss: 0.733607\n",
      "[91,   399] loss: 0.749194\n",
      "[91,   499] loss: 0.721291\n",
      "[91,   599] loss: 0.705031\n",
      "[91,   699] loss: 0.717225\n",
      "[92,    99] loss: 0.738134\n",
      "[92,   199] loss: 0.698635\n",
      "[92,   299] loss: 0.733607\n",
      "[92,   399] loss: 0.749194\n",
      "[92,   499] loss: 0.721291\n",
      "[92,   599] loss: 0.705031\n",
      "[92,   699] loss: 0.717225\n",
      "[93,    99] loss: 0.738134\n",
      "[93,   199] loss: 0.698635\n",
      "[93,   299] loss: 0.733607\n",
      "[93,   399] loss: 0.749194\n",
      "[93,   499] loss: 0.721291\n",
      "[93,   599] loss: 0.705031\n",
      "[93,   699] loss: 0.717225\n",
      "[94,    99] loss: 0.738134\n",
      "[94,   199] loss: 0.698635\n",
      "[94,   299] loss: 0.733607\n",
      "[94,   399] loss: 0.749194\n",
      "[94,   499] loss: 0.721291\n",
      "[94,   599] loss: 0.705031\n",
      "[94,   699] loss: 0.717225\n",
      "[95,    99] loss: 0.738134\n",
      "[95,   199] loss: 0.698635\n",
      "[95,   299] loss: 0.733607\n",
      "[95,   399] loss: 0.749194\n",
      "[95,   499] loss: 0.721291\n",
      "[95,   599] loss: 0.705031\n",
      "[95,   699] loss: 0.717225\n",
      "[96,    99] loss: 0.738134\n",
      "[96,   199] loss: 0.698635\n",
      "[96,   299] loss: 0.733607\n",
      "[96,   399] loss: 0.749194\n",
      "[96,   499] loss: 0.721291\n",
      "[96,   599] loss: 0.705031\n",
      "[96,   699] loss: 0.717225\n",
      "[97,    99] loss: 0.738134\n",
      "[97,   199] loss: 0.698635\n",
      "[97,   299] loss: 0.733607\n",
      "[97,   399] loss: 0.749194\n",
      "[97,   499] loss: 0.721291\n",
      "[97,   599] loss: 0.705031\n",
      "[97,   699] loss: 0.717225\n",
      "[98,    99] loss: 0.738134\n",
      "[98,   199] loss: 0.698635\n",
      "[98,   299] loss: 0.733607\n",
      "[98,   399] loss: 0.749194\n",
      "[98,   499] loss: 0.721291\n",
      "[98,   599] loss: 0.705031\n",
      "[98,   699] loss: 0.717225\n",
      "[99,    99] loss: 0.738134\n",
      "[99,   199] loss: 0.698635\n",
      "[99,   299] loss: 0.733607\n",
      "[99,   399] loss: 0.749194\n",
      "[99,   499] loss: 0.721291\n",
      "[99,   599] loss: 0.705031\n",
      "[99,   699] loss: 0.717225\n",
      "[100,    99] loss: 0.738134\n",
      "[100,   199] loss: 0.698635\n",
      "[100,   299] loss: 0.733607\n",
      "[100,   399] loss: 0.749194\n",
      "[100,   499] loss: 0.721291\n",
      "[100,   599] loss: 0.705031\n",
      "[100,   699] loss: 0.717225\n",
      "Finished Training\n",
      "[1,    99] loss: 5.622476\n",
      "[1,   199] loss: 0.763649\n",
      "[1,   299] loss: 0.888664\n",
      "[1,   399] loss: 0.706164\n",
      "[1,   499] loss: 0.723724\n",
      "[1,   599] loss: 0.711034\n",
      "[1,   699] loss: 0.707752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    99] loss: 0.740894\n",
      "[2,   199] loss: 0.727266\n",
      "[2,   299] loss: 0.700842\n",
      "[2,   399] loss: 0.706389\n",
      "[2,   499] loss: 0.724403\n",
      "[2,   599] loss: 0.711113\n",
      "[2,   699] loss: 0.708100\n",
      "[3,    99] loss: 0.738956\n",
      "[3,   199] loss: 0.715651\n",
      "[3,   299] loss: 0.702061\n",
      "[3,   399] loss: 0.706517\n",
      "[3,   499] loss: 0.724576\n",
      "[3,   599] loss: 0.711157\n",
      "[3,   699] loss: 0.708211\n",
      "[4,    99] loss: 0.739166\n",
      "[4,   199] loss: 0.715709\n",
      "[4,   299] loss: 0.702105\n",
      "[4,   399] loss: 0.706564\n",
      "[4,   499] loss: 0.724639\n",
      "[4,   599] loss: 0.711173\n",
      "[4,   699] loss: 0.708254\n",
      "[5,    99] loss: 0.739248\n",
      "[5,   199] loss: 0.715732\n",
      "[5,   299] loss: 0.702123\n",
      "[5,   399] loss: 0.706584\n",
      "[5,   499] loss: 0.724665\n",
      "[5,   599] loss: 0.711180\n",
      "[5,   699] loss: 0.708273\n",
      "[6,    99] loss: 0.739285\n",
      "[6,   199] loss: 0.715742\n",
      "[6,   299] loss: 0.702131\n",
      "[6,   399] loss: 0.706593\n",
      "[6,   499] loss: 0.724677\n",
      "[6,   599] loss: 0.711184\n",
      "[6,   699] loss: 0.708281\n",
      "[7,    99] loss: 0.739301\n",
      "[7,   199] loss: 0.715747\n",
      "[7,   299] loss: 0.702135\n",
      "[7,   399] loss: 0.706597\n",
      "[7,   499] loss: 0.724683\n",
      "[7,   599] loss: 0.711185\n",
      "[7,   699] loss: 0.708285\n",
      "[8,    99] loss: 0.739309\n",
      "[8,   199] loss: 0.715749\n",
      "[8,   299] loss: 0.702137\n",
      "[8,   399] loss: 0.706599\n",
      "[8,   499] loss: 0.724686\n",
      "[8,   599] loss: 0.711186\n",
      "[8,   699] loss: 0.708287\n",
      "[9,    99] loss: 0.739313\n",
      "[9,   199] loss: 0.715750\n",
      "[9,   299] loss: 0.702138\n",
      "[9,   399] loss: 0.706600\n",
      "[9,   499] loss: 0.724687\n",
      "[9,   599] loss: 0.711186\n",
      "[9,   699] loss: 0.708288\n",
      "[10,    99] loss: 0.739315\n",
      "[10,   199] loss: 0.715751\n",
      "[10,   299] loss: 0.702138\n",
      "[10,   399] loss: 0.706601\n",
      "[10,   499] loss: 0.724688\n",
      "[10,   599] loss: 0.711186\n",
      "[10,   699] loss: 0.708289\n",
      "[11,    99] loss: 0.739316\n",
      "[11,   199] loss: 0.715751\n",
      "[11,   299] loss: 0.702138\n",
      "[11,   399] loss: 0.706601\n",
      "[11,   499] loss: 0.724688\n",
      "[11,   599] loss: 0.711186\n",
      "[11,   699] loss: 0.708289\n",
      "[12,    99] loss: 0.739316\n",
      "[12,   199] loss: 0.715751\n",
      "[12,   299] loss: 0.702138\n",
      "[12,   399] loss: 0.706601\n",
      "[12,   499] loss: 0.724688\n",
      "[12,   599] loss: 0.711186\n",
      "[12,   699] loss: 0.708289\n",
      "[13,    99] loss: 0.739316\n",
      "[13,   199] loss: 0.715751\n",
      "[13,   299] loss: 0.702138\n",
      "[13,   399] loss: 0.706601\n",
      "[13,   499] loss: 0.724688\n",
      "[13,   599] loss: 0.711186\n",
      "[13,   699] loss: 0.708289\n",
      "[14,    99] loss: 0.739316\n",
      "[14,   199] loss: 0.715751\n",
      "[14,   299] loss: 0.702138\n",
      "[14,   399] loss: 0.706601\n",
      "[14,   499] loss: 0.724688\n",
      "[14,   599] loss: 0.711186\n",
      "[14,   699] loss: 0.708289\n",
      "[15,    99] loss: 0.739317\n",
      "[15,   199] loss: 0.715751\n",
      "[15,   299] loss: 0.702138\n",
      "[15,   399] loss: 0.706601\n",
      "[15,   499] loss: 0.724688\n",
      "[15,   599] loss: 0.711186\n",
      "[15,   699] loss: 0.708289\n",
      "[16,    99] loss: 0.739317\n",
      "[16,   199] loss: 0.715751\n",
      "[16,   299] loss: 0.702138\n",
      "[16,   399] loss: 0.706601\n",
      "[16,   499] loss: 0.724688\n",
      "[16,   599] loss: 0.711186\n",
      "[16,   699] loss: 0.708289\n",
      "[17,    99] loss: 0.739317\n",
      "[17,   199] loss: 0.715751\n",
      "[17,   299] loss: 0.702138\n",
      "[17,   399] loss: 0.706601\n",
      "[17,   499] loss: 0.724688\n",
      "[17,   599] loss: 0.711186\n",
      "[17,   699] loss: 0.708289\n",
      "[18,    99] loss: 0.739317\n",
      "[18,   199] loss: 0.715751\n",
      "[18,   299] loss: 0.702138\n",
      "[18,   399] loss: 0.706601\n",
      "[18,   499] loss: 0.724688\n",
      "[18,   599] loss: 0.711186\n",
      "[18,   699] loss: 0.708289\n",
      "[19,    99] loss: 0.739317\n",
      "[19,   199] loss: 0.715751\n",
      "[19,   299] loss: 0.702138\n",
      "[19,   399] loss: 0.706601\n",
      "[19,   499] loss: 0.724688\n",
      "[19,   599] loss: 0.711186\n",
      "[19,   699] loss: 0.708289\n",
      "[20,    99] loss: 0.739317\n",
      "[20,   199] loss: 0.715751\n",
      "[20,   299] loss: 0.702138\n",
      "[20,   399] loss: 0.706601\n",
      "[20,   499] loss: 0.724688\n",
      "[20,   599] loss: 0.711186\n",
      "[20,   699] loss: 0.708289\n",
      "[21,    99] loss: 0.739317\n",
      "[21,   199] loss: 0.715751\n",
      "[21,   299] loss: 0.702138\n",
      "[21,   399] loss: 0.706601\n",
      "[21,   499] loss: 0.724688\n",
      "[21,   599] loss: 0.711186\n",
      "[21,   699] loss: 0.708289\n",
      "[22,    99] loss: 0.739317\n",
      "[22,   199] loss: 0.715751\n",
      "[22,   299] loss: 0.702138\n",
      "[22,   399] loss: 0.706601\n",
      "[22,   499] loss: 0.724688\n",
      "[22,   599] loss: 0.711186\n",
      "[22,   699] loss: 0.708289\n",
      "[23,    99] loss: 0.739317\n",
      "[23,   199] loss: 0.715751\n",
      "[23,   299] loss: 0.702138\n",
      "[23,   399] loss: 0.706601\n",
      "[23,   499] loss: 0.724688\n",
      "[23,   599] loss: 0.711186\n",
      "[23,   699] loss: 0.708289\n",
      "[24,    99] loss: 0.739317\n",
      "[24,   199] loss: 0.715751\n",
      "[24,   299] loss: 0.702138\n",
      "[24,   399] loss: 0.706601\n",
      "[24,   499] loss: 0.724688\n",
      "[24,   599] loss: 0.711186\n",
      "[24,   699] loss: 0.708289\n",
      "[25,    99] loss: 0.739317\n",
      "[25,   199] loss: 0.715751\n",
      "[25,   299] loss: 0.702138\n",
      "[25,   399] loss: 0.706601\n",
      "[25,   499] loss: 0.724688\n",
      "[25,   599] loss: 0.711186\n",
      "[25,   699] loss: 0.708289\n",
      "[26,    99] loss: 0.739317\n",
      "[26,   199] loss: 0.715751\n",
      "[26,   299] loss: 0.702138\n",
      "[26,   399] loss: 0.706601\n",
      "[26,   499] loss: 0.724688\n",
      "[26,   599] loss: 0.711186\n",
      "[26,   699] loss: 0.708289\n",
      "[27,    99] loss: 0.739317\n",
      "[27,   199] loss: 0.715751\n",
      "[27,   299] loss: 0.702138\n",
      "[27,   399] loss: 0.706601\n",
      "[27,   499] loss: 0.724688\n",
      "[27,   599] loss: 0.711186\n",
      "[27,   699] loss: 0.708289\n",
      "[28,    99] loss: 0.739317\n",
      "[28,   199] loss: 0.715751\n",
      "[28,   299] loss: 0.702138\n",
      "[28,   399] loss: 0.706601\n",
      "[28,   499] loss: 0.724688\n",
      "[28,   599] loss: 0.711186\n",
      "[28,   699] loss: 0.708289\n",
      "[29,    99] loss: 0.739317\n",
      "[29,   199] loss: 0.715751\n",
      "[29,   299] loss: 0.702138\n",
      "[29,   399] loss: 0.706601\n",
      "[29,   499] loss: 0.724688\n",
      "[29,   599] loss: 0.711186\n",
      "[29,   699] loss: 0.708289\n",
      "[30,    99] loss: 0.739317\n",
      "[30,   199] loss: 0.715751\n",
      "[30,   299] loss: 0.702138\n",
      "[30,   399] loss: 0.706601\n",
      "[30,   499] loss: 0.724688\n",
      "[30,   599] loss: 0.711186\n",
      "[30,   699] loss: 0.708289\n",
      "[31,    99] loss: 0.739317\n",
      "[31,   199] loss: 0.715751\n",
      "[31,   299] loss: 0.702138\n",
      "[31,   399] loss: 0.706601\n",
      "[31,   499] loss: 0.724688\n",
      "[31,   599] loss: 0.711186\n",
      "[31,   699] loss: 0.708289\n",
      "[32,    99] loss: 0.739317\n",
      "[32,   199] loss: 0.715751\n",
      "[32,   299] loss: 0.702138\n",
      "[32,   399] loss: 0.706601\n",
      "[32,   499] loss: 0.724688\n",
      "[32,   599] loss: 0.711186\n",
      "[32,   699] loss: 0.708289\n",
      "[33,    99] loss: 0.739317\n",
      "[33,   199] loss: 0.715751\n",
      "[33,   299] loss: 0.702138\n",
      "[33,   399] loss: 0.706601\n",
      "[33,   499] loss: 0.724688\n",
      "[33,   599] loss: 0.711186\n",
      "[33,   699] loss: 0.708289\n",
      "[34,    99] loss: 0.739317\n",
      "[34,   199] loss: 0.715751\n",
      "[34,   299] loss: 0.702138\n",
      "[34,   399] loss: 0.706601\n",
      "[34,   499] loss: 0.724688\n",
      "[34,   599] loss: 0.711186\n",
      "[34,   699] loss: 0.708289\n",
      "[35,    99] loss: 0.739317\n",
      "[35,   199] loss: 0.715751\n",
      "[35,   299] loss: 0.702138\n",
      "[35,   399] loss: 0.706601\n",
      "[35,   499] loss: 0.724688\n",
      "[35,   599] loss: 0.711186\n",
      "[35,   699] loss: 0.708289\n",
      "[36,    99] loss: 0.739317\n",
      "[36,   199] loss: 0.715751\n",
      "[36,   299] loss: 0.702138\n",
      "[36,   399] loss: 0.706601\n",
      "[36,   499] loss: 0.724688\n",
      "[36,   599] loss: 0.711186\n",
      "[36,   699] loss: 0.708289\n",
      "[37,    99] loss: 0.739317\n",
      "[37,   199] loss: 0.715751\n",
      "[37,   299] loss: 0.702138\n",
      "[37,   399] loss: 0.706601\n",
      "[37,   499] loss: 0.724688\n",
      "[37,   599] loss: 0.711186\n",
      "[37,   699] loss: 0.708289\n",
      "[38,    99] loss: 0.739317\n",
      "[38,   199] loss: 0.715751\n",
      "[38,   299] loss: 0.702138\n",
      "[38,   399] loss: 0.706601\n",
      "[38,   499] loss: 0.724688\n",
      "[38,   599] loss: 0.711186\n",
      "[38,   699] loss: 0.708289\n",
      "[39,    99] loss: 0.739317\n",
      "[39,   199] loss: 0.715751\n",
      "[39,   299] loss: 0.702138\n",
      "[39,   399] loss: 0.706601\n",
      "[39,   499] loss: 0.724688\n",
      "[39,   599] loss: 0.711186\n",
      "[39,   699] loss: 0.708289\n",
      "[40,    99] loss: 0.739317\n",
      "[40,   199] loss: 0.715751\n",
      "[40,   299] loss: 0.702138\n",
      "[40,   399] loss: 0.706601\n",
      "[40,   499] loss: 0.724688\n",
      "[40,   599] loss: 0.711186\n",
      "[40,   699] loss: 0.708289\n",
      "[41,    99] loss: 0.739317\n",
      "[41,   199] loss: 0.715751\n",
      "[41,   299] loss: 0.702138\n",
      "[41,   399] loss: 0.706601\n",
      "[41,   499] loss: 0.724688\n",
      "[41,   599] loss: 0.711186\n",
      "[41,   699] loss: 0.708289\n",
      "[42,    99] loss: 0.739317\n",
      "[42,   199] loss: 0.715751\n",
      "[42,   299] loss: 0.702138\n",
      "[42,   399] loss: 0.706601\n",
      "[42,   499] loss: 0.724688\n",
      "[42,   599] loss: 0.711186\n",
      "[42,   699] loss: 0.708289\n",
      "[43,    99] loss: 0.739317\n",
      "[43,   199] loss: 0.715751\n",
      "[43,   299] loss: 0.702138\n",
      "[43,   399] loss: 0.706601\n",
      "[43,   499] loss: 0.724688\n",
      "[43,   599] loss: 0.711186\n",
      "[43,   699] loss: 0.708289\n",
      "[44,    99] loss: 0.739317\n",
      "[44,   199] loss: 0.715751\n",
      "[44,   299] loss: 0.702138\n",
      "[44,   399] loss: 0.706601\n",
      "[44,   499] loss: 0.724688\n",
      "[44,   599] loss: 0.711186\n",
      "[44,   699] loss: 0.708289\n",
      "[45,    99] loss: 0.739317\n",
      "[45,   199] loss: 0.715751\n",
      "[45,   299] loss: 0.702138\n",
      "[45,   399] loss: 0.706601\n",
      "[45,   499] loss: 0.724688\n",
      "[45,   599] loss: 0.711186\n",
      "[45,   699] loss: 0.708289\n",
      "[46,    99] loss: 0.739317\n",
      "[46,   199] loss: 0.715751\n",
      "[46,   299] loss: 0.702138\n",
      "[46,   399] loss: 0.706601\n",
      "[46,   499] loss: 0.724688\n",
      "[46,   599] loss: 0.711186\n",
      "[46,   699] loss: 0.708289\n",
      "[47,    99] loss: 0.739317\n",
      "[47,   199] loss: 0.715751\n",
      "[47,   299] loss: 0.702138\n",
      "[47,   399] loss: 0.706601\n",
      "[47,   499] loss: 0.724688\n",
      "[47,   599] loss: 0.711186\n",
      "[47,   699] loss: 0.708289\n",
      "[48,    99] loss: 0.739317\n",
      "[48,   199] loss: 0.715751\n",
      "[48,   299] loss: 0.702138\n",
      "[48,   399] loss: 0.706601\n",
      "[48,   499] loss: 0.724688\n",
      "[48,   599] loss: 0.711186\n",
      "[48,   699] loss: 0.708289\n",
      "[49,    99] loss: 0.739317\n",
      "[49,   199] loss: 0.715751\n",
      "[49,   299] loss: 0.702138\n",
      "[49,   399] loss: 0.706601\n",
      "[49,   499] loss: 0.724688\n",
      "[49,   599] loss: 0.711186\n",
      "[49,   699] loss: 0.708289\n",
      "[50,    99] loss: 0.739317\n",
      "[50,   199] loss: 0.715751\n",
      "[50,   299] loss: 0.702138\n",
      "[50,   399] loss: 0.706601\n",
      "[50,   499] loss: 0.724688\n",
      "[50,   599] loss: 0.711186\n",
      "[50,   699] loss: 0.708289\n",
      "[51,    99] loss: 0.739317\n",
      "[51,   199] loss: 0.715751\n",
      "[51,   299] loss: 0.702138\n",
      "[51,   399] loss: 0.706601\n",
      "[51,   499] loss: 0.724688\n",
      "[51,   599] loss: 0.711186\n",
      "[51,   699] loss: 0.708289\n",
      "[52,    99] loss: 0.739317\n",
      "[52,   199] loss: 0.715751\n",
      "[52,   299] loss: 0.702138\n",
      "[52,   399] loss: 0.706601\n",
      "[52,   499] loss: 0.724688\n",
      "[52,   599] loss: 0.711186\n",
      "[52,   699] loss: 0.708289\n",
      "[53,    99] loss: 0.739317\n",
      "[53,   199] loss: 0.715751\n",
      "[53,   299] loss: 0.702138\n",
      "[53,   399] loss: 0.706601\n",
      "[53,   499] loss: 0.724688\n",
      "[53,   599] loss: 0.711186\n",
      "[53,   699] loss: 0.708289\n",
      "[54,    99] loss: 0.739317\n",
      "[54,   199] loss: 0.715751\n",
      "[54,   299] loss: 0.702138\n",
      "[54,   399] loss: 0.706601\n",
      "[54,   499] loss: 0.724688\n",
      "[54,   599] loss: 0.711186\n",
      "[54,   699] loss: 0.708289\n",
      "[55,    99] loss: 0.739317\n",
      "[55,   199] loss: 0.715751\n",
      "[55,   299] loss: 0.702138\n",
      "[55,   399] loss: 0.706601\n",
      "[55,   499] loss: 0.724688\n",
      "[55,   599] loss: 0.711186\n",
      "[55,   699] loss: 0.708289\n",
      "[56,    99] loss: 0.739317\n",
      "[56,   199] loss: 0.715751\n",
      "[56,   299] loss: 0.702138\n",
      "[56,   399] loss: 0.706601\n",
      "[56,   499] loss: 0.724688\n",
      "[56,   599] loss: 0.711186\n",
      "[56,   699] loss: 0.708289\n",
      "[57,    99] loss: 0.739317\n",
      "[57,   199] loss: 0.715751\n",
      "[57,   299] loss: 0.702138\n",
      "[57,   399] loss: 0.706601\n",
      "[57,   499] loss: 0.724688\n",
      "[57,   599] loss: 0.711186\n",
      "[57,   699] loss: 0.708289\n",
      "[58,    99] loss: 0.739317\n",
      "[58,   199] loss: 0.715751\n",
      "[58,   299] loss: 0.702138\n",
      "[58,   399] loss: 0.706601\n",
      "[58,   499] loss: 0.724688\n",
      "[58,   599] loss: 0.711186\n",
      "[58,   699] loss: 0.708289\n",
      "[59,    99] loss: 0.739317\n",
      "[59,   199] loss: 0.715751\n",
      "[59,   299] loss: 0.702138\n",
      "[59,   399] loss: 0.706601\n",
      "[59,   499] loss: 0.724688\n",
      "[59,   599] loss: 0.711186\n",
      "[59,   699] loss: 0.708289\n",
      "[60,    99] loss: 0.739317\n",
      "[60,   199] loss: 0.715751\n",
      "[60,   299] loss: 0.702138\n",
      "[60,   399] loss: 0.706601\n",
      "[60,   499] loss: 0.724688\n",
      "[60,   599] loss: 0.711186\n",
      "[60,   699] loss: 0.708289\n",
      "[61,    99] loss: 0.739317\n",
      "[61,   199] loss: 0.715751\n",
      "[61,   299] loss: 0.702138\n",
      "[61,   399] loss: 0.706601\n",
      "[61,   499] loss: 0.724688\n",
      "[61,   599] loss: 0.711186\n",
      "[61,   699] loss: 0.708289\n",
      "[62,    99] loss: 0.739317\n",
      "[62,   199] loss: 0.715751\n",
      "[62,   299] loss: 0.702138\n",
      "[62,   399] loss: 0.706601\n",
      "[62,   499] loss: 0.724688\n",
      "[62,   599] loss: 0.711186\n",
      "[62,   699] loss: 0.708289\n",
      "[63,    99] loss: 0.739317\n",
      "[63,   199] loss: 0.715751\n",
      "[63,   299] loss: 0.702138\n",
      "[63,   399] loss: 0.706601\n",
      "[63,   499] loss: 0.724688\n",
      "[63,   599] loss: 0.711186\n",
      "[63,   699] loss: 0.708289\n",
      "[64,    99] loss: 0.739317\n",
      "[64,   199] loss: 0.715751\n",
      "[64,   299] loss: 0.702138\n",
      "[64,   399] loss: 0.706601\n",
      "[64,   499] loss: 0.724688\n",
      "[64,   599] loss: 0.711186\n",
      "[64,   699] loss: 0.708289\n",
      "[65,    99] loss: 0.739317\n",
      "[65,   199] loss: 0.715751\n",
      "[65,   299] loss: 0.702138\n",
      "[65,   399] loss: 0.706601\n",
      "[65,   499] loss: 0.724688\n",
      "[65,   599] loss: 0.711186\n",
      "[65,   699] loss: 0.708289\n",
      "[66,    99] loss: 0.739317\n",
      "[66,   199] loss: 0.715751\n",
      "[66,   299] loss: 0.702138\n",
      "[66,   399] loss: 0.706601\n",
      "[66,   499] loss: 0.724688\n",
      "[66,   599] loss: 0.711186\n",
      "[66,   699] loss: 0.708289\n",
      "[67,    99] loss: 0.739317\n",
      "[67,   199] loss: 0.715751\n",
      "[67,   299] loss: 0.702138\n",
      "[67,   399] loss: 0.706601\n",
      "[67,   499] loss: 0.724688\n",
      "[67,   599] loss: 0.711186\n",
      "[67,   699] loss: 0.708289\n",
      "[68,    99] loss: 0.739317\n",
      "[68,   199] loss: 0.715751\n",
      "[68,   299] loss: 0.702138\n",
      "[68,   399] loss: 0.706601\n",
      "[68,   499] loss: 0.724688\n",
      "[68,   599] loss: 0.711186\n",
      "[68,   699] loss: 0.708289\n",
      "[69,    99] loss: 0.739317\n",
      "[69,   199] loss: 0.715751\n",
      "[69,   299] loss: 0.702138\n",
      "[69,   399] loss: 0.706601\n",
      "[69,   499] loss: 0.724688\n",
      "[69,   599] loss: 0.711186\n",
      "[69,   699] loss: 0.708289\n",
      "[70,    99] loss: 0.739317\n",
      "[70,   199] loss: 0.715751\n",
      "[70,   299] loss: 0.702138\n",
      "[70,   399] loss: 0.706601\n",
      "[70,   499] loss: 0.724688\n",
      "[70,   599] loss: 0.711186\n",
      "[70,   699] loss: 0.708289\n",
      "[71,    99] loss: 0.739317\n",
      "[71,   199] loss: 0.715751\n",
      "[71,   299] loss: 0.702138\n",
      "[71,   399] loss: 0.706601\n",
      "[71,   499] loss: 0.724688\n",
      "[71,   599] loss: 0.711186\n",
      "[71,   699] loss: 0.708289\n",
      "[72,    99] loss: 0.739317\n",
      "[72,   199] loss: 0.715751\n",
      "[72,   299] loss: 0.702138\n",
      "[72,   399] loss: 0.706601\n",
      "[72,   499] loss: 0.724688\n",
      "[72,   599] loss: 0.711186\n",
      "[72,   699] loss: 0.708289\n",
      "[73,    99] loss: 0.739317\n",
      "[73,   199] loss: 0.715751\n",
      "[73,   299] loss: 0.702138\n",
      "[73,   399] loss: 0.706601\n",
      "[73,   499] loss: 0.724688\n",
      "[73,   599] loss: 0.711186\n",
      "[73,   699] loss: 0.708289\n",
      "[74,    99] loss: 0.739317\n",
      "[74,   199] loss: 0.715751\n",
      "[74,   299] loss: 0.702138\n",
      "[74,   399] loss: 0.706601\n",
      "[74,   499] loss: 0.724688\n",
      "[74,   599] loss: 0.711186\n",
      "[74,   699] loss: 0.708289\n",
      "[75,    99] loss: 0.739317\n",
      "[75,   199] loss: 0.715751\n",
      "[75,   299] loss: 0.702138\n",
      "[75,   399] loss: 0.706601\n",
      "[75,   499] loss: 0.724688\n",
      "[75,   599] loss: 0.711186\n",
      "[75,   699] loss: 0.708289\n",
      "[76,    99] loss: 0.739317\n",
      "[76,   199] loss: 0.715751\n",
      "[76,   299] loss: 0.702138\n",
      "[76,   399] loss: 0.706601\n",
      "[76,   499] loss: 0.724688\n",
      "[76,   599] loss: 0.711186\n",
      "[76,   699] loss: 0.708289\n",
      "[77,    99] loss: 0.739317\n",
      "[77,   199] loss: 0.715751\n",
      "[77,   299] loss: 0.702138\n",
      "[77,   399] loss: 0.706601\n",
      "[77,   499] loss: 0.724688\n",
      "[77,   599] loss: 0.711186\n",
      "[77,   699] loss: 0.708289\n",
      "[78,    99] loss: 0.739317\n",
      "[78,   199] loss: 0.715751\n",
      "[78,   299] loss: 0.702138\n",
      "[78,   399] loss: 0.706601\n",
      "[78,   499] loss: 0.724688\n",
      "[78,   599] loss: 0.711186\n",
      "[78,   699] loss: 0.708289\n",
      "[79,    99] loss: 0.739317\n",
      "[79,   199] loss: 0.715751\n",
      "[79,   299] loss: 0.702138\n",
      "[79,   399] loss: 0.706601\n",
      "[79,   499] loss: 0.724688\n",
      "[79,   599] loss: 0.711186\n",
      "[79,   699] loss: 0.708289\n",
      "[80,    99] loss: 0.739317\n",
      "[80,   199] loss: 0.715751\n",
      "[80,   299] loss: 0.702138\n",
      "[80,   399] loss: 0.706601\n",
      "[80,   499] loss: 0.724688\n",
      "[80,   599] loss: 0.711186\n",
      "[80,   699] loss: 0.708289\n",
      "[81,    99] loss: 0.739317\n",
      "[81,   199] loss: 0.715751\n",
      "[81,   299] loss: 0.702138\n",
      "[81,   399] loss: 0.706601\n",
      "[81,   499] loss: 0.724688\n",
      "[81,   599] loss: 0.711186\n",
      "[81,   699] loss: 0.708289\n",
      "[82,    99] loss: 0.739317\n",
      "[82,   199] loss: 0.715751\n",
      "[82,   299] loss: 0.702138\n",
      "[82,   399] loss: 0.706601\n",
      "[82,   499] loss: 0.724688\n",
      "[82,   599] loss: 0.711186\n",
      "[82,   699] loss: 0.708289\n",
      "[83,    99] loss: 0.739317\n",
      "[83,   199] loss: 0.715751\n",
      "[83,   299] loss: 0.702138\n",
      "[83,   399] loss: 0.706601\n",
      "[83,   499] loss: 0.724688\n",
      "[83,   599] loss: 0.711186\n",
      "[83,   699] loss: 0.708289\n",
      "[84,    99] loss: 0.739317\n",
      "[84,   199] loss: 0.715751\n",
      "[84,   299] loss: 0.702138\n",
      "[84,   399] loss: 0.706601\n",
      "[84,   499] loss: 0.724688\n",
      "[84,   599] loss: 0.711186\n",
      "[84,   699] loss: 0.708289\n",
      "[85,    99] loss: 0.739317\n",
      "[85,   199] loss: 0.715751\n",
      "[85,   299] loss: 0.702138\n",
      "[85,   399] loss: 0.706601\n",
      "[85,   499] loss: 0.724688\n",
      "[85,   599] loss: 0.711186\n",
      "[85,   699] loss: 0.708289\n",
      "[86,    99] loss: 0.739317\n",
      "[86,   199] loss: 0.715751\n",
      "[86,   299] loss: 0.702138\n",
      "[86,   399] loss: 0.706601\n",
      "[86,   499] loss: 0.724688\n",
      "[86,   599] loss: 0.711186\n",
      "[86,   699] loss: 0.708289\n",
      "[87,    99] loss: 0.739317\n",
      "[87,   199] loss: 0.715751\n",
      "[87,   299] loss: 0.702138\n",
      "[87,   399] loss: 0.706601\n",
      "[87,   499] loss: 0.724688\n",
      "[87,   599] loss: 0.711186\n",
      "[87,   699] loss: 0.708289\n",
      "[88,    99] loss: 0.739317\n",
      "[88,   199] loss: 0.715751\n",
      "[88,   299] loss: 0.702138\n",
      "[88,   399] loss: 0.706601\n",
      "[88,   499] loss: 0.724688\n",
      "[88,   599] loss: 0.711186\n",
      "[88,   699] loss: 0.708289\n",
      "[89,    99] loss: 0.739317\n",
      "[89,   199] loss: 0.715751\n",
      "[89,   299] loss: 0.702138\n",
      "[89,   399] loss: 0.706601\n",
      "[89,   499] loss: 0.724688\n",
      "[89,   599] loss: 0.711186\n",
      "[89,   699] loss: 0.708289\n",
      "[90,    99] loss: 0.739317\n",
      "[90,   199] loss: 0.715751\n",
      "[90,   299] loss: 0.702138\n",
      "[90,   399] loss: 0.706601\n",
      "[90,   499] loss: 0.724688\n",
      "[90,   599] loss: 0.711186\n",
      "[90,   699] loss: 0.708289\n",
      "[91,    99] loss: 0.739317\n",
      "[91,   199] loss: 0.715751\n",
      "[91,   299] loss: 0.702138\n",
      "[91,   399] loss: 0.706601\n",
      "[91,   499] loss: 0.724688\n",
      "[91,   599] loss: 0.711186\n",
      "[91,   699] loss: 0.708289\n",
      "[92,    99] loss: 0.739317\n",
      "[92,   199] loss: 0.715751\n",
      "[92,   299] loss: 0.702138\n",
      "[92,   399] loss: 0.706601\n",
      "[92,   499] loss: 0.724688\n",
      "[92,   599] loss: 0.711186\n",
      "[92,   699] loss: 0.708289\n",
      "[93,    99] loss: 0.739317\n",
      "[93,   199] loss: 0.715751\n",
      "[93,   299] loss: 0.702138\n",
      "[93,   399] loss: 0.706601\n",
      "[93,   499] loss: 0.724688\n",
      "[93,   599] loss: 0.711186\n",
      "[93,   699] loss: 0.708289\n",
      "[94,    99] loss: 0.739317\n",
      "[94,   199] loss: 0.715751\n",
      "[94,   299] loss: 0.702138\n",
      "[94,   399] loss: 0.706601\n",
      "[94,   499] loss: 0.724688\n",
      "[94,   599] loss: 0.711186\n",
      "[94,   699] loss: 0.708289\n",
      "[95,    99] loss: 0.739317\n",
      "[95,   199] loss: 0.715751\n",
      "[95,   299] loss: 0.702138\n",
      "[95,   399] loss: 0.706601\n",
      "[95,   499] loss: 0.724688\n",
      "[95,   599] loss: 0.711186\n",
      "[95,   699] loss: 0.708289\n",
      "[96,    99] loss: 0.739317\n",
      "[96,   199] loss: 0.715751\n",
      "[96,   299] loss: 0.702138\n",
      "[96,   399] loss: 0.706601\n",
      "[96,   499] loss: 0.724688\n",
      "[96,   599] loss: 0.711186\n",
      "[96,   699] loss: 0.708289\n",
      "[97,    99] loss: 0.739317\n",
      "[97,   199] loss: 0.715751\n",
      "[97,   299] loss: 0.702138\n",
      "[97,   399] loss: 0.706601\n",
      "[97,   499] loss: 0.724688\n",
      "[97,   599] loss: 0.711186\n",
      "[97,   699] loss: 0.708289\n",
      "[98,    99] loss: 0.739317\n",
      "[98,   199] loss: 0.715751\n",
      "[98,   299] loss: 0.702138\n",
      "[98,   399] loss: 0.706601\n",
      "[98,   499] loss: 0.724688\n",
      "[98,   599] loss: 0.711186\n",
      "[98,   699] loss: 0.708289\n",
      "[99,    99] loss: 0.739317\n",
      "[99,   199] loss: 0.715751\n",
      "[99,   299] loss: 0.702138\n",
      "[99,   399] loss: 0.706601\n",
      "[99,   499] loss: 0.724688\n",
      "[99,   599] loss: 0.711186\n",
      "[99,   699] loss: 0.708289\n",
      "[100,    99] loss: 0.739317\n",
      "[100,   199] loss: 0.715751\n",
      "[100,   299] loss: 0.702138\n",
      "[100,   399] loss: 0.706601\n",
      "[100,   499] loss: 0.724688\n",
      "[100,   599] loss: 0.711186\n",
      "[100,   699] loss: 0.708289\n",
      "Finished Training\n",
      "[1,    99] loss: 0.782196\n",
      "[1,   199] loss: 0.697100\n",
      "[1,   299] loss: 0.620085\n",
      "[1,   399] loss: 0.763172\n",
      "[1,   499] loss: 0.709120\n",
      "[1,   599] loss: 0.710492\n",
      "[1,   699] loss: 0.745199\n",
      "[2,    99] loss: 0.649397\n",
      "[2,   199] loss: 0.610455\n",
      "[2,   299] loss: 0.518733\n",
      "[2,   399] loss: 0.647863\n",
      "[2,   499] loss: 0.638715\n",
      "[2,   599] loss: 0.636882\n",
      "[2,   699] loss: 0.740548\n",
      "[3,    99] loss: 0.585295\n",
      "[3,   199] loss: 0.584907\n",
      "[3,   299] loss: 0.487038\n",
      "[3,   399] loss: 0.766561\n",
      "[3,   499] loss: 0.640949\n",
      "[3,   599] loss: 0.629900\n",
      "[3,   699] loss: 0.630609\n",
      "[4,    99] loss: 0.547395\n",
      "[4,   199] loss: 0.539798\n",
      "[4,   299] loss: 0.508769\n",
      "[4,   399] loss: 0.685622\n",
      "[4,   499] loss: 0.610278\n",
      "[4,   599] loss: 0.600758\n",
      "[4,   699] loss: 0.560198\n",
      "[5,    99] loss: 0.516051\n",
      "[5,   199] loss: 0.523647\n",
      "[5,   299] loss: 0.619935\n",
      "[5,   399] loss: 0.842949\n",
      "[5,   499] loss: 0.594976\n",
      "[5,   599] loss: 0.584293\n",
      "[5,   699] loss: 0.597987\n",
      "[6,    99] loss: 0.538674\n",
      "[6,   199] loss: 0.475127\n",
      "[6,   299] loss: 0.469294\n",
      "[6,   399] loss: 0.715909\n",
      "[6,   499] loss: 0.652213\n",
      "[6,   599] loss: 0.582580\n",
      "[6,   699] loss: 0.501096\n",
      "[7,    99] loss: 0.545269\n",
      "[7,   199] loss: 0.464890\n",
      "[7,   299] loss: 0.445728\n",
      "[7,   399] loss: 0.632344\n",
      "[7,   499] loss: 0.505474\n",
      "[7,   599] loss: 0.473540\n",
      "[7,   699] loss: 0.424802\n",
      "[8,    99] loss: 0.550590\n",
      "[8,   199] loss: 0.436517\n",
      "[8,   299] loss: 0.433362\n",
      "[8,   399] loss: 0.609732\n",
      "[8,   499] loss: 0.501574\n",
      "[8,   599] loss: 0.475903\n",
      "[8,   699] loss: 0.548143\n",
      "[9,    99] loss: 0.534356\n",
      "[9,   199] loss: 0.405475\n",
      "[9,   299] loss: 0.385468\n",
      "[9,   399] loss: 0.662176\n",
      "[9,   499] loss: 0.647727\n",
      "[9,   599] loss: 0.474509\n",
      "[9,   699] loss: 0.431108\n",
      "[10,    99] loss: 0.499603\n",
      "[10,   199] loss: 0.356926\n",
      "[10,   299] loss: 0.357302\n",
      "[10,   399] loss: 0.604629\n",
      "[10,   499] loss: 0.506780\n",
      "[10,   599] loss: 0.448621\n",
      "[10,   699] loss: 0.373806\n",
      "[11,    99] loss: 0.476383\n",
      "[11,   199] loss: 0.378532\n",
      "[11,   299] loss: 0.385293\n",
      "[11,   399] loss: 0.558909\n",
      "[11,   499] loss: 0.644918\n",
      "[11,   599] loss: 0.419713\n",
      "[11,   699] loss: 0.324669\n",
      "[12,    99] loss: 0.395801\n",
      "[12,   199] loss: 0.350775\n",
      "[12,   299] loss: 0.314076\n",
      "[12,   399] loss: 0.519310\n",
      "[12,   499] loss: 0.483814\n",
      "[12,   599] loss: 0.391991\n",
      "[12,   699] loss: 0.341740\n",
      "[13,    99] loss: 0.463929\n",
      "[13,   199] loss: 0.561255\n",
      "[13,   299] loss: 0.497933\n",
      "[13,   399] loss: 0.501069\n",
      "[13,   499] loss: 0.430092\n",
      "[13,   599] loss: 0.414734\n",
      "[13,   699] loss: 0.300231\n",
      "[14,    99] loss: 0.440134\n",
      "[14,   199] loss: 0.362207\n",
      "[14,   299] loss: 0.279895\n",
      "[14,   399] loss: 0.863860\n",
      "[14,   499] loss: 0.391524\n",
      "[14,   599] loss: 0.348663\n",
      "[14,   699] loss: 0.302086\n",
      "[15,    99] loss: 0.351827\n",
      "[15,   199] loss: 0.400087\n",
      "[15,   299] loss: 0.384715\n",
      "[15,   399] loss: 0.385851\n",
      "[15,   499] loss: 0.446051\n",
      "[15,   599] loss: 0.413306\n",
      "[15,   699] loss: 0.270069\n",
      "[16,    99] loss: 0.349712\n",
      "[16,   199] loss: 0.291006\n",
      "[16,   299] loss: 0.307824\n",
      "[16,   399] loss: 0.632521\n",
      "[16,   499] loss: 0.378388\n",
      "[16,   599] loss: 0.354147\n",
      "[16,   699] loss: 0.300411\n",
      "[17,    99] loss: 0.292072\n",
      "[17,   199] loss: 0.229757\n",
      "[17,   299] loss: 0.264595\n",
      "[17,   399] loss: 0.460382\n",
      "[17,   499] loss: 0.411819\n",
      "[17,   599] loss: 0.327262\n",
      "[17,   699] loss: 0.339685\n",
      "[18,    99] loss: 0.291030\n",
      "[18,   199] loss: 0.302241\n",
      "[18,   299] loss: 0.333577\n",
      "[18,   399] loss: 0.474360\n",
      "[18,   499] loss: 0.399994\n",
      "[18,   599] loss: 0.296185\n",
      "[18,   699] loss: 0.285582\n",
      "[19,    99] loss: 0.285184\n",
      "[19,   199] loss: 0.308192\n",
      "[19,   299] loss: 0.442393\n",
      "[19,   399] loss: 0.861389\n",
      "[19,   499] loss: 0.638638\n",
      "[19,   599] loss: 0.357072\n",
      "[19,   699] loss: 0.317462\n",
      "[20,    99] loss: 0.320982\n",
      "[20,   199] loss: 0.256713\n",
      "[20,   299] loss: 0.268188\n",
      "[20,   399] loss: 0.487863\n",
      "[20,   499] loss: 0.373139\n",
      "[20,   599] loss: 0.328574\n",
      "[20,   699] loss: 0.249512\n",
      "[21,    99] loss: 0.330265\n",
      "[21,   199] loss: 0.262101\n",
      "[21,   299] loss: 0.254949\n",
      "[21,   399] loss: 0.972410\n",
      "[21,   499] loss: 0.488133\n",
      "[21,   599] loss: 0.324591\n",
      "[21,   699] loss: 0.276588\n",
      "[22,    99] loss: 0.274190\n",
      "[22,   199] loss: 0.183628\n",
      "[22,   299] loss: 0.883799\n",
      "[22,   399] loss: 0.401575\n",
      "[22,   499] loss: 0.368677\n",
      "[22,   599] loss: 0.252445\n",
      "[22,   699] loss: 0.221685\n",
      "[23,    99] loss: 0.305295\n",
      "[23,   199] loss: 0.282021\n",
      "[23,   299] loss: 0.271393\n",
      "[23,   399] loss: 0.504549\n",
      "[23,   499] loss: 0.317390\n",
      "[23,   599] loss: 0.259638\n",
      "[23,   699] loss: 0.173148\n",
      "[24,    99] loss: 0.329144\n",
      "[24,   199] loss: 0.311726\n",
      "[24,   299] loss: 0.216096\n",
      "[24,   399] loss: 0.477647\n",
      "[24,   499] loss: 0.371707\n",
      "[24,   599] loss: 0.262504\n",
      "[24,   699] loss: 0.171065\n",
      "[25,    99] loss: 0.249932\n",
      "[25,   199] loss: 0.224340\n",
      "[25,   299] loss: 0.199299\n",
      "[25,   399] loss: 0.241086\n",
      "[25,   499] loss: 0.421896\n",
      "[25,   599] loss: 0.279297\n",
      "[25,   699] loss: 0.224555\n",
      "[26,    99] loss: 0.284813\n",
      "[26,   199] loss: 0.243591\n",
      "[26,   299] loss: 0.181648\n",
      "[26,   399] loss: 0.223052\n",
      "[26,   499] loss: 0.346503\n",
      "[26,   599] loss: 0.443209\n",
      "[26,   699] loss: 0.262553\n",
      "[27,    99] loss: 0.238878\n",
      "[27,   199] loss: 0.278532\n",
      "[27,   299] loss: 0.312614\n",
      "[27,   399] loss: 0.261686\n",
      "[27,   499] loss: 0.323109\n",
      "[27,   599] loss: 0.198844\n",
      "[27,   699] loss: 0.146574\n",
      "[28,    99] loss: 0.217067\n",
      "[28,   199] loss: 0.244016\n",
      "[28,   299] loss: 0.260679\n",
      "[28,   399] loss: 0.174744\n",
      "[28,   499] loss: 0.359762\n",
      "[28,   599] loss: 0.351467\n",
      "[28,   699] loss: 0.220437\n",
      "[29,    99] loss: 0.426311\n",
      "[29,   199] loss: 0.207573\n",
      "[29,   299] loss: 0.262760\n",
      "[29,   399] loss: 0.351887\n",
      "[29,   499] loss: 0.308058\n",
      "[29,   599] loss: 0.259820\n",
      "[29,   699] loss: 0.156966\n",
      "[30,    99] loss: 0.212346\n",
      "[30,   199] loss: 0.290771\n",
      "[30,   299] loss: 0.161338\n",
      "[30,   399] loss: 0.204280\n",
      "[30,   499] loss: 0.254110\n",
      "[30,   599] loss: 0.146879\n",
      "[30,   699] loss: 0.137166\n",
      "[31,    99] loss: 0.209440\n",
      "[31,   199] loss: 0.113282\n",
      "[31,   299] loss: 0.389479\n",
      "[31,   399] loss: 0.820064\n",
      "[31,   499] loss: 0.491491\n",
      "[31,   599] loss: 0.259067\n",
      "[31,   699] loss: 0.224129\n",
      "[32,    99] loss: 0.213111\n",
      "[32,   199] loss: 0.205265\n",
      "[32,   299] loss: 0.211662\n",
      "[32,   399] loss: 0.309835\n",
      "[32,   499] loss: 0.351597\n",
      "[32,   599] loss: 0.316546\n",
      "[32,   699] loss: 0.191845\n",
      "[33,    99] loss: 0.289666\n",
      "[33,   199] loss: 0.240430\n",
      "[33,   299] loss: 0.284241\n",
      "[33,   399] loss: 0.554215\n",
      "[33,   499] loss: 0.264650\n",
      "[33,   599] loss: 0.146123\n",
      "[33,   699] loss: 0.120880\n",
      "[34,    99] loss: 0.203074\n",
      "[34,   199] loss: 0.250057\n",
      "[34,   299] loss: 0.129262\n",
      "[34,   399] loss: 0.271494\n",
      "[34,   499] loss: 0.237694\n",
      "[34,   599] loss: 0.178947\n",
      "[34,   699] loss: 0.152991\n",
      "[35,    99] loss: 0.201724\n",
      "[35,   199] loss: 0.190526\n",
      "[35,   299] loss: 0.146475\n",
      "[35,   399] loss: 0.210096\n",
      "[35,   499] loss: 0.245389\n",
      "[35,   599] loss: 0.091762\n",
      "[35,   699] loss: 0.170398\n",
      "[36,    99] loss: 0.411247\n",
      "[36,   199] loss: 0.285036\n",
      "[36,   299] loss: 0.398287\n",
      "[36,   399] loss: 0.271986\n",
      "[36,   499] loss: 0.251919\n",
      "[36,   599] loss: 0.131296\n",
      "[36,   699] loss: 0.122733\n",
      "[37,    99] loss: 0.167853\n",
      "[37,   199] loss: 0.239342\n",
      "[37,   299] loss: 0.145823\n",
      "[37,   399] loss: 0.225505\n",
      "[37,   499] loss: 0.260375\n",
      "[37,   599] loss: 0.086333\n",
      "[37,   699] loss: 0.147872\n",
      "[38,    99] loss: 0.170229\n",
      "[38,   199] loss: 0.159904\n",
      "[38,   299] loss: 0.143158\n",
      "[38,   399] loss: 0.469165\n",
      "[38,   499] loss: 0.260007\n",
      "[38,   599] loss: 0.138977\n",
      "[38,   699] loss: 0.152191\n",
      "[39,    99] loss: 0.306467\n",
      "[39,   199] loss: 0.166734\n",
      "[39,   299] loss: 0.178428\n",
      "[39,   399] loss: 0.257525\n",
      "[39,   499] loss: 0.234749\n",
      "[39,   599] loss: 0.448457\n",
      "[39,   699] loss: 0.168415\n",
      "[40,    99] loss: 0.236407\n",
      "[40,   199] loss: 0.231704\n",
      "[40,   299] loss: 0.243846\n",
      "[40,   399] loss: 0.358613\n",
      "[40,   499] loss: 0.218805\n",
      "[40,   599] loss: 0.171000\n",
      "[40,   699] loss: 0.105975\n",
      "[41,    99] loss: 0.158791\n",
      "[41,   199] loss: 0.269332\n",
      "[41,   299] loss: 0.120633\n",
      "[41,   399] loss: 0.261538\n",
      "[41,   499] loss: 0.243630\n",
      "[41,   599] loss: 0.153477\n",
      "[41,   699] loss: 0.098416\n",
      "[42,    99] loss: 0.189099\n",
      "[42,   199] loss: 0.184431\n",
      "[42,   299] loss: 0.123508\n",
      "[42,   399] loss: 0.323765\n",
      "[42,   499] loss: 0.228900\n",
      "[42,   599] loss: 0.221886\n",
      "[42,   699] loss: 0.159548\n",
      "[43,    99] loss: 0.216514\n",
      "[43,   199] loss: 0.229337\n",
      "[43,   299] loss: 0.144244\n",
      "[43,   399] loss: 0.125694\n",
      "[43,   499] loss: 0.214873\n",
      "[43,   599] loss: 0.116200\n",
      "[43,   699] loss: 0.102568\n",
      "[44,    99] loss: 0.167282\n",
      "[44,   199] loss: 0.218113\n",
      "[44,   299] loss: 0.217071\n",
      "[44,   399] loss: 0.218610\n",
      "[44,   499] loss: 0.295832\n",
      "[44,   599] loss: 0.253720\n",
      "[44,   699] loss: 0.120619\n",
      "[45,    99] loss: 0.209552\n",
      "[45,   199] loss: 0.148559\n",
      "[45,   299] loss: 0.110266\n",
      "[45,   399] loss: 0.393957\n",
      "[45,   499] loss: 0.321337\n",
      "[45,   599] loss: 0.096106\n",
      "[45,   699] loss: 0.104153\n",
      "[46,    99] loss: 0.176885\n",
      "[46,   199] loss: 0.131293\n",
      "[46,   299] loss: 0.095042\n",
      "[46,   399] loss: 0.274895\n",
      "[46,   499] loss: 0.264802\n",
      "[46,   599] loss: 0.046823\n",
      "[46,   699] loss: 0.094315\n",
      "[47,    99] loss: 0.171377\n",
      "[47,   199] loss: 0.297785\n",
      "[47,   299] loss: 0.272670\n",
      "[47,   399] loss: 0.190437\n",
      "[47,   499] loss: 0.353518\n",
      "[47,   599] loss: 0.356157\n",
      "[47,   699] loss: 0.165745\n",
      "[48,    99] loss: 0.203353\n",
      "[48,   199] loss: 0.142233\n",
      "[48,   299] loss: 0.149976\n",
      "[48,   399] loss: 0.193663\n",
      "[48,   499] loss: 0.178212\n",
      "[48,   599] loss: 0.137801\n",
      "[48,   699] loss: 0.102365\n",
      "[49,    99] loss: 0.204400\n",
      "[49,   199] loss: 0.111080\n",
      "[49,   299] loss: 0.115059\n",
      "[49,   399] loss: 0.209241\n",
      "[49,   499] loss: 0.212483\n",
      "[49,   599] loss: 0.164635\n",
      "[49,   699] loss: 0.174900\n",
      "[50,    99] loss: 0.223437\n",
      "[50,   199] loss: 0.187053\n",
      "[50,   299] loss: 0.143329\n",
      "[50,   399] loss: 0.147498\n",
      "[50,   499] loss: 0.229813\n",
      "[50,   599] loss: 0.192386\n",
      "[50,   699] loss: 0.156337\n",
      "[51,    99] loss: 0.274210\n",
      "[51,   199] loss: 0.268916\n",
      "[51,   299] loss: 0.243133\n",
      "[51,   399] loss: 0.194464\n",
      "[51,   499] loss: 0.195444\n",
      "[51,   599] loss: 0.124937\n",
      "[51,   699] loss: 0.109807\n",
      "[52,    99] loss: 0.189514\n",
      "[52,   199] loss: 0.147679\n",
      "[52,   299] loss: 0.045302\n",
      "[52,   399] loss: 0.145772\n",
      "[52,   499] loss: 0.296288\n",
      "[52,   599] loss: 0.181148\n",
      "[52,   699] loss: 0.122363\n",
      "[53,    99] loss: 0.161515\n",
      "[53,   199] loss: 0.098474\n",
      "[53,   299] loss: 0.064760\n",
      "[53,   399] loss: 0.131038\n",
      "[53,   499] loss: 0.224200\n",
      "[53,   599] loss: 0.339801\n",
      "[53,   699] loss: 0.268917\n",
      "[54,    99] loss: 0.326309\n",
      "[54,   199] loss: 0.208018\n",
      "[54,   299] loss: 0.122331\n",
      "[54,   399] loss: 0.171508\n",
      "[54,   499] loss: 0.333462\n",
      "[54,   599] loss: 0.112763\n",
      "[54,   699] loss: 0.134746\n",
      "[55,    99] loss: 0.153313\n",
      "[55,   199] loss: 0.201070\n",
      "[55,   299] loss: 0.059917\n",
      "[55,   399] loss: 0.146918\n",
      "[55,   499] loss: 0.342179\n",
      "[55,   599] loss: 0.193099\n",
      "[55,   699] loss: 0.148102\n",
      "[56,    99] loss: 0.267554\n",
      "[56,   199] loss: 0.295740\n",
      "[56,   299] loss: 0.091336\n",
      "[56,   399] loss: 0.181608\n",
      "[56,   499] loss: 0.152412\n",
      "[56,   599] loss: 0.726154\n",
      "[56,   699] loss: 0.527116\n",
      "[57,    99] loss: 0.351887\n",
      "[57,   199] loss: 0.228272\n",
      "[57,   299] loss: 0.195994\n",
      "[57,   399] loss: 0.234757\n",
      "[57,   499] loss: 0.226967\n",
      "[57,   599] loss: 0.269541\n",
      "[57,   699] loss: 0.142040\n",
      "[58,    99] loss: 0.323601\n",
      "[58,   199] loss: 0.237991\n",
      "[58,   299] loss: 0.131484\n",
      "[58,   399] loss: 0.178758\n",
      "[58,   499] loss: 0.238023\n",
      "[58,   599] loss: 0.218990\n",
      "[58,   699] loss: 0.156523\n",
      "[59,    99] loss: 0.175254\n",
      "[59,   199] loss: 0.107700\n",
      "[59,   299] loss: 0.236262\n",
      "[59,   399] loss: 0.150149\n",
      "[59,   499] loss: 0.183699\n",
      "[59,   599] loss: 0.071212\n",
      "[59,   699] loss: 0.108156\n",
      "[60,    99] loss: 0.256016\n",
      "[60,   199] loss: 0.163191\n",
      "[60,   299] loss: 0.152903\n",
      "[60,   399] loss: 0.266394\n",
      "[60,   499] loss: 0.254408\n",
      "[60,   599] loss: 0.143270\n",
      "[60,   699] loss: 0.464657\n",
      "[61,    99] loss: 0.325478\n",
      "[61,   199] loss: 0.269089\n",
      "[61,   299] loss: 0.237248\n",
      "[61,   399] loss: 0.204566\n",
      "[61,   499] loss: 0.225205\n",
      "[61,   599] loss: 0.157010\n",
      "[61,   699] loss: 0.120874\n",
      "[62,    99] loss: 0.250992\n",
      "[62,   199] loss: 0.217169\n",
      "[62,   299] loss: 0.129797\n",
      "[62,   399] loss: 0.170662\n",
      "[62,   499] loss: 0.197616\n",
      "[62,   599] loss: 0.163857\n",
      "[62,   699] loss: 0.166670\n",
      "[63,    99] loss: 0.268788\n",
      "[63,   199] loss: 0.172640\n",
      "[63,   299] loss: 0.070255\n",
      "[63,   399] loss: 0.120282\n",
      "[63,   499] loss: 0.406710\n",
      "[63,   599] loss: 0.112682\n",
      "[63,   699] loss: 0.105432\n",
      "[64,    99] loss: 0.185540\n",
      "[64,   199] loss: 0.215918\n",
      "[64,   299] loss: 0.063217\n",
      "[64,   399] loss: 0.290327\n",
      "[64,   499] loss: 0.193156\n",
      "[64,   599] loss: 0.125566\n",
      "[64,   699] loss: 0.094482\n",
      "[65,    99] loss: 0.228766\n",
      "[65,   199] loss: 0.216852\n",
      "[65,   299] loss: 0.132559\n",
      "[65,   399] loss: 0.162907\n",
      "[65,   499] loss: 0.200742\n",
      "[65,   599] loss: 0.310444\n",
      "[65,   699] loss: 0.092385\n",
      "[66,    99] loss: 0.184204\n",
      "[66,   199] loss: 0.175877\n",
      "[66,   299] loss: 0.099277\n",
      "[66,   399] loss: 0.108029\n",
      "[66,   499] loss: 0.184331\n",
      "[66,   599] loss: 0.036039\n",
      "[66,   699] loss: 0.087873\n",
      "[67,    99] loss: 0.188007\n",
      "[67,   199] loss: 0.068212\n",
      "[67,   299] loss: 0.157320\n",
      "[67,   399] loss: 0.230212\n",
      "[67,   499] loss: 0.253465\n",
      "[67,   599] loss: 0.682983\n",
      "[67,   699] loss: 0.102121\n",
      "[68,    99] loss: 0.176973\n",
      "[68,   199] loss: 0.163154\n",
      "[68,   299] loss: 0.169876\n",
      "[68,   399] loss: 0.194596\n",
      "[68,   499] loss: 0.267887\n",
      "[68,   599] loss: 0.095358\n",
      "[68,   699] loss: 0.102105\n",
      "[69,    99] loss: 0.206913\n",
      "[69,   199] loss: 0.175301\n",
      "[69,   299] loss: 0.071954\n",
      "[69,   399] loss: 0.136759\n",
      "[69,   499] loss: 0.265844\n",
      "[69,   599] loss: 0.050257\n",
      "[69,   699] loss: 0.115211\n",
      "[70,    99] loss: 0.206889\n",
      "[70,   199] loss: 0.202126\n",
      "[70,   299] loss: 0.092426\n",
      "[70,   399] loss: 0.124927\n",
      "[70,   499] loss: 0.323981\n",
      "[70,   599] loss: 0.149248\n",
      "[70,   699] loss: 0.174539\n",
      "[71,    99] loss: 0.253554\n",
      "[71,   199] loss: 0.177815\n",
      "[71,   299] loss: 0.090981\n",
      "[71,   399] loss: 0.161058\n",
      "[71,   499] loss: 0.491451\n",
      "[71,   599] loss: 0.115174\n",
      "[71,   699] loss: 0.160358\n",
      "[72,    99] loss: 0.196942\n",
      "[72,   199] loss: 0.146955\n",
      "[72,   299] loss: 0.048758\n",
      "[72,   399] loss: 0.083236\n",
      "[72,   499] loss: 0.355123\n",
      "[72,   599] loss: 0.167869\n",
      "[72,   699] loss: 0.117544\n",
      "[73,    99] loss: 0.179481\n",
      "[73,   199] loss: 0.233193\n",
      "[73,   299] loss: 0.080616\n",
      "[73,   399] loss: 0.145857\n",
      "[73,   499] loss: 0.273902\n",
      "[73,   599] loss: 0.129965\n",
      "[73,   699] loss: 0.096218\n",
      "[74,    99] loss: 0.201839\n",
      "[74,   199] loss: 0.177184\n",
      "[74,   299] loss: 0.061267\n",
      "[74,   399] loss: 0.140491\n",
      "[74,   499] loss: 0.195526\n",
      "[74,   599] loss: 0.097118\n",
      "[74,   699] loss: 0.088476\n",
      "[75,    99] loss: 0.165875\n",
      "[75,   199] loss: 0.143480\n",
      "[75,   299] loss: 0.042046\n",
      "[75,   399] loss: 0.107154\n",
      "[75,   499] loss: 0.333001\n",
      "[75,   599] loss: 0.258152\n",
      "[75,   699] loss: 0.214352\n",
      "[76,    99] loss: 0.238222\n",
      "[76,   199] loss: 0.154064\n",
      "[76,   299] loss: 0.309226\n",
      "[76,   399] loss: 0.170229\n",
      "[76,   499] loss: 0.335105\n",
      "[76,   599] loss: 0.158269\n",
      "[76,   699] loss: 0.127716\n",
      "[77,    99] loss: 0.181126\n",
      "[77,   199] loss: 0.238625\n",
      "[77,   299] loss: 0.161173\n",
      "[77,   399] loss: 0.226063\n",
      "[77,   499] loss: 0.329476\n",
      "[77,   599] loss: 0.094659\n",
      "[77,   699] loss: 0.088897\n",
      "[78,    99] loss: 0.191541\n",
      "[78,   199] loss: 0.170576\n",
      "[78,   299] loss: 0.106050\n",
      "[78,   399] loss: 0.425061\n",
      "[78,   499] loss: 0.156188\n",
      "[78,   599] loss: 0.091502\n",
      "[78,   699] loss: 0.110642\n",
      "[79,    99] loss: 0.237347\n",
      "[79,   199] loss: 0.124743\n",
      "[79,   299] loss: 0.185400\n",
      "[79,   399] loss: 0.283895\n",
      "[79,   499] loss: 0.260574\n",
      "[79,   599] loss: 0.128607\n",
      "[79,   699] loss: 0.100127\n",
      "[80,    99] loss: 0.212875\n",
      "[80,   199] loss: 0.172442\n",
      "[80,   299] loss: 0.911212\n",
      "[80,   399] loss: 0.272067\n",
      "[80,   499] loss: 0.326468\n",
      "[80,   599] loss: 0.166225\n",
      "[80,   699] loss: 0.198269\n",
      "[81,    99] loss: 0.247704\n",
      "[81,   199] loss: 0.151898\n",
      "[81,   299] loss: 0.101495\n",
      "[81,   399] loss: 0.145267\n",
      "[81,   499] loss: 0.421275\n",
      "[81,   599] loss: 0.139045\n",
      "[81,   699] loss: 0.296395\n",
      "[82,    99] loss: 0.210821\n",
      "[82,   199] loss: 0.182471\n",
      "[82,   299] loss: 0.116401\n",
      "[82,   399] loss: 0.151100\n",
      "[82,   499] loss: 0.233262\n",
      "[82,   599] loss: 0.097128\n",
      "[82,   699] loss: 0.148449\n",
      "[83,    99] loss: 0.200561\n",
      "[83,   199] loss: 0.212453\n",
      "[83,   299] loss: 0.091814\n",
      "[83,   399] loss: 0.248900\n",
      "[83,   499] loss: 0.285475\n",
      "[83,   599] loss: 0.145813\n",
      "[83,   699] loss: 0.148027\n",
      "[84,    99] loss: 0.207245\n",
      "[84,   199] loss: 0.277593\n",
      "[84,   299] loss: 0.378638\n",
      "[84,   399] loss: 0.251558\n",
      "[84,   499] loss: 0.170398\n",
      "[84,   599] loss: 0.101942\n",
      "[84,   699] loss: 0.200677\n",
      "[85,    99] loss: 0.202089\n",
      "[85,   199] loss: 0.133495\n",
      "[85,   299] loss: 0.100896\n",
      "[85,   399] loss: 0.120840\n",
      "[85,   499] loss: 0.281457\n",
      "[85,   599] loss: 0.146570\n",
      "[85,   699] loss: 0.124651\n",
      "[86,    99] loss: 0.186676\n",
      "[86,   199] loss: 0.166199\n",
      "[86,   299] loss: 0.187044\n",
      "[86,   399] loss: 0.212966\n",
      "[86,   499] loss: 0.221208\n",
      "[86,   599] loss: 0.114817\n",
      "[86,   699] loss: 0.106558\n",
      "[87,    99] loss: 0.179600\n",
      "[87,   199] loss: 0.182614\n",
      "[87,   299] loss: 0.042730\n",
      "[87,   399] loss: 0.124736\n",
      "[87,   499] loss: 0.458659\n",
      "[87,   599] loss: 0.125334\n",
      "[87,   699] loss: 0.124654\n",
      "[88,    99] loss: 0.176596\n",
      "[88,   199] loss: 0.149051\n",
      "[88,   299] loss: 0.042015\n",
      "[88,   399] loss: 0.114044\n",
      "[88,   499] loss: 0.286291\n",
      "[88,   599] loss: 0.042283\n",
      "[88,   699] loss: 0.093044\n",
      "[89,    99] loss: 0.534837\n",
      "[89,   199] loss: 0.153644\n",
      "[89,   299] loss: 0.041708\n",
      "[89,   399] loss: 0.234880\n",
      "[89,   499] loss: 0.182759\n",
      "[89,   599] loss: 0.063764\n",
      "[89,   699] loss: 0.123403\n",
      "[90,    99] loss: 0.176176\n",
      "[90,   199] loss: 0.208488\n",
      "[90,   299] loss: 0.064882\n",
      "[90,   399] loss: 0.204591\n",
      "[90,   499] loss: 0.173097\n",
      "[90,   599] loss: 0.064561\n",
      "[90,   699] loss: 0.143204\n",
      "[91,    99] loss: 0.181158\n",
      "[91,   199] loss: 0.338344\n",
      "[91,   299] loss: 0.404990\n",
      "[91,   399] loss: 0.316990\n",
      "[91,   499] loss: 0.288395\n",
      "[91,   599] loss: 0.061684\n",
      "[91,   699] loss: 0.091114\n",
      "[92,    99] loss: 0.187821\n",
      "[92,   199] loss: 0.356555\n",
      "[92,   299] loss: 0.083765\n",
      "[92,   399] loss: 0.147180\n",
      "[92,   499] loss: 0.317852\n",
      "[92,   599] loss: 0.064849\n",
      "[92,   699] loss: 0.091896\n",
      "[93,    99] loss: 0.183184\n",
      "[93,   199] loss: 0.163333\n",
      "[93,   299] loss: 0.097694\n",
      "[93,   399] loss: 0.147306\n",
      "[93,   499] loss: 0.404292\n",
      "[93,   599] loss: 0.140807\n",
      "[93,   699] loss: 0.138726\n",
      "[94,    99] loss: 0.188321\n",
      "[94,   199] loss: 0.227326\n",
      "[94,   299] loss: 0.055509\n",
      "[94,   399] loss: 0.097828\n",
      "[94,   499] loss: 0.199804\n",
      "[94,   599] loss: 0.077256\n",
      "[94,   699] loss: 0.088645\n",
      "[95,    99] loss: 0.240877\n",
      "[95,   199] loss: 0.146224\n",
      "[95,   299] loss: 0.038015\n",
      "[95,   399] loss: 0.076920\n",
      "[95,   499] loss: 0.542078\n",
      "[95,   599] loss: 0.188247\n",
      "[95,   699] loss: 0.140665\n",
      "[96,    99] loss: 0.228156\n",
      "[96,   199] loss: 0.175344\n",
      "[96,   299] loss: 0.067882\n",
      "[96,   399] loss: 0.117547\n",
      "[96,   499] loss: 0.200648\n",
      "[96,   599] loss: 0.075977\n",
      "[96,   699] loss: 0.089002\n",
      "[97,    99] loss: 0.184445\n",
      "[97,   199] loss: 0.153389\n",
      "[97,   299] loss: 0.041359\n",
      "[97,   399] loss: 0.094931\n",
      "[97,   499] loss: 0.195585\n",
      "[97,   599] loss: 0.197412\n",
      "[97,   699] loss: 0.090327\n",
      "[98,    99] loss: 0.191973\n",
      "[98,   199] loss: 0.108596\n",
      "[98,   299] loss: 0.047702\n",
      "[98,   399] loss: 0.048626\n",
      "[98,   499] loss: 0.189198\n",
      "[98,   599] loss: 0.043259\n",
      "[98,   699] loss: 0.197466\n",
      "[99,    99] loss: 0.212558\n",
      "[99,   199] loss: 0.206972\n",
      "[99,   299] loss: 0.061039\n",
      "[99,   399] loss: 0.028937\n",
      "[99,   499] loss: 0.415854\n",
      "[99,   599] loss: 0.117987\n",
      "[99,   699] loss: 0.089784\n",
      "[100,    99] loss: 0.211068\n",
      "[100,   199] loss: 0.133487\n",
      "[100,   299] loss: 0.061306\n",
      "[100,   399] loss: 0.222055\n",
      "[100,   499] loss: 0.244825\n",
      "[100,   599] loss: 0.067805\n",
      "[100,   699] loss: 0.089065\n",
      "Finished Training\n",
      "[1,    99] loss: 0.772102\n",
      "[1,   199] loss: 0.682549\n",
      "[1,   299] loss: 0.710939\n",
      "[1,   399] loss: 0.731398\n",
      "[1,   499] loss: 0.721067\n",
      "[1,   599] loss: 0.710655\n",
      "[1,   699] loss: 0.743350\n",
      "[2,    99] loss: 0.732440\n",
      "[2,   199] loss: 0.681144\n",
      "[2,   299] loss: 0.688802\n",
      "[2,   399] loss: 0.645037\n",
      "[2,   499] loss: 0.620732\n",
      "[2,   599] loss: 0.679580\n",
      "[2,   699] loss: 0.638859\n",
      "[3,    99] loss: 0.659426\n",
      "[3,   199] loss: 0.617639\n",
      "[3,   299] loss: 0.659337\n",
      "[3,   399] loss: 0.581766\n",
      "[3,   499] loss: 0.572855\n",
      "[3,   599] loss: 0.628150\n",
      "[3,   699] loss: 0.625838\n",
      "[4,    99] loss: 0.623142\n",
      "[4,   199] loss: 0.572204\n",
      "[4,   299] loss: 0.629641\n",
      "[4,   399] loss: 0.532028\n",
      "[4,   499] loss: 0.680159\n",
      "[4,   599] loss: 0.743849\n",
      "[4,   699] loss: 0.577728\n",
      "[5,    99] loss: 0.573541\n",
      "[5,   199] loss: 0.556794\n",
      "[5,   299] loss: 0.625179\n",
      "[5,   399] loss: 0.515967\n",
      "[5,   499] loss: 0.493854\n",
      "[5,   599] loss: 0.514953\n",
      "[5,   699] loss: 0.527968\n",
      "[6,    99] loss: 0.589987\n",
      "[6,   199] loss: 0.527036\n",
      "[6,   299] loss: 0.590414\n",
      "[6,   399] loss: 0.542967\n",
      "[6,   499] loss: 0.531983\n",
      "[6,   599] loss: 0.518347\n",
      "[6,   699] loss: 0.473399\n",
      "[7,    99] loss: 0.608096\n",
      "[7,   199] loss: 0.497278\n",
      "[7,   299] loss: 0.587161\n",
      "[7,   399] loss: 0.524272\n",
      "[7,   499] loss: 0.563168\n",
      "[7,   599] loss: 0.544124\n",
      "[7,   699] loss: 0.602403\n",
      "[8,    99] loss: 0.592212\n",
      "[8,   199] loss: 0.499036\n",
      "[8,   299] loss: 0.549067\n",
      "[8,   399] loss: 0.511449\n",
      "[8,   499] loss: 0.472891\n",
      "[8,   599] loss: 0.474647\n",
      "[8,   699] loss: 0.498007\n",
      "[9,    99] loss: 0.562361\n",
      "[9,   199] loss: 0.521787\n",
      "[9,   299] loss: 0.490946\n",
      "[9,   399] loss: 0.511151\n",
      "[9,   499] loss: 0.497583\n",
      "[9,   599] loss: 0.457129\n",
      "[9,   699] loss: 0.431408\n",
      "[10,    99] loss: 0.593393\n",
      "[10,   199] loss: 0.465296\n",
      "[10,   299] loss: 0.507286\n",
      "[10,   399] loss: 0.552654\n",
      "[10,   499] loss: 0.443333\n",
      "[10,   599] loss: 0.460398\n",
      "[10,   699] loss: 0.502044\n",
      "[11,    99] loss: 0.520797\n",
      "[11,   199] loss: 0.465987\n",
      "[11,   299] loss: 0.489149\n",
      "[11,   399] loss: 0.463716\n",
      "[11,   499] loss: 0.443988\n",
      "[11,   599] loss: 0.524003\n",
      "[11,   699] loss: 0.498681\n",
      "[12,    99] loss: 0.605376\n",
      "[12,   199] loss: 0.575740\n",
      "[12,   299] loss: 0.540257\n",
      "[12,   399] loss: 0.490493\n",
      "[12,   499] loss: 0.410935\n",
      "[12,   599] loss: 0.438944\n",
      "[12,   699] loss: 0.420151\n",
      "[13,    99] loss: 0.433284\n",
      "[13,   199] loss: 0.421768\n",
      "[13,   299] loss: 0.722818\n",
      "[13,   399] loss: 0.471212\n",
      "[13,   499] loss: 0.441571\n",
      "[13,   599] loss: 0.388999\n",
      "[13,   699] loss: 0.450855\n",
      "[14,    99] loss: 0.498529\n",
      "[14,   199] loss: 0.405602\n",
      "[14,   299] loss: 0.480198\n",
      "[14,   399] loss: 0.444248\n",
      "[14,   499] loss: 0.363456\n",
      "[14,   599] loss: 0.376742\n",
      "[14,   699] loss: 0.425711\n",
      "[15,    99] loss: 0.492462\n",
      "[15,   199] loss: 0.586251\n",
      "[15,   299] loss: 0.567760\n",
      "[15,   399] loss: 0.502627\n",
      "[15,   499] loss: 0.486934\n",
      "[15,   599] loss: 0.402930\n",
      "[15,   699] loss: 0.403314\n",
      "[16,    99] loss: 0.454833\n",
      "[16,   199] loss: 0.427848\n",
      "[16,   299] loss: 0.428274\n",
      "[16,   399] loss: 0.422720\n",
      "[16,   499] loss: 0.459394\n",
      "[16,   599] loss: 0.365575\n",
      "[16,   699] loss: 0.367238\n",
      "[17,    99] loss: 0.520065\n",
      "[17,   199] loss: 0.427950\n",
      "[17,   299] loss: 0.501530\n",
      "[17,   399] loss: 0.424353\n",
      "[17,   499] loss: 0.389378\n",
      "[17,   599] loss: 0.365630\n",
      "[17,   699] loss: 0.487754\n",
      "[18,    99] loss: 0.483192\n",
      "[18,   199] loss: 0.386531\n",
      "[18,   299] loss: 0.499523\n",
      "[18,   399] loss: 0.401685\n",
      "[18,   499] loss: 0.380473\n",
      "[18,   599] loss: 0.413195\n",
      "[18,   699] loss: 0.443888\n",
      "[19,    99] loss: 0.600005\n",
      "[19,   199] loss: 0.390795\n",
      "[19,   299] loss: 0.451167\n",
      "[19,   399] loss: 0.458023\n",
      "[19,   499] loss: 0.363682\n",
      "[19,   599] loss: 0.314766\n",
      "[19,   699] loss: 0.379140\n",
      "[20,    99] loss: 0.432381\n",
      "[20,   199] loss: 0.395678\n",
      "[20,   299] loss: 0.437939\n",
      "[20,   399] loss: 0.411998\n",
      "[20,   499] loss: 0.399917\n",
      "[20,   599] loss: 0.710746\n",
      "[20,   699] loss: 0.415739\n",
      "[21,    99] loss: 0.442096\n",
      "[21,   199] loss: 0.338170\n",
      "[21,   299] loss: 0.369517\n",
      "[21,   399] loss: 0.359853\n",
      "[21,   499] loss: 0.413231\n",
      "[21,   599] loss: 0.393769\n",
      "[21,   699] loss: 0.387160\n",
      "[22,    99] loss: 0.390604\n",
      "[22,   199] loss: 0.356175\n",
      "[22,   299] loss: 0.425885\n",
      "[22,   399] loss: 0.372027\n",
      "[22,   499] loss: 0.283896\n",
      "[22,   599] loss: 0.365774\n",
      "[22,   699] loss: 0.282998\n",
      "[23,    99] loss: 0.393865\n",
      "[23,   199] loss: 0.399397\n",
      "[23,   299] loss: 0.400038\n",
      "[23,   399] loss: 0.386146\n",
      "[23,   499] loss: 0.310202\n",
      "[23,   599] loss: 0.339815\n",
      "[23,   699] loss: 0.674292\n",
      "[24,    99] loss: 0.342689\n",
      "[24,   199] loss: 0.355471\n",
      "[24,   299] loss: 0.336613\n",
      "[24,   399] loss: 0.340993\n",
      "[24,   499] loss: 0.382290\n",
      "[24,   599] loss: 0.364738\n",
      "[24,   699] loss: 0.347469\n",
      "[25,    99] loss: 0.435397\n",
      "[25,   199] loss: 0.350744\n",
      "[25,   299] loss: 0.486897\n",
      "[25,   399] loss: 0.350032\n",
      "[25,   499] loss: 0.291437\n",
      "[25,   599] loss: 0.346444\n",
      "[25,   699] loss: 0.384340\n",
      "[26,    99] loss: 0.343843\n",
      "[26,   199] loss: 0.407042\n",
      "[26,   299] loss: 0.272296\n",
      "[26,   399] loss: 0.322550\n",
      "[26,   499] loss: 0.215980\n",
      "[26,   599] loss: 0.274709\n",
      "[26,   699] loss: 0.394382\n",
      "[27,    99] loss: 0.408594\n",
      "[27,   199] loss: 0.339182\n",
      "[27,   299] loss: 0.424871\n",
      "[27,   399] loss: 0.428489\n",
      "[27,   499] loss: 0.305834\n",
      "[27,   599] loss: 0.336257\n",
      "[27,   699] loss: 0.394729\n",
      "[28,    99] loss: 0.426764\n",
      "[28,   199] loss: 0.399488\n",
      "[28,   299] loss: 0.339393\n",
      "[28,   399] loss: 0.356673\n",
      "[28,   499] loss: 0.248092\n",
      "[28,   599] loss: 0.364378\n",
      "[28,   699] loss: 0.457312\n",
      "[29,    99] loss: 0.577700\n",
      "[29,   199] loss: 0.818199\n",
      "[29,   299] loss: 0.576576\n",
      "[29,   399] loss: 0.368270\n",
      "[29,   499] loss: 0.664118\n",
      "[29,   599] loss: 0.785289\n",
      "[29,   699] loss: 0.472565\n",
      "[30,    99] loss: 0.704859\n",
      "[30,   199] loss: 0.407747\n",
      "[30,   299] loss: 0.419742\n",
      "[30,   399] loss: 0.382794\n",
      "[30,   499] loss: 0.318556\n",
      "[30,   599] loss: 0.432678\n",
      "[30,   699] loss: 0.342760\n",
      "[31,    99] loss: 0.301242\n",
      "[31,   199] loss: 0.361852\n",
      "[31,   299] loss: 0.302374\n",
      "[31,   399] loss: 0.354573\n",
      "[31,   499] loss: 0.589502\n",
      "[31,   599] loss: 0.441324\n",
      "[31,   699] loss: 0.398511\n",
      "[32,    99] loss: 0.553056\n",
      "[32,   199] loss: 0.326152\n",
      "[32,   299] loss: 0.420223\n",
      "[32,   399] loss: 0.322871\n",
      "[32,   499] loss: 0.228481\n",
      "[32,   599] loss: 0.338228\n",
      "[32,   699] loss: 0.364820\n",
      "[33,    99] loss: 0.397998\n",
      "[33,   199] loss: 0.326548\n",
      "[33,   299] loss: 0.402814\n",
      "[33,   399] loss: 0.310666\n",
      "[33,   499] loss: 0.226414\n",
      "[33,   599] loss: 0.336116\n",
      "[33,   699] loss: 0.453041\n",
      "[34,    99] loss: 0.406649\n",
      "[34,   199] loss: 0.294959\n",
      "[34,   299] loss: 0.288267\n",
      "[34,   399] loss: 0.613111\n",
      "[34,   499] loss: 0.311840\n",
      "[34,   599] loss: 0.325500\n",
      "[34,   699] loss: 0.379251\n",
      "[35,    99] loss: 0.344458\n",
      "[35,   199] loss: 0.320361\n",
      "[35,   299] loss: 0.292878\n",
      "[35,   399] loss: 0.285174\n",
      "[35,   499] loss: 0.208268\n",
      "[35,   599] loss: 0.308894\n",
      "[35,   699] loss: 0.340130\n",
      "[36,    99] loss: 0.365857\n",
      "[36,   199] loss: 0.289496\n",
      "[36,   299] loss: 0.262851\n",
      "[36,   399] loss: 0.259064\n",
      "[36,   499] loss: 0.204722\n",
      "[36,   599] loss: 0.376356\n",
      "[36,   699] loss: 0.684033\n",
      "[37,    99] loss: 0.285328\n",
      "[37,   199] loss: 0.478380\n",
      "[37,   299] loss: 0.330689\n",
      "[37,   399] loss: 0.317736\n",
      "[37,   499] loss: 0.226106\n",
      "[37,   599] loss: 0.236621\n",
      "[37,   699] loss: 0.411234\n",
      "[38,    99] loss: 0.302024\n",
      "[38,   199] loss: 0.384315\n",
      "[38,   299] loss: 0.315880\n",
      "[38,   399] loss: 0.299502\n",
      "[38,   499] loss: 0.190532\n",
      "[38,   599] loss: 0.329428\n",
      "[38,   699] loss: 0.306131\n",
      "[39,    99] loss: 0.267560\n",
      "[39,   199] loss: 0.364011\n",
      "[39,   299] loss: 0.259545\n",
      "[39,   399] loss: 0.300492\n",
      "[39,   499] loss: 0.199777\n",
      "[39,   599] loss: 0.271173\n",
      "[39,   699] loss: 0.280488\n",
      "[40,    99] loss: 0.420716\n",
      "[40,   199] loss: 0.457912\n",
      "[40,   299] loss: 0.224891\n",
      "[40,   399] loss: 0.294092\n",
      "[40,   499] loss: 0.503455\n",
      "[40,   599] loss: 0.318898\n",
      "[40,   699] loss: 0.301166\n",
      "[41,    99] loss: 0.521957\n",
      "[41,   199] loss: 0.476719\n",
      "[41,   299] loss: 0.253439\n",
      "[41,   399] loss: 0.267410\n",
      "[41,   499] loss: 0.188868\n",
      "[41,   599] loss: 0.389116\n",
      "[41,   699] loss: 0.323590\n",
      "[42,    99] loss: 0.287580\n",
      "[42,   199] loss: 0.347574\n",
      "[42,   299] loss: 0.664606\n",
      "[42,   399] loss: 0.364213\n",
      "[42,   499] loss: 0.268486\n",
      "[42,   599] loss: 0.318909\n",
      "[42,   699] loss: 0.314997\n",
      "[43,    99] loss: 0.315796\n",
      "[43,   199] loss: 0.289719\n",
      "[43,   299] loss: 0.509058\n",
      "[43,   399] loss: 0.361066\n",
      "[43,   499] loss: 0.229831\n",
      "[43,   599] loss: 0.527885\n",
      "[43,   699] loss: 0.354765\n",
      "[44,    99] loss: 0.344146\n",
      "[44,   199] loss: 0.300207\n",
      "[44,   299] loss: 0.270004\n",
      "[44,   399] loss: 0.280161\n",
      "[44,   499] loss: 0.168713\n",
      "[44,   599] loss: 0.242930\n",
      "[44,   699] loss: 0.346451\n",
      "[45,    99] loss: 0.360809\n",
      "[45,   199] loss: 0.284829\n",
      "[45,   299] loss: 0.445986\n",
      "[45,   399] loss: 0.311939\n",
      "[45,   499] loss: 0.230577\n",
      "[45,   599] loss: 0.289775\n",
      "[45,   699] loss: 0.298045\n",
      "[46,    99] loss: 0.270617\n",
      "[46,   199] loss: 0.283932\n",
      "[46,   299] loss: 0.340561\n",
      "[46,   399] loss: 0.306898\n",
      "[46,   499] loss: 0.193946\n",
      "[46,   599] loss: 0.313369\n",
      "[46,   699] loss: 0.344651\n",
      "[47,    99] loss: 0.329667\n",
      "[47,   199] loss: 0.347593\n",
      "[47,   299] loss: 0.390608\n",
      "[47,   399] loss: 0.375137\n",
      "[47,   499] loss: 0.201720\n",
      "[47,   599] loss: 0.432215\n",
      "[47,   699] loss: 0.413173\n",
      "[48,    99] loss: 0.262159\n",
      "[48,   199] loss: 0.245441\n",
      "[48,   299] loss: 0.218630\n",
      "[48,   399] loss: 0.267681\n",
      "[48,   499] loss: 0.272456\n",
      "[48,   599] loss: 0.266923\n",
      "[48,   699] loss: 0.715296\n",
      "[49,    99] loss: 0.370226\n",
      "[49,   199] loss: 0.339354\n",
      "[49,   299] loss: 0.244431\n",
      "[49,   399] loss: 0.268814\n",
      "[49,   499] loss: 0.235830\n",
      "[49,   599] loss: 0.299217\n",
      "[49,   699] loss: 0.263022\n",
      "[50,    99] loss: 0.271992\n",
      "[50,   199] loss: 0.373134\n",
      "[50,   299] loss: 0.276647\n",
      "[50,   399] loss: 0.303010\n",
      "[50,   499] loss: 0.178979\n",
      "[50,   599] loss: 0.338506\n",
      "[50,   699] loss: 0.352065\n",
      "[51,    99] loss: 0.261235\n",
      "[51,   199] loss: 0.356993\n",
      "[51,   299] loss: 0.220917\n",
      "[51,   399] loss: 0.252023\n",
      "[51,   499] loss: 0.205557\n",
      "[51,   599] loss: 0.366300\n",
      "[51,   699] loss: 0.345388\n",
      "[52,    99] loss: 0.278078\n",
      "[52,   199] loss: 0.319197\n",
      "[52,   299] loss: 0.236561\n",
      "[52,   399] loss: 0.402992\n",
      "[52,   499] loss: 0.266398\n",
      "[52,   599] loss: 0.437333\n",
      "[52,   699] loss: 0.292939\n",
      "[53,    99] loss: 0.259516\n",
      "[53,   199] loss: 0.310100\n",
      "[53,   299] loss: 0.192304\n",
      "[53,   399] loss: 0.275794\n",
      "[53,   499] loss: 0.160973\n",
      "[53,   599] loss: 0.296791\n",
      "[53,   699] loss: 0.284863\n",
      "[54,    99] loss: 0.377671\n",
      "[54,   199] loss: 0.275784\n",
      "[54,   299] loss: 0.252773\n",
      "[54,   399] loss: 0.342353\n",
      "[54,   499] loss: 0.236126\n",
      "[54,   599] loss: 0.322511\n",
      "[54,   699] loss: 0.317473\n",
      "[55,    99] loss: 0.289474\n",
      "[55,   199] loss: 0.261560\n",
      "[55,   299] loss: 0.304254\n",
      "[55,   399] loss: 0.412386\n",
      "[55,   499] loss: 0.199392\n",
      "[55,   599] loss: 0.302963\n",
      "[55,   699] loss: 0.271903\n",
      "[56,    99] loss: 0.270945\n",
      "[56,   199] loss: 0.391988\n",
      "[56,   299] loss: 0.297385\n",
      "[56,   399] loss: 0.228242\n",
      "[56,   499] loss: 0.158992\n",
      "[56,   599] loss: 0.323706\n",
      "[56,   699] loss: 0.234106\n",
      "[57,    99] loss: 0.249103\n",
      "[57,   199] loss: 0.380204\n",
      "[57,   299] loss: 0.378559\n",
      "[57,   399] loss: 0.273892\n",
      "[57,   499] loss: 0.406264\n",
      "[57,   599] loss: 0.394078\n",
      "[57,   699] loss: 0.297126\n",
      "[58,    99] loss: 0.425116\n",
      "[58,   199] loss: 0.294557\n",
      "[58,   299] loss: 0.218964\n",
      "[58,   399] loss: 0.270786\n",
      "[58,   499] loss: 0.270265\n",
      "[58,   599] loss: 0.294603\n",
      "[58,   699] loss: 0.249432\n",
      "[59,    99] loss: 0.424409\n",
      "[59,   199] loss: 0.250220\n",
      "[59,   299] loss: 0.201962\n",
      "[59,   399] loss: 0.289616\n",
      "[59,   499] loss: 0.155512\n",
      "[59,   599] loss: 0.227999\n",
      "[59,   699] loss: 0.508483\n",
      "[60,    99] loss: 0.258927\n",
      "[60,   199] loss: 0.614238\n",
      "[60,   299] loss: 0.344288\n",
      "[60,   399] loss: 0.306870\n",
      "[60,   499] loss: 0.213711\n",
      "[60,   599] loss: 0.328739\n",
      "[60,   699] loss: 0.278821\n",
      "[61,    99] loss: 0.410092\n",
      "[61,   199] loss: 0.471396\n",
      "[61,   299] loss: 0.202691\n",
      "[61,   399] loss: 0.222748\n",
      "[61,   499] loss: 0.163646\n",
      "[61,   599] loss: 0.274966\n",
      "[61,   699] loss: 0.234287\n",
      "[62,    99] loss: 0.242692\n",
      "[62,   199] loss: 0.211691\n",
      "[62,   299] loss: 0.338550\n",
      "[62,   399] loss: 0.360426\n",
      "[62,   499] loss: 0.195886\n",
      "[62,   599] loss: 0.339456\n",
      "[62,   699] loss: 0.264888\n",
      "[63,    99] loss: 0.225701\n",
      "[63,   199] loss: 0.293739\n",
      "[63,   299] loss: 0.260769\n",
      "[63,   399] loss: 0.231762\n",
      "[63,   499] loss: 0.163790\n",
      "[63,   599] loss: 0.244823\n",
      "[63,   699] loss: 0.280218\n",
      "[64,    99] loss: 0.244404\n",
      "[64,   199] loss: 0.168431\n",
      "[64,   299] loss: 0.433728\n",
      "[64,   399] loss: 0.281157\n",
      "[64,   499] loss: 0.178773\n",
      "[64,   599] loss: 0.237720\n",
      "[64,   699] loss: 0.434543\n",
      "[65,    99] loss: 0.210059\n",
      "[65,   199] loss: 0.259241\n",
      "[65,   299] loss: 0.153645\n",
      "[65,   399] loss: 0.177969\n",
      "[65,   499] loss: 0.150591\n",
      "[65,   599] loss: 0.242687\n",
      "[65,   699] loss: 0.232934\n",
      "[66,    99] loss: 0.381820\n",
      "[66,   199] loss: 0.313092\n",
      "[66,   299] loss: 0.371009\n",
      "[66,   399] loss: 0.267467\n",
      "[66,   499] loss: 0.168658\n",
      "[66,   599] loss: 0.382943\n",
      "[66,   699] loss: 0.448721\n",
      "[67,    99] loss: 0.288912\n",
      "[67,   199] loss: 0.299322\n",
      "[67,   299] loss: 0.864456\n",
      "[67,   399] loss: 0.642455\n",
      "[67,   499] loss: 0.740882\n",
      "[67,   599] loss: 0.532226\n",
      "[67,   699] loss: 0.918172\n",
      "[68,    99] loss: 0.388647\n",
      "[68,   199] loss: 0.409342\n",
      "[68,   299] loss: 0.302136\n",
      "[68,   399] loss: 0.434597\n",
      "[68,   499] loss: 0.202783\n",
      "[68,   599] loss: 0.281898\n",
      "[68,   699] loss: 0.301249\n",
      "[69,    99] loss: 0.242388\n",
      "[69,   199] loss: 0.567876\n",
      "[69,   299] loss: 0.269243\n",
      "[69,   399] loss: 0.232527\n",
      "[69,   499] loss: 0.173166\n",
      "[69,   599] loss: 0.242361\n",
      "[69,   699] loss: 0.252293\n",
      "[70,    99] loss: 0.373622\n",
      "[70,   199] loss: 0.425591\n",
      "[70,   299] loss: 0.236278\n",
      "[70,   399] loss: 0.220474\n",
      "[70,   499] loss: 0.206473\n",
      "[70,   599] loss: 0.238559\n",
      "[70,   699] loss: 0.578342\n",
      "[71,    99] loss: 0.239054\n",
      "[71,   199] loss: 0.283591\n",
      "[71,   299] loss: 0.181402\n",
      "[71,   399] loss: 0.177584\n",
      "[71,   499] loss: 0.149778\n",
      "[71,   599] loss: 0.232649\n",
      "[71,   699] loss: 0.277092\n",
      "[72,    99] loss: 0.220957\n",
      "[72,   199] loss: 0.183206\n",
      "[72,   299] loss: 0.384511\n",
      "[72,   399] loss: 0.279437\n",
      "[72,   499] loss: 0.146843\n",
      "[72,   599] loss: 0.219236\n",
      "[72,   699] loss: 0.265866\n",
      "[73,    99] loss: 0.230305\n",
      "[73,   199] loss: 0.291672\n",
      "[73,   299] loss: 0.123289\n",
      "[73,   399] loss: 0.179858\n",
      "[73,   499] loss: 0.151710\n",
      "[73,   599] loss: 0.202294\n",
      "[73,   699] loss: 0.251914\n",
      "[74,    99] loss: 0.253387\n",
      "[74,   199] loss: 0.190448\n",
      "[74,   299] loss: 0.203723\n",
      "[74,   399] loss: 0.188155\n",
      "[74,   499] loss: 0.180665\n",
      "[74,   599] loss: 0.288021\n",
      "[74,   699] loss: 0.630042\n",
      "[75,    99] loss: 0.319344\n",
      "[75,   199] loss: 0.312810\n",
      "[75,   299] loss: 0.254012\n",
      "[75,   399] loss: 0.264933\n",
      "[75,   499] loss: 0.188193\n",
      "[75,   599] loss: 0.281510\n",
      "[75,   699] loss: 0.248762\n",
      "[76,    99] loss: 0.231043\n",
      "[76,   199] loss: 0.258204\n",
      "[76,   299] loss: 0.276218\n",
      "[76,   399] loss: 0.222944\n",
      "[76,   499] loss: 0.134385\n",
      "[76,   599] loss: 0.217178\n",
      "[76,   699] loss: 0.267087\n",
      "[77,    99] loss: 0.220457\n",
      "[77,   199] loss: 0.335147\n",
      "[77,   299] loss: 0.354915\n",
      "[77,   399] loss: 0.377491\n",
      "[77,   499] loss: 0.183723\n",
      "[77,   599] loss: 0.230351\n",
      "[77,   699] loss: 0.243025\n",
      "[78,    99] loss: 0.251871\n",
      "[78,   199] loss: 0.213150\n",
      "[78,   299] loss: 0.578639\n",
      "[78,   399] loss: 0.327763\n",
      "[78,   499] loss: 0.284843\n",
      "[78,   599] loss: 0.280952\n",
      "[78,   699] loss: 0.292196\n",
      "[79,    99] loss: 0.244902\n",
      "[79,   199] loss: 0.269022\n",
      "[79,   299] loss: 0.193813\n",
      "[79,   399] loss: 0.344355\n",
      "[79,   499] loss: 0.282034\n",
      "[79,   599] loss: 0.275366\n",
      "[79,   699] loss: 0.350585\n",
      "[80,    99] loss: 0.219591\n",
      "[80,   199] loss: 0.270228\n",
      "[80,   299] loss: 0.286972\n",
      "[80,   399] loss: 0.463725\n",
      "[80,   499] loss: 0.218572\n",
      "[80,   599] loss: 0.311923\n",
      "[80,   699] loss: 3.862492\n",
      "[81,    99] loss: 0.477386\n",
      "[81,   199] loss: 0.299156\n",
      "[81,   299] loss: 0.353423\n",
      "[81,   399] loss: 0.205836\n",
      "[81,   499] loss: 0.150263\n",
      "[81,   599] loss: 0.192909\n",
      "[81,   699] loss: 0.225648\n",
      "[82,    99] loss: 0.227166\n",
      "[82,   199] loss: 0.211139\n",
      "[82,   299] loss: 0.069727\n",
      "[82,   399] loss: 0.197284\n",
      "[82,   499] loss: 0.128906\n",
      "[82,   599] loss: 0.151103\n",
      "[82,   699] loss: 0.189413\n",
      "[83,    99] loss: 0.215428\n",
      "[83,   199] loss: 0.163746\n",
      "[83,   299] loss: 0.164888\n",
      "[83,   399] loss: 0.169262\n",
      "[83,   499] loss: 0.151574\n",
      "[83,   599] loss: 0.359536\n",
      "[83,   699] loss: 0.311238\n",
      "[84,    99] loss: 0.206547\n",
      "[84,   199] loss: 0.177890\n",
      "[84,   299] loss: 0.121343\n",
      "[84,   399] loss: 0.181126\n",
      "[84,   499] loss: 0.537610\n",
      "[84,   599] loss: 0.332169\n",
      "[84,   699] loss: 0.276257\n",
      "[85,    99] loss: 0.265887\n",
      "[85,   199] loss: 0.202109\n",
      "[85,   299] loss: 0.357789\n",
      "[85,   399] loss: 0.241961\n",
      "[85,   499] loss: 0.150309\n",
      "[85,   599] loss: 0.229951\n",
      "[85,   699] loss: 0.773496\n",
      "[86,    99] loss: 0.442173\n",
      "[86,   199] loss: 0.216914\n",
      "[86,   299] loss: 0.150527\n",
      "[86,   399] loss: 0.212722\n",
      "[86,   499] loss: 0.142925\n",
      "[86,   599] loss: 0.201516\n",
      "[86,   699] loss: 0.253100\n",
      "[87,    99] loss: 0.186211\n",
      "[87,   199] loss: 0.273846\n",
      "[87,   299] loss: 0.492850\n",
      "[87,   399] loss: 0.405014\n",
      "[87,   499] loss: 0.215437\n",
      "[87,   599] loss: 0.248208\n",
      "[87,   699] loss: 0.274172\n",
      "[88,    99] loss: 0.206081\n",
      "[88,   199] loss: 0.240805\n",
      "[88,   299] loss: 0.380116\n",
      "[88,   399] loss: 0.199012\n",
      "[88,   499] loss: 0.134828\n",
      "[88,   599] loss: 0.181087\n",
      "[88,   699] loss: 0.747970\n",
      "[89,    99] loss: 0.305216\n",
      "[89,   199] loss: 0.210522\n",
      "[89,   299] loss: 0.177268\n",
      "[89,   399] loss: 0.164501\n",
      "[89,   499] loss: 1.255543\n",
      "[89,   599] loss: 1.375182\n",
      "[89,   699] loss: 0.671962\n",
      "[90,    99] loss: 0.481299\n",
      "[90,   199] loss: 0.525032\n",
      "[90,   299] loss: 0.496702\n",
      "[90,   399] loss: 0.465260\n",
      "[90,   499] loss: 0.356462\n",
      "[90,   599] loss: 0.381244\n",
      "[90,   699] loss: 0.358036\n",
      "[91,    99] loss: 0.429355\n",
      "[91,   199] loss: 0.414121\n",
      "[91,   299] loss: 0.542006\n",
      "[91,   399] loss: 0.397863\n",
      "[91,   499] loss: 0.312247\n",
      "[91,   599] loss: 0.328291\n",
      "[91,   699] loss: 0.341250\n",
      "[92,    99] loss: 0.347798\n",
      "[92,   199] loss: 0.389334\n",
      "[92,   299] loss: 0.313520\n",
      "[92,   399] loss: 0.304576\n",
      "[92,   499] loss: 0.594328\n",
      "[92,   599] loss: 0.308647\n",
      "[92,   699] loss: 0.372516\n",
      "[93,    99] loss: 0.330321\n",
      "[93,   199] loss: 0.425260\n",
      "[93,   299] loss: 0.551511\n",
      "[93,   399] loss: 0.442344\n",
      "[93,   499] loss: 0.262786\n",
      "[93,   599] loss: 0.283451\n",
      "[93,   699] loss: 0.467416\n",
      "[94,    99] loss: 0.305765\n",
      "[94,   199] loss: 0.321147\n",
      "[94,   299] loss: 0.152661\n",
      "[94,   399] loss: 0.179863\n",
      "[94,   499] loss: 0.162235\n",
      "[94,   599] loss: 0.238660\n",
      "[94,   699] loss: 0.310603\n",
      "[95,    99] loss: 0.405210\n",
      "[95,   199] loss: 0.262214\n",
      "[95,   299] loss: 0.290319\n",
      "[95,   399] loss: 0.148250\n",
      "[95,   499] loss: 0.152881\n",
      "[95,   599] loss: 0.242521\n",
      "[95,   699] loss: 0.257998\n",
      "[96,    99] loss: 0.418883\n",
      "[96,   199] loss: 0.461485\n",
      "[96,   299] loss: 0.356070\n",
      "[96,   399] loss: 0.181473\n",
      "[96,   499] loss: 0.134911\n",
      "[96,   599] loss: 0.406581\n",
      "[96,   699] loss: 0.218683\n",
      "[97,    99] loss: 0.240006\n",
      "[97,   199] loss: 0.246640\n",
      "[97,   299] loss: 0.162308\n",
      "[97,   399] loss: 0.206248\n",
      "[97,   499] loss: 0.154057\n",
      "[97,   599] loss: 0.219449\n",
      "[97,   699] loss: 0.256306\n",
      "[98,    99] loss: 1.445115\n",
      "[98,   199] loss: 0.189827\n",
      "[98,   299] loss: 0.330976\n",
      "[98,   399] loss: 0.187078\n",
      "[98,   499] loss: 0.216841\n",
      "[98,   599] loss: 0.224819\n",
      "[98,   699] loss: 0.347884\n",
      "[99,    99] loss: 0.460918\n",
      "[99,   199] loss: 0.224990\n",
      "[99,   299] loss: 0.188814\n",
      "[99,   399] loss: 0.204467\n",
      "[99,   499] loss: 0.141913\n",
      "[99,   599] loss: 0.235719\n",
      "[99,   699] loss: 0.239556\n",
      "[100,    99] loss: 0.253315\n",
      "[100,   199] loss: 0.250021\n",
      "[100,   299] loss: 0.170919\n",
      "[100,   399] loss: 0.167299\n",
      "[100,   499] loss: 0.122871\n",
      "[100,   599] loss: 0.148392\n",
      "[100,   699] loss: 0.281231\n",
      "Finished Training\n",
      "[1,    99] loss: 0.705327\n",
      "[1,   199] loss: 0.759133\n",
      "[1,   299] loss: 0.682361\n",
      "[1,   399] loss: 0.662461\n",
      "[1,   499] loss: 0.678130\n",
      "[1,   599] loss: 0.656282\n",
      "[1,   699] loss: 0.670397\n",
      "[2,    99] loss: 0.700249\n",
      "[2,   199] loss: 0.684547\n",
      "[2,   299] loss: 0.612405\n",
      "[2,   399] loss: 0.660123\n",
      "[2,   499] loss: 0.712983\n",
      "[2,   599] loss: 0.587347\n",
      "[2,   699] loss: 0.583402\n",
      "[3,    99] loss: 0.674761\n",
      "[3,   199] loss: 0.647935\n",
      "[3,   299] loss: 0.620999\n",
      "[3,   399] loss: 0.612335\n",
      "[3,   499] loss: 0.664430\n",
      "[3,   599] loss: 0.542316\n",
      "[3,   699] loss: 0.540584\n",
      "[4,    99] loss: 0.604641\n",
      "[4,   199] loss: 0.584735\n",
      "[4,   299] loss: 0.656421\n",
      "[4,   399] loss: 0.570960\n",
      "[4,   499] loss: 0.605137\n",
      "[4,   599] loss: 0.463603\n",
      "[4,   699] loss: 0.475586\n",
      "[5,    99] loss: 0.642848\n",
      "[5,   199] loss: 0.612887\n",
      "[5,   299] loss: 0.618805\n",
      "[5,   399] loss: 0.587196\n",
      "[5,   499] loss: 0.587984\n",
      "[5,   599] loss: 0.450419\n",
      "[5,   699] loss: 0.487121\n",
      "[6,    99] loss: 0.580543\n",
      "[6,   199] loss: 0.557205\n",
      "[6,   299] loss: 0.628850\n",
      "[6,   399] loss: 0.819767\n",
      "[6,   499] loss: 0.559233\n",
      "[6,   599] loss: 0.408280\n",
      "[6,   699] loss: 0.462036\n",
      "[7,    99] loss: 0.608110\n",
      "[7,   199] loss: 0.565484\n",
      "[7,   299] loss: 0.567817\n",
      "[7,   399] loss: 0.513264\n",
      "[7,   499] loss: 0.570930\n",
      "[7,   599] loss: 0.446467\n",
      "[7,   699] loss: 0.487875\n",
      "[8,    99] loss: 0.582906\n",
      "[8,   199] loss: 0.549459\n",
      "[8,   299] loss: 0.542019\n",
      "[8,   399] loss: 0.518292\n",
      "[8,   499] loss: 0.553436\n",
      "[8,   599] loss: 0.402576\n",
      "[8,   699] loss: 0.497487\n",
      "[9,    99] loss: 0.497826\n",
      "[9,   199] loss: 0.506671\n",
      "[9,   299] loss: 0.486554\n",
      "[9,   399] loss: 0.521511\n",
      "[9,   499] loss: 0.547458\n",
      "[9,   599] loss: 0.353573\n",
      "[9,   699] loss: 0.492963\n",
      "[10,    99] loss: 0.598397\n",
      "[10,   199] loss: 0.512744\n",
      "[10,   299] loss: 0.439660\n",
      "[10,   399] loss: 0.435119\n",
      "[10,   499] loss: 0.458673\n",
      "[10,   599] loss: 0.352894\n",
      "[10,   699] loss: 0.331022\n",
      "[11,    99] loss: 0.484096\n",
      "[11,   199] loss: 0.458373\n",
      "[11,   299] loss: 0.533501\n",
      "[11,   399] loss: 0.478851\n",
      "[11,   499] loss: 0.422400\n",
      "[11,   599] loss: 0.367377\n",
      "[11,   699] loss: 0.374042\n",
      "[12,    99] loss: 0.452062\n",
      "[12,   199] loss: 0.425265\n",
      "[12,   299] loss: 0.418204\n",
      "[12,   399] loss: 0.476110\n",
      "[12,   499] loss: 0.404413\n",
      "[12,   599] loss: 0.336615\n",
      "[12,   699] loss: 0.374136\n",
      "[13,    99] loss: 0.412539\n",
      "[13,   199] loss: 0.380251\n",
      "[13,   299] loss: 0.431376\n",
      "[13,   399] loss: 0.407470\n",
      "[13,   499] loss: 0.408343\n",
      "[13,   599] loss: 0.320210\n",
      "[13,   699] loss: 0.364529\n",
      "[14,    99] loss: 0.394781\n",
      "[14,   199] loss: 0.486204\n",
      "[14,   299] loss: 0.383422\n",
      "[14,   399] loss: 0.376277\n",
      "[14,   499] loss: 0.347542\n",
      "[14,   599] loss: 0.311481\n",
      "[14,   699] loss: 0.371471\n",
      "[15,    99] loss: 0.437376\n",
      "[15,   199] loss: 0.404091\n",
      "[15,   299] loss: 0.336575\n",
      "[15,   399] loss: 0.378441\n",
      "[15,   499] loss: 0.351896\n",
      "[15,   599] loss: 0.304382\n",
      "[15,   699] loss: 0.353642\n",
      "[16,    99] loss: 0.377104\n",
      "[16,   199] loss: 0.389519\n",
      "[16,   299] loss: 0.371222\n",
      "[16,   399] loss: 0.396745\n",
      "[16,   499] loss: 0.377418\n",
      "[16,   599] loss: 0.274762\n",
      "[16,   699] loss: 0.345371\n",
      "[17,    99] loss: 0.431297\n",
      "[17,   199] loss: 0.402188\n",
      "[17,   299] loss: 0.360857\n",
      "[17,   399] loss: 0.404218\n",
      "[17,   499] loss: 0.424500\n",
      "[17,   599] loss: 0.367913\n",
      "[17,   699] loss: 0.301948\n",
      "[18,    99] loss: 0.417221\n",
      "[18,   199] loss: 0.349045\n",
      "[18,   299] loss: 0.331429\n",
      "[18,   399] loss: 0.408063\n",
      "[18,   499] loss: 0.336040\n",
      "[18,   599] loss: 0.275159\n",
      "[18,   699] loss: 0.377599\n",
      "[19,    99] loss: 0.497739\n",
      "[19,   199] loss: 0.435873\n",
      "[19,   299] loss: 0.368113\n",
      "[19,   399] loss: 0.369841\n",
      "[19,   499] loss: 0.323976\n",
      "[19,   599] loss: 0.215529\n",
      "[19,   699] loss: 0.345239\n",
      "[20,    99] loss: 0.380738\n",
      "[20,   199] loss: 0.357459\n",
      "[20,   299] loss: 0.312481\n",
      "[20,   399] loss: 0.306195\n",
      "[20,   499] loss: 0.289443\n",
      "[20,   599] loss: 0.292971\n",
      "[20,   699] loss: 0.303207\n",
      "[21,    99] loss: 0.501554\n",
      "[21,   199] loss: 0.395510\n",
      "[21,   299] loss: 0.324293\n",
      "[21,   399] loss: 0.372335\n",
      "[21,   499] loss: 0.385220\n",
      "[21,   599] loss: 0.235849\n",
      "[21,   699] loss: 0.294413\n",
      "[22,    99] loss: 0.698797\n",
      "[22,   199] loss: 0.504735\n",
      "[22,   299] loss: 0.378063\n",
      "[22,   399] loss: 0.416254\n",
      "[22,   499] loss: 0.289296\n",
      "[22,   599] loss: 0.227396\n",
      "[22,   699] loss: 0.266935\n",
      "[23,    99] loss: 0.370784\n",
      "[23,   199] loss: 0.458210\n",
      "[23,   299] loss: 0.366007\n",
      "[23,   399] loss: 0.797621\n",
      "[23,   499] loss: 0.341536\n",
      "[23,   599] loss: 0.192393\n",
      "[23,   699] loss: 0.276947\n",
      "[24,    99] loss: 0.256120\n",
      "[24,   199] loss: 0.486229\n",
      "[24,   299] loss: 0.251759\n",
      "[24,   399] loss: 0.325512\n",
      "[24,   499] loss: 0.267363\n",
      "[24,   599] loss: 0.184240\n",
      "[24,   699] loss: 0.262418\n",
      "[25,    99] loss: 0.316050\n",
      "[25,   199] loss: 0.342656\n",
      "[25,   299] loss: 0.287925\n",
      "[25,   399] loss: 0.301166\n",
      "[25,   499] loss: 0.259597\n",
      "[25,   599] loss: 0.155911\n",
      "[25,   699] loss: 0.302642\n",
      "[26,    99] loss: 0.245811\n",
      "[26,   199] loss: 0.293345\n",
      "[26,   299] loss: 0.266371\n",
      "[26,   399] loss: 0.344093\n",
      "[26,   499] loss: 0.258730\n",
      "[26,   599] loss: 0.189802\n",
      "[26,   699] loss: 0.262653\n",
      "[27,    99] loss: 0.383890\n",
      "[27,   199] loss: 0.352018\n",
      "[27,   299] loss: 0.650492\n",
      "[27,   399] loss: 0.450005\n",
      "[27,   499] loss: 0.377998\n",
      "[27,   599] loss: 0.213251\n",
      "[27,   699] loss: 0.280988\n",
      "[28,    99] loss: 0.287077\n",
      "[28,   199] loss: 0.361807\n",
      "[28,   299] loss: 0.262934\n",
      "[28,   399] loss: 0.331570\n",
      "[28,   499] loss: 0.237670\n",
      "[28,   599] loss: 0.172142\n",
      "[28,   699] loss: 0.273491\n",
      "[29,    99] loss: 0.246917\n",
      "[29,   199] loss: 0.315884\n",
      "[29,   299] loss: 0.279822\n",
      "[29,   399] loss: 0.327285\n",
      "[29,   499] loss: 0.261651\n",
      "[29,   599] loss: 0.210230\n",
      "[29,   699] loss: 0.253009\n",
      "[30,    99] loss: 0.197205\n",
      "[30,   199] loss: 0.244572\n",
      "[30,   299] loss: 0.333523\n",
      "[30,   399] loss: 0.867450\n",
      "[30,   499] loss: 0.300543\n",
      "[30,   599] loss: 0.275715\n",
      "[30,   699] loss: 0.235828\n",
      "[31,    99] loss: 0.254140\n",
      "[31,   199] loss: 0.342943\n",
      "[31,   299] loss: 0.273690\n",
      "[31,   399] loss: 0.239679\n",
      "[31,   499] loss: 0.300618\n",
      "[31,   599] loss: 0.159074\n",
      "[31,   699] loss: 0.311952\n",
      "[32,    99] loss: 0.286458\n",
      "[32,   199] loss: 0.332031\n",
      "[32,   299] loss: 0.250732\n",
      "[32,   399] loss: 0.346105\n",
      "[32,   499] loss: 0.271180\n",
      "[32,   599] loss: 0.227498\n",
      "[32,   699] loss: 0.256872\n",
      "[33,    99] loss: 0.531897\n",
      "[33,   199] loss: 0.312782\n",
      "[33,   299] loss: 0.315705\n",
      "[33,   399] loss: 0.287639\n",
      "[33,   499] loss: 0.212087\n",
      "[33,   599] loss: 0.166561\n",
      "[33,   699] loss: 0.327792\n",
      "[34,    99] loss: 0.283094\n",
      "[34,   199] loss: 0.275689\n",
      "[34,   299] loss: 0.247067\n",
      "[34,   399] loss: 0.272947\n",
      "[34,   499] loss: 0.221860\n",
      "[34,   599] loss: 0.154018\n",
      "[34,   699] loss: 0.289950\n",
      "[35,    99] loss: 0.339961\n",
      "[35,   199] loss: 0.339446\n",
      "[35,   299] loss: 0.594670\n",
      "[35,   399] loss: 0.601055\n",
      "[35,   499] loss: 0.276616\n",
      "[35,   599] loss: 0.231939\n",
      "[35,   699] loss: 0.257751\n",
      "[36,    99] loss: 0.312151\n",
      "[36,   199] loss: 0.268412\n",
      "[36,   299] loss: 0.308936\n",
      "[36,   399] loss: 0.287269\n",
      "[36,   499] loss: 0.331126\n",
      "[36,   599] loss: 0.195906\n",
      "[36,   699] loss: 0.257025\n",
      "[37,    99] loss: 0.246087\n",
      "[37,   199] loss: 0.232771\n",
      "[37,   299] loss: 0.263581\n",
      "[37,   399] loss: 0.420371\n",
      "[37,   499] loss: 0.215821\n",
      "[37,   599] loss: 0.239771\n",
      "[37,   699] loss: 0.255146\n",
      "[38,    99] loss: 0.510122\n",
      "[38,   199] loss: 0.270056\n",
      "[38,   299] loss: 0.346122\n",
      "[38,   399] loss: 0.248345\n",
      "[38,   499] loss: 0.210294\n",
      "[38,   599] loss: 0.202711\n",
      "[38,   699] loss: 0.184725\n",
      "[39,    99] loss: 0.415820\n",
      "[39,   199] loss: 0.264401\n",
      "[39,   299] loss: 0.296276\n",
      "[39,   399] loss: 0.965001\n",
      "[39,   499] loss: 0.298713\n",
      "[39,   599] loss: 0.148836\n",
      "[39,   699] loss: 0.223646\n",
      "[40,    99] loss: 0.307147\n",
      "[40,   199] loss: 0.264289\n",
      "[40,   299] loss: 0.286777\n",
      "[40,   399] loss: 0.428962\n",
      "[40,   499] loss: 0.327453\n",
      "[40,   599] loss: 0.689726\n",
      "[40,   699] loss: 0.243958\n",
      "[41,    99] loss: 0.308552\n",
      "[41,   199] loss: 0.387330\n",
      "[41,   299] loss: 0.284470\n",
      "[41,   399] loss: 0.263631\n",
      "[41,   499] loss: 0.217772\n",
      "[41,   599] loss: 0.135048\n",
      "[41,   699] loss: 0.208838\n",
      "[42,    99] loss: 0.249813\n",
      "[42,   199] loss: 0.177880\n",
      "[42,   299] loss: 0.273024\n",
      "[42,   399] loss: 0.718097\n",
      "[42,   499] loss: 0.217168\n",
      "[42,   599] loss: 0.133714\n",
      "[42,   699] loss: 0.259377\n",
      "[43,    99] loss: 0.350956\n",
      "[43,   199] loss: 0.172146\n",
      "[43,   299] loss: 0.206531\n",
      "[43,   399] loss: 0.246910\n",
      "[43,   499] loss: 0.231293\n",
      "[43,   599] loss: 0.142770\n",
      "[43,   699] loss: 0.169930\n",
      "[44,    99] loss: 0.256343\n",
      "[44,   199] loss: 0.202251\n",
      "[44,   299] loss: 0.255768\n",
      "[44,   399] loss: 0.160061\n",
      "[44,   499] loss: 0.753186\n",
      "[44,   599] loss: 0.266334\n",
      "[44,   699] loss: 0.231039\n",
      "[45,    99] loss: 0.286146\n",
      "[45,   199] loss: 0.196803\n",
      "[45,   299] loss: 0.276345\n",
      "[45,   399] loss: 0.323762\n",
      "[45,   499] loss: 0.299531\n",
      "[45,   599] loss: 0.438191\n",
      "[45,   699] loss: 0.293197\n",
      "[46,    99] loss: 0.254274\n",
      "[46,   199] loss: 0.256770\n",
      "[46,   299] loss: 0.317474\n",
      "[46,   399] loss: 0.462689\n",
      "[46,   499] loss: 0.261241\n",
      "[46,   599] loss: 0.163907\n",
      "[46,   699] loss: 0.222047\n",
      "[47,    99] loss: 0.287258\n",
      "[47,   199] loss: 0.200145\n",
      "[47,   299] loss: 0.183452\n",
      "[47,   399] loss: 0.301967\n",
      "[47,   499] loss: 0.257566\n",
      "[47,   599] loss: 0.154552\n",
      "[47,   699] loss: 0.273167\n",
      "[48,    99] loss: 0.294848\n",
      "[48,   199] loss: 0.323504\n",
      "[48,   299] loss: 0.347289\n",
      "[48,   399] loss: 0.213561\n",
      "[48,   499] loss: 0.223668\n",
      "[48,   599] loss: 0.149644\n",
      "[48,   699] loss: 0.162830\n",
      "[49,    99] loss: 0.411956\n",
      "[49,   199] loss: 0.288154\n",
      "[49,   299] loss: 0.253255\n",
      "[49,   399] loss: 0.216152\n",
      "[49,   499] loss: 0.215168\n",
      "[49,   599] loss: 0.140521\n",
      "[49,   699] loss: 0.219806\n",
      "[50,    99] loss: 0.183554\n",
      "[50,   199] loss: 0.216039\n",
      "[50,   299] loss: 0.254285\n",
      "[50,   399] loss: 0.159140\n",
      "[50,   499] loss: 0.185062\n",
      "[50,   599] loss: 0.152573\n",
      "[50,   699] loss: 0.200956\n",
      "[51,    99] loss: 0.206378\n",
      "[51,   199] loss: 0.254242\n",
      "[51,   299] loss: 0.274623\n",
      "[51,   399] loss: 0.339998\n",
      "[51,   499] loss: 0.259440\n",
      "[51,   599] loss: 0.135777\n",
      "[51,   699] loss: 0.224214\n",
      "[52,    99] loss: 0.266146\n",
      "[52,   199] loss: 0.233724\n",
      "[52,   299] loss: 0.514938\n",
      "[52,   399] loss: 0.317274\n",
      "[52,   499] loss: 0.232819\n",
      "[52,   599] loss: 0.156345\n",
      "[52,   699] loss: 0.236234\n",
      "[53,    99] loss: 0.418776\n",
      "[53,   199] loss: 0.265803\n",
      "[53,   299] loss: 0.247957\n",
      "[53,   399] loss: 0.223038\n",
      "[53,   499] loss: 0.229705\n",
      "[53,   599] loss: 0.179053\n",
      "[53,   699] loss: 0.196432\n",
      "[54,    99] loss: 0.224976\n",
      "[54,   199] loss: 0.176796\n",
      "[54,   299] loss: 0.284945\n",
      "[54,   399] loss: 0.235871\n",
      "[54,   499] loss: 0.226765\n",
      "[54,   599] loss: 0.163928\n",
      "[54,   699] loss: 0.150076\n",
      "[55,    99] loss: 0.154431\n",
      "[55,   199] loss: 0.182397\n",
      "[55,   299] loss: 0.242093\n",
      "[55,   399] loss: 0.234738\n",
      "[55,   499] loss: 0.256228\n",
      "[55,   599] loss: 0.117257\n",
      "[55,   699] loss: 0.114256\n",
      "[56,    99] loss: 0.423948\n",
      "[56,   199] loss: 0.178338\n",
      "[56,   299] loss: 0.258075\n",
      "[56,   399] loss: 0.228653\n",
      "[56,   499] loss: 0.180405\n",
      "[56,   599] loss: 0.103520\n",
      "[56,   699] loss: 0.127032\n",
      "[57,    99] loss: 0.228034\n",
      "[57,   199] loss: 0.190021\n",
      "[57,   299] loss: 0.247004\n",
      "[57,   399] loss: 0.172177\n",
      "[57,   499] loss: 0.275095\n",
      "[57,   599] loss: 0.602634\n",
      "[57,   699] loss: 0.317731\n",
      "[58,    99] loss: 0.265348\n",
      "[58,   199] loss: 0.212410\n",
      "[58,   299] loss: 0.300532\n",
      "[58,   399] loss: 0.234622\n",
      "[58,   499] loss: 0.162882\n",
      "[58,   599] loss: 0.282762\n",
      "[58,   699] loss: 0.126184\n",
      "[59,    99] loss: 0.216984\n",
      "[59,   199] loss: 0.374757\n",
      "[59,   299] loss: 0.230124\n",
      "[59,   399] loss: 0.296610\n",
      "[59,   499] loss: 0.218796\n",
      "[59,   599] loss: 0.138753\n",
      "[59,   699] loss: 0.172359\n",
      "[60,    99] loss: 0.261078\n",
      "[60,   199] loss: 0.229479\n",
      "[60,   299] loss: 0.305547\n",
      "[60,   399] loss: 0.340849\n",
      "[60,   499] loss: 0.180012\n",
      "[60,   599] loss: 0.129979\n",
      "[60,   699] loss: 0.107540\n",
      "[61,    99] loss: 0.207102\n",
      "[61,   199] loss: 0.200864\n",
      "[61,   299] loss: 0.220794\n",
      "[61,   399] loss: 0.204125\n",
      "[61,   499] loss: 0.172501\n",
      "[61,   599] loss: 0.247216\n",
      "[61,   699] loss: 0.266880\n",
      "[62,    99] loss: 0.506064\n",
      "[62,   199] loss: 0.297489\n",
      "[62,   299] loss: 0.466923\n",
      "[62,   399] loss: 0.223324\n",
      "[62,   499] loss: 0.279662\n",
      "[62,   599] loss: 0.129187\n",
      "[62,   699] loss: 0.238328\n",
      "[63,    99] loss: 0.238351\n",
      "[63,   199] loss: 0.247378\n",
      "[63,   299] loss: 0.314705\n",
      "[63,   399] loss: 0.194916\n",
      "[63,   499] loss: 0.296461\n",
      "[63,   599] loss: 0.281765\n",
      "[63,   699] loss: 0.272975\n",
      "[64,    99] loss: 0.279378\n",
      "[64,   199] loss: 0.215833\n",
      "[64,   299] loss: 0.293408\n",
      "[64,   399] loss: 0.235977\n",
      "[64,   499] loss: 0.207329\n",
      "[64,   599] loss: 0.118618\n",
      "[64,   699] loss: 0.158302\n",
      "[65,    99] loss: 0.690819\n",
      "[65,   199] loss: 0.201687\n",
      "[65,   299] loss: 0.269361\n",
      "[65,   399] loss: 0.259602\n",
      "[65,   499] loss: 0.200106\n",
      "[65,   599] loss: 0.141300\n",
      "[65,   699] loss: 0.126309\n",
      "[66,    99] loss: 0.265622\n",
      "[66,   199] loss: 0.192891\n",
      "[66,   299] loss: 0.243822\n",
      "[66,   399] loss: 0.229122\n",
      "[66,   499] loss: 0.212140\n",
      "[66,   599] loss: 0.183695\n",
      "[66,   699] loss: 0.184852\n",
      "[67,    99] loss: 0.245747\n",
      "[67,   199] loss: 0.197636\n",
      "[67,   299] loss: 0.268510\n",
      "[67,   399] loss: 0.194059\n",
      "[67,   499] loss: 0.178395\n",
      "[67,   599] loss: 0.114711\n",
      "[67,   699] loss: 0.266388\n",
      "[68,    99] loss: 0.227545\n",
      "[68,   199] loss: 0.204681\n",
      "[68,   299] loss: 0.329658\n",
      "[68,   399] loss: 0.503253\n",
      "[68,   499] loss: 0.253793\n",
      "[68,   599] loss: 0.161930\n",
      "[68,   699] loss: 0.111239\n",
      "[69,    99] loss: 0.213219\n",
      "[69,   199] loss: 0.226704\n",
      "[69,   299] loss: 0.235134\n",
      "[69,   399] loss: 0.310388\n",
      "[69,   499] loss: 0.193977\n",
      "[69,   599] loss: 0.124181\n",
      "[69,   699] loss: 0.115038\n",
      "[70,    99] loss: 0.561339\n",
      "[70,   199] loss: 0.233941\n",
      "[70,   299] loss: 0.176721\n",
      "[70,   399] loss: 0.234735\n",
      "[70,   499] loss: 0.203680\n",
      "[70,   599] loss: 0.158915\n",
      "[70,   699] loss: 0.162539\n",
      "[71,    99] loss: 0.257749\n",
      "[71,   199] loss: 0.173625\n",
      "[71,   299] loss: 0.273254\n",
      "[71,   399] loss: 0.217244\n",
      "[71,   499] loss: 0.161980\n",
      "[71,   599] loss: 0.117008\n",
      "[71,   699] loss: 0.226250\n",
      "[72,    99] loss: 0.192323\n",
      "[72,   199] loss: 0.320870\n",
      "[72,   299] loss: 0.171000\n",
      "[72,   399] loss: 0.314596\n",
      "[72,   499] loss: 0.220430\n",
      "[72,   599] loss: 0.152072\n",
      "[72,   699] loss: 0.121367\n",
      "[73,    99] loss: 0.210685\n",
      "[73,   199] loss: 0.177046\n",
      "[73,   299] loss: 0.206511\n",
      "[73,   399] loss: 0.221784\n",
      "[73,   499] loss: 0.215514\n",
      "[73,   599] loss: 0.104857\n",
      "[73,   699] loss: 0.126905\n",
      "[74,    99] loss: 0.163669\n",
      "[74,   199] loss: 0.152459\n",
      "[74,   299] loss: 0.389880\n",
      "[74,   399] loss: 0.167894\n",
      "[74,   499] loss: 0.214894\n",
      "[74,   599] loss: 0.124754\n",
      "[74,   699] loss: 0.126705\n",
      "[75,    99] loss: 0.364829\n",
      "[75,   199] loss: 0.189160\n",
      "[75,   299] loss: 0.255154\n",
      "[75,   399] loss: 0.228578\n",
      "[75,   499] loss: 0.197963\n",
      "[75,   599] loss: 0.136072\n",
      "[75,   699] loss: 0.124325\n",
      "[76,    99] loss: 0.168164\n",
      "[76,   199] loss: 0.189060\n",
      "[76,   299] loss: 0.251943\n",
      "[76,   399] loss: 0.595804\n",
      "[76,   499] loss: 0.264906\n",
      "[76,   599] loss: 0.157654\n",
      "[76,   699] loss: 0.138096\n",
      "[77,    99] loss: 0.221490\n",
      "[77,   199] loss: 0.177889\n",
      "[77,   299] loss: 0.202354\n",
      "[77,   399] loss: 0.125036\n",
      "[77,   499] loss: 0.167171\n",
      "[77,   599] loss: 0.108549\n",
      "[77,   699] loss: 0.107042\n",
      "[78,    99] loss: 0.222748\n",
      "[78,   199] loss: 0.323288\n",
      "[78,   299] loss: 0.210037\n",
      "[78,   399] loss: 0.210359\n",
      "[78,   499] loss: 0.191775\n",
      "[78,   599] loss: 0.104605\n",
      "[78,   699] loss: 0.095538\n",
      "[79,    99] loss: 0.167155\n",
      "[79,   199] loss: 0.155339\n",
      "[79,   299] loss: 0.217466\n",
      "[79,   399] loss: 0.147479\n",
      "[79,   499] loss: 0.190095\n",
      "[79,   599] loss: 0.109546\n",
      "[79,   699] loss: 0.210581\n",
      "[80,    99] loss: 0.862077\n",
      "[80,   199] loss: 0.274145\n",
      "[80,   299] loss: 0.616822\n",
      "[80,   399] loss: 0.202347\n",
      "[80,   499] loss: 0.188280\n",
      "[80,   599] loss: 0.175400\n",
      "[80,   699] loss: 0.274117\n",
      "[81,    99] loss: 0.285443\n",
      "[81,   199] loss: 0.232113\n",
      "[81,   299] loss: 0.416985\n",
      "[81,   399] loss: 0.161877\n",
      "[81,   499] loss: 0.183203\n",
      "[81,   599] loss: 0.110849\n",
      "[81,   699] loss: 0.204916\n",
      "[82,    99] loss: 0.238092\n",
      "[82,   199] loss: 0.151909\n",
      "[82,   299] loss: 0.201927\n",
      "[82,   399] loss: 0.137064\n",
      "[82,   499] loss: 0.163057\n",
      "[82,   599] loss: 0.102711\n",
      "[82,   699] loss: 0.155528\n",
      "[83,    99] loss: 0.221912\n",
      "[83,   199] loss: 0.192049\n",
      "[83,   299] loss: 0.212083\n",
      "[83,   399] loss: 0.134740\n",
      "[83,   499] loss: 0.203519\n",
      "[83,   599] loss: 0.208826\n",
      "[83,   699] loss: 0.240272\n",
      "[84,    99] loss: 0.197851\n",
      "[84,   199] loss: 0.154512\n",
      "[84,   299] loss: 0.212955\n",
      "[84,   399] loss: 0.148366\n",
      "[84,   499] loss: 0.164723\n",
      "[84,   599] loss: 0.119684\n",
      "[84,   699] loss: 0.155553\n",
      "[85,    99] loss: 0.454028\n",
      "[85,   199] loss: 0.194052\n",
      "[85,   299] loss: 0.207459\n",
      "[85,   399] loss: 0.446255\n",
      "[85,   499] loss: 0.305576\n",
      "[85,   599] loss: 0.264799\n",
      "[85,   699] loss: 0.557406\n",
      "[86,    99] loss: 0.217809\n",
      "[86,   199] loss: 0.218256\n",
      "[86,   299] loss: 0.254121\n",
      "[86,   399] loss: 0.160654\n",
      "[86,   499] loss: 0.219387\n",
      "[86,   599] loss: 0.121353\n",
      "[86,   699] loss: 0.144036\n",
      "[87,    99] loss: 0.441387\n",
      "[87,   199] loss: 0.235898\n",
      "[87,   299] loss: 0.206389\n",
      "[87,   399] loss: 0.214118\n",
      "[87,   499] loss: 0.248044\n",
      "[87,   599] loss: 0.153013\n",
      "[87,   699] loss: 0.242896\n",
      "[88,    99] loss: 0.224537\n",
      "[88,   199] loss: 0.177936\n",
      "[88,   299] loss: 0.197686\n",
      "[88,   399] loss: 0.138483\n",
      "[88,   499] loss: 0.155530\n",
      "[88,   599] loss: 0.099953\n",
      "[88,   699] loss: 0.228291\n",
      "[89,    99] loss: 0.872578\n",
      "[89,   199] loss: 0.331570\n",
      "[89,   299] loss: 0.246192\n",
      "[89,   399] loss: 0.429842\n",
      "[89,   499] loss: 0.371414\n",
      "[89,   599] loss: 0.368509\n",
      "[89,   699] loss: 0.123817\n",
      "[90,    99] loss: 0.166323\n",
      "[90,   199] loss: 0.171311\n",
      "[90,   299] loss: 0.226848\n",
      "[90,   399] loss: 0.255287\n",
      "[90,   499] loss: 0.437074\n",
      "[90,   599] loss: 0.128134\n",
      "[90,   699] loss: 0.131614\n",
      "[91,    99] loss: 0.167996\n",
      "[91,   199] loss: 0.182623\n",
      "[91,   299] loss: 0.155638\n",
      "[91,   399] loss: 0.168662\n",
      "[91,   499] loss: 0.139590\n",
      "[91,   599] loss: 0.206250\n",
      "[91,   699] loss: 0.097760\n",
      "[92,    99] loss: 0.148207\n",
      "[92,   199] loss: 0.316563\n",
      "[92,   299] loss: 0.200299\n",
      "[92,   399] loss: 0.130578\n",
      "[92,   499] loss: 0.163065\n",
      "[92,   599] loss: 0.095525\n",
      "[92,   699] loss: 0.134026\n",
      "[93,    99] loss: 0.151530\n",
      "[93,   199] loss: 0.144295\n",
      "[93,   299] loss: 0.162901\n",
      "[93,   399] loss: 0.148377\n",
      "[93,   499] loss: 0.158639\n",
      "[93,   599] loss: 0.096599\n",
      "[93,   699] loss: 0.098956\n",
      "[94,    99] loss: 0.204853\n",
      "[94,   199] loss: 0.134954\n",
      "[94,   299] loss: 0.170063\n",
      "[94,   399] loss: 0.374198\n",
      "[94,   499] loss: 0.407442\n",
      "[94,   599] loss: 0.131577\n",
      "[94,   699] loss: 0.375997\n",
      "[95,    99] loss: 0.241397\n",
      "[95,   199] loss: 0.168839\n",
      "[95,   299] loss: 0.206853\n",
      "[95,   399] loss: 0.546607\n",
      "[95,   499] loss: 0.362548\n",
      "[95,   599] loss: 0.153650\n",
      "[95,   699] loss: 0.189037\n",
      "[96,    99] loss: 0.284279\n",
      "[96,   199] loss: 0.203402\n",
      "[96,   299] loss: 0.202597\n",
      "[96,   399] loss: 0.179143\n",
      "[96,   499] loss: 0.222065\n",
      "[96,   599] loss: 0.119874\n",
      "[96,   699] loss: 0.356901\n",
      "[97,    99] loss: 0.262349\n",
      "[97,   199] loss: 0.159824\n",
      "[97,   299] loss: 0.198826\n",
      "[97,   399] loss: 0.173746\n",
      "[97,   499] loss: 0.225460\n",
      "[97,   599] loss: 0.129595\n",
      "[97,   699] loss: 0.112780\n",
      "[98,    99] loss: 0.181641\n",
      "[98,   199] loss: 0.173549\n",
      "[98,   299] loss: 0.170888\n",
      "[98,   399] loss: 0.151090\n",
      "[98,   499] loss: 0.340820\n",
      "[98,   599] loss: 0.142070\n",
      "[98,   699] loss: 0.129571\n",
      "[99,    99] loss: 0.225369\n",
      "[99,   199] loss: 0.147279\n",
      "[99,   299] loss: 0.284535\n",
      "[99,   399] loss: 0.155915\n",
      "[99,   499] loss: 0.410951\n",
      "[99,   599] loss: 0.130664\n",
      "[99,   699] loss: 0.216599\n",
      "[100,    99] loss: 0.179732\n",
      "[100,   199] loss: 0.166779\n",
      "[100,   299] loss: 0.181022\n",
      "[100,   399] loss: 0.161592\n",
      "[100,   499] loss: 0.175249\n",
      "[100,   599] loss: 0.161925\n",
      "[100,   699] loss: 0.089545\n",
      "Finished Training\n",
      "[1,    99] loss: 0.728047\n",
      "[1,   199] loss: 0.718431\n",
      "[1,   299] loss: 0.680251\n",
      "[1,   399] loss: 0.656663\n",
      "[1,   499] loss: 0.672569\n",
      "[1,   599] loss: 0.653837\n",
      "[1,   699] loss: 0.619926\n",
      "[2,    99] loss: 0.674134\n",
      "[2,   199] loss: 0.715456\n",
      "[2,   299] loss: 0.641182\n",
      "[2,   399] loss: 0.665848\n",
      "[2,   499] loss: 0.662017\n",
      "[2,   599] loss: 0.617714\n",
      "[2,   699] loss: 0.630838\n",
      "[3,    99] loss: 0.607113\n",
      "[3,   199] loss: 0.832768\n",
      "[3,   299] loss: 0.632785\n",
      "[3,   399] loss: 0.659193\n",
      "[3,   499] loss: 0.705573\n",
      "[3,   599] loss: 0.626512\n",
      "[3,   699] loss: 0.612134\n",
      "[4,    99] loss: 0.587925\n",
      "[4,   199] loss: 0.673914\n",
      "[4,   299] loss: 0.622328\n",
      "[4,   399] loss: 0.638100\n",
      "[4,   499] loss: 0.650784\n",
      "[4,   599] loss: 0.615719\n",
      "[4,   699] loss: 0.624464\n",
      "[5,    99] loss: 0.568480\n",
      "[5,   199] loss: 0.747077\n",
      "[5,   299] loss: 0.607945\n",
      "[5,   399] loss: 0.659379\n",
      "[5,   499] loss: 0.736240\n",
      "[5,   599] loss: 0.610250\n",
      "[5,   699] loss: 0.688130\n",
      "[6,    99] loss: 0.602656\n",
      "[6,   199] loss: 0.636355\n",
      "[6,   299] loss: 0.576508\n",
      "[6,   399] loss: 0.590248\n",
      "[6,   499] loss: 0.562414\n",
      "[6,   599] loss: 0.623021\n",
      "[6,   699] loss: 0.546230\n",
      "[7,    99] loss: 0.638887\n",
      "[7,   199] loss: 0.872567\n",
      "[7,   299] loss: 0.611660\n",
      "[7,   399] loss: 0.641720\n",
      "[7,   499] loss: 0.614080\n",
      "[7,   599] loss: 0.591226\n",
      "[7,   699] loss: 0.587838\n",
      "[8,    99] loss: 0.598351\n",
      "[8,   199] loss: 0.602853\n",
      "[8,   299] loss: 0.547100\n",
      "[8,   399] loss: 0.607060\n",
      "[8,   499] loss: 0.531176\n",
      "[8,   599] loss: 0.468701\n",
      "[8,   699] loss: 0.567443\n",
      "[9,    99] loss: 0.615210\n",
      "[9,   199] loss: 0.674223\n",
      "[9,   299] loss: 0.574717\n",
      "[9,   399] loss: 0.607434\n",
      "[9,   499] loss: 0.496247\n",
      "[9,   599] loss: 0.556844\n",
      "[9,   699] loss: 0.517551\n",
      "[10,    99] loss: 0.537781\n",
      "[10,   199] loss: 0.668630\n",
      "[10,   299] loss: 0.520427\n",
      "[10,   399] loss: 0.597340\n",
      "[10,   499] loss: 0.503224\n",
      "[10,   599] loss: 0.765892\n",
      "[10,   699] loss: 0.507268\n",
      "[11,    99] loss: 0.577641\n",
      "[11,   199] loss: 0.833691\n",
      "[11,   299] loss: 0.495413\n",
      "[11,   399] loss: 0.534539\n",
      "[11,   499] loss: 0.535967\n",
      "[11,   599] loss: 0.529862\n",
      "[11,   699] loss: 0.521769\n",
      "[12,    99] loss: 0.542938\n",
      "[12,   199] loss: 0.714829\n",
      "[12,   299] loss: 0.442521\n",
      "[12,   399] loss: 0.544888\n",
      "[12,   499] loss: 0.520592\n",
      "[12,   599] loss: 0.446523\n",
      "[12,   699] loss: 0.492350\n",
      "[13,    99] loss: 0.534303\n",
      "[13,   199] loss: 0.702218\n",
      "[13,   299] loss: 0.512231\n",
      "[13,   399] loss: 0.521827\n",
      "[13,   499] loss: 0.547698\n",
      "[13,   599] loss: 0.560211\n",
      "[13,   699] loss: 0.659927\n",
      "[14,    99] loss: 0.694883\n",
      "[14,   199] loss: 0.542655\n",
      "[14,   299] loss: 0.505343\n",
      "[14,   399] loss: 0.497247\n",
      "[14,   499] loss: 0.442651\n",
      "[14,   599] loss: 0.474352\n",
      "[14,   699] loss: 0.544410\n",
      "[15,    99] loss: 0.696223\n",
      "[15,   199] loss: 0.442076\n",
      "[15,   299] loss: 0.448285\n",
      "[15,   399] loss: 0.514379\n",
      "[15,   499] loss: 0.445356\n",
      "[15,   599] loss: 0.424964\n",
      "[15,   699] loss: 0.409545\n",
      "[16,    99] loss: 0.551293\n",
      "[16,   199] loss: 0.468575\n",
      "[16,   299] loss: 0.465996\n",
      "[16,   399] loss: 0.503548\n",
      "[16,   499] loss: 0.426749\n",
      "[16,   599] loss: 0.433892\n",
      "[16,   699] loss: 0.423436\n",
      "[17,    99] loss: 0.557919\n",
      "[17,   199] loss: 0.913398\n",
      "[17,   299] loss: 0.518733\n",
      "[17,   399] loss: 0.558946\n",
      "[17,   499] loss: 0.491555\n",
      "[17,   599] loss: 0.436846\n",
      "[17,   699] loss: 0.451151\n",
      "[18,    99] loss: 0.521914\n",
      "[18,   199] loss: 0.431548\n",
      "[18,   299] loss: 0.419692\n",
      "[18,   399] loss: 0.557586\n",
      "[18,   499] loss: 0.418490\n",
      "[18,   599] loss: 0.661366\n",
      "[18,   699] loss: 0.419883\n",
      "[19,    99] loss: 0.447649\n",
      "[19,   199] loss: 0.440490\n",
      "[19,   299] loss: 0.404621\n",
      "[19,   399] loss: 0.353314\n",
      "[19,   499] loss: 0.389919\n",
      "[19,   599] loss: 0.424356\n",
      "[19,   699] loss: 0.632874\n",
      "[20,    99] loss: 0.728027\n",
      "[20,   199] loss: 0.451324\n",
      "[20,   299] loss: 0.370827\n",
      "[20,   399] loss: 0.452195\n",
      "[20,   499] loss: 0.375162\n",
      "[20,   599] loss: 0.411999\n",
      "[20,   699] loss: 0.405721\n",
      "[21,    99] loss: 0.536291\n",
      "[21,   199] loss: 0.402002\n",
      "[21,   299] loss: 0.563243\n",
      "[21,   399] loss: 0.411728\n",
      "[21,   499] loss: 0.460999\n",
      "[21,   599] loss: 0.444561\n",
      "[21,   699] loss: 0.416063\n",
      "[22,    99] loss: 0.504847\n",
      "[22,   199] loss: 0.435290\n",
      "[22,   299] loss: 0.324753\n",
      "[22,   399] loss: 0.408834\n",
      "[22,   499] loss: 0.334858\n",
      "[22,   599] loss: 0.364781\n",
      "[22,   699] loss: 0.381708\n",
      "[23,    99] loss: 0.489569\n",
      "[23,   199] loss: 0.462825\n",
      "[23,   299] loss: 0.401467\n",
      "[23,   399] loss: 0.473877\n",
      "[23,   499] loss: 0.388586\n",
      "[23,   599] loss: 0.610739\n",
      "[23,   699] loss: 0.478378\n",
      "[24,    99] loss: 0.424589\n",
      "[24,   199] loss: 0.441466\n",
      "[24,   299] loss: 0.359933\n",
      "[24,   399] loss: 0.457441\n",
      "[24,   499] loss: 0.481180\n",
      "[24,   599] loss: 0.518357\n",
      "[24,   699] loss: 0.404932\n",
      "[25,    99] loss: 0.418564\n",
      "[25,   199] loss: 0.520811\n",
      "[25,   299] loss: 0.489818\n",
      "[25,   399] loss: 0.621857\n",
      "[25,   499] loss: 0.465069\n",
      "[25,   599] loss: 0.401777\n",
      "[25,   699] loss: 0.363991\n",
      "[26,    99] loss: 0.432005\n",
      "[26,   199] loss: 0.769446\n",
      "[26,   299] loss: 0.320358\n",
      "[26,   399] loss: 0.428594\n",
      "[26,   499] loss: 0.376723\n",
      "[26,   599] loss: 0.320039\n",
      "[26,   699] loss: 0.452270\n",
      "[27,    99] loss: 0.384126\n",
      "[27,   199] loss: 0.386889\n",
      "[27,   299] loss: 0.294430\n",
      "[27,   399] loss: 0.407443\n",
      "[27,   499] loss: 0.310543\n",
      "[27,   599] loss: 0.600216\n",
      "[27,   699] loss: 0.363976\n",
      "[28,    99] loss: 0.397885\n",
      "[28,   199] loss: 0.423994\n",
      "[28,   299] loss: 0.581626\n",
      "[28,   399] loss: 0.397826\n",
      "[28,   499] loss: 0.579655\n",
      "[28,   599] loss: 0.387811\n",
      "[28,   699] loss: 0.360987\n",
      "[29,    99] loss: 0.512572\n",
      "[29,   199] loss: 0.457252\n",
      "[29,   299] loss: 0.343891\n",
      "[29,   399] loss: 0.491958\n",
      "[29,   499] loss: 0.329013\n",
      "[29,   599] loss: 0.392444\n",
      "[29,   699] loss: 0.417669\n",
      "[30,    99] loss: 0.430614\n",
      "[30,   199] loss: 0.407221\n",
      "[30,   299] loss: 0.323776\n",
      "[30,   399] loss: 0.409882\n",
      "[30,   499] loss: 0.384216\n",
      "[30,   599] loss: 0.466549\n",
      "[30,   699] loss: 0.336297\n",
      "[31,    99] loss: 0.432596\n",
      "[31,   199] loss: 0.725127\n",
      "[31,   299] loss: 0.544832\n",
      "[31,   399] loss: 0.492765\n",
      "[31,   499] loss: 0.366922\n",
      "[31,   599] loss: 0.321281\n",
      "[31,   699] loss: 0.318557\n",
      "[32,    99] loss: 0.622647\n",
      "[32,   199] loss: 0.326988\n",
      "[32,   299] loss: 0.257990\n",
      "[32,   399] loss: 0.336428\n",
      "[32,   499] loss: 0.369319\n",
      "[32,   599] loss: 0.331807\n",
      "[32,   699] loss: 0.364695\n",
      "[33,    99] loss: 0.398686\n",
      "[33,   199] loss: 0.700803\n",
      "[33,   299] loss: 0.291747\n",
      "[33,   399] loss: 0.392577\n",
      "[33,   499] loss: 0.305118\n",
      "[33,   599] loss: 0.254752\n",
      "[33,   699] loss: 0.365000\n",
      "[34,    99] loss: 0.357301\n",
      "[34,   199] loss: 0.384511\n",
      "[34,   299] loss: 0.230879\n",
      "[34,   399] loss: 0.334219\n",
      "[34,   499] loss: 0.340986\n",
      "[34,   599] loss: 0.307284\n",
      "[34,   699] loss: 0.283395\n",
      "[35,    99] loss: 0.463042\n",
      "[35,   199] loss: 0.384491\n",
      "[35,   299] loss: 0.269421\n",
      "[35,   399] loss: 0.563514\n",
      "[35,   499] loss: 0.424011\n",
      "[35,   599] loss: 0.321367\n",
      "[35,   699] loss: 0.313300\n",
      "[36,    99] loss: 0.393614\n",
      "[36,   199] loss: 0.389398\n",
      "[36,   299] loss: 0.270326\n",
      "[36,   399] loss: 0.297124\n",
      "[36,   499] loss: 0.264545\n",
      "[36,   599] loss: 0.354527\n",
      "[36,   699] loss: 0.346014\n",
      "[37,    99] loss: 0.406276\n",
      "[37,   199] loss: 0.274890\n",
      "[37,   299] loss: 0.230883\n",
      "[37,   399] loss: 0.391427\n",
      "[37,   499] loss: 0.249708\n",
      "[37,   599] loss: 0.266532\n",
      "[37,   699] loss: 0.333738\n",
      "[38,    99] loss: 0.363077\n",
      "[38,   199] loss: 0.323221\n",
      "[38,   299] loss: 0.268424\n",
      "[38,   399] loss: 0.301261\n",
      "[38,   499] loss: 0.229185\n",
      "[38,   599] loss: 0.344125\n",
      "[38,   699] loss: 0.359707\n",
      "[39,    99] loss: 0.388628\n",
      "[39,   199] loss: 0.349102\n",
      "[39,   299] loss: 0.234423\n",
      "[39,   399] loss: 0.307070\n",
      "[39,   499] loss: 0.252232\n",
      "[39,   599] loss: 0.283652\n",
      "[39,   699] loss: 0.261412\n",
      "[40,    99] loss: 0.412720\n",
      "[40,   199] loss: 0.350381\n",
      "[40,   299] loss: 0.347093\n",
      "[40,   399] loss: 0.382728\n",
      "[40,   499] loss: 0.377950\n",
      "[40,   599] loss: 0.287634\n",
      "[40,   699] loss: 0.225620\n",
      "[41,    99] loss: 1.703501\n",
      "[41,   199] loss: 0.413887\n",
      "[41,   299] loss: 0.256960\n",
      "[41,   399] loss: 0.955332\n",
      "[41,   499] loss: 0.305828\n",
      "[41,   599] loss: 0.282883\n",
      "[41,   699] loss: 0.292303\n",
      "[42,    99] loss: 0.493841\n",
      "[42,   199] loss: 0.299504\n",
      "[42,   299] loss: 0.280021\n",
      "[42,   399] loss: 0.304208\n",
      "[42,   499] loss: 0.327020\n",
      "[42,   599] loss: 0.271929\n",
      "[42,   699] loss: 0.444501\n",
      "[43,    99] loss: 0.315776\n",
      "[43,   199] loss: 0.379994\n",
      "[43,   299] loss: 0.251618\n",
      "[43,   399] loss: 0.358643\n",
      "[43,   499] loss: 0.214987\n",
      "[43,   599] loss: 0.224814\n",
      "[43,   699] loss: 0.259055\n",
      "[44,    99] loss: 0.396168\n",
      "[44,   199] loss: 0.204747\n",
      "[44,   299] loss: 0.222148\n",
      "[44,   399] loss: 0.330547\n",
      "[44,   499] loss: 0.246765\n",
      "[44,   599] loss: 0.321246\n",
      "[44,   699] loss: 0.258282\n",
      "[45,    99] loss: 0.228371\n",
      "[45,   199] loss: 0.219648\n",
      "[45,   299] loss: 0.240140\n",
      "[45,   399] loss: 0.291253\n",
      "[45,   499] loss: 0.221314\n",
      "[45,   599] loss: 0.233702\n",
      "[45,   699] loss: 0.286583\n",
      "[46,    99] loss: 0.476050\n",
      "[46,   199] loss: 0.297549\n",
      "[46,   299] loss: 0.232630\n",
      "[46,   399] loss: 0.280543\n",
      "[46,   499] loss: 0.280843\n",
      "[46,   599] loss: 0.270060\n",
      "[46,   699] loss: 0.256903\n",
      "[47,    99] loss: 0.386845\n",
      "[47,   199] loss: 0.368863\n",
      "[47,   299] loss: 0.496749\n",
      "[47,   399] loss: 0.255418\n",
      "[47,   499] loss: 0.271947\n",
      "[47,   599] loss: 0.310087\n",
      "[47,   699] loss: 0.288708\n",
      "[48,    99] loss: 0.313008\n",
      "[48,   199] loss: 0.297829\n",
      "[48,   299] loss: 0.360107\n",
      "[48,   399] loss: 0.390290\n",
      "[48,   499] loss: 0.383863\n",
      "[48,   599] loss: 0.675404\n",
      "[48,   699] loss: 0.380037\n",
      "[49,    99] loss: 0.341094\n",
      "[49,   199] loss: 0.335531\n",
      "[49,   299] loss: 0.298055\n",
      "[49,   399] loss: 0.373756\n",
      "[49,   499] loss: 0.258224\n",
      "[49,   599] loss: 0.300391\n",
      "[49,   699] loss: 0.309937\n",
      "[50,    99] loss: 0.314321\n",
      "[50,   199] loss: 0.272927\n",
      "[50,   299] loss: 0.362642\n",
      "[50,   399] loss: 0.327219\n",
      "[50,   499] loss: 0.285140\n",
      "[50,   599] loss: 0.286647\n",
      "[50,   699] loss: 0.408595\n",
      "[51,    99] loss: 0.345688\n",
      "[51,   199] loss: 1.904875\n",
      "[51,   299] loss: 0.423771\n",
      "[51,   399] loss: 0.526545\n",
      "[51,   499] loss: 0.236459\n",
      "[51,   599] loss: 0.294162\n",
      "[51,   699] loss: 1.050144\n",
      "[52,    99] loss: 0.256200\n",
      "[52,   199] loss: 0.391280\n",
      "[52,   299] loss: 0.408195\n",
      "[52,   399] loss: 0.365993\n",
      "[52,   499] loss: 0.251025\n",
      "[52,   599] loss: 0.257378\n",
      "[52,   699] loss: 0.255027\n",
      "[53,    99] loss: 0.296701\n",
      "[53,   199] loss: 0.259435\n",
      "[53,   299] loss: 0.269868\n",
      "[53,   399] loss: 0.255705\n",
      "[53,   499] loss: 0.644435\n",
      "[53,   599] loss: 1.087712\n",
      "[53,   699] loss: 0.375848\n",
      "[54,    99] loss: 0.401310\n",
      "[54,   199] loss: 0.315520\n",
      "[54,   299] loss: 0.209304\n",
      "[54,   399] loss: 0.245005\n",
      "[54,   499] loss: 0.138189\n",
      "[54,   599] loss: 0.171753\n",
      "[54,   699] loss: 0.314524\n",
      "[55,    99] loss: 0.283655\n",
      "[55,   199] loss: 0.153019\n",
      "[55,   299] loss: 0.298963\n",
      "[55,   399] loss: 0.241197\n",
      "[55,   499] loss: 0.153141\n",
      "[55,   599] loss: 0.257878\n",
      "[55,   699] loss: 0.243155\n",
      "[56,    99] loss: 0.241399\n",
      "[56,   199] loss: 0.183308\n",
      "[56,   299] loss: 0.381852\n",
      "[56,   399] loss: 0.223448\n",
      "[56,   499] loss: 0.170999\n",
      "[56,   599] loss: 0.198863\n",
      "[56,   699] loss: 0.318713\n",
      "[57,    99] loss: 0.229731\n",
      "[57,   199] loss: 0.189632\n",
      "[57,   299] loss: 0.172467\n",
      "[57,   399] loss: 0.687712\n",
      "[57,   499] loss: 0.141055\n",
      "[57,   599] loss: 0.326201\n",
      "[57,   699] loss: 0.244594\n",
      "[58,    99] loss: 0.287057\n",
      "[58,   199] loss: 0.435404\n",
      "[58,   299] loss: 0.317821\n",
      "[58,   399] loss: 0.194132\n",
      "[58,   499] loss: 0.169429\n",
      "[58,   599] loss: 0.246055\n",
      "[58,   699] loss: 0.296127\n",
      "[59,    99] loss: 0.421164\n",
      "[59,   199] loss: 0.252093\n",
      "[59,   299] loss: 0.172698\n",
      "[59,   399] loss: 0.384884\n",
      "[59,   499] loss: 0.146152\n",
      "[59,   599] loss: 0.195185\n",
      "[59,   699] loss: 0.262689\n",
      "[60,    99] loss: 0.221821\n",
      "[60,   199] loss: 0.743246\n",
      "[60,   299] loss: 0.230282\n",
      "[60,   399] loss: 0.231814\n",
      "[60,   499] loss: 0.345304\n",
      "[60,   599] loss: 0.332260\n",
      "[60,   699] loss: 0.238759\n",
      "[61,    99] loss: 0.380664\n",
      "[61,   199] loss: 0.410927\n",
      "[61,   299] loss: 0.237764\n",
      "[61,   399] loss: 0.240001\n",
      "[61,   499] loss: 0.201511\n",
      "[61,   599] loss: 0.368118\n",
      "[61,   699] loss: 0.341667\n",
      "[62,    99] loss: 0.262469\n",
      "[62,   199] loss: 0.223276\n",
      "[62,   299] loss: 0.245316\n",
      "[62,   399] loss: 0.269366\n",
      "[62,   499] loss: 0.135228\n",
      "[62,   599] loss: 0.200535\n",
      "[62,   699] loss: 0.245642\n",
      "[63,    99] loss: 0.643736\n",
      "[63,   199] loss: 0.233533\n",
      "[63,   299] loss: 0.206403\n",
      "[63,   399] loss: 0.320949\n",
      "[63,   499] loss: 0.131131\n",
      "[63,   599] loss: 0.165303\n",
      "[63,   699] loss: 0.188068\n",
      "[64,    99] loss: 0.697782\n",
      "[64,   199] loss: 0.283447\n",
      "[64,   299] loss: 0.225395\n",
      "[64,   399] loss: 0.254682\n",
      "[64,   499] loss: 0.204095\n",
      "[64,   599] loss: 0.219602\n",
      "[64,   699] loss: 0.314697\n",
      "[65,    99] loss: 0.193900\n",
      "[65,   199] loss: 0.163172\n",
      "[65,   299] loss: 0.164122\n",
      "[65,   399] loss: 0.214006\n",
      "[65,   499] loss: 0.143039\n",
      "[65,   599] loss: 0.201004\n",
      "[65,   699] loss: 0.242022\n",
      "[66,    99] loss: 0.255999\n",
      "[66,   199] loss: 0.243919\n",
      "[66,   299] loss: 0.197465\n",
      "[66,   399] loss: 0.258041\n",
      "[66,   499] loss: 0.178540\n",
      "[66,   599] loss: 0.225262\n",
      "[66,   699] loss: 0.249041\n",
      "[67,    99] loss: 0.502999\n",
      "[67,   199] loss: 0.175111\n",
      "[67,   299] loss: 0.162268\n",
      "[67,   399] loss: 0.343445\n",
      "[67,   499] loss: 0.174697\n",
      "[67,   599] loss: 0.461232\n",
      "[67,   699] loss: 0.353950\n",
      "[68,    99] loss: 0.808576\n",
      "[68,   199] loss: 0.196372\n",
      "[68,   299] loss: 0.206654\n",
      "[68,   399] loss: 1.270247\n",
      "[68,   499] loss: 0.151659\n",
      "[68,   599] loss: 0.223570\n",
      "[68,   699] loss: 0.284925\n",
      "[69,    99] loss: 0.322351\n",
      "[69,   199] loss: 0.239479\n",
      "[69,   299] loss: 0.241706\n",
      "[69,   399] loss: 0.424971\n",
      "[69,   499] loss: 0.250548\n",
      "[69,   599] loss: 0.196582\n",
      "[69,   699] loss: 0.275670\n",
      "[70,    99] loss: 0.155547\n",
      "[70,   199] loss: 0.308790\n",
      "[70,   299] loss: 0.172261\n",
      "[70,   399] loss: 0.210213\n",
      "[70,   499] loss: 0.137698\n",
      "[70,   599] loss: 0.253939\n",
      "[70,   699] loss: 0.249176\n",
      "[71,    99] loss: 0.262779\n",
      "[71,   199] loss: 0.174492\n",
      "[71,   299] loss: 0.205777\n",
      "[71,   399] loss: 0.306526\n",
      "[71,   499] loss: 0.503147\n",
      "[71,   599] loss: 0.409801\n",
      "[71,   699] loss: 0.226265\n",
      "[72,    99] loss: 0.240614\n",
      "[72,   199] loss: 0.291306\n",
      "[72,   299] loss: 0.634682\n",
      "[72,   399] loss: 0.361787\n",
      "[72,   499] loss: 0.134046\n",
      "[72,   599] loss: 0.371949\n",
      "[72,   699] loss: 0.246224\n",
      "[73,    99] loss: 0.371788\n",
      "[73,   199] loss: 0.301346\n",
      "[73,   299] loss: 0.197983\n",
      "[73,   399] loss: 0.271499\n",
      "[73,   499] loss: 0.654037\n",
      "[73,   599] loss: 0.305406\n",
      "[73,   699] loss: 0.692954\n",
      "[74,    99] loss: 0.511794\n",
      "[74,   199] loss: 0.279625\n",
      "[74,   299] loss: 0.154106\n",
      "[74,   399] loss: 0.249850\n",
      "[74,   499] loss: 0.286057\n",
      "[74,   599] loss: 0.175838\n",
      "[74,   699] loss: 0.407107\n",
      "[75,    99] loss: 0.214977\n",
      "[75,   199] loss: 0.174007\n",
      "[75,   299] loss: 0.185633\n",
      "[75,   399] loss: 0.334264\n",
      "[75,   499] loss: 0.146268\n",
      "[75,   599] loss: 0.182788\n",
      "[75,   699] loss: 0.210885\n",
      "[76,    99] loss: 0.180464\n",
      "[76,   199] loss: 0.115121\n",
      "[76,   299] loss: 0.146246\n",
      "[76,   399] loss: 0.143006\n",
      "[76,   499] loss: 0.121746\n",
      "[76,   599] loss: 0.147757\n",
      "[76,   699] loss: 0.208107\n",
      "[77,    99] loss: 0.137905\n",
      "[77,   199] loss: 0.124720\n",
      "[77,   299] loss: 0.128257\n",
      "[77,   399] loss: 0.259100\n",
      "[77,   499] loss: 0.206482\n",
      "[77,   599] loss: 0.300674\n",
      "[77,   699] loss: 0.255155\n",
      "[78,    99] loss: 0.198071\n",
      "[78,   199] loss: 0.331485\n",
      "[78,   299] loss: 0.164052\n",
      "[78,   399] loss: 0.246710\n",
      "[78,   499] loss: 0.155677\n",
      "[78,   599] loss: 0.404967\n",
      "[78,   699] loss: 0.336615\n",
      "[79,    99] loss: 0.115344\n",
      "[79,   199] loss: 0.099467\n",
      "[79,   299] loss: 0.108636\n",
      "[79,   399] loss: 0.303299\n",
      "[79,   499] loss: 0.141004\n",
      "[79,   599] loss: 0.174015\n",
      "[79,   699] loss: 0.155620\n",
      "[80,    99] loss: 0.131538\n",
      "[80,   199] loss: 0.150637\n",
      "[80,   299] loss: 0.148433\n",
      "[80,   399] loss: 0.096393\n",
      "[80,   499] loss: 0.094675\n",
      "[80,   599] loss: 0.257921\n",
      "[80,   699] loss: 0.269764\n",
      "[81,    99] loss: 1.905358\n",
      "[81,   199] loss: 0.402482\n",
      "[81,   299] loss: 0.147035\n",
      "[81,   399] loss: 0.161140\n",
      "[81,   499] loss: 0.174621\n",
      "[81,   599] loss: 0.303516\n",
      "[81,   699] loss: 0.371860\n",
      "[82,    99] loss: 0.215320\n",
      "[82,   199] loss: 0.172112\n",
      "[82,   299] loss: 0.159219\n",
      "[82,   399] loss: 0.192020\n",
      "[82,   499] loss: 0.133330\n",
      "[82,   599] loss: 0.146284\n",
      "[82,   699] loss: 0.238677\n",
      "[83,    99] loss: 0.192459\n",
      "[83,   199] loss: 0.246128\n",
      "[83,   299] loss: 0.155009\n",
      "[83,   399] loss: 0.146597\n",
      "[83,   499] loss: 0.104623\n",
      "[83,   599] loss: 0.253372\n",
      "[83,   699] loss: 0.166188\n",
      "[84,    99] loss: 0.285712\n",
      "[84,   199] loss: 0.121041\n",
      "[84,   299] loss: 0.162049\n",
      "[84,   399] loss: 0.181280\n",
      "[84,   499] loss: 0.120938\n",
      "[84,   599] loss: 0.200750\n",
      "[84,   699] loss: 0.258731\n",
      "[85,    99] loss: 0.151980\n",
      "[85,   199] loss: 0.206598\n",
      "[85,   299] loss: 0.133019\n",
      "[85,   399] loss: 0.131495\n",
      "[85,   499] loss: 0.152771\n",
      "[85,   599] loss: 0.220196\n",
      "[85,   699] loss: 0.220915\n",
      "[86,    99] loss: 0.112206\n",
      "[86,   199] loss: 0.120819\n",
      "[86,   299] loss: 0.148921\n",
      "[86,   399] loss: 0.246485\n",
      "[86,   499] loss: 0.116964\n",
      "[86,   599] loss: 0.287095\n",
      "[86,   699] loss: 0.273426\n",
      "[87,    99] loss: 0.202384\n",
      "[87,   199] loss: 0.289871\n",
      "[87,   299] loss: 0.131461\n",
      "[87,   399] loss: 0.189156\n",
      "[87,   499] loss: 0.107042\n",
      "[87,   599] loss: 1.154246\n",
      "[87,   699] loss: 0.224474\n",
      "[88,    99] loss: 0.237078\n",
      "[88,   199] loss: 1.031014\n",
      "[88,   299] loss: 0.275584\n",
      "[88,   399] loss: 0.475979\n",
      "[88,   499] loss: 0.385286\n",
      "[88,   599] loss: 0.274721\n",
      "[88,   699] loss: 0.326241\n",
      "[89,    99] loss: 0.218477\n",
      "[89,   199] loss: 0.212943\n",
      "[89,   299] loss: 0.133530\n",
      "[89,   399] loss: 0.186183\n",
      "[89,   499] loss: 0.243870\n",
      "[89,   599] loss: 0.156653\n",
      "[89,   699] loss: 0.151165\n",
      "[90,    99] loss: 0.170892\n",
      "[90,   199] loss: 0.117104\n",
      "[90,   299] loss: 0.140228\n",
      "[90,   399] loss: 0.310583\n",
      "[90,   499] loss: 0.128504\n",
      "[90,   599] loss: 0.156947\n",
      "[90,   699] loss: 0.230976\n",
      "[91,    99] loss: 0.164264\n",
      "[91,   199] loss: 0.125738\n",
      "[91,   299] loss: 0.190043\n",
      "[91,   399] loss: 0.110192\n",
      "[91,   499] loss: 0.116389\n",
      "[91,   599] loss: 0.144889\n",
      "[91,   699] loss: 0.162013\n",
      "[92,    99] loss: 0.097495\n",
      "[92,   199] loss: 0.172717\n",
      "[92,   299] loss: 0.138509\n",
      "[92,   399] loss: 0.242106\n",
      "[92,   499] loss: 0.112802\n",
      "[92,   599] loss: 0.136237\n",
      "[92,   699] loss: 0.146763\n",
      "[93,    99] loss: 0.165451\n",
      "[93,   199] loss: 0.114976\n",
      "[93,   299] loss: 0.133764\n",
      "[93,   399] loss: 0.099853\n",
      "[93,   499] loss: 0.108653\n",
      "[93,   599] loss: 0.209172\n",
      "[93,   699] loss: 0.112236\n",
      "[94,    99] loss: 0.113301\n",
      "[94,   199] loss: 0.123609\n",
      "[94,   299] loss: 0.139785\n",
      "[94,   399] loss: 0.110558\n",
      "[94,   499] loss: 0.324296\n",
      "[94,   599] loss: 0.459775\n",
      "[94,   699] loss: 0.239081\n",
      "[95,    99] loss: 0.641266\n",
      "[95,   199] loss: 0.364875\n",
      "[95,   299] loss: 0.149284\n",
      "[95,   399] loss: 0.404080\n",
      "[95,   499] loss: 0.212347\n",
      "[95,   599] loss: 0.205976\n",
      "[95,   699] loss: 0.419198\n",
      "[96,    99] loss: 0.440001\n",
      "[96,   199] loss: 0.127141\n",
      "[96,   299] loss: 0.152690\n",
      "[96,   399] loss: 0.213630\n",
      "[96,   499] loss: 0.701499\n",
      "[96,   599] loss: 0.228271\n",
      "[96,   699] loss: 0.355569\n",
      "[97,    99] loss: 0.216543\n",
      "[97,   199] loss: 0.127956\n",
      "[97,   299] loss: 0.128106\n",
      "[97,   399] loss: 0.183156\n",
      "[97,   499] loss: 0.119476\n",
      "[97,   599] loss: 0.160360\n",
      "[97,   699] loss: 0.317430\n",
      "[98,    99] loss: 0.911642\n",
      "[98,   199] loss: 0.340540\n",
      "[98,   299] loss: 0.322731\n",
      "[98,   399] loss: 0.334344\n",
      "[98,   499] loss: 0.128148\n",
      "[98,   599] loss: 0.137499\n",
      "[98,   699] loss: 0.640235\n",
      "[99,    99] loss: 0.263507\n",
      "[99,   199] loss: 1.097513\n",
      "[99,   299] loss: 0.215361\n",
      "[99,   399] loss: 0.196280\n",
      "[99,   499] loss: 0.174173\n",
      "[99,   599] loss: 0.240643\n",
      "[99,   699] loss: 0.147705\n",
      "[100,    99] loss: 0.337187\n",
      "[100,   199] loss: 0.178939\n",
      "[100,   299] loss: 0.187130\n",
      "[100,   399] loss: 0.572331\n",
      "[100,   499] loss: 0.148370\n",
      "[100,   599] loss: 0.210237\n",
      "[100,   699] loss: 0.299409\n",
      "Finished Training\n",
      "[1,    99] loss: 0.723356\n",
      "[1,   199] loss: 0.737624\n",
      "[1,   299] loss: 0.718958\n",
      "[1,   399] loss: 0.684983\n",
      "[1,   499] loss: 0.680839\n",
      "[1,   599] loss: 0.677240\n",
      "[1,   699] loss: 0.745779\n",
      "[2,    99] loss: 0.710143\n",
      "[2,   199] loss: 0.626199\n",
      "[2,   299] loss: 0.788630\n",
      "[2,   399] loss: 0.747745\n",
      "[2,   499] loss: 0.646155\n",
      "[2,   599] loss: 0.615472\n",
      "[2,   699] loss: 0.652751\n",
      "[3,    99] loss: 0.645766\n",
      "[3,   199] loss: 0.502727\n",
      "[3,   299] loss: 0.727960\n",
      "[3,   399] loss: 0.650294\n",
      "[3,   499] loss: 0.577356\n",
      "[3,   599] loss: 0.506690\n",
      "[3,   699] loss: 0.639632\n",
      "[4,    99] loss: 0.627821\n",
      "[4,   199] loss: 0.477853\n",
      "[4,   299] loss: 0.701679\n",
      "[4,   399] loss: 0.555840\n",
      "[4,   499] loss: 0.524270\n",
      "[4,   599] loss: 0.454853\n",
      "[4,   699] loss: 0.593232\n",
      "[5,    99] loss: 0.603424\n",
      "[5,   199] loss: 0.442599\n",
      "[5,   299] loss: 0.724240\n",
      "[5,   399] loss: 0.516410\n",
      "[5,   499] loss: 0.528452\n",
      "[5,   599] loss: 0.429122\n",
      "[5,   699] loss: 0.556452\n",
      "[6,    99] loss: 0.490525\n",
      "[6,   199] loss: 0.381018\n",
      "[6,   299] loss: 0.586349\n",
      "[6,   399] loss: 0.447523\n",
      "[6,   499] loss: 0.357301\n",
      "[6,   599] loss: 0.386674\n",
      "[6,   699] loss: 0.590674\n",
      "[7,    99] loss: 0.468771\n",
      "[7,   199] loss: 0.367299\n",
      "[7,   299] loss: 0.545170\n",
      "[7,   399] loss: 0.373003\n",
      "[7,   499] loss: 0.354740\n",
      "[7,   599] loss: 0.416287\n",
      "[7,   699] loss: 0.479231\n",
      "[8,    99] loss: 0.551604\n",
      "[8,   199] loss: 0.385087\n",
      "[8,   299] loss: 0.561556\n",
      "[8,   399] loss: 0.488847\n",
      "[8,   499] loss: 0.308969\n",
      "[8,   599] loss: 0.412513\n",
      "[8,   699] loss: 0.454129\n",
      "[9,    99] loss: 0.420454\n",
      "[9,   199] loss: 0.352055\n",
      "[9,   299] loss: 0.523987\n",
      "[9,   399] loss: 0.354749\n",
      "[9,   499] loss: 0.300214\n",
      "[9,   599] loss: 0.399862\n",
      "[9,   699] loss: 0.424629\n",
      "[10,    99] loss: 0.473308\n",
      "[10,   199] loss: 0.369212\n",
      "[10,   299] loss: 0.448583\n",
      "[10,   399] loss: 0.350869\n",
      "[10,   499] loss: 0.244555\n",
      "[10,   599] loss: 0.374276\n",
      "[10,   699] loss: 0.397659\n",
      "[11,    99] loss: 0.369017\n",
      "[11,   199] loss: 0.305250\n",
      "[11,   299] loss: 0.418577\n",
      "[11,   399] loss: 0.344140\n",
      "[11,   499] loss: 0.245551\n",
      "[11,   599] loss: 0.376547\n",
      "[11,   699] loss: 0.516359\n",
      "[12,    99] loss: 0.407578\n",
      "[12,   199] loss: 0.272403\n",
      "[12,   299] loss: 0.390711\n",
      "[12,   399] loss: 0.401205\n",
      "[12,   499] loss: 0.409835\n",
      "[12,   599] loss: 0.422234\n",
      "[12,   699] loss: 0.397788\n",
      "[13,    99] loss: 0.381992\n",
      "[13,   199] loss: 0.310512\n",
      "[13,   299] loss: 0.329916\n",
      "[13,   399] loss: 0.414769\n",
      "[13,   499] loss: 0.271663\n",
      "[13,   599] loss: 0.343433\n",
      "[13,   699] loss: 0.412426\n",
      "[14,    99] loss: 0.310649\n",
      "[14,   199] loss: 0.312269\n",
      "[14,   299] loss: 0.371453\n",
      "[14,   399] loss: 0.248788\n",
      "[14,   499] loss: 0.217128\n",
      "[14,   599] loss: 0.337844\n",
      "[14,   699] loss: 0.589240\n",
      "[15,    99] loss: 0.351347\n",
      "[15,   199] loss: 0.284357\n",
      "[15,   299] loss: 0.396236\n",
      "[15,   399] loss: 0.343693\n",
      "[15,   499] loss: 0.258396\n",
      "[15,   599] loss: 0.393124\n",
      "[15,   699] loss: 0.605856\n",
      "[16,    99] loss: 0.307743\n",
      "[16,   199] loss: 0.250125\n",
      "[16,   299] loss: 0.347797\n",
      "[16,   399] loss: 0.402695\n",
      "[16,   499] loss: 0.185729\n",
      "[16,   599] loss: 0.327942\n",
      "[16,   699] loss: 0.372085\n",
      "[17,    99] loss: 0.445199\n",
      "[17,   199] loss: 0.309567\n",
      "[17,   299] loss: 0.451945\n",
      "[17,   399] loss: 0.405432\n",
      "[17,   499] loss: 0.260760\n",
      "[17,   599] loss: 0.333962\n",
      "[17,   699] loss: 0.394939\n",
      "[18,    99] loss: 0.345544\n",
      "[18,   199] loss: 0.231742\n",
      "[18,   299] loss: 0.643264\n",
      "[18,   399] loss: 0.284942\n",
      "[18,   499] loss: 0.201856\n",
      "[18,   599] loss: 0.218867\n",
      "[18,   699] loss: 0.332275\n",
      "[19,    99] loss: 0.400671\n",
      "[19,   199] loss: 0.345960\n",
      "[19,   299] loss: 0.332666\n",
      "[19,   399] loss: 0.430724\n",
      "[19,   499] loss: 0.221972\n",
      "[19,   599] loss: 0.273015\n",
      "[19,   699] loss: 0.397517\n",
      "[20,    99] loss: 0.411747\n",
      "[20,   199] loss: 0.195555\n",
      "[20,   299] loss: 0.316884\n",
      "[20,   399] loss: 0.180870\n",
      "[20,   499] loss: 0.264009\n",
      "[20,   599] loss: 0.335945\n",
      "[20,   699] loss: 0.432422\n",
      "[21,    99] loss: 0.364268\n",
      "[21,   199] loss: 0.289001\n",
      "[21,   299] loss: 0.319419\n",
      "[21,   399] loss: 0.312965\n",
      "[21,   499] loss: 0.255721\n",
      "[21,   599] loss: 0.231500\n",
      "[21,   699] loss: 0.299310\n",
      "[22,    99] loss: 0.316798\n",
      "[22,   199] loss: 0.246015\n",
      "[22,   299] loss: 0.270606\n",
      "[22,   399] loss: 0.224282\n",
      "[22,   499] loss: 0.171430\n",
      "[22,   599] loss: 0.204707\n",
      "[22,   699] loss: 0.365361\n",
      "[23,    99] loss: 0.562756\n",
      "[23,   199] loss: 0.286782\n",
      "[23,   299] loss: 0.274519\n",
      "[23,   399] loss: 0.168759\n",
      "[23,   499] loss: 0.205864\n",
      "[23,   599] loss: 0.311252\n",
      "[23,   699] loss: 0.478513\n",
      "[24,    99] loss: 0.320017\n",
      "[24,   199] loss: 0.204452\n",
      "[24,   299] loss: 0.243629\n",
      "[24,   399] loss: 0.313984\n",
      "[24,   499] loss: 0.167778\n",
      "[24,   599] loss: 0.249818\n",
      "[24,   699] loss: 0.274261\n",
      "[25,    99] loss: 0.248532\n",
      "[25,   199] loss: 0.188086\n",
      "[25,   299] loss: 0.368064\n",
      "[25,   399] loss: 0.282354\n",
      "[25,   499] loss: 0.205026\n",
      "[25,   599] loss: 0.159638\n",
      "[25,   699] loss: 0.281163\n",
      "[26,    99] loss: 0.265969\n",
      "[26,   199] loss: 0.215900\n",
      "[26,   299] loss: 0.200462\n",
      "[26,   399] loss: 0.153466\n",
      "[26,   499] loss: 0.221046\n",
      "[26,   599] loss: 0.110758\n",
      "[26,   699] loss: 0.322023\n",
      "[27,    99] loss: 0.322879\n",
      "[27,   199] loss: 0.186978\n",
      "[27,   299] loss: 0.233148\n",
      "[27,   399] loss: 0.282865\n",
      "[27,   499] loss: 0.161018\n",
      "[27,   599] loss: 0.114922\n",
      "[27,   699] loss: 0.342122\n",
      "[28,    99] loss: 0.234920\n",
      "[28,   199] loss: 0.196382\n",
      "[28,   299] loss: 0.301255\n",
      "[28,   399] loss: 0.105419\n",
      "[28,   499] loss: 0.219399\n",
      "[28,   599] loss: 0.182947\n",
      "[28,   699] loss: 0.453022\n",
      "[29,    99] loss: 0.312026\n",
      "[29,   199] loss: 0.164959\n",
      "[29,   299] loss: 0.236104\n",
      "[29,   399] loss: 0.215775\n",
      "[29,   499] loss: 0.177876\n",
      "[29,   599] loss: 0.377811\n",
      "[29,   699] loss: 0.305674\n",
      "[30,    99] loss: 0.387750\n",
      "[30,   199] loss: 0.212689\n",
      "[30,   299] loss: 0.281043\n",
      "[30,   399] loss: 0.131389\n",
      "[30,   499] loss: 0.166903\n",
      "[30,   599] loss: 0.128399\n",
      "[30,   699] loss: 0.372103\n",
      "[31,    99] loss: 0.350997\n",
      "[31,   199] loss: 0.172348\n",
      "[31,   299] loss: 0.192188\n",
      "[31,   399] loss: 0.103960\n",
      "[31,   499] loss: 0.178932\n",
      "[31,   599] loss: 0.268439\n",
      "[31,   699] loss: 0.185293\n",
      "[32,    99] loss: 0.344048\n",
      "[32,   199] loss: 0.192872\n",
      "[32,   299] loss: 0.281815\n",
      "[32,   399] loss: 0.256048\n",
      "[32,   499] loss: 0.227815\n",
      "[32,   599] loss: 0.142802\n",
      "[32,   699] loss: 0.176732\n",
      "[33,    99] loss: 0.338829\n",
      "[33,   199] loss: 0.188948\n",
      "[33,   299] loss: 0.477143\n",
      "[33,   399] loss: 0.150367\n",
      "[33,   499] loss: 0.174916\n",
      "[33,   599] loss: 0.221193\n",
      "[33,   699] loss: 0.355713\n",
      "[34,    99] loss: 0.351771\n",
      "[34,   199] loss: 0.141531\n",
      "[34,   299] loss: 0.208180\n",
      "[34,   399] loss: 0.133620\n",
      "[34,   499] loss: 0.155511\n",
      "[34,   599] loss: 0.086349\n",
      "[34,   699] loss: 0.501644\n",
      "[35,    99] loss: 0.378588\n",
      "[35,   199] loss: 0.119370\n",
      "[35,   299] loss: 0.205032\n",
      "[35,   399] loss: 0.226919\n",
      "[35,   499] loss: 0.209560\n",
      "[35,   599] loss: 0.082405\n",
      "[35,   699] loss: 0.277217\n",
      "[36,    99] loss: 0.300791\n",
      "[36,   199] loss: 0.105091\n",
      "[36,   299] loss: 0.296565\n",
      "[36,   399] loss: 0.133726\n",
      "[36,   499] loss: 0.208640\n",
      "[36,   599] loss: 0.091603\n",
      "[36,   699] loss: 0.296455\n",
      "[37,    99] loss: 0.307049\n",
      "[37,   199] loss: 0.123648\n",
      "[37,   299] loss: 0.206257\n",
      "[37,   399] loss: 0.113966\n",
      "[37,   499] loss: 0.165947\n",
      "[37,   599] loss: 0.063731\n",
      "[37,   699] loss: 0.303876\n",
      "[38,    99] loss: 0.394204\n",
      "[38,   199] loss: 0.125392\n",
      "[38,   299] loss: 0.259378\n",
      "[38,   399] loss: 0.211631\n",
      "[38,   499] loss: 0.183139\n",
      "[38,   599] loss: 0.192741\n",
      "[38,   699] loss: 0.338863\n",
      "[39,    99] loss: 0.294153\n",
      "[39,   199] loss: 0.224622\n",
      "[39,   299] loss: 0.512487\n",
      "[39,   399] loss: 0.164976\n",
      "[39,   499] loss: 0.309065\n",
      "[39,   599] loss: 0.136989\n",
      "[39,   699] loss: 0.227044\n",
      "[40,    99] loss: 0.245582\n",
      "[40,   199] loss: 0.113662\n",
      "[40,   299] loss: 0.213216\n",
      "[40,   399] loss: 0.131763\n",
      "[40,   499] loss: 0.177259\n",
      "[40,   599] loss: 0.246670\n",
      "[40,   699] loss: 0.319965\n",
      "[41,    99] loss: 0.204757\n",
      "[41,   199] loss: 0.212692\n",
      "[41,   299] loss: 0.259794\n",
      "[41,   399] loss: 0.130141\n",
      "[41,   499] loss: 0.153433\n",
      "[41,   599] loss: 0.071625\n",
      "[41,   699] loss: 0.179098\n",
      "[42,    99] loss: 0.369767\n",
      "[42,   199] loss: 0.141649\n",
      "[42,   299] loss: 0.230549\n",
      "[42,   399] loss: 0.178162\n",
      "[42,   499] loss: 0.224912\n",
      "[42,   599] loss: 0.110454\n",
      "[42,   699] loss: 0.274996\n",
      "[43,    99] loss: 0.290331\n",
      "[43,   199] loss: 0.119312\n",
      "[43,   299] loss: 0.188990\n",
      "[43,   399] loss: 0.112752\n",
      "[43,   499] loss: 0.167611\n",
      "[43,   599] loss: 0.120972\n",
      "[43,   699] loss: 0.150869\n",
      "[44,    99] loss: 0.201412\n",
      "[44,   199] loss: 0.103988\n",
      "[44,   299] loss: 0.164610\n",
      "[44,   399] loss: 0.243320\n",
      "[44,   499] loss: 0.217188\n",
      "[44,   599] loss: 0.117392\n",
      "[44,   699] loss: 0.325610\n",
      "[45,    99] loss: 0.250537\n",
      "[45,   199] loss: 0.135281\n",
      "[45,   299] loss: 0.227087\n",
      "[45,   399] loss: 0.259855\n",
      "[45,   499] loss: 0.166245\n",
      "[45,   599] loss: 0.150102\n",
      "[45,   699] loss: 0.227575\n",
      "[46,    99] loss: 0.230003\n",
      "[46,   199] loss: 0.107467\n",
      "[46,   299] loss: 0.388636\n",
      "[46,   399] loss: 0.566573\n",
      "[46,   499] loss: 0.176080\n",
      "[46,   599] loss: 0.400878\n",
      "[46,   699] loss: 0.338067\n",
      "[47,    99] loss: 0.377427\n",
      "[47,   199] loss: 0.139760\n",
      "[47,   299] loss: 0.537167\n",
      "[47,   399] loss: 0.149529\n",
      "[47,   499] loss: 0.212011\n",
      "[47,   599] loss: 0.089389\n",
      "[47,   699] loss: 0.174083\n",
      "[48,    99] loss: 0.310403\n",
      "[48,   199] loss: 0.210454\n",
      "[48,   299] loss: 0.447468\n",
      "[48,   399] loss: 0.128908\n",
      "[48,   499] loss: 0.204004\n",
      "[48,   599] loss: 0.103605\n",
      "[48,   699] loss: 0.192536\n",
      "[49,    99] loss: 0.268350\n",
      "[49,   199] loss: 0.238199\n",
      "[49,   299] loss: 0.260188\n",
      "[49,   399] loss: 0.148935\n",
      "[49,   499] loss: 0.170509\n",
      "[49,   599] loss: 0.121018\n",
      "[49,   699] loss: 0.260954\n",
      "[50,    99] loss: 0.375476\n",
      "[50,   199] loss: 0.143388\n",
      "[50,   299] loss: 0.240907\n",
      "[50,   399] loss: 0.146644\n",
      "[50,   499] loss: 0.216706\n",
      "[50,   599] loss: 0.121755\n",
      "[50,   699] loss: 0.346746\n",
      "[51,    99] loss: 0.233971\n",
      "[51,   199] loss: 0.111962\n",
      "[51,   299] loss: 0.322305\n",
      "[51,   399] loss: 0.153612\n",
      "[51,   499] loss: 0.137666\n",
      "[51,   599] loss: 0.156534\n",
      "[51,   699] loss: 0.222717\n",
      "[52,    99] loss: 0.355454\n",
      "[52,   199] loss: 0.152960\n",
      "[52,   299] loss: 0.268788\n",
      "[52,   399] loss: 0.235170\n",
      "[52,   499] loss: 0.163754\n",
      "[52,   599] loss: 0.182773\n",
      "[52,   699] loss: 0.226657\n",
      "[53,    99] loss: 0.253330\n",
      "[53,   199] loss: 0.138996\n",
      "[53,   299] loss: 0.261415\n",
      "[53,   399] loss: 0.183468\n",
      "[53,   499] loss: 0.252936\n",
      "[53,   599] loss: 0.063308\n",
      "[53,   699] loss: 0.242400\n",
      "[54,    99] loss: 0.319407\n",
      "[54,   199] loss: 0.181110\n",
      "[54,   299] loss: 0.196356\n",
      "[54,   399] loss: 0.103959\n",
      "[54,   499] loss: 0.149119\n",
      "[54,   599] loss: 0.264945\n",
      "[54,   699] loss: 0.164544\n",
      "[55,    99] loss: 0.231806\n",
      "[55,   199] loss: 0.251765\n",
      "[55,   299] loss: 0.207201\n",
      "[55,   399] loss: 0.099386\n",
      "[55,   499] loss: 0.132319\n",
      "[55,   599] loss: 0.147099\n",
      "[55,   699] loss: 0.171163\n",
      "[56,    99] loss: 0.263850\n",
      "[56,   199] loss: 0.099154\n",
      "[56,   299] loss: 0.178679\n",
      "[56,   399] loss: 0.108240\n",
      "[56,   499] loss: 0.154057\n",
      "[56,   599] loss: 0.146999\n",
      "[56,   699] loss: 0.288513\n",
      "[57,    99] loss: 0.326354\n",
      "[57,   199] loss: 0.138140\n",
      "[57,   299] loss: 0.223156\n",
      "[57,   399] loss: 0.204256\n",
      "[57,   499] loss: 0.132146\n",
      "[57,   599] loss: 0.241970\n",
      "[57,   699] loss: 0.193030\n",
      "[58,    99] loss: 0.952126\n",
      "[58,   199] loss: 0.084085\n",
      "[58,   299] loss: 0.428896\n",
      "[58,   399] loss: 0.393387\n",
      "[58,   499] loss: 0.206265\n",
      "[58,   599] loss: 0.215713\n",
      "[58,   699] loss: 0.540453\n",
      "[59,    99] loss: 0.445250\n",
      "[59,   199] loss: 0.176568\n",
      "[59,   299] loss: 0.258061\n",
      "[59,   399] loss: 0.274530\n",
      "[59,   499] loss: 0.146710\n",
      "[59,   599] loss: 0.060082\n",
      "[59,   699] loss: 0.164481\n",
      "[60,    99] loss: 0.410575\n",
      "[60,   199] loss: 0.141924\n",
      "[60,   299] loss: 0.176750\n",
      "[60,   399] loss: 0.154819\n",
      "[60,   499] loss: 0.219420\n",
      "[60,   599] loss: 0.297353\n",
      "[60,   699] loss: 0.272019\n",
      "[61,    99] loss: 0.176058\n",
      "[61,   199] loss: 0.091459\n",
      "[61,   299] loss: 0.174905\n",
      "[61,   399] loss: 0.215191\n",
      "[61,   499] loss: 0.301838\n",
      "[61,   599] loss: 0.061741\n",
      "[61,   699] loss: 0.271414\n",
      "[62,    99] loss: 0.294667\n",
      "[62,   199] loss: 0.133812\n",
      "[62,   299] loss: 0.203946\n",
      "[62,   399] loss: 0.218361\n",
      "[62,   499] loss: 0.337791\n",
      "[62,   599] loss: 0.165026\n",
      "[62,   699] loss: 0.213122\n",
      "[63,    99] loss: 0.409072\n",
      "[63,   199] loss: 0.124020\n",
      "[63,   299] loss: 0.279863\n",
      "[63,   399] loss: 0.293173\n",
      "[63,   499] loss: 0.151668\n",
      "[63,   599] loss: 0.070929\n",
      "[63,   699] loss: 0.172873\n",
      "[64,    99] loss: 0.226333\n",
      "[64,   199] loss: 0.211195\n",
      "[64,   299] loss: 0.280382\n",
      "[64,   399] loss: 0.180333\n",
      "[64,   499] loss: 0.139226\n",
      "[64,   599] loss: 0.081054\n",
      "[64,   699] loss: 0.955041\n",
      "[65,    99] loss: 0.308305\n",
      "[65,   199] loss: 0.153212\n",
      "[65,   299] loss: 0.171894\n",
      "[65,   399] loss: 0.241778\n",
      "[65,   499] loss: 0.147296\n",
      "[65,   599] loss: 0.320051\n",
      "[65,   699] loss: 0.146868\n",
      "[66,    99] loss: 0.737809\n",
      "[66,   199] loss: 0.148008\n",
      "[66,   299] loss: 0.202022\n",
      "[66,   399] loss: 0.133673\n",
      "[66,   499] loss: 0.180810\n",
      "[66,   599] loss: 0.101829\n",
      "[66,   699] loss: 0.423452\n",
      "[67,    99] loss: 0.444774\n",
      "[67,   199] loss: 0.098327\n",
      "[67,   299] loss: 0.190569\n",
      "[67,   399] loss: 0.114746\n",
      "[67,   499] loss: 0.135611\n",
      "[67,   599] loss: 0.072985\n",
      "[67,   699] loss: 0.097083\n",
      "[68,    99] loss: 0.311287\n",
      "[68,   199] loss: 0.080608\n",
      "[68,   299] loss: 0.202447\n",
      "[68,   399] loss: 0.105457\n",
      "[68,   499] loss: 0.141959\n",
      "[68,   599] loss: 0.061221\n",
      "[68,   699] loss: 0.090161\n",
      "[69,    99] loss: 0.217991\n",
      "[69,   199] loss: 0.083105\n",
      "[69,   299] loss: 0.203588\n",
      "[69,   399] loss: 0.074984\n",
      "[69,   499] loss: 0.291707\n",
      "[69,   599] loss: 0.061871\n",
      "[69,   699] loss: 0.273439\n",
      "[70,    99] loss: 0.338504\n",
      "[70,   199] loss: 0.126379\n",
      "[70,   299] loss: 0.190329\n",
      "[70,   399] loss: 0.113041\n",
      "[70,   499] loss: 0.150577\n",
      "[70,   599] loss: 0.452673\n",
      "[70,   699] loss: 0.149117\n",
      "[71,    99] loss: 1.054566\n",
      "[71,   199] loss: 0.219473\n",
      "[71,   299] loss: 0.282246\n",
      "[71,   399] loss: 0.338285\n",
      "[71,   499] loss: 0.212335\n",
      "[71,   599] loss: 0.145029\n",
      "[71,   699] loss: 0.234841\n",
      "[72,    99] loss: 0.292379\n",
      "[72,   199] loss: 0.126257\n",
      "[72,   299] loss: 0.163094\n",
      "[72,   399] loss: 0.152508\n",
      "[72,   499] loss: 0.127432\n",
      "[72,   599] loss: 0.106503\n",
      "[72,   699] loss: 0.227345\n",
      "[73,    99] loss: 0.314028\n",
      "[73,   199] loss: 0.122889\n",
      "[73,   299] loss: 0.177781\n",
      "[73,   399] loss: 0.094910\n",
      "[73,   499] loss: 0.107980\n",
      "[73,   599] loss: 0.231723\n",
      "[73,   699] loss: 0.090231\n",
      "[74,    99] loss: 0.182906\n",
      "[74,   199] loss: 0.271406\n",
      "[74,   299] loss: 0.245233\n",
      "[74,   399] loss: 0.136143\n",
      "[74,   499] loss: 0.181133\n",
      "[74,   599] loss: 0.072734\n",
      "[74,   699] loss: 0.166358\n",
      "[75,    99] loss: 0.337311\n",
      "[75,   199] loss: 0.100386\n",
      "[75,   299] loss: 0.201569\n",
      "[75,   399] loss: 0.112484\n",
      "[75,   499] loss: 0.120970\n",
      "[75,   599] loss: 0.058598\n",
      "[75,   699] loss: 0.111730\n",
      "[76,    99] loss: 0.162814\n",
      "[76,   199] loss: 0.112584\n",
      "[76,   299] loss: 0.182602\n",
      "[76,   399] loss: 0.130937\n",
      "[76,   499] loss: 0.146355\n",
      "[76,   599] loss: 0.322416\n",
      "[76,   699] loss: 0.117274\n",
      "[77,    99] loss: 0.233942\n",
      "[77,   199] loss: 0.081989\n",
      "[77,   299] loss: 0.495818\n",
      "[77,   399] loss: 0.154116\n",
      "[77,   499] loss: 0.131557\n",
      "[77,   599] loss: 0.068341\n",
      "[77,   699] loss: 0.143703\n",
      "[78,    99] loss: 0.295673\n",
      "[78,   199] loss: 0.090192\n",
      "[78,   299] loss: 0.192735\n",
      "[78,   399] loss: 0.132700\n",
      "[78,   499] loss: 0.174806\n",
      "[78,   599] loss: 0.089701\n",
      "[78,   699] loss: 0.378675\n",
      "[79,    99] loss: 0.172767\n",
      "[79,   199] loss: 0.153417\n",
      "[79,   299] loss: 0.193430\n",
      "[79,   399] loss: 0.139117\n",
      "[79,   499] loss: 0.099292\n",
      "[79,   599] loss: 0.292619\n",
      "[79,   699] loss: 0.855097\n",
      "[80,    99] loss: 0.299757\n",
      "[80,   199] loss: 0.086717\n",
      "[80,   299] loss: 0.188154\n",
      "[80,   399] loss: 0.087822\n",
      "[80,   499] loss: 0.127522\n",
      "[80,   599] loss: 0.061723\n",
      "[80,   699] loss: 0.081931\n",
      "[81,    99] loss: 0.275329\n",
      "[81,   199] loss: 0.077126\n",
      "[81,   299] loss: 0.189582\n",
      "[81,   399] loss: 0.096911\n",
      "[81,   499] loss: 0.192495\n",
      "[81,   599] loss: 0.178359\n",
      "[81,   699] loss: 0.094821\n",
      "[82,    99] loss: 0.201034\n",
      "[82,   199] loss: 0.127774\n",
      "[82,   299] loss: 0.196973\n",
      "[82,   399] loss: 0.074987\n",
      "[82,   499] loss: 0.136852\n",
      "[82,   599] loss: 0.067132\n",
      "[82,   699] loss: 0.122115\n",
      "[83,    99] loss: 0.152870\n",
      "[83,   199] loss: 0.047779\n",
      "[83,   299] loss: 0.152703\n",
      "[83,   399] loss: 0.119847\n",
      "[83,   499] loss: 0.545447\n",
      "[83,   599] loss: 0.570972\n",
      "[83,   699] loss: 0.229741\n",
      "[84,    99] loss: 0.885185\n",
      "[84,   199] loss: 0.086297\n",
      "[84,   299] loss: 0.200337\n",
      "[84,   399] loss: 0.120230\n",
      "[84,   499] loss: 0.131979\n",
      "[84,   599] loss: 0.063395\n",
      "[84,   699] loss: 0.117813\n",
      "[85,    99] loss: 0.160483\n",
      "[85,   199] loss: 0.041872\n",
      "[85,   299] loss: 0.176046\n",
      "[85,   399] loss: 0.132535\n",
      "[85,   499] loss: 0.116874\n",
      "[85,   599] loss: 0.048573\n",
      "[85,   699] loss: 0.104838\n",
      "[86,    99] loss: 0.145190\n",
      "[86,   199] loss: 0.143521\n",
      "[86,   299] loss: 0.194407\n",
      "[86,   399] loss: 0.238119\n",
      "[86,   499] loss: 0.471676\n",
      "[86,   599] loss: 0.096301\n",
      "[86,   699] loss: 0.206312\n",
      "[87,    99] loss: 0.181525\n",
      "[87,   199] loss: 0.100164\n",
      "[87,   299] loss: 0.191423\n",
      "[87,   399] loss: 0.250206\n",
      "[87,   499] loss: 0.235569\n",
      "[87,   599] loss: 0.081533\n",
      "[87,   699] loss: 0.134778\n",
      "[88,    99] loss: 0.210008\n",
      "[88,   199] loss: 0.257531\n",
      "[88,   299] loss: 0.223773\n",
      "[88,   399] loss: 0.153657\n",
      "[88,   499] loss: 0.131273\n",
      "[88,   599] loss: 0.069070\n",
      "[88,   699] loss: 0.100829\n",
      "[89,    99] loss: 0.308020\n",
      "[89,   199] loss: 0.099369\n",
      "[89,   299] loss: 0.471464\n",
      "[89,   399] loss: 0.116206\n",
      "[89,   499] loss: 0.163462\n",
      "[89,   599] loss: 0.096489\n",
      "[89,   699] loss: 0.151515\n",
      "[90,    99] loss: 0.629455\n",
      "[90,   199] loss: 0.148724\n",
      "[90,   299] loss: 0.169383\n",
      "[90,   399] loss: 0.241242\n",
      "[90,   499] loss: 0.158834\n",
      "[90,   599] loss: 0.164691\n",
      "[90,   699] loss: 0.352019\n",
      "[91,    99] loss: 0.173959\n",
      "[91,   199] loss: 0.228135\n",
      "[91,   299] loss: 0.449058\n",
      "[91,   399] loss: 0.116509\n",
      "[91,   499] loss: 0.311105\n",
      "[91,   599] loss: 0.141654\n",
      "[91,   699] loss: 0.214781\n",
      "[92,    99] loss: 0.171489\n",
      "[92,   199] loss: 0.123446\n",
      "[92,   299] loss: 0.200159\n",
      "[92,   399] loss: 0.111090\n",
      "[92,   499] loss: 0.134857\n",
      "[92,   599] loss: 0.107834\n",
      "[92,   699] loss: 0.419014\n",
      "[93,    99] loss: 0.319317\n",
      "[93,   199] loss: 0.115488\n",
      "[93,   299] loss: 0.293226\n",
      "[93,   399] loss: 0.172533\n",
      "[93,   499] loss: 0.162679\n",
      "[93,   599] loss: 0.091169\n",
      "[93,   699] loss: 0.084790\n",
      "[94,    99] loss: 0.236655\n",
      "[94,   199] loss: 0.150597\n",
      "[94,   299] loss: 0.141299\n",
      "[94,   399] loss: 0.135182\n",
      "[94,   499] loss: 0.123827\n",
      "[94,   599] loss: 0.083753\n",
      "[94,   699] loss: 0.116080\n",
      "[95,    99] loss: 0.117761\n",
      "[95,   199] loss: 0.038439\n",
      "[95,   299] loss: 0.162295\n",
      "[95,   399] loss: 0.117285\n",
      "[95,   499] loss: 0.132426\n",
      "[95,   599] loss: 0.159784\n",
      "[95,   699] loss: 0.104847\n",
      "[96,    99] loss: 0.161456\n",
      "[96,   199] loss: 0.135954\n",
      "[96,   299] loss: 0.270455\n",
      "[96,   399] loss: 0.102415\n",
      "[96,   499] loss: 0.363195\n",
      "[96,   599] loss: 0.172259\n",
      "[96,   699] loss: 0.195271\n",
      "[97,    99] loss: 0.297700\n",
      "[97,   199] loss: 0.140269\n",
      "[97,   299] loss: 0.421495\n",
      "[97,   399] loss: 0.135612\n",
      "[97,   499] loss: 0.129313\n",
      "[97,   599] loss: 0.096871\n",
      "[97,   699] loss: 0.098106\n",
      "[98,    99] loss: 0.202332\n",
      "[98,   199] loss: 0.074873\n",
      "[98,   299] loss: 0.428691\n",
      "[98,   399] loss: 0.197425\n",
      "[98,   499] loss: 0.115145\n",
      "[98,   599] loss: 0.146032\n",
      "[98,   699] loss: 0.118353\n",
      "[99,    99] loss: 0.137774\n",
      "[99,   199] loss: 0.065643\n",
      "[99,   299] loss: 0.170533\n",
      "[99,   399] loss: 0.081480\n",
      "[99,   499] loss: 0.112377\n",
      "[99,   599] loss: 0.054202\n",
      "[99,   699] loss: 0.167450\n",
      "[100,    99] loss: 0.267411\n",
      "[100,   199] loss: 0.122396\n",
      "[100,   299] loss: 0.196914\n",
      "[100,   399] loss: 0.085391\n",
      "[100,   499] loss: 0.148494\n",
      "[100,   599] loss: 0.061520\n",
      "[100,   699] loss: 0.088251\n",
      "Finished Training\n",
      "[1,    99] loss: 0.700225\n",
      "[1,   199] loss: 0.677289\n",
      "[1,   299] loss: 0.690766\n",
      "[1,   399] loss: 0.637962\n",
      "[1,   499] loss: 0.654686\n",
      "[1,   599] loss: 0.636427\n",
      "[1,   699] loss: 0.568341\n",
      "[2,    99] loss: 0.662299\n",
      "[2,   199] loss: 0.573703\n",
      "[2,   299] loss: 0.624565\n",
      "[2,   399] loss: 0.550375\n",
      "[2,   499] loss: 0.566257\n",
      "[2,   599] loss: 0.553850\n",
      "[2,   699] loss: 0.473381\n",
      "[3,    99] loss: 0.595870\n",
      "[3,   199] loss: 0.486128\n",
      "[3,   299] loss: 0.532338\n",
      "[3,   399] loss: 0.470681\n",
      "[3,   499] loss: 0.485651\n",
      "[3,   599] loss: 0.456135\n",
      "[3,   699] loss: 0.382796\n",
      "[4,    99] loss: 0.510087\n",
      "[4,   199] loss: 0.418246\n",
      "[4,   299] loss: 0.435868\n",
      "[4,   399] loss: 0.393219\n",
      "[4,   499] loss: 0.403359\n",
      "[4,   599] loss: 0.363526\n",
      "[4,   699] loss: 0.312653\n",
      "[5,    99] loss: 0.440272\n",
      "[5,   199] loss: 0.359229\n",
      "[5,   299] loss: 0.351875\n",
      "[5,   399] loss: 0.325873\n",
      "[5,   499] loss: 0.348504\n",
      "[5,   599] loss: 0.302126\n",
      "[5,   699] loss: 0.245844\n",
      "[6,    99] loss: 0.433567\n",
      "[6,   199] loss: 0.334688\n",
      "[6,   299] loss: 0.292625\n",
      "[6,   399] loss: 0.283584\n",
      "[6,   499] loss: 0.266696\n",
      "[6,   599] loss: 0.267800\n",
      "[6,   699] loss: 0.222152\n",
      "[7,    99] loss: 0.373400\n",
      "[7,   199] loss: 0.284318\n",
      "[7,   299] loss: 0.256110\n",
      "[7,   399] loss: 0.261855\n",
      "[7,   499] loss: 0.238162\n",
      "[7,   599] loss: 0.240146\n",
      "[7,   699] loss: 0.199703\n",
      "[8,    99] loss: 0.319604\n",
      "[8,   199] loss: 0.256798\n",
      "[8,   299] loss: 0.216529\n",
      "[8,   399] loss: 0.228905\n",
      "[8,   499] loss: 0.218863\n",
      "[8,   599] loss: 0.210425\n",
      "[8,   699] loss: 0.180458\n",
      "[9,    99] loss: 0.310799\n",
      "[9,   199] loss: 0.245830\n",
      "[9,   299] loss: 0.218353\n",
      "[9,   399] loss: 0.212286\n",
      "[9,   499] loss: 0.183628\n",
      "[9,   599] loss: 0.188623\n",
      "[9,   699] loss: 0.169628\n",
      "[10,    99] loss: 0.263859\n",
      "[10,   199] loss: 0.217468\n",
      "[10,   299] loss: 0.200753\n",
      "[10,   399] loss: 0.201310\n",
      "[10,   499] loss: 0.157754\n",
      "[10,   599] loss: 0.173079\n",
      "[10,   699] loss: 0.159033\n",
      "[11,    99] loss: 0.245108\n",
      "[11,   199] loss: 0.192520\n",
      "[11,   299] loss: 0.183452\n",
      "[11,   399] loss: 0.175268\n",
      "[11,   499] loss: 0.153055\n",
      "[11,   599] loss: 0.153261\n",
      "[11,   699] loss: 0.135429\n",
      "[12,    99] loss: 0.218427\n",
      "[12,   199] loss: 0.187534\n",
      "[12,   299] loss: 0.146179\n",
      "[12,   399] loss: 0.137533\n",
      "[12,   499] loss: 0.149772\n",
      "[12,   599] loss: 0.130512\n",
      "[12,   699] loss: 0.135302\n",
      "[13,    99] loss: 0.235686\n",
      "[13,   199] loss: 0.183539\n",
      "[13,   299] loss: 0.158318\n",
      "[13,   399] loss: 0.125532\n",
      "[13,   499] loss: 0.134393\n",
      "[13,   599] loss: 0.104783\n",
      "[13,   699] loss: 0.132537\n",
      "[14,    99] loss: 0.202529\n",
      "[14,   199] loss: 0.155105\n",
      "[14,   299] loss: 0.166955\n",
      "[14,   399] loss: 0.166263\n",
      "[14,   499] loss: 0.134333\n",
      "[14,   599] loss: 0.110552\n",
      "[14,   699] loss: 0.113420\n",
      "[15,    99] loss: 0.201959\n",
      "[15,   199] loss: 0.151803\n",
      "[15,   299] loss: 0.156214\n",
      "[15,   399] loss: 0.112404\n",
      "[15,   499] loss: 0.156831\n",
      "[15,   599] loss: 0.183047\n",
      "[15,   699] loss: 0.100891\n",
      "[16,    99] loss: 0.175059\n",
      "[16,   199] loss: 0.144051\n",
      "[16,   299] loss: 0.148811\n",
      "[16,   399] loss: 0.092455\n",
      "[16,   499] loss: 0.103486\n",
      "[16,   599] loss: 0.081341\n",
      "[16,   699] loss: 0.089523\n",
      "[17,    99] loss: 0.134342\n",
      "[17,   199] loss: 0.138671\n",
      "[17,   299] loss: 0.116246\n",
      "[17,   399] loss: 0.140627\n",
      "[17,   499] loss: 0.091638\n",
      "[17,   599] loss: 0.070720\n",
      "[17,   699] loss: 0.075807\n",
      "[18,    99] loss: 0.189997\n",
      "[18,   199] loss: 0.177981\n",
      "[18,   299] loss: 0.094995\n",
      "[18,   399] loss: 0.091599\n",
      "[18,   499] loss: 0.110864\n",
      "[18,   599] loss: 0.080451\n",
      "[18,   699] loss: 0.095894\n",
      "[19,    99] loss: 0.136517\n",
      "[19,   199] loss: 0.113782\n",
      "[19,   299] loss: 0.112318\n",
      "[19,   399] loss: 0.071091\n",
      "[19,   499] loss: 0.100839\n",
      "[19,   599] loss: 0.056412\n",
      "[19,   699] loss: 0.072887\n",
      "[20,    99] loss: 0.102230\n",
      "[20,   199] loss: 0.127174\n",
      "[20,   299] loss: 0.074995\n",
      "[20,   399] loss: 0.105215\n",
      "[20,   499] loss: 0.090860\n",
      "[20,   599] loss: 0.063141\n",
      "[20,   699] loss: 0.070053\n",
      "[21,    99] loss: 0.105401\n",
      "[21,   199] loss: 0.100364\n",
      "[21,   299] loss: 0.069759\n",
      "[21,   399] loss: 0.058321\n",
      "[21,   499] loss: 0.096695\n",
      "[21,   599] loss: 0.054410\n",
      "[21,   699] loss: 0.059023\n",
      "[22,    99] loss: 0.163905\n",
      "[22,   199] loss: 0.147038\n",
      "[22,   299] loss: 0.076377\n",
      "[22,   399] loss: 0.109027\n",
      "[22,   499] loss: 0.058279\n",
      "[22,   599] loss: 0.039940\n",
      "[22,   699] loss: 0.041495\n",
      "[23,    99] loss: 0.077648\n",
      "[23,   199] loss: 0.121556\n",
      "[23,   299] loss: 0.053541\n",
      "[23,   399] loss: 0.068813\n",
      "[23,   499] loss: 0.075732\n",
      "[23,   599] loss: 0.036062\n",
      "[23,   699] loss: 0.036411\n",
      "[24,    99] loss: 0.079888\n",
      "[24,   199] loss: 0.122515\n",
      "[24,   299] loss: 0.225252\n",
      "[24,   399] loss: 0.099103\n",
      "[24,   499] loss: 0.141527\n",
      "[24,   599] loss: 0.065421\n",
      "[24,   699] loss: 0.073413\n",
      "[25,    99] loss: 0.063420\n",
      "[25,   199] loss: 0.084631\n",
      "[25,   299] loss: 0.069968\n",
      "[25,   399] loss: 0.035811\n",
      "[25,   499] loss: 0.134154\n",
      "[25,   599] loss: 0.051658\n",
      "[25,   699] loss: 0.046519\n",
      "[26,    99] loss: 0.084102\n",
      "[26,   199] loss: 0.100327\n",
      "[26,   299] loss: 0.054392\n",
      "[26,   399] loss: 0.061774\n",
      "[26,   499] loss: 0.057334\n",
      "[26,   599] loss: 0.029478\n",
      "[26,   699] loss: 0.040828\n",
      "[27,    99] loss: 0.080720\n",
      "[27,   199] loss: 0.069247\n",
      "[27,   299] loss: 0.020541\n",
      "[27,   399] loss: 0.052593\n",
      "[27,   499] loss: 0.049564\n",
      "[27,   599] loss: 0.047487\n",
      "[27,   699] loss: 0.027330\n",
      "[28,    99] loss: 0.218639\n",
      "[28,   199] loss: 0.116424\n",
      "[28,   299] loss: 0.076204\n",
      "[28,   399] loss: 0.128874\n",
      "[28,   499] loss: 0.036130\n",
      "[28,   599] loss: 0.047552\n",
      "[28,   699] loss: 0.136675\n",
      "[29,    99] loss: 0.074541\n",
      "[29,   199] loss: 0.040235\n",
      "[29,   299] loss: 0.073561\n",
      "[29,   399] loss: 0.127899\n",
      "[29,   499] loss: 0.132114\n",
      "[29,   599] loss: 0.041612\n",
      "[29,   699] loss: 0.058189\n",
      "[30,    99] loss: 0.092696\n",
      "[30,   199] loss: 0.057135\n",
      "[30,   299] loss: 0.094280\n",
      "[30,   399] loss: 0.029706\n",
      "[30,   499] loss: 0.102746\n",
      "[30,   599] loss: 0.030576\n",
      "[30,   699] loss: 0.022488\n",
      "[31,    99] loss: 0.049671\n",
      "[31,   199] loss: 0.031094\n",
      "[31,   299] loss: 0.081920\n",
      "[31,   399] loss: 0.061456\n",
      "[31,   499] loss: 0.022269\n",
      "[31,   599] loss: 0.018804\n",
      "[31,   699] loss: 0.026138\n",
      "[32,    99] loss: 0.053068\n",
      "[32,   199] loss: 0.064812\n",
      "[32,   299] loss: 0.024821\n",
      "[32,   399] loss: 0.023502\n",
      "[32,   499] loss: 0.053521\n",
      "[32,   599] loss: 0.014645\n",
      "[32,   699] loss: 0.028975\n",
      "[33,    99] loss: 0.092612\n",
      "[33,   199] loss: 0.107378\n",
      "[33,   299] loss: 0.202212\n",
      "[33,   399] loss: 0.120028\n",
      "[33,   499] loss: 0.037725\n",
      "[33,   599] loss: 0.018380\n",
      "[33,   699] loss: 0.026054\n",
      "[34,    99] loss: 0.037457\n",
      "[34,   199] loss: 0.081312\n",
      "[34,   299] loss: 0.041228\n",
      "[34,   399] loss: 0.055708\n",
      "[34,   499] loss: 0.023642\n",
      "[34,   599] loss: 0.020356\n",
      "[34,   699] loss: 0.031430\n",
      "[35,    99] loss: 0.147330\n",
      "[35,   199] loss: 0.069145\n",
      "[35,   299] loss: 0.020781\n",
      "[35,   399] loss: 0.013857\n",
      "[35,   499] loss: 0.027740\n",
      "[35,   599] loss: 0.019866\n",
      "[35,   699] loss: 0.062847\n",
      "[36,    99] loss: 0.106856\n",
      "[36,   199] loss: 0.027498\n",
      "[36,   299] loss: 0.079734\n",
      "[36,   399] loss: 0.233550\n",
      "[36,   499] loss: 0.285154\n",
      "[36,   599] loss: 0.068893\n",
      "[36,   699] loss: 0.103789\n",
      "[37,    99] loss: 0.086806\n",
      "[37,   199] loss: 0.074923\n",
      "[37,   299] loss: 0.069993\n",
      "[37,   399] loss: 0.063905\n",
      "[37,   499] loss: 0.054088\n",
      "[37,   599] loss: 0.027396\n",
      "[37,   699] loss: 0.026006\n",
      "[38,    99] loss: 0.064719\n",
      "[38,   199] loss: 0.035518\n",
      "[38,   299] loss: 0.053679\n",
      "[38,   399] loss: 0.042007\n",
      "[38,   499] loss: 0.034553\n",
      "[38,   599] loss: 0.043572\n",
      "[38,   699] loss: 0.039572\n",
      "[39,    99] loss: 0.034157\n",
      "[39,   199] loss: 0.017662\n",
      "[39,   299] loss: 0.108560\n",
      "[39,   399] loss: 0.075706\n",
      "[39,   499] loss: 0.009867\n",
      "[39,   599] loss: 0.010424\n",
      "[39,   699] loss: 0.011592\n",
      "[40,    99] loss: 0.024351\n",
      "[40,   199] loss: 0.023869\n",
      "[40,   299] loss: 0.032901\n",
      "[40,   399] loss: 0.044049\n",
      "[40,   499] loss: 0.010675\n",
      "[40,   599] loss: 0.007913\n",
      "[40,   699] loss: 0.015043\n",
      "[41,    99] loss: 0.033063\n",
      "[41,   199] loss: 0.050227\n",
      "[41,   299] loss: 0.141971\n",
      "[41,   399] loss: 0.015973\n",
      "[41,   499] loss: 0.019259\n",
      "[41,   599] loss: 0.008788\n",
      "[41,   699] loss: 0.042817\n",
      "[42,    99] loss: 0.170036\n",
      "[42,   199] loss: 0.062944\n",
      "[42,   299] loss: 0.032906\n",
      "[42,   399] loss: 0.009948\n",
      "[42,   499] loss: 0.034136\n",
      "[42,   599] loss: 0.018667\n",
      "[42,   699] loss: 0.060385\n",
      "[43,    99] loss: 0.054204\n",
      "[43,   199] loss: 0.015751\n",
      "[43,   299] loss: 0.079078\n",
      "[43,   399] loss: 0.166776\n",
      "[43,   499] loss: 0.045543\n",
      "[43,   599] loss: 0.148346\n",
      "[43,   699] loss: 0.030391\n",
      "[44,    99] loss: 0.358700\n",
      "[44,   199] loss: 0.122930\n",
      "[44,   299] loss: 0.053854\n",
      "[44,   399] loss: 0.032498\n",
      "[44,   499] loss: 0.040268\n",
      "[44,   599] loss: 0.008648\n",
      "[44,   699] loss: 0.029207\n",
      "[45,    99] loss: 0.044807\n",
      "[45,   199] loss: 0.018695\n",
      "[45,   299] loss: 0.048421\n",
      "[45,   399] loss: 0.023488\n",
      "[45,   499] loss: 0.008960\n",
      "[45,   599] loss: 0.052568\n",
      "[45,   699] loss: 0.022118\n",
      "[46,    99] loss: 0.066979\n",
      "[46,   199] loss: 0.015614\n",
      "[46,   299] loss: 0.033458\n",
      "[46,   399] loss: 0.036332\n",
      "[46,   499] loss: 0.028576\n",
      "[46,   599] loss: 0.007884\n",
      "[46,   699] loss: 0.033992\n",
      "[47,    99] loss: 0.041750\n",
      "[47,   199] loss: 0.026336\n",
      "[47,   299] loss: 0.016803\n",
      "[47,   399] loss: 0.008378\n",
      "[47,   499] loss: 0.013987\n",
      "[47,   599] loss: 0.003345\n",
      "[47,   699] loss: 0.011231\n",
      "[48,    99] loss: 0.021237\n",
      "[48,   199] loss: 0.014556\n",
      "[48,   299] loss: 0.064562\n",
      "[48,   399] loss: 0.003853\n",
      "[48,   499] loss: 0.094782\n",
      "[48,   599] loss: 0.017457\n",
      "[48,   699] loss: 0.040015\n",
      "[49,    99] loss: 0.018619\n",
      "[49,   199] loss: 0.017975\n",
      "[49,   299] loss: 0.033311\n",
      "[49,   399] loss: 0.394168\n",
      "[49,   499] loss: 0.131677\n",
      "[49,   599] loss: 0.077464\n",
      "[49,   699] loss: 0.040238\n",
      "[50,    99] loss: 0.080955\n",
      "[50,   199] loss: 0.024449\n",
      "[50,   299] loss: 0.085363\n",
      "[50,   399] loss: 0.028738\n",
      "[50,   499] loss: 0.023357\n",
      "[50,   599] loss: 0.026323\n",
      "[50,   699] loss: 0.021056\n",
      "[51,    99] loss: 0.029374\n",
      "[51,   199] loss: 0.015301\n",
      "[51,   299] loss: 0.027860\n",
      "[51,   399] loss: 0.015370\n",
      "[51,   499] loss: 0.003309\n",
      "[51,   599] loss: 0.008439\n",
      "[51,   699] loss: 0.011248\n",
      "[52,    99] loss: 0.038313\n",
      "[52,   199] loss: 0.053160\n",
      "[52,   299] loss: 0.006037\n",
      "[52,   399] loss: 0.029151\n",
      "[52,   499] loss: 0.122678\n",
      "[52,   599] loss: 0.050288\n",
      "[52,   699] loss: 0.023311\n",
      "[53,    99] loss: 0.093502\n",
      "[53,   199] loss: 0.143202\n",
      "[53,   299] loss: 0.285444\n",
      "[53,   399] loss: 0.057197\n",
      "[53,   499] loss: 0.067921\n",
      "[53,   599] loss: 0.077045\n",
      "[53,   699] loss: 0.025117\n",
      "[54,    99] loss: 0.037827\n",
      "[54,   199] loss: 0.018131\n",
      "[54,   299] loss: 0.006326\n",
      "[54,   399] loss: 0.008757\n",
      "[54,   499] loss: 0.008106\n",
      "[54,   599] loss: 0.004798\n",
      "[54,   699] loss: 0.014424\n",
      "[55,    99] loss: 0.021735\n",
      "[55,   199] loss: 0.008196\n",
      "[55,   299] loss: 0.039122\n",
      "[55,   399] loss: 0.004275\n",
      "[55,   499] loss: 0.004229\n",
      "[55,   599] loss: 0.009521\n",
      "[55,   699] loss: 0.009413\n",
      "[56,    99] loss: 0.009804\n",
      "[56,   199] loss: 0.007733\n",
      "[56,   299] loss: 0.025517\n",
      "[56,   399] loss: 0.005179\n",
      "[56,   499] loss: 0.004985\n",
      "[56,   599] loss: 0.004236\n",
      "[56,   699] loss: 0.025515\n",
      "[57,    99] loss: 0.030024\n",
      "[57,   199] loss: 0.036126\n",
      "[57,   299] loss: 0.019358\n",
      "[57,   399] loss: 0.002820\n",
      "[57,   499] loss: 0.005678\n",
      "[57,   599] loss: 0.010060\n",
      "[57,   699] loss: 0.023344\n",
      "[58,    99] loss: 0.055473\n",
      "[58,   199] loss: 0.116527\n",
      "[58,   299] loss: 0.062492\n",
      "[58,   399] loss: 0.028281\n",
      "[58,   499] loss: 0.103259\n",
      "[58,   599] loss: 0.021371\n",
      "[58,   699] loss: 0.025944\n",
      "[59,    99] loss: 0.024276\n",
      "[59,   199] loss: 0.024987\n",
      "[59,   299] loss: 0.077476\n",
      "[59,   399] loss: 0.087985\n",
      "[59,   499] loss: 0.013750\n",
      "[59,   599] loss: 0.013588\n",
      "[59,   699] loss: 0.025223\n",
      "[60,    99] loss: 0.021993\n",
      "[60,   199] loss: 0.007530\n",
      "[60,   299] loss: 0.016209\n",
      "[60,   399] loss: 0.002763\n",
      "[60,   499] loss: 0.036904\n",
      "[60,   599] loss: 0.006466\n",
      "[60,   699] loss: 0.028239\n",
      "[61,    99] loss: 0.021586\n",
      "[61,   199] loss: 0.009767\n",
      "[61,   299] loss: 0.020126\n",
      "[61,   399] loss: 0.002566\n",
      "[61,   499] loss: 0.006586\n",
      "[61,   599] loss: 0.002634\n",
      "[61,   699] loss: 0.033363\n",
      "[62,    99] loss: 0.135417\n",
      "[62,   199] loss: 0.113082\n",
      "[62,   299] loss: 0.014203\n",
      "[62,   399] loss: 0.011369\n",
      "[62,   499] loss: 0.020129\n",
      "[62,   599] loss: 0.008045\n",
      "[62,   699] loss: 0.025259\n",
      "[63,    99] loss: 0.033386\n",
      "[63,   199] loss: 0.021193\n",
      "[63,   299] loss: 0.027060\n",
      "[63,   399] loss: 0.034122\n",
      "[63,   499] loss: 0.091027\n",
      "[63,   599] loss: 0.006939\n",
      "[63,   699] loss: 0.030747\n",
      "[64,    99] loss: 0.043420\n",
      "[64,   199] loss: 0.007505\n",
      "[64,   299] loss: 0.009650\n",
      "[64,   399] loss: 0.003413\n",
      "[64,   499] loss: 0.005998\n",
      "[64,   599] loss: 0.005851\n",
      "[64,   699] loss: 0.108626\n",
      "[65,    99] loss: 0.146552\n",
      "[65,   199] loss: 0.048706\n",
      "[65,   299] loss: 0.077223\n",
      "[65,   399] loss: 0.432817\n",
      "[65,   499] loss: 0.265988\n",
      "[65,   599] loss: 0.023265\n",
      "[65,   699] loss: 0.037319\n",
      "[66,    99] loss: 0.080448\n",
      "[66,   199] loss: 0.070070\n",
      "[66,   299] loss: 0.137956\n",
      "[66,   399] loss: 0.065323\n",
      "[66,   499] loss: 0.029952\n",
      "[66,   599] loss: 0.035524\n",
      "[66,   699] loss: 0.011289\n",
      "[67,    99] loss: 0.012565\n",
      "[67,   199] loss: 0.093897\n",
      "[67,   299] loss: 0.072285\n",
      "[67,   399] loss: 0.005971\n",
      "[67,   499] loss: 0.005254\n",
      "[67,   599] loss: 0.005310\n",
      "[67,   699] loss: 0.004326\n",
      "[68,    99] loss: 0.006668\n",
      "[68,   199] loss: 0.008671\n",
      "[68,   299] loss: 0.021363\n",
      "[68,   399] loss: 0.002166\n",
      "[68,   499] loss: 0.002980\n",
      "[68,   599] loss: 0.001777\n",
      "[68,   699] loss: 0.002849\n",
      "[69,    99] loss: 0.004776\n",
      "[69,   199] loss: 0.007004\n",
      "[69,   299] loss: 0.011096\n",
      "[69,   399] loss: 0.001488\n",
      "[69,   499] loss: 0.001685\n",
      "[69,   599] loss: 0.001636\n",
      "[69,   699] loss: 0.002692\n",
      "[70,    99] loss: 0.004021\n",
      "[70,   199] loss: 0.003664\n",
      "[70,   299] loss: 0.005883\n",
      "[70,   399] loss: 0.001358\n",
      "[70,   499] loss: 0.001278\n",
      "[70,   599] loss: 0.000936\n",
      "[70,   699] loss: 0.004135\n",
      "[71,    99] loss: 0.013351\n",
      "[71,   199] loss: 0.107698\n",
      "[71,   299] loss: 0.103193\n",
      "[71,   399] loss: 0.269900\n",
      "[71,   499] loss: 0.019991\n",
      "[71,   599] loss: 0.049867\n",
      "[71,   699] loss: 0.030724\n",
      "[72,    99] loss: 0.137601\n",
      "[72,   199] loss: 0.128276\n",
      "[72,   299] loss: 0.051254\n",
      "[72,   399] loss: 0.079694\n",
      "[72,   499] loss: 0.009378\n",
      "[72,   599] loss: 0.007550\n",
      "[72,   699] loss: 0.010464\n",
      "[73,    99] loss: 0.018489\n",
      "[73,   199] loss: 0.024791\n",
      "[73,   299] loss: 0.077687\n",
      "[73,   399] loss: 0.017222\n",
      "[73,   499] loss: 0.006287\n",
      "[73,   599] loss: 0.005312\n",
      "[73,   699] loss: 0.006192\n",
      "[74,    99] loss: 0.006170\n",
      "[74,   199] loss: 0.008045\n",
      "[74,   299] loss: 0.031067\n",
      "[74,   399] loss: 0.002297\n",
      "[74,   499] loss: 0.004254\n",
      "[74,   599] loss: 0.002243\n",
      "[74,   699] loss: 0.017804\n",
      "[75,    99] loss: 0.068513\n",
      "[75,   199] loss: 0.014269\n",
      "[75,   299] loss: 0.007118\n",
      "[75,   399] loss: 0.002752\n",
      "[75,   499] loss: 0.130665\n",
      "[75,   599] loss: 0.158717\n",
      "[75,   699] loss: 0.082331\n",
      "[76,    99] loss: 0.047183\n",
      "[76,   199] loss: 0.107786\n",
      "[76,   299] loss: 0.269306\n",
      "[76,   399] loss: 0.016131\n",
      "[76,   499] loss: 0.081674\n",
      "[76,   599] loss: 0.019421\n",
      "[76,   699] loss: 0.010962\n",
      "[77,    99] loss: 0.009186\n",
      "[77,   199] loss: 0.012646\n",
      "[77,   299] loss: 0.039763\n",
      "[77,   399] loss: 0.004073\n",
      "[77,   499] loss: 0.012010\n",
      "[77,   599] loss: 0.003693\n",
      "[77,   699] loss: 0.020741\n",
      "[78,    99] loss: 0.007437\n",
      "[78,   199] loss: 0.003327\n",
      "[78,   299] loss: 0.014059\n",
      "[78,   399] loss: 0.002859\n",
      "[78,   499] loss: 0.028345\n",
      "[78,   599] loss: 0.003277\n",
      "[78,   699] loss: 0.004713\n",
      "[79,    99] loss: 0.002629\n",
      "[79,   199] loss: 0.003189\n",
      "[79,   299] loss: 0.011636\n",
      "[79,   399] loss: 0.000907\n",
      "[79,   499] loss: 0.001609\n",
      "[79,   599] loss: 0.002007\n",
      "[79,   699] loss: 0.002472\n",
      "[80,    99] loss: 0.001813\n",
      "[80,   199] loss: 0.001650\n",
      "[80,   299] loss: 0.007625\n",
      "[80,   399] loss: 0.000951\n",
      "[80,   499] loss: 0.001124\n",
      "[80,   599] loss: 0.001037\n",
      "[80,   699] loss: 0.002444\n",
      "[81,    99] loss: 0.002061\n",
      "[81,   199] loss: 0.001112\n",
      "[81,   299] loss: 0.007377\n",
      "[81,   399] loss: 0.000555\n",
      "[81,   499] loss: 0.001486\n",
      "[81,   599] loss: 0.000729\n",
      "[81,   699] loss: 0.013823\n",
      "[82,    99] loss: 0.068308\n",
      "[82,   199] loss: 0.045324\n",
      "[82,   299] loss: 0.025154\n",
      "[82,   399] loss: 0.100673\n",
      "[82,   499] loss: 0.082721\n",
      "[82,   599] loss: 0.045472\n",
      "[82,   699] loss: 0.122480\n",
      "[83,    99] loss: 0.037025\n",
      "[83,   199] loss: 0.045862\n",
      "[83,   299] loss: 0.040392\n",
      "[83,   399] loss: 0.020520\n",
      "[83,   499] loss: 0.018067\n",
      "[83,   599] loss: 0.006766\n",
      "[83,   699] loss: 0.003141\n",
      "[84,    99] loss: 0.013193\n",
      "[84,   199] loss: 0.004928\n",
      "[84,   299] loss: 0.011532\n",
      "[84,   399] loss: 0.003683\n",
      "[84,   499] loss: 0.001506\n",
      "[84,   599] loss: 0.001801\n",
      "[84,   699] loss: 0.001954\n",
      "[85,    99] loss: 0.002003\n",
      "[85,   199] loss: 0.000906\n",
      "[85,   299] loss: 0.014954\n",
      "[85,   399] loss: 0.001622\n",
      "[85,   499] loss: 0.002890\n",
      "[85,   599] loss: 0.001286\n",
      "[85,   699] loss: 0.012097\n",
      "[86,    99] loss: 0.022734\n",
      "[86,   199] loss: 0.002717\n",
      "[86,   299] loss: 0.060358\n",
      "[86,   399] loss: 0.001510\n",
      "[86,   499] loss: 0.022946\n",
      "[86,   599] loss: 0.011077\n",
      "[86,   699] loss: 0.005492\n",
      "[87,    99] loss: 0.003406\n",
      "[87,   199] loss: 0.004362\n",
      "[87,   299] loss: 0.003533\n",
      "[87,   399] loss: 0.056303\n",
      "[87,   499] loss: 0.004591\n",
      "[87,   599] loss: 0.000833\n",
      "[87,   699] loss: 0.002294\n",
      "[88,    99] loss: 0.002327\n",
      "[88,   199] loss: 0.011117\n",
      "[88,   299] loss: 0.103327\n",
      "[88,   399] loss: 0.003483\n",
      "[88,   499] loss: 0.086930\n",
      "[88,   599] loss: 0.005598\n",
      "[88,   699] loss: 0.004251\n",
      "[89,    99] loss: 0.005339\n",
      "[89,   199] loss: 0.004867\n",
      "[89,   299] loss: 0.024471\n",
      "[89,   399] loss: 0.152287\n",
      "[89,   499] loss: 0.164004\n",
      "[89,   599] loss: 0.033943\n",
      "[89,   699] loss: 0.062672\n",
      "[90,    99] loss: 0.097966\n",
      "[90,   199] loss: 0.062234\n",
      "[90,   299] loss: 0.071386\n",
      "[90,   399] loss: 0.060628\n",
      "[90,   499] loss: 0.147173\n",
      "[90,   599] loss: 0.044637\n",
      "[90,   699] loss: 0.005049\n",
      "[91,    99] loss: 0.003483\n",
      "[91,   199] loss: 0.034280\n",
      "[91,   299] loss: 0.013935\n",
      "[91,   399] loss: 0.003065\n",
      "[91,   499] loss: 0.000956\n",
      "[91,   599] loss: 0.006100\n",
      "[91,   699] loss: 0.001446\n",
      "[92,    99] loss: 0.002442\n",
      "[92,   199] loss: 0.002423\n",
      "[92,   299] loss: 0.004796\n",
      "[92,   399] loss: 0.001364\n",
      "[92,   499] loss: 0.001406\n",
      "[92,   599] loss: 0.000685\n",
      "[92,   699] loss: 0.001870\n",
      "[93,    99] loss: 0.002023\n",
      "[93,   199] loss: 0.001105\n",
      "[93,   299] loss: 0.001008\n",
      "[93,   399] loss: 0.001219\n",
      "[93,   499] loss: 0.000699\n",
      "[93,   599] loss: 0.000415\n",
      "[93,   699] loss: 0.000956\n",
      "[94,    99] loss: 0.001294\n",
      "[94,   199] loss: 0.000671\n",
      "[94,   299] loss: 0.000791\n",
      "[94,   399] loss: 0.000863\n",
      "[94,   499] loss: 0.000541\n",
      "[94,   599] loss: 0.000326\n",
      "[94,   699] loss: 0.000721\n",
      "[95,    99] loss: 0.001005\n",
      "[95,   199] loss: 0.000544\n",
      "[95,   299] loss: 0.000759\n",
      "[95,   399] loss: 0.000821\n",
      "[95,   499] loss: 0.000471\n",
      "[95,   599] loss: 0.000253\n",
      "[95,   699] loss: 0.000597\n",
      "[96,    99] loss: 0.000816\n",
      "[96,   199] loss: 0.000558\n",
      "[96,   299] loss: 0.003212\n",
      "[96,   399] loss: 0.002204\n",
      "[96,   499] loss: 0.000489\n",
      "[96,   599] loss: 0.000384\n",
      "[96,   699] loss: 0.001192\n",
      "[97,    99] loss: 0.001252\n",
      "[97,   199] loss: 0.466094\n",
      "[97,   299] loss: 0.069472\n",
      "[97,   399] loss: 0.087859\n",
      "[97,   499] loss: 0.027223\n",
      "[97,   599] loss: 0.023148\n",
      "[97,   699] loss: 0.010965\n",
      "[98,    99] loss: 0.010482\n",
      "[98,   199] loss: 0.017738\n",
      "[98,   299] loss: 0.027204\n",
      "[98,   399] loss: 0.005992\n",
      "[98,   499] loss: 0.005729\n",
      "[98,   599] loss: 0.003920\n",
      "[98,   699] loss: 0.002808\n",
      "[99,    99] loss: 0.026038\n",
      "[99,   199] loss: 0.083178\n",
      "[99,   299] loss: 0.181940\n",
      "[99,   399] loss: 0.009586\n",
      "[99,   499] loss: 0.007007\n",
      "[99,   599] loss: 0.004564\n",
      "[99,   699] loss: 0.018381\n",
      "[100,    99] loss: 0.020243\n",
      "[100,   199] loss: 0.008679\n",
      "[100,   299] loss: 0.044713\n",
      "[100,   399] loss: 0.065944\n",
      "[100,   499] loss: 0.027367\n",
      "[100,   599] loss: 0.010269\n",
      "[100,   699] loss: 0.061678\n",
      "Finished Training\n",
      "[1,    99] loss: 0.668724\n",
      "[1,   199] loss: 0.686498\n",
      "[1,   299] loss: 0.663336\n",
      "[1,   399] loss: 0.645332\n",
      "[1,   499] loss: 0.638347\n",
      "[1,   599] loss: 0.606764\n",
      "[1,   699] loss: 0.595601\n",
      "[2,    99] loss: 0.606211\n",
      "[2,   199] loss: 0.602479\n",
      "[2,   299] loss: 0.586367\n",
      "[2,   399] loss: 0.581554\n",
      "[2,   499] loss: 0.555671\n",
      "[2,   599] loss: 0.534136\n",
      "[2,   699] loss: 0.509785\n",
      "[3,    99] loss: 0.535806\n",
      "[3,   199] loss: 0.553765\n",
      "[3,   299] loss: 0.499495\n",
      "[3,   399] loss: 0.517792\n",
      "[3,   499] loss: 0.473672\n",
      "[3,   599] loss: 0.463964\n",
      "[3,   699] loss: 0.440235\n",
      "[4,    99] loss: 0.472520\n",
      "[4,   199] loss: 0.515380\n",
      "[4,   299] loss: 0.415524\n",
      "[4,   399] loss: 0.440305\n",
      "[4,   499] loss: 0.401027\n",
      "[4,   599] loss: 0.398921\n",
      "[4,   699] loss: 0.364644\n",
      "[5,    99] loss: 0.412787\n",
      "[5,   199] loss: 0.493727\n",
      "[5,   299] loss: 0.345302\n",
      "[5,   399] loss: 0.379058\n",
      "[5,   499] loss: 0.336022\n",
      "[5,   599] loss: 0.343307\n",
      "[5,   699] loss: 0.313580\n",
      "[6,    99] loss: 0.361474\n",
      "[6,   199] loss: 0.431570\n",
      "[6,   299] loss: 0.288212\n",
      "[6,   399] loss: 0.323383\n",
      "[6,   499] loss: 0.290276\n",
      "[6,   599] loss: 0.301179\n",
      "[6,   699] loss: 0.269813\n",
      "[7,    99] loss: 0.315256\n",
      "[7,   199] loss: 0.402875\n",
      "[7,   299] loss: 0.244565\n",
      "[7,   399] loss: 0.271360\n",
      "[7,   499] loss: 0.264786\n",
      "[7,   599] loss: 0.261063\n",
      "[7,   699] loss: 0.234780\n",
      "[8,    99] loss: 0.288886\n",
      "[8,   199] loss: 0.370353\n",
      "[8,   299] loss: 0.220516\n",
      "[8,   399] loss: 0.233132\n",
      "[8,   499] loss: 0.244108\n",
      "[8,   599] loss: 0.234798\n",
      "[8,   699] loss: 0.216857\n",
      "[9,    99] loss: 0.259872\n",
      "[9,   199] loss: 0.353132\n",
      "[9,   299] loss: 0.197531\n",
      "[9,   399] loss: 0.192775\n",
      "[9,   499] loss: 0.236025\n",
      "[9,   599] loss: 0.214163\n",
      "[9,   699] loss: 0.187089\n",
      "[10,    99] loss: 0.234791\n",
      "[10,   199] loss: 0.326131\n",
      "[10,   299] loss: 0.172982\n",
      "[10,   399] loss: 0.180890\n",
      "[10,   499] loss: 0.215752\n",
      "[10,   599] loss: 0.193456\n",
      "[10,   699] loss: 0.169464\n",
      "[11,    99] loss: 0.221881\n",
      "[11,   199] loss: 0.309646\n",
      "[11,   299] loss: 0.164563\n",
      "[11,   399] loss: 0.152013\n",
      "[11,   499] loss: 0.200328\n",
      "[11,   599] loss: 0.172258\n",
      "[11,   699] loss: 0.160078\n",
      "[12,    99] loss: 0.197594\n",
      "[12,   199] loss: 0.271180\n",
      "[12,   299] loss: 0.146741\n",
      "[12,   399] loss: 0.130109\n",
      "[12,   499] loss: 0.180543\n",
      "[12,   599] loss: 0.146558\n",
      "[12,   699] loss: 0.145034\n",
      "[13,    99] loss: 0.185055\n",
      "[13,   199] loss: 0.252069\n",
      "[13,   299] loss: 0.139304\n",
      "[13,   399] loss: 0.120472\n",
      "[13,   499] loss: 0.167278\n",
      "[13,   599] loss: 0.135700\n",
      "[13,   699] loss: 0.129206\n",
      "[14,    99] loss: 0.181694\n",
      "[14,   199] loss: 0.234268\n",
      "[14,   299] loss: 0.131737\n",
      "[14,   399] loss: 0.109870\n",
      "[14,   499] loss: 0.164461\n",
      "[14,   599] loss: 0.112661\n",
      "[14,   699] loss: 0.126863\n",
      "[15,    99] loss: 0.184461\n",
      "[15,   199] loss: 0.229986\n",
      "[15,   299] loss: 0.119059\n",
      "[15,   399] loss: 0.106285\n",
      "[15,   499] loss: 0.147859\n",
      "[15,   599] loss: 0.094253\n",
      "[15,   699] loss: 0.091424\n",
      "[16,    99] loss: 0.128449\n",
      "[16,   199] loss: 0.198871\n",
      "[16,   299] loss: 0.103631\n",
      "[16,   399] loss: 0.111025\n",
      "[16,   499] loss: 0.115595\n",
      "[16,   599] loss: 0.113278\n",
      "[16,   699] loss: 0.076771\n",
      "[17,    99] loss: 0.133526\n",
      "[17,   199] loss: 0.195084\n",
      "[17,   299] loss: 0.139448\n",
      "[17,   399] loss: 0.093795\n",
      "[17,   499] loss: 0.122964\n",
      "[17,   599] loss: 0.074114\n",
      "[17,   699] loss: 0.071607\n",
      "[18,    99] loss: 0.153393\n",
      "[18,   199] loss: 0.196811\n",
      "[18,   299] loss: 0.106055\n",
      "[18,   399] loss: 0.083310\n",
      "[18,   499] loss: 0.112075\n",
      "[18,   599] loss: 0.059086\n",
      "[18,   699] loss: 0.071983\n",
      "[19,    99] loss: 0.090975\n",
      "[19,   199] loss: 0.162147\n",
      "[19,   299] loss: 0.060462\n",
      "[19,   399] loss: 0.117530\n",
      "[19,   499] loss: 0.091041\n",
      "[19,   599] loss: 0.062014\n",
      "[19,   699] loss: 0.054687\n",
      "[20,    99] loss: 0.087234\n",
      "[20,   199] loss: 0.155703\n",
      "[20,   299] loss: 0.081046\n",
      "[20,   399] loss: 0.087992\n",
      "[20,   499] loss: 0.106501\n",
      "[20,   599] loss: 0.105764\n",
      "[20,   699] loss: 0.081126\n",
      "[21,    99] loss: 0.091647\n",
      "[21,   199] loss: 0.172680\n",
      "[21,   299] loss: 0.055529\n",
      "[21,   399] loss: 0.066868\n",
      "[21,   499] loss: 0.070340\n",
      "[21,   599] loss: 0.045513\n",
      "[21,   699] loss: 0.038560\n",
      "[22,    99] loss: 0.054204\n",
      "[22,   199] loss: 0.140247\n",
      "[22,   299] loss: 0.045630\n",
      "[22,   399] loss: 0.065136\n",
      "[22,   499] loss: 0.063281\n",
      "[22,   599] loss: 0.053330\n",
      "[22,   699] loss: 0.035720\n",
      "[23,    99] loss: 0.063441\n",
      "[23,   199] loss: 0.159782\n",
      "[23,   299] loss: 0.062509\n",
      "[23,   399] loss: 0.088250\n",
      "[23,   499] loss: 0.063222\n",
      "[23,   599] loss: 0.053720\n",
      "[23,   699] loss: 0.083150\n",
      "[24,    99] loss: 0.061075\n",
      "[24,   199] loss: 0.125125\n",
      "[24,   299] loss: 0.063345\n",
      "[24,   399] loss: 0.077242\n",
      "[24,   499] loss: 0.061000\n",
      "[24,   599] loss: 0.048221\n",
      "[24,   699] loss: 0.052683\n",
      "[25,    99] loss: 0.088238\n",
      "[25,   199] loss: 0.165366\n",
      "[25,   299] loss: 0.058764\n",
      "[25,   399] loss: 0.129259\n",
      "[25,   499] loss: 0.079316\n",
      "[25,   599] loss: 0.046159\n",
      "[25,   699] loss: 0.081642\n",
      "[26,    99] loss: 0.087837\n",
      "[26,   199] loss: 0.182306\n",
      "[26,   299] loss: 0.053994\n",
      "[26,   399] loss: 0.073421\n",
      "[26,   499] loss: 0.070009\n",
      "[26,   599] loss: 0.040953\n",
      "[26,   699] loss: 0.041914\n",
      "[27,    99] loss: 0.066762\n",
      "[27,   199] loss: 0.103094\n",
      "[27,   299] loss: 0.048599\n",
      "[27,   399] loss: 0.055843\n",
      "[27,   499] loss: 0.060257\n",
      "[27,   599] loss: 0.088330\n",
      "[27,   699] loss: 0.030317\n",
      "[28,    99] loss: 0.039808\n",
      "[28,   199] loss: 0.117869\n",
      "[28,   299] loss: 0.058996\n",
      "[28,   399] loss: 0.040273\n",
      "[28,   499] loss: 0.092066\n",
      "[28,   599] loss: 0.031676\n",
      "[28,   699] loss: 0.041788\n",
      "[29,    99] loss: 0.138794\n",
      "[29,   199] loss: 0.087042\n",
      "[29,   299] loss: 0.051993\n",
      "[29,   399] loss: 0.056787\n",
      "[29,   499] loss: 0.079264\n",
      "[29,   599] loss: 0.062399\n",
      "[29,   699] loss: 0.048267\n",
      "[30,    99] loss: 0.035963\n",
      "[30,   199] loss: 0.079710\n",
      "[30,   299] loss: 0.041768\n",
      "[30,   399] loss: 0.041216\n",
      "[30,   499] loss: 0.056886\n",
      "[30,   599] loss: 0.059641\n",
      "[30,   699] loss: 0.035721\n",
      "[31,    99] loss: 0.033086\n",
      "[31,   199] loss: 0.146089\n",
      "[31,   299] loss: 0.079673\n",
      "[31,   399] loss: 0.036357\n",
      "[31,   499] loss: 0.086280\n",
      "[31,   599] loss: 0.064067\n",
      "[31,   699] loss: 0.020446\n",
      "[32,    99] loss: 0.165660\n",
      "[32,   199] loss: 0.134290\n",
      "[32,   299] loss: 0.086238\n",
      "[32,   399] loss: 0.061609\n",
      "[32,   499] loss: 0.051674\n",
      "[32,   599] loss: 0.153291\n",
      "[32,   699] loss: 0.093881\n",
      "[33,    99] loss: 0.083699\n",
      "[33,   199] loss: 0.181432\n",
      "[33,   299] loss: 0.060889\n",
      "[33,   399] loss: 0.024877\n",
      "[33,   499] loss: 0.078071\n",
      "[33,   599] loss: 0.027461\n",
      "[33,   699] loss: 0.032927\n",
      "[34,    99] loss: 0.026344\n",
      "[34,   199] loss: 0.103488\n",
      "[34,   299] loss: 0.067624\n",
      "[34,   399] loss: 0.036537\n",
      "[34,   499] loss: 0.059165\n",
      "[34,   599] loss: 0.023198\n",
      "[34,   699] loss: 0.044261\n",
      "[35,    99] loss: 0.019851\n",
      "[35,   199] loss: 0.111848\n",
      "[35,   299] loss: 0.040645\n",
      "[35,   399] loss: 0.029355\n",
      "[35,   499] loss: 0.041547\n",
      "[35,   599] loss: 0.028349\n",
      "[35,   699] loss: 0.020996\n",
      "[36,    99] loss: 0.045572\n",
      "[36,   199] loss: 0.066860\n",
      "[36,   299] loss: 0.028351\n",
      "[36,   399] loss: 0.033903\n",
      "[36,   499] loss: 0.030918\n",
      "[36,   599] loss: 0.028224\n",
      "[36,   699] loss: 0.010296\n",
      "[37,    99] loss: 0.009653\n",
      "[37,   199] loss: 0.072104\n",
      "[37,   299] loss: 0.021322\n",
      "[37,   399] loss: 0.027035\n",
      "[37,   499] loss: 0.045976\n",
      "[37,   599] loss: 0.025665\n",
      "[37,   699] loss: 0.035688\n",
      "[38,    99] loss: 0.013533\n",
      "[38,   199] loss: 0.066941\n",
      "[38,   299] loss: 0.017073\n",
      "[38,   399] loss: 0.116104\n",
      "[38,   499] loss: 0.211376\n",
      "[38,   599] loss: 0.065054\n",
      "[38,   699] loss: 0.043974\n",
      "[39,    99] loss: 0.125066\n",
      "[39,   199] loss: 0.129136\n",
      "[39,   299] loss: 0.086563\n",
      "[39,   399] loss: 0.056508\n",
      "[39,   499] loss: 0.105007\n",
      "[39,   599] loss: 0.039749\n",
      "[39,   699] loss: 0.023371\n",
      "[40,    99] loss: 0.050022\n",
      "[40,   199] loss: 0.076748\n",
      "[40,   299] loss: 0.059518\n",
      "[40,   399] loss: 0.014648\n",
      "[40,   499] loss: 0.061811\n",
      "[40,   599] loss: 0.016401\n",
      "[40,   699] loss: 0.050130\n",
      "[41,    99] loss: 0.032520\n",
      "[41,   199] loss: 0.059968\n",
      "[41,   299] loss: 0.022748\n",
      "[41,   399] loss: 0.009017\n",
      "[41,   499] loss: 0.046226\n",
      "[41,   599] loss: 0.030029\n",
      "[41,   699] loss: 0.029438\n",
      "[42,    99] loss: 0.064001\n",
      "[42,   199] loss: 0.049836\n",
      "[42,   299] loss: 0.044321\n",
      "[42,   399] loss: 0.011094\n",
      "[42,   499] loss: 0.113726\n",
      "[42,   599] loss: 0.024808\n",
      "[42,   699] loss: 0.080640\n",
      "[43,    99] loss: 0.062870\n",
      "[43,   199] loss: 0.099356\n",
      "[43,   299] loss: 0.093450\n",
      "[43,   399] loss: 0.016393\n",
      "[43,   499] loss: 0.038910\n",
      "[43,   599] loss: 0.062320\n",
      "[43,   699] loss: 0.049387\n",
      "[44,    99] loss: 0.014669\n",
      "[44,   199] loss: 0.053696\n",
      "[44,   299] loss: 0.039043\n",
      "[44,   399] loss: 0.014753\n",
      "[44,   499] loss: 0.044436\n",
      "[44,   599] loss: 0.028752\n",
      "[44,   699] loss: 0.021146\n",
      "[45,    99] loss: 0.078398\n",
      "[45,   199] loss: 0.160713\n",
      "[45,   299] loss: 0.121980\n",
      "[45,   399] loss: 0.100218\n",
      "[45,   499] loss: 0.047304\n",
      "[45,   599] loss: 0.100037\n",
      "[45,   699] loss: 0.040620\n",
      "[46,    99] loss: 0.060027\n",
      "[46,   199] loss: 0.084407\n",
      "[46,   299] loss: 0.042156\n",
      "[46,   399] loss: 0.075105\n",
      "[46,   499] loss: 0.050503\n",
      "[46,   599] loss: 0.020381\n",
      "[46,   699] loss: 0.063074\n",
      "[47,    99] loss: 0.033969\n",
      "[47,   199] loss: 0.062187\n",
      "[47,   299] loss: 0.060298\n",
      "[47,   399] loss: 0.012611\n",
      "[47,   499] loss: 0.069091\n",
      "[47,   599] loss: 0.027166\n",
      "[47,   699] loss: 0.016670\n",
      "[48,    99] loss: 0.009754\n",
      "[48,   199] loss: 0.031657\n",
      "[48,   299] loss: 0.026538\n",
      "[48,   399] loss: 0.009465\n",
      "[48,   499] loss: 0.053608\n",
      "[48,   599] loss: 0.036096\n",
      "[48,   699] loss: 0.005393\n",
      "[49,    99] loss: 0.008032\n",
      "[49,   199] loss: 0.058305\n",
      "[49,   299] loss: 0.018069\n",
      "[49,   399] loss: 0.003664\n",
      "[49,   499] loss: 0.047593\n",
      "[49,   599] loss: 0.021535\n",
      "[49,   699] loss: 0.014505\n",
      "[50,    99] loss: 0.027898\n",
      "[50,   199] loss: 0.110325\n",
      "[50,   299] loss: 0.035267\n",
      "[50,   399] loss: 0.030693\n",
      "[50,   499] loss: 0.034008\n",
      "[50,   599] loss: 0.091879\n",
      "[50,   699] loss: 0.060989\n",
      "[51,    99] loss: 0.041347\n",
      "[51,   199] loss: 0.073193\n",
      "[51,   299] loss: 0.048999\n",
      "[51,   399] loss: 0.053062\n",
      "[51,   499] loss: 0.096525\n",
      "[51,   599] loss: 0.042516\n",
      "[51,   699] loss: 0.046272\n",
      "[52,    99] loss: 0.049022\n",
      "[52,   199] loss: 0.056365\n",
      "[52,   299] loss: 0.030648\n",
      "[52,   399] loss: 0.003983\n",
      "[52,   499] loss: 0.050428\n",
      "[52,   599] loss: 0.016399\n",
      "[52,   699] loss: 0.011679\n",
      "[53,    99] loss: 0.007920\n",
      "[53,   199] loss: 0.027119\n",
      "[53,   299] loss: 0.032490\n",
      "[53,   399] loss: 0.014495\n",
      "[53,   499] loss: 0.053143\n",
      "[53,   599] loss: 0.024080\n",
      "[53,   699] loss: 0.006698\n",
      "[54,    99] loss: 0.007739\n",
      "[54,   199] loss: 0.061686\n",
      "[54,   299] loss: 0.029673\n",
      "[54,   399] loss: 0.025621\n",
      "[54,   499] loss: 0.091776\n",
      "[54,   599] loss: 0.067366\n",
      "[54,   699] loss: 0.028740\n",
      "[55,    99] loss: 0.108316\n",
      "[55,   199] loss: 0.246654\n",
      "[55,   299] loss: 0.114894\n",
      "[55,   399] loss: 0.069582\n",
      "[55,   499] loss: 0.046276\n",
      "[55,   599] loss: 0.022053\n",
      "[55,   699] loss: 0.032699\n",
      "[56,    99] loss: 0.012990\n",
      "[56,   199] loss: 0.047163\n",
      "[56,   299] loss: 0.029807\n",
      "[56,   399] loss: 0.043435\n",
      "[56,   499] loss: 0.017416\n",
      "[56,   599] loss: 0.010549\n",
      "[56,   699] loss: 0.006754\n",
      "[57,    99] loss: 0.005427\n",
      "[57,   199] loss: 0.016085\n",
      "[57,   299] loss: 0.009401\n",
      "[57,   399] loss: 0.002117\n",
      "[57,   499] loss: 0.023717\n",
      "[57,   599] loss: 0.012078\n",
      "[57,   699] loss: 0.006320\n",
      "[58,    99] loss: 0.004072\n",
      "[58,   199] loss: 0.035988\n",
      "[58,   299] loss: 0.021774\n",
      "[58,   399] loss: 0.043941\n",
      "[58,   499] loss: 0.067093\n",
      "[58,   599] loss: 0.053657\n",
      "[58,   699] loss: 0.047263\n",
      "[59,    99] loss: 0.045218\n",
      "[59,   199] loss: 0.052391\n",
      "[59,   299] loss: 0.074234\n",
      "[59,   399] loss: 0.036847\n",
      "[59,   499] loss: 0.112165\n",
      "[59,   599] loss: 0.020262\n",
      "[59,   699] loss: 0.006908\n",
      "[60,    99] loss: 0.002692\n",
      "[60,   199] loss: 0.013284\n",
      "[60,   299] loss: 0.018830\n",
      "[60,   399] loss: 0.006686\n",
      "[60,   499] loss: 0.017513\n",
      "[60,   599] loss: 0.012991\n",
      "[60,   699] loss: 0.006771\n",
      "[61,    99] loss: 0.002580\n",
      "[61,   199] loss: 0.020056\n",
      "[61,   299] loss: 0.018938\n",
      "[61,   399] loss: 0.031834\n",
      "[61,   499] loss: 0.014659\n",
      "[61,   599] loss: 0.010761\n",
      "[61,   699] loss: 0.005996\n",
      "[62,    99] loss: 0.002597\n",
      "[62,   199] loss: 0.013868\n",
      "[62,   299] loss: 0.011811\n",
      "[62,   399] loss: 0.006174\n",
      "[62,   499] loss: 0.034678\n",
      "[62,   599] loss: 0.021504\n",
      "[62,   699] loss: 0.071856\n",
      "[63,    99] loss: 0.108000\n",
      "[63,   199] loss: 0.291053\n",
      "[63,   299] loss: 0.162100\n",
      "[63,   399] loss: 0.137684\n",
      "[63,   499] loss: 0.039640\n",
      "[63,   599] loss: 0.012647\n",
      "[63,   699] loss: 0.063639\n",
      "[64,    99] loss: 0.059693\n",
      "[64,   199] loss: 0.154075\n",
      "[64,   299] loss: 0.088163\n",
      "[64,   399] loss: 0.011915\n",
      "[64,   499] loss: 0.037998\n",
      "[64,   599] loss: 0.027610\n",
      "[64,   699] loss: 0.008861\n",
      "[65,    99] loss: 0.035366\n",
      "[65,   199] loss: 0.031077\n",
      "[65,   299] loss: 0.032065\n",
      "[65,   399] loss: 0.011132\n",
      "[65,   499] loss: 0.050179\n",
      "[65,   599] loss: 0.034491\n",
      "[65,   699] loss: 0.006780\n",
      "[66,    99] loss: 0.026150\n",
      "[66,   199] loss: 0.036768\n",
      "[66,   299] loss: 0.013438\n",
      "[66,   399] loss: 0.005482\n",
      "[66,   499] loss: 0.075817\n",
      "[66,   599] loss: 0.022777\n",
      "[66,   699] loss: 0.004281\n",
      "[67,    99] loss: 0.001243\n",
      "[67,   199] loss: 0.007830\n",
      "[67,   299] loss: 0.004258\n",
      "[67,   399] loss: 0.001935\n",
      "[67,   499] loss: 0.014644\n",
      "[67,   599] loss: 0.017811\n",
      "[67,   699] loss: 0.001706\n",
      "[68,    99] loss: 0.001159\n",
      "[68,   199] loss: 0.012320\n",
      "[68,   299] loss: 0.002258\n",
      "[68,   399] loss: 0.002041\n",
      "[68,   499] loss: 0.017779\n",
      "[68,   599] loss: 0.030456\n",
      "[68,   699] loss: 0.001405\n",
      "[69,    99] loss: 0.000992\n",
      "[69,   199] loss: 0.073678\n",
      "[69,   299] loss: 0.001454\n",
      "[69,   399] loss: 0.004136\n",
      "[69,   499] loss: 0.020769\n",
      "[69,   599] loss: 0.018621\n",
      "[69,   699] loss: 0.001621\n",
      "[70,    99] loss: 0.001113\n",
      "[70,   199] loss: 0.039885\n",
      "[70,   299] loss: 0.004958\n",
      "[70,   399] loss: 0.022775\n",
      "[70,   499] loss: 0.029820\n",
      "[70,   599] loss: 0.045689\n",
      "[70,   699] loss: 0.111920\n",
      "[71,    99] loss: 0.032434\n",
      "[71,   199] loss: 0.103906\n",
      "[71,   299] loss: 0.101538\n",
      "[71,   399] loss: 0.006035\n",
      "[71,   499] loss: 0.023505\n",
      "[71,   599] loss: 0.209286\n",
      "[71,   699] loss: 0.214865\n",
      "[72,    99] loss: 0.128067\n",
      "[72,   199] loss: 0.098214\n",
      "[72,   299] loss: 0.077261\n",
      "[72,   399] loss: 0.005739\n",
      "[72,   499] loss: 0.046679\n",
      "[72,   599] loss: 0.059841\n",
      "[72,   699] loss: 0.013080\n",
      "[73,    99] loss: 0.014596\n",
      "[73,   199] loss: 0.011637\n",
      "[73,   299] loss: 0.011689\n",
      "[73,   399] loss: 0.002243\n",
      "[73,   499] loss: 0.013878\n",
      "[73,   599] loss: 0.006656\n",
      "[73,   699] loss: 0.005273\n",
      "[74,    99] loss: 0.001369\n",
      "[74,   199] loss: 0.005628\n",
      "[74,   299] loss: 0.001691\n",
      "[74,   399] loss: 0.001511\n",
      "[74,   499] loss: 0.006140\n",
      "[74,   599] loss: 0.011845\n",
      "[74,   699] loss: 0.001569\n",
      "[75,    99] loss: 0.000938\n",
      "[75,   199] loss: 0.003484\n",
      "[75,   299] loss: 0.012170\n",
      "[75,   399] loss: 0.069319\n",
      "[75,   499] loss: 0.043833\n",
      "[75,   599] loss: 0.041070\n",
      "[75,   699] loss: 0.007928\n",
      "[76,    99] loss: 0.002169\n",
      "[76,   199] loss: 0.025737\n",
      "[76,   299] loss: 0.093821\n",
      "[76,   399] loss: 0.098282\n",
      "[76,   499] loss: 0.090533\n",
      "[76,   599] loss: 0.119603\n",
      "[76,   699] loss: 0.014839\n",
      "[77,    99] loss: 0.091243\n",
      "[77,   199] loss: 0.040540\n",
      "[77,   299] loss: 0.136486\n",
      "[77,   399] loss: 0.008857\n",
      "[77,   499] loss: 0.057020\n",
      "[77,   599] loss: 0.007716\n",
      "[77,   699] loss: 0.023614\n",
      "[78,    99] loss: 0.022565\n",
      "[78,   199] loss: 0.016896\n",
      "[78,   299] loss: 0.033187\n",
      "[78,   399] loss: 0.004337\n",
      "[78,   499] loss: 0.021640\n",
      "[78,   599] loss: 0.041014\n",
      "[78,   699] loss: 0.002723\n",
      "[79,    99] loss: 0.034835\n",
      "[79,   199] loss: 0.013931\n",
      "[79,   299] loss: 0.016408\n",
      "[79,   399] loss: 0.001936\n",
      "[79,   499] loss: 0.062131\n",
      "[79,   599] loss: 0.025109\n",
      "[79,   699] loss: 0.002959\n",
      "[80,    99] loss: 0.005722\n",
      "[80,   199] loss: 0.042208\n",
      "[80,   299] loss: 0.005820\n",
      "[80,   399] loss: 0.000843\n",
      "[80,   499] loss: 0.043436\n",
      "[80,   599] loss: 0.011279\n",
      "[80,   699] loss: 0.005185\n",
      "[81,    99] loss: 0.001643\n",
      "[81,   199] loss: 0.012745\n",
      "[81,   299] loss: 0.001749\n",
      "[81,   399] loss: 0.000539\n",
      "[81,   499] loss: 0.018669\n",
      "[81,   599] loss: 0.007104\n",
      "[81,   699] loss: 0.002998\n",
      "[82,    99] loss: 0.001822\n",
      "[82,   199] loss: 0.016334\n",
      "[82,   299] loss: 0.002477\n",
      "[82,   399] loss: 0.000509\n",
      "[82,   499] loss: 0.041260\n",
      "[82,   599] loss: 0.007974\n",
      "[82,   699] loss: 0.003102\n",
      "[83,    99] loss: 0.001499\n",
      "[83,   199] loss: 0.041493\n",
      "[83,   299] loss: 0.100284\n",
      "[83,   399] loss: 0.119083\n",
      "[83,   499] loss: 0.100921\n",
      "[83,   599] loss: 0.084703\n",
      "[83,   699] loss: 0.014998\n",
      "[84,    99] loss: 0.008557\n",
      "[84,   199] loss: 0.031672\n",
      "[84,   299] loss: 0.005120\n",
      "[84,   399] loss: 0.001205\n",
      "[84,   499] loss: 0.008910\n",
      "[84,   599] loss: 0.024603\n",
      "[84,   699] loss: 0.002347\n",
      "[85,    99] loss: 0.003884\n",
      "[85,   199] loss: 0.011170\n",
      "[85,   299] loss: 0.024690\n",
      "[85,   399] loss: 0.012614\n",
      "[85,   499] loss: 0.080564\n",
      "[85,   599] loss: 0.011495\n",
      "[85,   699] loss: 0.001731\n",
      "[86,    99] loss: 0.020059\n",
      "[86,   199] loss: 0.020369\n",
      "[86,   299] loss: 0.024451\n",
      "[86,   399] loss: 0.006271\n",
      "[86,   499] loss: 0.169047\n",
      "[86,   599] loss: 0.168897\n",
      "[86,   699] loss: 0.033750\n",
      "[87,    99] loss: 0.081813\n",
      "[87,   199] loss: 0.072795\n",
      "[87,   299] loss: 0.013819\n",
      "[87,   399] loss: 0.100601\n",
      "[87,   499] loss: 0.041063\n",
      "[87,   599] loss: 0.013245\n",
      "[87,   699] loss: 0.012389\n",
      "[88,    99] loss: 0.013137\n",
      "[88,   199] loss: 0.085767\n",
      "[88,   299] loss: 0.018036\n",
      "[88,   399] loss: 0.001801\n",
      "[88,   499] loss: 0.041170\n",
      "[88,   599] loss: 0.010430\n",
      "[88,   699] loss: 0.002392\n",
      "[89,    99] loss: 0.001448\n",
      "[89,   199] loss: 0.002771\n",
      "[89,   299] loss: 0.007078\n",
      "[89,   399] loss: 0.000979\n",
      "[89,   499] loss: 0.004822\n",
      "[89,   599] loss: 0.001525\n",
      "[89,   699] loss: 0.001364\n",
      "[90,    99] loss: 0.000909\n",
      "[90,   199] loss: 0.002050\n",
      "[90,   299] loss: 0.002153\n",
      "[90,   399] loss: 0.000698\n",
      "[90,   499] loss: 0.001708\n",
      "[90,   599] loss: 0.002022\n",
      "[90,   699] loss: 0.001434\n",
      "[91,    99] loss: 0.000612\n",
      "[91,   199] loss: 0.001719\n",
      "[91,   299] loss: 0.001018\n",
      "[91,   399] loss: 0.000550\n",
      "[91,   499] loss: 0.001346\n",
      "[91,   599] loss: 0.002409\n",
      "[91,   699] loss: 0.001050\n",
      "[92,    99] loss: 0.000461\n",
      "[92,   199] loss: 0.001390\n",
      "[92,   299] loss: 0.000960\n",
      "[92,   399] loss: 0.000403\n",
      "[92,   499] loss: 0.002296\n",
      "[92,   599] loss: 0.017905\n",
      "[92,   699] loss: 0.098334\n",
      "[93,    99] loss: 0.445091\n",
      "[93,   199] loss: 0.139449\n",
      "[93,   299] loss: 0.112234\n",
      "[93,   399] loss: 0.006895\n",
      "[93,   499] loss: 0.022937\n",
      "[93,   599] loss: 0.030087\n",
      "[93,   699] loss: 0.012947\n",
      "[94,    99] loss: 0.004219\n",
      "[94,   199] loss: 0.003329\n",
      "[94,   299] loss: 0.004755\n",
      "[94,   399] loss: 0.001899\n",
      "[94,   499] loss: 0.003600\n",
      "[94,   599] loss: 0.005556\n",
      "[94,   699] loss: 0.001539\n",
      "[95,    99] loss: 0.038101\n",
      "[95,   199] loss: 0.028537\n",
      "[95,   299] loss: 0.026461\n",
      "[95,   399] loss: 0.012528\n",
      "[95,   499] loss: 0.034261\n",
      "[95,   599] loss: 0.051493\n",
      "[95,   699] loss: 0.053088\n",
      "[96,    99] loss: 0.024924\n",
      "[96,   199] loss: 0.021560\n",
      "[96,   299] loss: 0.047222\n",
      "[96,   399] loss: 0.060945\n",
      "[96,   499] loss: 0.143516\n",
      "[96,   599] loss: 0.031892\n",
      "[96,   699] loss: 0.004182\n",
      "[97,    99] loss: 0.005298\n",
      "[97,   199] loss: 0.006372\n",
      "[97,   299] loss: 0.008769\n",
      "[97,   399] loss: 0.002586\n",
      "[97,   499] loss: 0.004790\n",
      "[97,   599] loss: 0.005314\n",
      "[97,   699] loss: 0.002096\n",
      "[98,    99] loss: 0.002884\n",
      "[98,   199] loss: 0.001878\n",
      "[98,   299] loss: 0.002972\n",
      "[98,   399] loss: 0.000925\n",
      "[98,   499] loss: 0.001773\n",
      "[98,   599] loss: 0.002506\n",
      "[98,   699] loss: 0.001105\n",
      "[99,    99] loss: 0.002263\n",
      "[99,   199] loss: 0.001774\n",
      "[99,   299] loss: 0.002633\n",
      "[99,   399] loss: 0.000628\n",
      "[99,   499] loss: 0.002139\n",
      "[99,   599] loss: 0.002608\n",
      "[99,   699] loss: 0.000795\n",
      "[100,    99] loss: 0.020436\n",
      "[100,   199] loss: 0.016482\n",
      "[100,   299] loss: 0.043198\n",
      "[100,   399] loss: 0.003940\n",
      "[100,   499] loss: 0.018718\n",
      "[100,   599] loss: 0.106548\n",
      "[100,   699] loss: 0.098253\n",
      "Finished Training\n",
      "[1,    99] loss: 0.698492\n",
      "[1,   199] loss: 0.668373\n",
      "[1,   299] loss: 0.694669\n",
      "[1,   399] loss: 0.668587\n",
      "[1,   499] loss: 0.667544\n",
      "[1,   599] loss: 0.638535\n",
      "[1,   699] loss: 0.600675\n",
      "[2,    99] loss: 0.639537\n",
      "[2,   199] loss: 0.605153\n",
      "[2,   299] loss: 0.621245\n",
      "[2,   399] loss: 0.572932\n",
      "[2,   499] loss: 0.598147\n",
      "[2,   599] loss: 0.562855\n",
      "[2,   699] loss: 0.497957\n",
      "[3,    99] loss: 0.547095\n",
      "[3,   199] loss: 0.516107\n",
      "[3,   299] loss: 0.537549\n",
      "[3,   399] loss: 0.484570\n",
      "[3,   499] loss: 0.534858\n",
      "[3,   599] loss: 0.497939\n",
      "[3,   699] loss: 0.410142\n",
      "[4,    99] loss: 0.456397\n",
      "[4,   199] loss: 0.435670\n",
      "[4,   299] loss: 0.460230\n",
      "[4,   399] loss: 0.406130\n",
      "[4,   499] loss: 0.474255\n",
      "[4,   599] loss: 0.424954\n",
      "[4,   699] loss: 0.349296\n",
      "[5,    99] loss: 0.383640\n",
      "[5,   199] loss: 0.352844\n",
      "[5,   299] loss: 0.411379\n",
      "[5,   399] loss: 0.345990\n",
      "[5,   499] loss: 0.384224\n",
      "[5,   599] loss: 0.383527\n",
      "[5,   699] loss: 0.296866\n",
      "[6,    99] loss: 0.324316\n",
      "[6,   199] loss: 0.290558\n",
      "[6,   299] loss: 0.383210\n",
      "[6,   399] loss: 0.291781\n",
      "[6,   499] loss: 0.330164\n",
      "[6,   599] loss: 0.333528\n",
      "[6,   699] loss: 0.250331\n",
      "[7,    99] loss: 0.281242\n",
      "[7,   199] loss: 0.228942\n",
      "[7,   299] loss: 0.341514\n",
      "[7,   399] loss: 0.256156\n",
      "[7,   499] loss: 0.288084\n",
      "[7,   599] loss: 0.295782\n",
      "[7,   699] loss: 0.213926\n",
      "[8,    99] loss: 0.256301\n",
      "[8,   199] loss: 0.197977\n",
      "[8,   299] loss: 0.305994\n",
      "[8,   399] loss: 0.237153\n",
      "[8,   499] loss: 0.259767\n",
      "[8,   599] loss: 0.249960\n",
      "[8,   699] loss: 0.187587\n",
      "[9,    99] loss: 0.238225\n",
      "[9,   199] loss: 0.174518\n",
      "[9,   299] loss: 0.294008\n",
      "[9,   399] loss: 0.210833\n",
      "[9,   499] loss: 0.223179\n",
      "[9,   599] loss: 0.246942\n",
      "[9,   699] loss: 0.157134\n",
      "[10,    99] loss: 0.206718\n",
      "[10,   199] loss: 0.148125\n",
      "[10,   299] loss: 0.278748\n",
      "[10,   399] loss: 0.170323\n",
      "[10,   499] loss: 0.197380\n",
      "[10,   599] loss: 0.203769\n",
      "[10,   699] loss: 0.128211\n",
      "[11,    99] loss: 0.179859\n",
      "[11,   199] loss: 0.122199\n",
      "[11,   299] loss: 0.272075\n",
      "[11,   399] loss: 0.158653\n",
      "[11,   499] loss: 0.183160\n",
      "[11,   599] loss: 0.183891\n",
      "[11,   699] loss: 0.121741\n",
      "[12,    99] loss: 0.158355\n",
      "[12,   199] loss: 0.099384\n",
      "[12,   299] loss: 0.269745\n",
      "[12,   399] loss: 0.137715\n",
      "[12,   499] loss: 0.166985\n",
      "[12,   599] loss: 0.156524\n",
      "[12,   699] loss: 0.101305\n",
      "[13,    99] loss: 0.128599\n",
      "[13,   199] loss: 0.087256\n",
      "[13,   299] loss: 0.254859\n",
      "[13,   399] loss: 0.133586\n",
      "[13,   499] loss: 0.160165\n",
      "[13,   599] loss: 0.138373\n",
      "[13,   699] loss: 0.096018\n",
      "[14,    99] loss: 0.125556\n",
      "[14,   199] loss: 0.079101\n",
      "[14,   299] loss: 0.228334\n",
      "[14,   399] loss: 0.140159\n",
      "[14,   499] loss: 0.127099\n",
      "[14,   599] loss: 0.136521\n",
      "[14,   699] loss: 0.066238\n",
      "[15,    99] loss: 0.102141\n",
      "[15,   199] loss: 0.072710\n",
      "[15,   299] loss: 0.253263\n",
      "[15,   399] loss: 0.102953\n",
      "[15,   499] loss: 0.105846\n",
      "[15,   599] loss: 0.149051\n",
      "[15,   699] loss: 0.075577\n",
      "[16,    99] loss: 0.092709\n",
      "[16,   199] loss: 0.058432\n",
      "[16,   299] loss: 0.219634\n",
      "[16,   399] loss: 0.096504\n",
      "[16,   499] loss: 0.112515\n",
      "[16,   599] loss: 0.097972\n",
      "[16,   699] loss: 0.096238\n",
      "[17,    99] loss: 0.085844\n",
      "[17,   199] loss: 0.047114\n",
      "[17,   299] loss: 0.202773\n",
      "[17,   399] loss: 0.206430\n",
      "[17,   499] loss: 0.113911\n",
      "[17,   599] loss: 0.143647\n",
      "[17,   699] loss: 0.050303\n",
      "[18,    99] loss: 0.100627\n",
      "[18,   199] loss: 0.064108\n",
      "[18,   299] loss: 0.218826\n",
      "[18,   399] loss: 0.092863\n",
      "[18,   499] loss: 0.164934\n",
      "[18,   599] loss: 0.172775\n",
      "[18,   699] loss: 0.090198\n",
      "[19,    99] loss: 0.062493\n",
      "[19,   199] loss: 0.033956\n",
      "[19,   299] loss: 0.178974\n",
      "[19,   399] loss: 0.077762\n",
      "[19,   499] loss: 0.075731\n",
      "[19,   599] loss: 0.071840\n",
      "[19,   699] loss: 0.040230\n",
      "[20,    99] loss: 0.058713\n",
      "[20,   199] loss: 0.032876\n",
      "[20,   299] loss: 0.167302\n",
      "[20,   399] loss: 0.109000\n",
      "[20,   499] loss: 0.097082\n",
      "[20,   599] loss: 0.145099\n",
      "[20,   699] loss: 0.059415\n",
      "[21,    99] loss: 0.096239\n",
      "[21,   199] loss: 0.039038\n",
      "[21,   299] loss: 0.200448\n",
      "[21,   399] loss: 0.085501\n",
      "[21,   499] loss: 0.053980\n",
      "[21,   599] loss: 0.061365\n",
      "[21,   699] loss: 0.048474\n",
      "[22,    99] loss: 0.045082\n",
      "[22,   199] loss: 0.020195\n",
      "[22,   299] loss: 0.140956\n",
      "[22,   399] loss: 0.047675\n",
      "[22,   499] loss: 0.046765\n",
      "[22,   599] loss: 0.149228\n",
      "[22,   699] loss: 0.042643\n",
      "[23,    99] loss: 0.068963\n",
      "[23,   199] loss: 0.038209\n",
      "[23,   299] loss: 0.169060\n",
      "[23,   399] loss: 0.037990\n",
      "[23,   499] loss: 0.072176\n",
      "[23,   599] loss: 0.065205\n",
      "[23,   699] loss: 0.025133\n",
      "[24,    99] loss: 0.066406\n",
      "[24,   199] loss: 0.030796\n",
      "[24,   299] loss: 0.119338\n",
      "[24,   399] loss: 0.085309\n",
      "[24,   499] loss: 0.055268\n",
      "[24,   599] loss: 0.066896\n",
      "[24,   699] loss: 0.098799\n",
      "[25,    99] loss: 0.030329\n",
      "[25,   199] loss: 0.031951\n",
      "[25,   299] loss: 0.118845\n",
      "[25,   399] loss: 0.133735\n",
      "[25,   499] loss: 0.094298\n",
      "[25,   599] loss: 0.075799\n",
      "[25,   699] loss: 0.022302\n",
      "[26,    99] loss: 0.055295\n",
      "[26,   199] loss: 0.022240\n",
      "[26,   299] loss: 0.145065\n",
      "[26,   399] loss: 0.039597\n",
      "[26,   499] loss: 0.056721\n",
      "[26,   599] loss: 0.064887\n",
      "[26,   699] loss: 0.021401\n",
      "[27,    99] loss: 0.021588\n",
      "[27,   199] loss: 0.015604\n",
      "[27,   299] loss: 0.096400\n",
      "[27,   399] loss: 0.072527\n",
      "[27,   499] loss: 0.194590\n",
      "[27,   599] loss: 0.306836\n",
      "[27,   699] loss: 0.086331\n",
      "[28,    99] loss: 0.078277\n",
      "[28,   199] loss: 0.047969\n",
      "[28,   299] loss: 0.084154\n",
      "[28,   399] loss: 0.032167\n",
      "[28,   499] loss: 0.055976\n",
      "[28,   599] loss: 0.051904\n",
      "[28,   699] loss: 0.021197\n",
      "[29,    99] loss: 0.029021\n",
      "[29,   199] loss: 0.016339\n",
      "[29,   299] loss: 0.127592\n",
      "[29,   399] loss: 0.030776\n",
      "[29,   499] loss: 0.054276\n",
      "[29,   599] loss: 0.063149\n",
      "[29,   699] loss: 0.014456\n",
      "[30,    99] loss: 0.018720\n",
      "[30,   199] loss: 0.008729\n",
      "[30,   299] loss: 0.101211\n",
      "[30,   399] loss: 0.016200\n",
      "[30,   499] loss: 0.044305\n",
      "[30,   599] loss: 0.128039\n",
      "[30,   699] loss: 0.029650\n",
      "[31,    99] loss: 0.039579\n",
      "[31,   199] loss: 0.034479\n",
      "[31,   299] loss: 0.238640\n",
      "[31,   399] loss: 0.171843\n",
      "[31,   499] loss: 0.083747\n",
      "[31,   599] loss: 0.094627\n",
      "[31,   699] loss: 0.028554\n",
      "[32,    99] loss: 0.036498\n",
      "[32,   199] loss: 0.021940\n",
      "[32,   299] loss: 0.088834\n",
      "[32,   399] loss: 0.047040\n",
      "[32,   499] loss: 0.031560\n",
      "[32,   599] loss: 0.096095\n",
      "[32,   699] loss: 0.022459\n",
      "[33,    99] loss: 0.020803\n",
      "[33,   199] loss: 0.014679\n",
      "[33,   299] loss: 0.077218\n",
      "[33,   399] loss: 0.034434\n",
      "[33,   499] loss: 0.057574\n",
      "[33,   599] loss: 0.074179\n",
      "[33,   699] loss: 0.099443\n",
      "[34,    99] loss: 0.017718\n",
      "[34,   199] loss: 0.022806\n",
      "[34,   299] loss: 0.068923\n",
      "[34,   399] loss: 0.054757\n",
      "[34,   499] loss: 0.110728\n",
      "[34,   599] loss: 0.132798\n",
      "[34,   699] loss: 0.040737\n",
      "[35,    99] loss: 0.043334\n",
      "[35,   199] loss: 0.079378\n",
      "[35,   299] loss: 0.126864\n",
      "[35,   399] loss: 0.157050\n",
      "[35,   499] loss: 0.080616\n",
      "[35,   599] loss: 0.132972\n",
      "[35,   699] loss: 0.035491\n",
      "[36,    99] loss: 0.031174\n",
      "[36,   199] loss: 0.029292\n",
      "[36,   299] loss: 0.054641\n",
      "[36,   399] loss: 0.019540\n",
      "[36,   499] loss: 0.018461\n",
      "[36,   599] loss: 0.063884\n",
      "[36,   699] loss: 0.020706\n",
      "[37,    99] loss: 0.023441\n",
      "[37,   199] loss: 0.019711\n",
      "[37,   299] loss: 0.042393\n",
      "[37,   399] loss: 0.009110\n",
      "[37,   499] loss: 0.007852\n",
      "[37,   599] loss: 0.023416\n",
      "[37,   699] loss: 0.016241\n",
      "[38,    99] loss: 0.047969\n",
      "[38,   199] loss: 0.021097\n",
      "[38,   299] loss: 0.050622\n",
      "[38,   399] loss: 0.008960\n",
      "[38,   499] loss: 0.088911\n",
      "[38,   599] loss: 0.012479\n",
      "[38,   699] loss: 0.018418\n",
      "[39,    99] loss: 0.049842\n",
      "[39,   199] loss: 0.118702\n",
      "[39,   299] loss: 0.149418\n",
      "[39,   399] loss: 0.049176\n",
      "[39,   499] loss: 0.023891\n",
      "[39,   599] loss: 0.098899\n",
      "[39,   699] loss: 0.015140\n",
      "[40,    99] loss: 0.015711\n",
      "[40,   199] loss: 0.013335\n",
      "[40,   299] loss: 0.048670\n",
      "[40,   399] loss: 0.086195\n",
      "[40,   499] loss: 0.012436\n",
      "[40,   599] loss: 0.057065\n",
      "[40,   699] loss: 0.017332\n",
      "[41,    99] loss: 0.041022\n",
      "[41,   199] loss: 0.082304\n",
      "[41,   299] loss: 0.090998\n",
      "[41,   399] loss: 0.262675\n",
      "[41,   499] loss: 0.087639\n",
      "[41,   599] loss: 0.049354\n",
      "[41,   699] loss: 0.019147\n",
      "[42,    99] loss: 0.015012\n",
      "[42,   199] loss: 0.028007\n",
      "[42,   299] loss: 0.146514\n",
      "[42,   399] loss: 0.010973\n",
      "[42,   499] loss: 0.040256\n",
      "[42,   599] loss: 0.032621\n",
      "[42,   699] loss: 0.046304\n",
      "[43,    99] loss: 0.159233\n",
      "[43,   199] loss: 0.140870\n",
      "[43,   299] loss: 0.089146\n",
      "[43,   399] loss: 0.014157\n",
      "[43,   499] loss: 0.028476\n",
      "[43,   599] loss: 0.047758\n",
      "[43,   699] loss: 0.017136\n",
      "[44,    99] loss: 0.012123\n",
      "[44,   199] loss: 0.039687\n",
      "[44,   299] loss: 0.019488\n",
      "[44,   399] loss: 0.019515\n",
      "[44,   499] loss: 0.010652\n",
      "[44,   599] loss: 0.089117\n",
      "[44,   699] loss: 0.005248\n",
      "[45,    99] loss: 0.011548\n",
      "[45,   199] loss: 0.004829\n",
      "[45,   299] loss: 0.031045\n",
      "[45,   399] loss: 0.008600\n",
      "[45,   499] loss: 0.006944\n",
      "[45,   599] loss: 0.012672\n",
      "[45,   699] loss: 0.002649\n",
      "[46,    99] loss: 0.006704\n",
      "[46,   199] loss: 0.001663\n",
      "[46,   299] loss: 0.011032\n",
      "[46,   399] loss: 0.003305\n",
      "[46,   499] loss: 0.003626\n",
      "[46,   599] loss: 0.008189\n",
      "[46,   699] loss: 0.001403\n",
      "[47,    99] loss: 0.010790\n",
      "[47,   199] loss: 0.002082\n",
      "[47,   299] loss: 0.006838\n",
      "[47,   399] loss: 0.002361\n",
      "[47,   499] loss: 0.004906\n",
      "[47,   599] loss: 0.015959\n",
      "[47,   699] loss: 0.001739\n",
      "[48,    99] loss: 0.014696\n",
      "[48,   199] loss: 0.097180\n",
      "[48,   299] loss: 0.323271\n",
      "[48,   399] loss: 0.202543\n",
      "[48,   499] loss: 0.203413\n",
      "[48,   599] loss: 0.105520\n",
      "[48,   699] loss: 0.069785\n",
      "[49,    99] loss: 0.057763\n",
      "[49,   199] loss: 0.035021\n",
      "[49,   299] loss: 0.032262\n",
      "[49,   399] loss: 0.053523\n",
      "[49,   499] loss: 0.019529\n",
      "[49,   599] loss: 0.117522\n",
      "[49,   699] loss: 0.008968\n",
      "[50,    99] loss: 0.024351\n",
      "[50,   199] loss: 0.006071\n",
      "[50,   299] loss: 0.014067\n",
      "[50,   399] loss: 0.005879\n",
      "[50,   499] loss: 0.006214\n",
      "[50,   599] loss: 0.006484\n",
      "[50,   699] loss: 0.002642\n",
      "[51,    99] loss: 0.005675\n",
      "[51,   199] loss: 0.002782\n",
      "[51,   299] loss: 0.005974\n",
      "[51,   399] loss: 0.002576\n",
      "[51,   499] loss: 0.002604\n",
      "[51,   599] loss: 0.003289\n",
      "[51,   699] loss: 0.001480\n",
      "[52,    99] loss: 0.002744\n",
      "[52,   199] loss: 0.001406\n",
      "[52,   299] loss: 0.005165\n",
      "[52,   399] loss: 0.001880\n",
      "[52,   499] loss: 0.002139\n",
      "[52,   599] loss: 0.003713\n",
      "[52,   699] loss: 0.001013\n",
      "[53,    99] loss: 0.004284\n",
      "[53,   199] loss: 0.002071\n",
      "[53,   299] loss: 0.003786\n",
      "[53,   399] loss: 0.001722\n",
      "[53,   499] loss: 0.001768\n",
      "[53,   599] loss: 0.097019\n",
      "[53,   699] loss: 0.300878\n",
      "[54,    99] loss: 0.125167\n",
      "[54,   199] loss: 0.071700\n",
      "[54,   299] loss: 0.073237\n",
      "[54,   399] loss: 0.111567\n",
      "[54,   499] loss: 0.090654\n",
      "[54,   599] loss: 0.113217\n",
      "[54,   699] loss: 0.022815\n",
      "[55,    99] loss: 0.019529\n",
      "[55,   199] loss: 0.046368\n",
      "[55,   299] loss: 0.136876\n",
      "[55,   399] loss: 0.053600\n",
      "[55,   499] loss: 0.032045\n",
      "[55,   599] loss: 0.023566\n",
      "[55,   699] loss: 0.008393\n",
      "[56,    99] loss: 0.015822\n",
      "[56,   199] loss: 0.002752\n",
      "[56,   299] loss: 0.021665\n",
      "[56,   399] loss: 0.007786\n",
      "[56,   499] loss: 0.058758\n",
      "[56,   599] loss: 0.006222\n",
      "[56,   699] loss: 0.004440\n",
      "[57,    99] loss: 0.003980\n",
      "[57,   199] loss: 0.002251\n",
      "[57,   299] loss: 0.013487\n",
      "[57,   399] loss: 0.004642\n",
      "[57,   499] loss: 0.042401\n",
      "[57,   599] loss: 0.003038\n",
      "[57,   699] loss: 0.002042\n",
      "[58,    99] loss: 0.004782\n",
      "[58,   199] loss: 0.001981\n",
      "[58,   299] loss: 0.005758\n",
      "[58,   399] loss: 0.003309\n",
      "[58,   499] loss: 0.017230\n",
      "[58,   599] loss: 0.002441\n",
      "[58,   699] loss: 0.001215\n",
      "[59,    99] loss: 0.001919\n",
      "[59,   199] loss: 0.000749\n",
      "[59,   299] loss: 0.005234\n",
      "[59,   399] loss: 0.002029\n",
      "[59,   499] loss: 0.005323\n",
      "[59,   599] loss: 0.002488\n",
      "[59,   699] loss: 0.001179\n",
      "[60,    99] loss: 0.005373\n",
      "[60,   199] loss: 0.109606\n",
      "[60,   299] loss: 0.313537\n",
      "[60,   399] loss: 0.154020\n",
      "[60,   499] loss: 0.102480\n",
      "[60,   599] loss: 0.307267\n",
      "[60,   699] loss: 0.050693\n",
      "[61,    99] loss: 0.031923\n",
      "[61,   199] loss: 0.049160\n",
      "[61,   299] loss: 0.041361\n",
      "[61,   399] loss: 0.060736\n",
      "[61,   499] loss: 0.010944\n",
      "[61,   599] loss: 0.123015\n",
      "[61,   699] loss: 0.008649\n",
      "[62,    99] loss: 0.014841\n",
      "[62,   199] loss: 0.008257\n",
      "[62,   299] loss: 0.014215\n",
      "[62,   399] loss: 0.004380\n",
      "[62,   499] loss: 0.006214\n",
      "[62,   599] loss: 0.054813\n",
      "[62,   699] loss: 0.004649\n",
      "[63,    99] loss: 0.009411\n",
      "[63,   199] loss: 0.002851\n",
      "[63,   299] loss: 0.009308\n",
      "[63,   399] loss: 0.002417\n",
      "[63,   499] loss: 0.046855\n",
      "[63,   599] loss: 0.007574\n",
      "[63,   699] loss: 0.003091\n",
      "[64,    99] loss: 0.012597\n",
      "[64,   199] loss: 0.004151\n",
      "[64,   299] loss: 0.005172\n",
      "[64,   399] loss: 0.001988\n",
      "[64,   499] loss: 0.014098\n",
      "[64,   599] loss: 0.008826\n",
      "[64,   699] loss: 0.002589\n",
      "[65,    99] loss: 0.013600\n",
      "[65,   199] loss: 0.002662\n",
      "[65,   299] loss: 0.004160\n",
      "[65,   399] loss: 0.001902\n",
      "[65,   499] loss: 0.065168\n",
      "[65,   599] loss: 0.015569\n",
      "[65,   699] loss: 0.001653\n",
      "[66,    99] loss: 0.020995\n",
      "[66,   199] loss: 0.001663\n",
      "[66,   299] loss: 0.034478\n",
      "[66,   399] loss: 0.121820\n",
      "[66,   499] loss: 0.070023\n",
      "[66,   599] loss: 0.074708\n",
      "[66,   699] loss: 0.051584\n",
      "[67,    99] loss: 0.188730\n",
      "[67,   199] loss: 0.060479\n",
      "[67,   299] loss: 0.179567\n",
      "[67,   399] loss: 0.030287\n",
      "[67,   499] loss: 0.067229\n",
      "[67,   599] loss: 0.023236\n",
      "[67,   699] loss: 0.016722\n",
      "[68,    99] loss: 0.010343\n",
      "[68,   199] loss: 0.012387\n",
      "[68,   299] loss: 0.011613\n",
      "[68,   399] loss: 0.004067\n",
      "[68,   499] loss: 0.004038\n",
      "[68,   599] loss: 0.007070\n",
      "[68,   699] loss: 0.001759\n",
      "[69,    99] loss: 0.004324\n",
      "[69,   199] loss: 0.001274\n",
      "[69,   299] loss: 0.004690\n",
      "[69,   399] loss: 0.002069\n",
      "[69,   499] loss: 0.001943\n",
      "[69,   599] loss: 0.005248\n",
      "[69,   699] loss: 0.000896\n",
      "[70,    99] loss: 0.007600\n",
      "[70,   199] loss: 0.000948\n",
      "[70,   299] loss: 0.002729\n",
      "[70,   399] loss: 0.001256\n",
      "[70,   499] loss: 0.001320\n",
      "[70,   599] loss: 0.009976\n",
      "[70,   699] loss: 0.000824\n",
      "[71,    99] loss: 0.016032\n",
      "[71,   199] loss: 0.001717\n",
      "[71,   299] loss: 0.002217\n",
      "[71,   399] loss: 0.000986\n",
      "[71,   499] loss: 0.001125\n",
      "[71,   599] loss: 0.010258\n",
      "[71,   699] loss: 0.000562\n",
      "[72,    99] loss: 0.011651\n",
      "[72,   199] loss: 0.060977\n",
      "[72,   299] loss: 0.135670\n",
      "[72,   399] loss: 0.087789\n",
      "[72,   499] loss: 0.198403\n",
      "[72,   599] loss: 0.038075\n",
      "[72,   699] loss: 0.063982\n",
      "[73,    99] loss: 0.225591\n",
      "[73,   199] loss: 0.053461\n",
      "[73,   299] loss: 0.103878\n",
      "[73,   399] loss: 0.054025\n",
      "[73,   499] loss: 0.059932\n",
      "[73,   599] loss: 0.095985\n",
      "[73,   699] loss: 0.003396\n",
      "[74,    99] loss: 0.009842\n",
      "[74,   199] loss: 0.004180\n",
      "[74,   299] loss: 0.016593\n",
      "[74,   399] loss: 0.045597\n",
      "[74,   499] loss: 0.003129\n",
      "[74,   599] loss: 0.005005\n",
      "[74,   699] loss: 0.005504\n",
      "[75,    99] loss: 0.015714\n",
      "[75,   199] loss: 0.011886\n",
      "[75,   299] loss: 0.012741\n",
      "[75,   399] loss: 0.003623\n",
      "[75,   499] loss: 0.002015\n",
      "[75,   599] loss: 0.002509\n",
      "[75,   699] loss: 0.000949\n",
      "[76,    99] loss: 0.001432\n",
      "[76,   199] loss: 0.001040\n",
      "[76,   299] loss: 0.004362\n",
      "[76,   399] loss: 0.001111\n",
      "[76,   499] loss: 0.000810\n",
      "[76,   599] loss: 0.001187\n",
      "[76,   699] loss: 0.000687\n",
      "[77,    99] loss: 0.000694\n",
      "[77,   199] loss: 0.000695\n",
      "[77,   299] loss: 0.001978\n",
      "[77,   399] loss: 0.000677\n",
      "[77,   499] loss: 0.000590\n",
      "[77,   599] loss: 0.000834\n",
      "[77,   699] loss: 0.000511\n",
      "[78,    99] loss: 0.000518\n",
      "[78,   199] loss: 0.000477\n",
      "[78,   299] loss: 0.001616\n",
      "[78,   399] loss: 0.000523\n",
      "[78,   499] loss: 0.000466\n",
      "[78,   599] loss: 0.000974\n",
      "[78,   699] loss: 0.000342\n",
      "[79,    99] loss: 0.002201\n",
      "[79,   199] loss: 0.161524\n",
      "[79,   299] loss: 0.086496\n",
      "[79,   399] loss: 0.147936\n",
      "[79,   499] loss: 0.050183\n",
      "[79,   599] loss: 0.196390\n",
      "[79,   699] loss: 0.013248\n",
      "[80,    99] loss: 0.097979\n",
      "[80,   199] loss: 0.039865\n",
      "[80,   299] loss: 0.083100\n",
      "[80,   399] loss: 0.029171\n",
      "[80,   499] loss: 0.097050\n",
      "[80,   599] loss: 0.009906\n",
      "[80,   699] loss: 0.057020\n",
      "[81,    99] loss: 0.033745\n",
      "[81,   199] loss: 0.003639\n",
      "[81,   299] loss: 0.037984\n",
      "[81,   399] loss: 0.005130\n",
      "[81,   499] loss: 0.038057\n",
      "[81,   599] loss: 0.006673\n",
      "[81,   699] loss: 0.007877\n",
      "[82,    99] loss: 0.003594\n",
      "[82,   199] loss: 0.001137\n",
      "[82,   299] loss: 0.030897\n",
      "[82,   399] loss: 0.002981\n",
      "[82,   499] loss: 0.022701\n",
      "[82,   599] loss: 0.003060\n",
      "[82,   699] loss: 0.001891\n",
      "[83,    99] loss: 0.001693\n",
      "[83,   199] loss: 0.000768\n",
      "[83,   299] loss: 0.058044\n",
      "[83,   399] loss: 0.001887\n",
      "[83,   499] loss: 0.034654\n",
      "[83,   599] loss: 0.002756\n",
      "[83,   699] loss: 0.001025\n",
      "[84,    99] loss: 0.001163\n",
      "[84,   199] loss: 0.000787\n",
      "[84,   299] loss: 0.025940\n",
      "[84,   399] loss: 0.001489\n",
      "[84,   499] loss: 0.007384\n",
      "[84,   599] loss: 0.001256\n",
      "[84,   699] loss: 0.000635\n",
      "[85,    99] loss: 0.000676\n",
      "[85,   199] loss: 0.000402\n",
      "[85,   299] loss: 0.005480\n",
      "[85,   399] loss: 0.000825\n",
      "[85,   499] loss: 0.001619\n",
      "[85,   599] loss: 0.001728\n",
      "[85,   699] loss: 0.000547\n",
      "[86,    99] loss: 0.000530\n",
      "[86,   199] loss: 0.000292\n",
      "[86,   299] loss: 0.002513\n",
      "[86,   399] loss: 0.000646\n",
      "[86,   499] loss: 0.000812\n",
      "[86,   599] loss: 0.118371\n",
      "[86,   699] loss: 0.113316\n",
      "[87,    99] loss: 0.223907\n",
      "[87,   199] loss: 0.135616\n",
      "[87,   299] loss: 0.081755\n",
      "[87,   399] loss: 0.019667\n",
      "[87,   499] loss: 0.058591\n",
      "[87,   599] loss: 0.080505\n",
      "[87,   699] loss: 0.044048\n",
      "[88,    99] loss: 0.026362\n",
      "[88,   199] loss: 0.009901\n",
      "[88,   299] loss: 0.021420\n",
      "[88,   399] loss: 0.005404\n",
      "[88,   499] loss: 0.008675\n",
      "[88,   599] loss: 0.006301\n",
      "[88,   699] loss: 0.024061\n",
      "[89,    99] loss: 0.001584\n",
      "[89,   199] loss: 0.000864\n",
      "[89,   299] loss: 0.003967\n",
      "[89,   399] loss: 0.002227\n",
      "[89,   499] loss: 0.001489\n",
      "[89,   599] loss: 0.001007\n",
      "[89,   699] loss: 0.000652\n",
      "[90,    99] loss: 0.000650\n",
      "[90,   199] loss: 0.000420\n",
      "[90,   299] loss: 0.002393\n",
      "[90,   399] loss: 0.000960\n",
      "[90,   499] loss: 0.000822\n",
      "[90,   599] loss: 0.000667\n",
      "[90,   699] loss: 0.000419\n",
      "[91,    99] loss: 0.000474\n",
      "[91,   199] loss: 0.000311\n",
      "[91,   299] loss: 0.001973\n",
      "[91,   399] loss: 0.000711\n",
      "[91,   499] loss: 0.000617\n",
      "[91,   599] loss: 0.000515\n",
      "[91,   699] loss: 0.000310\n",
      "[92,    99] loss: 0.000325\n",
      "[92,   199] loss: 0.000240\n",
      "[92,   299] loss: 0.001662\n",
      "[92,   399] loss: 0.000538\n",
      "[92,   499] loss: 0.000495\n",
      "[92,   599] loss: 0.000392\n",
      "[92,   699] loss: 0.000248\n",
      "[93,    99] loss: 0.000247\n",
      "[93,   199] loss: 0.000182\n",
      "[93,   299] loss: 0.001326\n",
      "[93,   399] loss: 0.000420\n",
      "[93,   499] loss: 0.000412\n",
      "[93,   599] loss: 0.000316\n",
      "[93,   699] loss: 0.000196\n",
      "[94,    99] loss: 0.000197\n",
      "[94,   199] loss: 0.000138\n",
      "[94,   299] loss: 0.001037\n",
      "[94,   399] loss: 0.000319\n",
      "[94,   499] loss: 0.000414\n",
      "[94,   599] loss: 0.000255\n",
      "[94,   699] loss: 0.000155\n",
      "[95,    99] loss: 0.000191\n",
      "[95,   199] loss: 0.000100\n",
      "[95,   299] loss: 0.000881\n",
      "[95,   399] loss: 0.000249\n",
      "[95,   499] loss: 0.011703\n",
      "[95,   599] loss: 0.198289\n",
      "[95,   699] loss: 0.037822\n",
      "[96,    99] loss: 0.146551\n",
      "[96,   199] loss: 0.163863\n",
      "[96,   299] loss: 0.094525\n",
      "[96,   399] loss: 0.017755\n",
      "[96,   499] loss: 0.066927\n",
      "[96,   599] loss: 0.399773\n",
      "[96,   699] loss: 0.080159\n",
      "[97,    99] loss: 0.017778\n",
      "[97,   199] loss: 0.013051\n",
      "[97,   299] loss: 0.034680\n",
      "[97,   399] loss: 0.009521\n",
      "[97,   499] loss: 0.010499\n",
      "[97,   599] loss: 0.002284\n",
      "[97,   699] loss: 0.006085\n",
      "[98,    99] loss: 0.001856\n",
      "[98,   199] loss: 0.001154\n",
      "[98,   299] loss: 0.009426\n",
      "[98,   399] loss: 0.001865\n",
      "[98,   499] loss: 0.001815\n",
      "[98,   599] loss: 0.001162\n",
      "[98,   699] loss: 0.002817\n",
      "[99,    99] loss: 0.000991\n",
      "[99,   199] loss: 0.000899\n",
      "[99,   299] loss: 0.002009\n",
      "[99,   399] loss: 0.000999\n",
      "[99,   499] loss: 0.000769\n",
      "[99,   599] loss: 0.000788\n",
      "[99,   699] loss: 0.001782\n",
      "[100,    99] loss: 0.000599\n",
      "[100,   199] loss: 0.000601\n",
      "[100,   299] loss: 0.001467\n",
      "[100,   399] loss: 0.000626\n",
      "[100,   499] loss: 0.000559\n",
      "[100,   599] loss: 0.000623\n",
      "[100,   699] loss: 0.001356\n",
      "Finished Training\n",
      "[1,    99] loss: 0.695220\n",
      "[1,   199] loss: 0.666597\n",
      "[1,   299] loss: 0.653918\n",
      "[1,   399] loss: 0.673058\n",
      "[1,   499] loss: 0.647248\n",
      "[1,   599] loss: 0.625161\n",
      "[1,   699] loss: 0.628708\n",
      "[2,    99] loss: 0.500599\n",
      "[2,   199] loss: 0.594421\n",
      "[2,   299] loss: 0.579641\n",
      "[2,   399] loss: 0.555082\n",
      "[2,   499] loss: 0.560837\n",
      "[2,   599] loss: 0.516618\n",
      "[2,   699] loss: 0.476589\n",
      "[3,    99] loss: 0.402021\n",
      "[3,   199] loss: 0.472014\n",
      "[3,   299] loss: 0.494994\n",
      "[3,   399] loss: 0.457919\n",
      "[3,   499] loss: 0.461358\n",
      "[3,   599] loss: 0.428282\n",
      "[3,   699] loss: 0.351911\n",
      "[4,    99] loss: 0.330288\n",
      "[4,   199] loss: 0.377958\n",
      "[4,   299] loss: 0.419434\n",
      "[4,   399] loss: 0.367261\n",
      "[4,   499] loss: 0.377428\n",
      "[4,   599] loss: 0.349172\n",
      "[4,   699] loss: 0.277418\n",
      "[5,    99] loss: 0.269299\n",
      "[5,   199] loss: 0.301390\n",
      "[5,   299] loss: 0.363319\n",
      "[5,   399] loss: 0.297630\n",
      "[5,   499] loss: 0.309658\n",
      "[5,   599] loss: 0.272868\n",
      "[5,   699] loss: 0.226492\n",
      "[6,    99] loss: 0.214101\n",
      "[6,   199] loss: 0.253191\n",
      "[6,   299] loss: 0.311834\n",
      "[6,   399] loss: 0.234105\n",
      "[6,   499] loss: 0.259013\n",
      "[6,   599] loss: 0.241950\n",
      "[6,   699] loss: 0.199336\n",
      "[7,    99] loss: 0.186640\n",
      "[7,   199] loss: 0.210578\n",
      "[7,   299] loss: 0.270506\n",
      "[7,   399] loss: 0.204255\n",
      "[7,   499] loss: 0.223764\n",
      "[7,   599] loss: 0.166625\n",
      "[7,   699] loss: 0.157567\n",
      "[8,    99] loss: 0.170293\n",
      "[8,   199] loss: 0.183094\n",
      "[8,   299] loss: 0.250302\n",
      "[8,   399] loss: 0.186228\n",
      "[8,   499] loss: 0.194703\n",
      "[8,   599] loss: 0.176815\n",
      "[8,   699] loss: 0.127583\n",
      "[9,    99] loss: 0.119638\n",
      "[9,   199] loss: 0.130998\n",
      "[9,   299] loss: 0.239668\n",
      "[9,   399] loss: 0.187316\n",
      "[9,   499] loss: 0.161334\n",
      "[9,   599] loss: 0.138001\n",
      "[9,   699] loss: 0.129078\n",
      "[10,    99] loss: 0.155995\n",
      "[10,   199] loss: 0.154233\n",
      "[10,   299] loss: 0.184776\n",
      "[10,   399] loss: 0.167597\n",
      "[10,   499] loss: 0.149315\n",
      "[10,   599] loss: 0.126529\n",
      "[10,   699] loss: 0.156680\n",
      "[11,    99] loss: 0.091288\n",
      "[11,   199] loss: 0.094774\n",
      "[11,   299] loss: 0.181947\n",
      "[11,   399] loss: 0.177203\n",
      "[11,   499] loss: 0.156775\n",
      "[11,   599] loss: 0.100324\n",
      "[11,   699] loss: 0.150268\n",
      "[12,    99] loss: 0.100758\n",
      "[12,   199] loss: 0.084912\n",
      "[12,   299] loss: 0.162079\n",
      "[12,   399] loss: 0.165241\n",
      "[12,   499] loss: 0.173598\n",
      "[12,   599] loss: 0.083726\n",
      "[12,   699] loss: 0.092331\n",
      "[13,    99] loss: 0.086937\n",
      "[13,   199] loss: 0.080673\n",
      "[13,   299] loss: 0.149494\n",
      "[13,   399] loss: 0.155771\n",
      "[13,   499] loss: 0.144384\n",
      "[13,   599] loss: 0.080529\n",
      "[13,   699] loss: 0.106165\n",
      "[14,    99] loss: 0.063708\n",
      "[14,   199] loss: 0.069619\n",
      "[14,   299] loss: 0.131971\n",
      "[14,   399] loss: 0.129077\n",
      "[14,   499] loss: 0.198596\n",
      "[14,   599] loss: 0.148205\n",
      "[14,   699] loss: 0.097338\n",
      "[15,    99] loss: 0.084695\n",
      "[15,   199] loss: 0.057399\n",
      "[15,   299] loss: 0.138941\n",
      "[15,   399] loss: 0.121278\n",
      "[15,   499] loss: 0.148343\n",
      "[15,   599] loss: 0.095564\n",
      "[15,   699] loss: 0.104420\n",
      "[16,    99] loss: 0.154633\n",
      "[16,   199] loss: 0.058347\n",
      "[16,   299] loss: 0.102998\n",
      "[16,   399] loss: 0.099824\n",
      "[16,   499] loss: 0.125824\n",
      "[16,   599] loss: 0.071012\n",
      "[16,   699] loss: 0.175080\n",
      "[17,    99] loss: 0.072839\n",
      "[17,   199] loss: 0.046033\n",
      "[17,   299] loss: 0.101252\n",
      "[17,   399] loss: 0.094439\n",
      "[17,   499] loss: 0.143030\n",
      "[17,   599] loss: 0.083727\n",
      "[17,   699] loss: 0.085060\n",
      "[18,    99] loss: 0.073012\n",
      "[18,   199] loss: 0.036521\n",
      "[18,   299] loss: 0.098298\n",
      "[18,   399] loss: 0.080645\n",
      "[18,   499] loss: 0.108989\n",
      "[18,   599] loss: 0.090411\n",
      "[18,   699] loss: 0.093770\n",
      "[19,    99] loss: 0.069217\n",
      "[19,   199] loss: 0.044322\n",
      "[19,   299] loss: 0.071947\n",
      "[19,   399] loss: 0.073757\n",
      "[19,   499] loss: 0.084965\n",
      "[19,   599] loss: 0.063160\n",
      "[19,   699] loss: 0.038603\n",
      "[20,    99] loss: 0.100884\n",
      "[20,   199] loss: 0.039136\n",
      "[20,   299] loss: 0.079493\n",
      "[20,   399] loss: 0.054939\n",
      "[20,   499] loss: 0.129396\n",
      "[20,   599] loss: 0.070674\n",
      "[20,   699] loss: 0.077584\n",
      "[21,    99] loss: 0.045427\n",
      "[21,   199] loss: 0.033315\n",
      "[21,   299] loss: 0.093640\n",
      "[21,   399] loss: 0.045522\n",
      "[21,   499] loss: 0.124747\n",
      "[21,   599] loss: 0.083638\n",
      "[21,   699] loss: 0.086645\n",
      "[22,    99] loss: 0.043852\n",
      "[22,   199] loss: 0.037071\n",
      "[22,   299] loss: 0.108897\n",
      "[22,   399] loss: 0.129961\n",
      "[22,   499] loss: 0.186204\n",
      "[22,   599] loss: 0.079099\n",
      "[22,   699] loss: 0.056783\n",
      "[23,    99] loss: 0.042444\n",
      "[23,   199] loss: 0.042601\n",
      "[23,   299] loss: 0.089682\n",
      "[23,   399] loss: 0.046889\n",
      "[23,   499] loss: 0.027594\n",
      "[23,   599] loss: 0.062268\n",
      "[23,   699] loss: 0.163200\n",
      "[24,    99] loss: 0.045107\n",
      "[24,   199] loss: 0.030204\n",
      "[24,   299] loss: 0.039023\n",
      "[24,   399] loss: 0.022618\n",
      "[24,   499] loss: 0.021490\n",
      "[24,   599] loss: 0.039927\n",
      "[24,   699] loss: 0.069605\n",
      "[25,    99] loss: 0.122485\n",
      "[25,   199] loss: 0.050069\n",
      "[25,   299] loss: 0.067539\n",
      "[25,   399] loss: 0.030751\n",
      "[25,   499] loss: 0.055191\n",
      "[25,   599] loss: 0.032317\n",
      "[25,   699] loss: 0.048140\n",
      "[26,    99] loss: 0.044304\n",
      "[26,   199] loss: 0.017661\n",
      "[26,   299] loss: 0.021454\n",
      "[26,   399] loss: 0.083704\n",
      "[26,   499] loss: 0.068275\n",
      "[26,   599] loss: 0.042035\n",
      "[26,   699] loss: 0.068061\n",
      "[27,    99] loss: 0.059040\n",
      "[27,   199] loss: 0.029138\n",
      "[27,   299] loss: 0.048382\n",
      "[27,   399] loss: 0.040467\n",
      "[27,   499] loss: 0.056774\n",
      "[27,   599] loss: 0.054482\n",
      "[27,   699] loss: 0.013748\n",
      "[28,    99] loss: 0.094561\n",
      "[28,   199] loss: 0.022825\n",
      "[28,   299] loss: 0.057272\n",
      "[28,   399] loss: 0.031234\n",
      "[28,   499] loss: 0.142709\n",
      "[28,   599] loss: 0.075972\n",
      "[28,   699] loss: 0.034055\n",
      "[29,    99] loss: 0.017373\n",
      "[29,   199] loss: 0.032369\n",
      "[29,   299] loss: 0.069750\n",
      "[29,   399] loss: 0.021735\n",
      "[29,   499] loss: 0.057812\n",
      "[29,   599] loss: 0.081132\n",
      "[29,   699] loss: 0.019919\n",
      "[30,    99] loss: 0.012033\n",
      "[30,   199] loss: 0.034961\n",
      "[30,   299] loss: 0.067760\n",
      "[30,   399] loss: 0.015515\n",
      "[30,   499] loss: 0.024894\n",
      "[30,   599] loss: 0.054818\n",
      "[30,   699] loss: 0.034761\n",
      "[31,    99] loss: 0.014976\n",
      "[31,   199] loss: 0.022128\n",
      "[31,   299] loss: 0.021327\n",
      "[31,   399] loss: 0.034630\n",
      "[31,   499] loss: 0.033671\n",
      "[31,   599] loss: 0.037327\n",
      "[31,   699] loss: 0.057353\n",
      "[32,    99] loss: 0.101091\n",
      "[32,   199] loss: 0.040119\n",
      "[32,   299] loss: 0.037776\n",
      "[32,   399] loss: 0.142681\n",
      "[32,   499] loss: 0.101436\n",
      "[32,   599] loss: 0.086265\n",
      "[32,   699] loss: 0.056893\n",
      "[33,    99] loss: 0.022626\n",
      "[33,   199] loss: 0.013948\n",
      "[33,   299] loss: 0.022194\n",
      "[33,   399] loss: 0.014760\n",
      "[33,   499] loss: 0.034966\n",
      "[33,   599] loss: 0.035959\n",
      "[33,   699] loss: 0.328534\n",
      "[34,    99] loss: 0.041457\n",
      "[34,   199] loss: 0.039614\n",
      "[34,   299] loss: 0.068020\n",
      "[34,   399] loss: 0.025462\n",
      "[34,   499] loss: 0.119232\n",
      "[34,   599] loss: 0.030544\n",
      "[34,   699] loss: 0.107440\n",
      "[35,    99] loss: 0.017605\n",
      "[35,   199] loss: 0.028413\n",
      "[35,   299] loss: 0.016871\n",
      "[35,   399] loss: 0.027766\n",
      "[35,   499] loss: 0.064376\n",
      "[35,   599] loss: 0.047490\n",
      "[35,   699] loss: 0.020016\n",
      "[36,    99] loss: 0.011955\n",
      "[36,   199] loss: 0.024120\n",
      "[36,   299] loss: 0.123957\n",
      "[36,   399] loss: 0.021918\n",
      "[36,   499] loss: 0.076121\n",
      "[36,   599] loss: 0.073780\n",
      "[36,   699] loss: 0.019706\n",
      "[37,    99] loss: 0.078302\n",
      "[37,   199] loss: 0.078084\n",
      "[37,   299] loss: 0.051614\n",
      "[37,   399] loss: 0.009014\n",
      "[37,   499] loss: 0.020337\n",
      "[37,   599] loss: 0.113602\n",
      "[37,   699] loss: 0.234291\n",
      "[38,    99] loss: 0.038722\n",
      "[38,   199] loss: 0.021182\n",
      "[38,   299] loss: 0.048996\n",
      "[38,   399] loss: 0.009580\n",
      "[38,   499] loss: 0.057463\n",
      "[38,   599] loss: 0.024621\n",
      "[38,   699] loss: 0.020245\n",
      "[39,    99] loss: 0.010208\n",
      "[39,   199] loss: 0.023459\n",
      "[39,   299] loss: 0.023707\n",
      "[39,   399] loss: 0.015960\n",
      "[39,   499] loss: 0.026486\n",
      "[39,   599] loss: 0.044506\n",
      "[39,   699] loss: 0.018599\n",
      "[40,    99] loss: 0.012839\n",
      "[40,   199] loss: 0.013152\n",
      "[40,   299] loss: 0.057544\n",
      "[40,   399] loss: 0.120559\n",
      "[40,   499] loss: 0.045645\n",
      "[40,   599] loss: 0.035460\n",
      "[40,   699] loss: 0.011107\n",
      "[41,    99] loss: 0.026480\n",
      "[41,   199] loss: 0.026505\n",
      "[41,   299] loss: 0.033988\n",
      "[41,   399] loss: 0.008081\n",
      "[41,   499] loss: 0.033933\n",
      "[41,   599] loss: 0.063639\n",
      "[41,   699] loss: 0.037201\n",
      "[42,    99] loss: 0.016828\n",
      "[42,   199] loss: 0.014756\n",
      "[42,   299] loss: 0.038561\n",
      "[42,   399] loss: 0.008207\n",
      "[42,   499] loss: 0.025404\n",
      "[42,   599] loss: 0.040461\n",
      "[42,   699] loss: 0.276670\n",
      "[43,    99] loss: 0.065823\n",
      "[43,   199] loss: 0.039661\n",
      "[43,   299] loss: 0.011663\n",
      "[43,   399] loss: 0.003389\n",
      "[43,   499] loss: 0.012821\n",
      "[43,   599] loss: 0.044363\n",
      "[43,   699] loss: 0.103226\n",
      "[44,    99] loss: 0.012508\n",
      "[44,   199] loss: 0.021509\n",
      "[44,   299] loss: 0.007964\n",
      "[44,   399] loss: 0.009436\n",
      "[44,   499] loss: 0.008664\n",
      "[44,   599] loss: 0.010928\n",
      "[44,   699] loss: 0.013151\n",
      "[45,    99] loss: 0.006450\n",
      "[45,   199] loss: 0.007375\n",
      "[45,   299] loss: 0.017852\n",
      "[45,   399] loss: 0.004682\n",
      "[45,   499] loss: 0.006249\n",
      "[45,   599] loss: 0.015953\n",
      "[45,   699] loss: 0.004405\n",
      "[46,    99] loss: 0.007916\n",
      "[46,   199] loss: 0.050232\n",
      "[46,   299] loss: 0.087401\n",
      "[46,   399] loss: 0.147129\n",
      "[46,   499] loss: 0.025711\n",
      "[46,   599] loss: 0.019112\n",
      "[46,   699] loss: 0.017393\n",
      "[47,    99] loss: 0.024739\n",
      "[47,   199] loss: 0.019814\n",
      "[47,   299] loss: 0.063222\n",
      "[47,   399] loss: 0.020670\n",
      "[47,   499] loss: 0.039606\n",
      "[47,   599] loss: 0.019442\n",
      "[47,   699] loss: 0.024607\n",
      "[48,    99] loss: 0.015317\n",
      "[48,   199] loss: 0.033061\n",
      "[48,   299] loss: 0.156658\n",
      "[48,   399] loss: 0.020263\n",
      "[48,   499] loss: 0.081688\n",
      "[48,   599] loss: 0.089601\n",
      "[48,   699] loss: 0.012686\n",
      "[49,    99] loss: 0.024111\n",
      "[49,   199] loss: 0.016557\n",
      "[49,   299] loss: 0.024878\n",
      "[49,   399] loss: 0.085137\n",
      "[49,   499] loss: 0.084392\n",
      "[49,   599] loss: 0.082838\n",
      "[49,   699] loss: 0.248328\n",
      "[50,    99] loss: 0.010054\n",
      "[50,   199] loss: 0.015958\n",
      "[50,   299] loss: 0.021795\n",
      "[50,   399] loss: 0.013493\n",
      "[50,   499] loss: 0.056522\n",
      "[50,   599] loss: 0.015867\n",
      "[50,   699] loss: 0.012235\n",
      "[51,    99] loss: 0.005494\n",
      "[51,   199] loss: 0.016893\n",
      "[51,   299] loss: 0.048116\n",
      "[51,   399] loss: 0.002567\n",
      "[51,   499] loss: 0.012111\n",
      "[51,   599] loss: 0.004915\n",
      "[51,   699] loss: 0.003983\n",
      "[52,    99] loss: 0.001220\n",
      "[52,   199] loss: 0.013813\n",
      "[52,   299] loss: 0.034427\n",
      "[52,   399] loss: 0.003195\n",
      "[52,   499] loss: 0.004618\n",
      "[52,   599] loss: 0.012470\n",
      "[52,   699] loss: 0.031079\n",
      "[53,    99] loss: 0.042001\n",
      "[53,   199] loss: 0.035411\n",
      "[53,   299] loss: 0.060931\n",
      "[53,   399] loss: 0.008570\n",
      "[53,   499] loss: 0.004605\n",
      "[53,   599] loss: 0.014386\n",
      "[53,   699] loss: 0.005674\n",
      "[54,    99] loss: 0.002571\n",
      "[54,   199] loss: 0.007131\n",
      "[54,   299] loss: 0.004322\n",
      "[54,   399] loss: 0.004244\n",
      "[54,   499] loss: 0.001878\n",
      "[54,   599] loss: 0.007600\n",
      "[54,   699] loss: 0.065419\n",
      "[55,    99] loss: 0.059666\n",
      "[55,   199] loss: 0.125135\n",
      "[55,   299] loss: 0.077637\n",
      "[55,   399] loss: 0.025390\n",
      "[55,   499] loss: 0.060624\n",
      "[55,   599] loss: 0.139928\n",
      "[55,   699] loss: 0.080930\n",
      "[56,    99] loss: 0.004640\n",
      "[56,   199] loss: 0.011835\n",
      "[56,   299] loss: 0.004432\n",
      "[56,   399] loss: 0.007162\n",
      "[56,   499] loss: 0.128714\n",
      "[56,   599] loss: 0.030313\n",
      "[56,   699] loss: 0.010677\n",
      "[57,    99] loss: 0.004718\n",
      "[57,   199] loss: 0.013030\n",
      "[57,   299] loss: 0.008669\n",
      "[57,   399] loss: 0.009499\n",
      "[57,   499] loss: 0.054848\n",
      "[57,   599] loss: 0.064719\n",
      "[57,   699] loss: 0.008831\n",
      "[58,    99] loss: 0.001575\n",
      "[58,   199] loss: 0.004531\n",
      "[58,   299] loss: 0.003321\n",
      "[58,   399] loss: 0.004051\n",
      "[58,   499] loss: 0.003873\n",
      "[58,   599] loss: 0.019595\n",
      "[58,   699] loss: 0.003812\n",
      "[59,    99] loss: 0.001540\n",
      "[59,   199] loss: 0.005406\n",
      "[59,   299] loss: 0.002923\n",
      "[59,   399] loss: 0.001475\n",
      "[59,   499] loss: 0.033024\n",
      "[59,   599] loss: 0.016304\n",
      "[59,   699] loss: 0.003023\n",
      "[60,    99] loss: 0.000977\n",
      "[60,   199] loss: 0.005388\n",
      "[60,   299] loss: 0.001704\n",
      "[60,   399] loss: 0.001214\n",
      "[60,   499] loss: 0.003801\n",
      "[60,   599] loss: 0.055188\n",
      "[60,   699] loss: 0.003529\n",
      "[61,    99] loss: 0.003934\n",
      "[61,   199] loss: 0.005188\n",
      "[61,   299] loss: 0.003341\n",
      "[61,   399] loss: 0.001706\n",
      "[61,   499] loss: 0.007614\n",
      "[61,   599] loss: 0.037124\n",
      "[61,   699] loss: 0.028243\n",
      "[62,    99] loss: 0.075038\n",
      "[62,   199] loss: 0.027292\n",
      "[62,   299] loss: 0.021335\n",
      "[62,   399] loss: 0.013276\n",
      "[62,   499] loss: 0.128046\n",
      "[62,   599] loss: 0.047156\n",
      "[62,   699] loss: 0.044849\n",
      "[63,    99] loss: 0.077715\n",
      "[63,   199] loss: 0.056803\n",
      "[63,   299] loss: 0.027812\n",
      "[63,   399] loss: 0.006620\n",
      "[63,   499] loss: 0.008688\n",
      "[63,   599] loss: 0.046582\n",
      "[63,   699] loss: 0.073415\n",
      "[64,    99] loss: 0.060499\n",
      "[64,   199] loss: 0.009455\n",
      "[64,   299] loss: 0.001521\n",
      "[64,   399] loss: 0.002393\n",
      "[64,   499] loss: 0.003237\n",
      "[64,   599] loss: 0.020841\n",
      "[64,   699] loss: 0.003617\n",
      "[65,    99] loss: 0.001480\n",
      "[65,   199] loss: 0.004133\n",
      "[65,   299] loss: 0.007263\n",
      "[65,   399] loss: 0.001312\n",
      "[65,   499] loss: 0.002998\n",
      "[65,   599] loss: 0.023551\n",
      "[65,   699] loss: 0.002630\n",
      "[66,    99] loss: 0.001348\n",
      "[66,   199] loss: 0.004355\n",
      "[66,   299] loss: 0.002721\n",
      "[66,   399] loss: 0.058667\n",
      "[66,   499] loss: 0.046258\n",
      "[66,   599] loss: 0.060494\n",
      "[66,   699] loss: 0.090499\n",
      "[67,    99] loss: 0.003092\n",
      "[67,   199] loss: 0.025210\n",
      "[67,   299] loss: 0.070280\n",
      "[67,   399] loss: 0.014169\n",
      "[67,   499] loss: 0.008037\n",
      "[67,   599] loss: 0.052471\n",
      "[67,   699] loss: 0.005684\n",
      "[68,    99] loss: 0.003645\n",
      "[68,   199] loss: 0.004439\n",
      "[68,   299] loss: 0.003465\n",
      "[68,   399] loss: 0.000812\n",
      "[68,   499] loss: 0.001251\n",
      "[68,   599] loss: 0.011670\n",
      "[68,   699] loss: 0.002015\n",
      "[69,    99] loss: 0.000940\n",
      "[69,   199] loss: 0.003875\n",
      "[69,   299] loss: 0.001879\n",
      "[69,   399] loss: 0.000734\n",
      "[69,   499] loss: 0.001291\n",
      "[69,   599] loss: 0.027567\n",
      "[69,   699] loss: 0.002412\n",
      "[70,    99] loss: 0.000680\n",
      "[70,   199] loss: 0.003503\n",
      "[70,   299] loss: 0.001618\n",
      "[70,   399] loss: 0.001307\n",
      "[70,   499] loss: 0.002917\n",
      "[70,   599] loss: 0.030464\n",
      "[70,   699] loss: 0.034865\n",
      "[71,    99] loss: 0.093859\n",
      "[71,   199] loss: 0.091064\n",
      "[71,   299] loss: 0.087120\n",
      "[71,   399] loss: 0.031440\n",
      "[71,   499] loss: 0.095711\n",
      "[71,   599] loss: 0.021007\n",
      "[71,   699] loss: 0.145562\n",
      "[72,    99] loss: 0.042549\n",
      "[72,   199] loss: 0.067470\n",
      "[72,   299] loss: 0.022911\n",
      "[72,   399] loss: 0.005846\n",
      "[72,   499] loss: 0.007575\n",
      "[72,   599] loss: 0.010961\n",
      "[72,   699] loss: 0.008179\n",
      "[73,    99] loss: 0.008726\n",
      "[73,   199] loss: 0.004939\n",
      "[73,   299] loss: 0.001156\n",
      "[73,   399] loss: 0.001171\n",
      "[73,   499] loss: 0.015339\n",
      "[73,   599] loss: 0.005056\n",
      "[73,   699] loss: 0.001473\n",
      "[74,    99] loss: 0.001289\n",
      "[74,   199] loss: 0.003195\n",
      "[74,   299] loss: 0.000638\n",
      "[74,   399] loss: 0.000807\n",
      "[74,   499] loss: 0.077828\n",
      "[74,   599] loss: 0.004675\n",
      "[74,   699] loss: 0.001507\n",
      "[75,    99] loss: 0.001029\n",
      "[75,   199] loss: 0.003026\n",
      "[75,   299] loss: 0.000800\n",
      "[75,   399] loss: 0.006842\n",
      "[75,   499] loss: 0.064996\n",
      "[75,   599] loss: 0.073215\n",
      "[75,   699] loss: 0.007630\n",
      "[76,    99] loss: 0.008713\n",
      "[76,   199] loss: 0.006017\n",
      "[76,   299] loss: 0.004481\n",
      "[76,   399] loss: 0.004228\n",
      "[76,   499] loss: 0.026030\n",
      "[76,   599] loss: 0.119955\n",
      "[76,   699] loss: 0.028897\n",
      "[77,    99] loss: 0.033108\n",
      "[77,   199] loss: 0.024095\n",
      "[77,   299] loss: 0.054759\n",
      "[77,   399] loss: 0.006543\n",
      "[77,   499] loss: 0.006680\n",
      "[77,   599] loss: 0.117673\n",
      "[77,   699] loss: 0.258051\n",
      "[78,    99] loss: 0.012845\n",
      "[78,   199] loss: 0.070364\n",
      "[78,   299] loss: 0.038556\n",
      "[78,   399] loss: 0.004786\n",
      "[78,   499] loss: 0.005255\n",
      "[78,   599] loss: 0.037283\n",
      "[78,   699] loss: 0.094221\n",
      "[79,    99] loss: 0.021042\n",
      "[79,   199] loss: 0.014216\n",
      "[79,   299] loss: 0.116230\n",
      "[79,   399] loss: 0.010251\n",
      "[79,   499] loss: 0.036261\n",
      "[79,   599] loss: 0.015803\n",
      "[79,   699] loss: 0.007251\n",
      "[80,    99] loss: 0.005664\n",
      "[80,   199] loss: 0.010675\n",
      "[80,   299] loss: 0.005367\n",
      "[80,   399] loss: 0.001119\n",
      "[80,   499] loss: 0.002080\n",
      "[80,   599] loss: 0.035222\n",
      "[80,   699] loss: 0.001275\n",
      "[81,    99] loss: 0.003813\n",
      "[81,   199] loss: 0.009398\n",
      "[81,   299] loss: 0.001785\n",
      "[81,   399] loss: 0.092070\n",
      "[81,   499] loss: 0.058532\n",
      "[81,   599] loss: 0.025324\n",
      "[81,   699] loss: 0.007932\n",
      "[82,    99] loss: 0.040638\n",
      "[82,   199] loss: 0.011107\n",
      "[82,   299] loss: 0.013561\n",
      "[82,   399] loss: 0.005171\n",
      "[82,   499] loss: 0.005535\n",
      "[82,   599] loss: 0.010029\n",
      "[82,   699] loss: 0.176266\n",
      "[83,    99] loss: 0.030839\n",
      "[83,   199] loss: 0.004093\n",
      "[83,   299] loss: 0.001117\n",
      "[83,   399] loss: 0.003543\n",
      "[83,   499] loss: 0.008104\n",
      "[83,   599] loss: 0.001944\n",
      "[83,   699] loss: 0.030784\n",
      "[84,    99] loss: 0.012510\n",
      "[84,   199] loss: 0.004658\n",
      "[84,   299] loss: 0.000617\n",
      "[84,   399] loss: 0.118397\n",
      "[84,   499] loss: 0.018069\n",
      "[84,   599] loss: 0.022037\n",
      "[84,   699] loss: 0.014439\n",
      "[85,    99] loss: 0.001107\n",
      "[85,   199] loss: 0.006589\n",
      "[85,   299] loss: 0.001068\n",
      "[85,   399] loss: 0.003558\n",
      "[85,   499] loss: 0.011580\n",
      "[85,   599] loss: 0.003915\n",
      "[85,   699] loss: 0.000857\n",
      "[86,    99] loss: 0.000652\n",
      "[86,   199] loss: 0.003019\n",
      "[86,   299] loss: 0.000581\n",
      "[86,   399] loss: 0.000772\n",
      "[86,   499] loss: 0.000957\n",
      "[86,   599] loss: 0.001143\n",
      "[86,   699] loss: 0.000487\n",
      "[87,    99] loss: 0.000504\n",
      "[87,   199] loss: 0.002647\n",
      "[87,   299] loss: 0.000377\n",
      "[87,   399] loss: 0.000506\n",
      "[87,   499] loss: 0.000783\n",
      "[87,   599] loss: 0.000649\n",
      "[87,   699] loss: 0.000400\n",
      "[88,    99] loss: 0.000367\n",
      "[88,   199] loss: 0.002440\n",
      "[88,   299] loss: 0.000275\n",
      "[88,   399] loss: 0.000341\n",
      "[88,   499] loss: 0.000593\n",
      "[88,   599] loss: 0.000494\n",
      "[88,   699] loss: 0.000332\n",
      "[89,    99] loss: 0.000272\n",
      "[89,   199] loss: 0.002283\n",
      "[89,   299] loss: 0.000199\n",
      "[89,   399] loss: 0.000228\n",
      "[89,   499] loss: 0.000436\n",
      "[89,   599] loss: 0.000363\n",
      "[89,   699] loss: 0.000269\n",
      "[90,    99] loss: 0.000196\n",
      "[90,   199] loss: 0.002146\n",
      "[90,   299] loss: 0.000143\n",
      "[90,   399] loss: 0.000152\n",
      "[90,   499] loss: 0.000292\n",
      "[90,   599] loss: 0.000264\n",
      "[90,   699] loss: 0.000216\n",
      "[91,    99] loss: 0.000143\n",
      "[91,   199] loss: 0.002033\n",
      "[91,   299] loss: 0.000110\n",
      "[91,   399] loss: 0.000102\n",
      "[91,   499] loss: 0.000191\n",
      "[91,   599] loss: 0.000210\n",
      "[91,   699] loss: 0.000179\n",
      "[92,    99] loss: 0.000102\n",
      "[92,   199] loss: 0.001933\n",
      "[92,   299] loss: 0.000080\n",
      "[92,   399] loss: 0.000071\n",
      "[92,   499] loss: 0.000133\n",
      "[92,   599] loss: 0.000166\n",
      "[92,   699] loss: 0.000147\n",
      "[93,    99] loss: 0.000071\n",
      "[93,   199] loss: 0.001816\n",
      "[93,   299] loss: 0.000065\n",
      "[93,   399] loss: 0.000054\n",
      "[93,   499] loss: 0.000099\n",
      "[93,   599] loss: 0.003636\n",
      "[93,   699] loss: 0.413906\n",
      "[94,    99] loss: 0.181545\n",
      "[94,   199] loss: 0.117423\n",
      "[94,   299] loss: 0.088601\n",
      "[94,   399] loss: 0.054327\n",
      "[94,   499] loss: 0.076920\n",
      "[94,   599] loss: 0.069620\n",
      "[94,   699] loss: 0.014539\n",
      "[95,    99] loss: 0.036837\n",
      "[95,   199] loss: 0.014779\n",
      "[95,   299] loss: 0.004335\n",
      "[95,   399] loss: 0.001342\n",
      "[95,   499] loss: 0.004243\n",
      "[95,   599] loss: 0.016020\n",
      "[95,   699] loss: 0.053967\n",
      "[96,    99] loss: 0.018957\n",
      "[96,   199] loss: 0.003271\n",
      "[96,   299] loss: 0.001058\n",
      "[96,   399] loss: 0.000870\n",
      "[96,   499] loss: 0.003209\n",
      "[96,   599] loss: 0.003125\n",
      "[96,   699] loss: 0.002124\n",
      "[97,    99] loss: 0.000930\n",
      "[97,   199] loss: 0.002128\n",
      "[97,   299] loss: 0.001571\n",
      "[97,   399] loss: 0.001085\n",
      "[97,   499] loss: 0.001037\n",
      "[97,   599] loss: 0.001963\n",
      "[97,   699] loss: 0.011777\n",
      "[98,    99] loss: 0.059438\n",
      "[98,   199] loss: 0.003858\n",
      "[98,   299] loss: 0.045256\n",
      "[98,   399] loss: 0.000953\n",
      "[98,   499] loss: 0.007126\n",
      "[98,   599] loss: 0.001673\n",
      "[98,   699] loss: 0.001242\n",
      "[99,    99] loss: 0.000858\n",
      "[99,   199] loss: 0.002038\n",
      "[99,   299] loss: 0.001411\n",
      "[99,   399] loss: 0.000804\n",
      "[99,   499] loss: 0.001448\n",
      "[99,   599] loss: 0.001364\n",
      "[99,   699] loss: 0.000911\n",
      "[100,    99] loss: 0.000381\n",
      "[100,   199] loss: 0.001524\n",
      "[100,   299] loss: 0.000398\n",
      "[100,   399] loss: 0.000657\n",
      "[100,   499] loss: 0.000581\n",
      "[100,   599] loss: 0.000701\n",
      "[100,   699] loss: 0.000796\n",
      "Finished Training\n",
      "[1,    99] loss: 0.689415\n",
      "[1,   199] loss: 0.696903\n",
      "[1,   299] loss: 0.670471\n",
      "[1,   399] loss: 0.646409\n",
      "[1,   499] loss: 0.652873\n",
      "[1,   599] loss: 0.645105\n",
      "[1,   699] loss: 0.616978\n",
      "[2,    99] loss: 0.597890\n",
      "[2,   199] loss: 0.626664\n",
      "[2,   299] loss: 0.594779\n",
      "[2,   399] loss: 0.556179\n",
      "[2,   499] loss: 0.577022\n",
      "[2,   599] loss: 0.599066\n",
      "[2,   699] loss: 0.525180\n",
      "[3,    99] loss: 0.537322\n",
      "[3,   199] loss: 0.551574\n",
      "[3,   299] loss: 0.503799\n",
      "[3,   399] loss: 0.455725\n",
      "[3,   499] loss: 0.494390\n",
      "[3,   599] loss: 0.534812\n",
      "[3,   699] loss: 0.427266\n",
      "[4,    99] loss: 0.463340\n",
      "[4,   199] loss: 0.464042\n",
      "[4,   299] loss: 0.414882\n",
      "[4,   399] loss: 0.367249\n",
      "[4,   499] loss: 0.413000\n",
      "[4,   599] loss: 0.444217\n",
      "[4,   699] loss: 0.357044\n",
      "[5,    99] loss: 0.385769\n",
      "[5,   199] loss: 0.381290\n",
      "[5,   299] loss: 0.345536\n",
      "[5,   399] loss: 0.311886\n",
      "[5,   499] loss: 0.342799\n",
      "[5,   599] loss: 0.357651\n",
      "[5,   699] loss: 0.295873\n",
      "[6,    99] loss: 0.327713\n",
      "[6,   199] loss: 0.322957\n",
      "[6,   299] loss: 0.284144\n",
      "[6,   399] loss: 0.260864\n",
      "[6,   499] loss: 0.288159\n",
      "[6,   599] loss: 0.288191\n",
      "[6,   699] loss: 0.255458\n",
      "[7,    99] loss: 0.290243\n",
      "[7,   199] loss: 0.292108\n",
      "[7,   299] loss: 0.249113\n",
      "[7,   399] loss: 0.230418\n",
      "[7,   499] loss: 0.258570\n",
      "[7,   599] loss: 0.243484\n",
      "[7,   699] loss: 0.225976\n",
      "[8,    99] loss: 0.255459\n",
      "[8,   199] loss: 0.260970\n",
      "[8,   299] loss: 0.228779\n",
      "[8,   399] loss: 0.200396\n",
      "[8,   499] loss: 0.231386\n",
      "[8,   599] loss: 0.192469\n",
      "[8,   699] loss: 0.196513\n",
      "[9,    99] loss: 0.214335\n",
      "[9,   199] loss: 0.262832\n",
      "[9,   299] loss: 0.208804\n",
      "[9,   399] loss: 0.180941\n",
      "[9,   499] loss: 0.191203\n",
      "[9,   599] loss: 0.171233\n",
      "[9,   699] loss: 0.175822\n",
      "[10,    99] loss: 0.188237\n",
      "[10,   199] loss: 0.222879\n",
      "[10,   299] loss: 0.181123\n",
      "[10,   399] loss: 0.174359\n",
      "[10,   499] loss: 0.177623\n",
      "[10,   599] loss: 0.144970\n",
      "[10,   699] loss: 0.164558\n",
      "[11,    99] loss: 0.178522\n",
      "[11,   199] loss: 0.216669\n",
      "[11,   299] loss: 0.165914\n",
      "[11,   399] loss: 0.152653\n",
      "[11,   499] loss: 0.152430\n",
      "[11,   599] loss: 0.118102\n",
      "[11,   699] loss: 0.149579\n",
      "[12,    99] loss: 0.171235\n",
      "[12,   199] loss: 0.250195\n",
      "[12,   299] loss: 0.149416\n",
      "[12,   399] loss: 0.141676\n",
      "[12,   499] loss: 0.141328\n",
      "[12,   599] loss: 0.108365\n",
      "[12,   699] loss: 0.139939\n",
      "[13,    99] loss: 0.139686\n",
      "[13,   199] loss: 0.190119\n",
      "[13,   299] loss: 0.147097\n",
      "[13,   399] loss: 0.132144\n",
      "[13,   499] loss: 0.113373\n",
      "[13,   599] loss: 0.104212\n",
      "[13,   699] loss: 0.131964\n",
      "[14,    99] loss: 0.124813\n",
      "[14,   199] loss: 0.170087\n",
      "[14,   299] loss: 0.122508\n",
      "[14,   399] loss: 0.133679\n",
      "[14,   499] loss: 0.120526\n",
      "[14,   599] loss: 0.135245\n",
      "[14,   699] loss: 0.134929\n",
      "[15,    99] loss: 0.130943\n",
      "[15,   199] loss: 0.194291\n",
      "[15,   299] loss: 0.127093\n",
      "[15,   399] loss: 0.097667\n",
      "[15,   499] loss: 0.133150\n",
      "[15,   599] loss: 0.127048\n",
      "[15,   699] loss: 0.104943\n",
      "[16,    99] loss: 0.111586\n",
      "[16,   199] loss: 0.139601\n",
      "[16,   299] loss: 0.102299\n",
      "[16,   399] loss: 0.117632\n",
      "[16,   499] loss: 0.081668\n",
      "[16,   599] loss: 0.074042\n",
      "[16,   699] loss: 0.102683\n",
      "[17,    99] loss: 0.076501\n",
      "[17,   199] loss: 0.093503\n",
      "[17,   299] loss: 0.095279\n",
      "[17,   399] loss: 0.095741\n",
      "[17,   499] loss: 0.068155\n",
      "[17,   599] loss: 0.094101\n",
      "[17,   699] loss: 0.117393\n",
      "[18,    99] loss: 0.089621\n",
      "[18,   199] loss: 0.098611\n",
      "[18,   299] loss: 0.087586\n",
      "[18,   399] loss: 0.087091\n",
      "[18,   499] loss: 0.081028\n",
      "[18,   599] loss: 0.086931\n",
      "[18,   699] loss: 0.187370\n",
      "[19,    99] loss: 0.089700\n",
      "[19,   199] loss: 0.129894\n",
      "[19,   299] loss: 0.080478\n",
      "[19,   399] loss: 0.074945\n",
      "[19,   499] loss: 0.048276\n",
      "[19,   599] loss: 0.037422\n",
      "[19,   699] loss: 0.099270\n",
      "[20,    99] loss: 0.043608\n",
      "[20,   199] loss: 0.055675\n",
      "[20,   299] loss: 0.059227\n",
      "[20,   399] loss: 0.073059\n",
      "[20,   499] loss: 0.051102\n",
      "[20,   599] loss: 0.042557\n",
      "[20,   699] loss: 0.143733\n",
      "[21,    99] loss: 0.062877\n",
      "[21,   199] loss: 0.098446\n",
      "[21,   299] loss: 0.060555\n",
      "[21,   399] loss: 0.042774\n",
      "[21,   499] loss: 0.036924\n",
      "[21,   599] loss: 0.025211\n",
      "[21,   699] loss: 0.092084\n",
      "[22,    99] loss: 0.035458\n",
      "[22,   199] loss: 0.053612\n",
      "[22,   299] loss: 0.083156\n",
      "[22,   399] loss: 0.215682\n",
      "[22,   499] loss: 0.048673\n",
      "[22,   599] loss: 0.076079\n",
      "[22,   699] loss: 0.113423\n",
      "[23,    99] loss: 0.100544\n",
      "[23,   199] loss: 0.077840\n",
      "[23,   299] loss: 0.057161\n",
      "[23,   399] loss: 0.030704\n",
      "[23,   499] loss: 0.025453\n",
      "[23,   599] loss: 0.018776\n",
      "[23,   699] loss: 0.094966\n",
      "[24,    99] loss: 0.032916\n",
      "[24,   199] loss: 0.074937\n",
      "[24,   299] loss: 0.065341\n",
      "[24,   399] loss: 0.098087\n",
      "[24,   499] loss: 0.023658\n",
      "[24,   599] loss: 0.011439\n",
      "[24,   699] loss: 0.063127\n",
      "[25,    99] loss: 0.029859\n",
      "[25,   199] loss: 0.029279\n",
      "[25,   299] loss: 0.042554\n",
      "[25,   399] loss: 0.092747\n",
      "[25,   499] loss: 0.161326\n",
      "[25,   599] loss: 0.165506\n",
      "[25,   699] loss: 0.128666\n",
      "[26,    99] loss: 0.131978\n",
      "[26,   199] loss: 0.098401\n",
      "[26,   299] loss: 0.047862\n",
      "[26,   399] loss: 0.033152\n",
      "[26,   499] loss: 0.024490\n",
      "[26,   599] loss: 0.027866\n",
      "[26,   699] loss: 0.064677\n",
      "[27,    99] loss: 0.025758\n",
      "[27,   199] loss: 0.033750\n",
      "[27,   299] loss: 0.036786\n",
      "[27,   399] loss: 0.026215\n",
      "[27,   499] loss: 0.016496\n",
      "[27,   599] loss: 0.061112\n",
      "[27,   699] loss: 0.075852\n",
      "[28,    99] loss: 0.132044\n",
      "[28,   199] loss: 0.065948\n",
      "[28,   299] loss: 0.055506\n",
      "[28,   399] loss: 0.048364\n",
      "[28,   499] loss: 0.046814\n",
      "[28,   599] loss: 0.047809\n",
      "[28,   699] loss: 0.085786\n",
      "[29,    99] loss: 0.050383\n",
      "[29,   199] loss: 0.036241\n",
      "[29,   299] loss: 0.063052\n",
      "[29,   399] loss: 0.041601\n",
      "[29,   499] loss: 0.077346\n",
      "[29,   599] loss: 0.032946\n",
      "[29,   699] loss: 0.108506\n",
      "[30,    99] loss: 0.081681\n",
      "[30,   199] loss: 0.028549\n",
      "[30,   299] loss: 0.048678\n",
      "[30,   399] loss: 0.030988\n",
      "[30,   499] loss: 0.011126\n",
      "[30,   599] loss: 0.070018\n",
      "[30,   699] loss: 0.086981\n",
      "[31,    99] loss: 0.055802\n",
      "[31,   199] loss: 0.034517\n",
      "[31,   299] loss: 0.045230\n",
      "[31,   399] loss: 0.075011\n",
      "[31,   499] loss: 0.105599\n",
      "[31,   599] loss: 0.038973\n",
      "[31,   699] loss: 0.103951\n",
      "[32,    99] loss: 0.042474\n",
      "[32,   199] loss: 0.037378\n",
      "[32,   299] loss: 0.039691\n",
      "[32,   399] loss: 0.241603\n",
      "[32,   499] loss: 0.186759\n",
      "[32,   599] loss: 0.096867\n",
      "[32,   699] loss: 0.061450\n",
      "[33,    99] loss: 0.038925\n",
      "[33,   199] loss: 0.024703\n",
      "[33,   299] loss: 0.040993\n",
      "[33,   399] loss: 0.040321\n",
      "[33,   499] loss: 0.016848\n",
      "[33,   599] loss: 0.008420\n",
      "[33,   699] loss: 0.038653\n",
      "[34,    99] loss: 0.015461\n",
      "[34,   199] loss: 0.022383\n",
      "[34,   299] loss: 0.036155\n",
      "[34,   399] loss: 0.009340\n",
      "[34,   499] loss: 0.007196\n",
      "[34,   599] loss: 0.004050\n",
      "[34,   699] loss: 0.022435\n",
      "[35,    99] loss: 0.014085\n",
      "[35,   199] loss: 0.012859\n",
      "[35,   299] loss: 0.033197\n",
      "[35,   399] loss: 0.007573\n",
      "[35,   499] loss: 0.004440\n",
      "[35,   599] loss: 0.002842\n",
      "[35,   699] loss: 0.022276\n",
      "[36,    99] loss: 0.011121\n",
      "[36,   199] loss: 0.009634\n",
      "[36,   299] loss: 0.042377\n",
      "[36,   399] loss: 0.024218\n",
      "[36,   499] loss: 0.006354\n",
      "[36,   599] loss: 0.002408\n",
      "[36,   699] loss: 0.040849\n",
      "[37,    99] loss: 0.014294\n",
      "[37,   199] loss: 0.025273\n",
      "[37,   299] loss: 0.070346\n",
      "[37,   399] loss: 0.112081\n",
      "[37,   499] loss: 0.052360\n",
      "[37,   599] loss: 0.126516\n",
      "[37,   699] loss: 0.149941\n",
      "[38,    99] loss: 0.069818\n",
      "[38,   199] loss: 0.052782\n",
      "[38,   299] loss: 0.036878\n",
      "[38,   399] loss: 0.090677\n",
      "[38,   499] loss: 0.024430\n",
      "[38,   599] loss: 0.048257\n",
      "[38,   699] loss: 0.103439\n",
      "[39,    99] loss: 0.054477\n",
      "[39,   199] loss: 0.021928\n",
      "[39,   299] loss: 0.016545\n",
      "[39,   399] loss: 0.026519\n",
      "[39,   499] loss: 0.012559\n",
      "[39,   599] loss: 0.062598\n",
      "[39,   699] loss: 0.060534\n",
      "[40,    99] loss: 0.016897\n",
      "[40,   199] loss: 0.012041\n",
      "[40,   299] loss: 0.036954\n",
      "[40,   399] loss: 0.007321\n",
      "[40,   499] loss: 0.004345\n",
      "[40,   599] loss: 0.004081\n",
      "[40,   699] loss: 0.010297\n",
      "[41,    99] loss: 0.005998\n",
      "[41,   199] loss: 0.010545\n",
      "[41,   299] loss: 0.020961\n",
      "[41,   399] loss: 0.062893\n",
      "[41,   499] loss: 0.016804\n",
      "[41,   599] loss: 0.014006\n",
      "[41,   699] loss: 0.024255\n",
      "[42,    99] loss: 0.020516\n",
      "[42,   199] loss: 0.177493\n",
      "[42,   299] loss: 0.080780\n",
      "[42,   399] loss: 0.096338\n",
      "[42,   499] loss: 0.110342\n",
      "[42,   599] loss: 0.124131\n",
      "[42,   699] loss: 0.112960\n",
      "[43,    99] loss: 0.041302\n",
      "[43,   199] loss: 0.087731\n",
      "[43,   299] loss: 0.067495\n",
      "[43,   399] loss: 0.013864\n",
      "[43,   499] loss: 0.004331\n",
      "[43,   599] loss: 0.029199\n",
      "[43,   699] loss: 0.034106\n",
      "[44,    99] loss: 0.011863\n",
      "[44,   199] loss: 0.026674\n",
      "[44,   299] loss: 0.110806\n",
      "[44,   399] loss: 0.009787\n",
      "[44,   499] loss: 0.004745\n",
      "[44,   599] loss: 0.018697\n",
      "[44,   699] loss: 0.015947\n",
      "[45,    99] loss: 0.005901\n",
      "[45,   199] loss: 0.005977\n",
      "[45,   299] loss: 0.030328\n",
      "[45,   399] loss: 0.015238\n",
      "[45,   499] loss: 0.003327\n",
      "[45,   599] loss: 0.012397\n",
      "[45,   699] loss: 0.014937\n",
      "[46,    99] loss: 0.008833\n",
      "[46,   199] loss: 0.011039\n",
      "[46,   299] loss: 0.019524\n",
      "[46,   399] loss: 0.075322\n",
      "[46,   499] loss: 0.003607\n",
      "[46,   599] loss: 0.008011\n",
      "[46,   699] loss: 0.009219\n",
      "[47,    99] loss: 0.004130\n",
      "[47,   199] loss: 0.008099\n",
      "[47,   299] loss: 0.085347\n",
      "[47,   399] loss: 0.151251\n",
      "[47,   499] loss: 0.079973\n",
      "[47,   599] loss: 0.174239\n",
      "[47,   699] loss: 0.236212\n",
      "[48,    99] loss: 0.106555\n",
      "[48,   199] loss: 0.011299\n",
      "[48,   299] loss: 0.016011\n",
      "[48,   399] loss: 0.021196\n",
      "[48,   499] loss: 0.012335\n",
      "[48,   599] loss: 0.073717\n",
      "[48,   699] loss: 0.039015\n",
      "[49,    99] loss: 0.020135\n",
      "[49,   199] loss: 0.142389\n",
      "[49,   299] loss: 0.008399\n",
      "[49,   399] loss: 0.010333\n",
      "[49,   499] loss: 0.008585\n",
      "[49,   599] loss: 0.004428\n",
      "[49,   699] loss: 0.007042\n",
      "[50,    99] loss: 0.003889\n",
      "[50,   199] loss: 0.004574\n",
      "[50,   299] loss: 0.007479\n",
      "[50,   399] loss: 0.007876\n",
      "[50,   499] loss: 0.018781\n",
      "[50,   599] loss: 0.002966\n",
      "[50,   699] loss: 0.027301\n",
      "[51,    99] loss: 0.004677\n",
      "[51,   199] loss: 0.073726\n",
      "[51,   299] loss: 0.012785\n",
      "[51,   399] loss: 0.004319\n",
      "[51,   499] loss: 0.009851\n",
      "[51,   599] loss: 0.002860\n",
      "[51,   699] loss: 0.003548\n",
      "[52,    99] loss: 0.009531\n",
      "[52,   199] loss: 0.069328\n",
      "[52,   299] loss: 0.194828\n",
      "[52,   399] loss: 0.176411\n",
      "[52,   499] loss: 0.086707\n",
      "[52,   599] loss: 0.115005\n",
      "[52,   699] loss: 0.115888\n",
      "[53,    99] loss: 0.017464\n",
      "[53,   199] loss: 0.004145\n",
      "[53,   299] loss: 0.071457\n",
      "[53,   399] loss: 0.016185\n",
      "[53,   499] loss: 0.008575\n",
      "[53,   599] loss: 0.004998\n",
      "[53,   699] loss: 0.006341\n",
      "[54,    99] loss: 0.003807\n",
      "[54,   199] loss: 0.003350\n",
      "[54,   299] loss: 0.004337\n",
      "[54,   399] loss: 0.001531\n",
      "[54,   499] loss: 0.002972\n",
      "[54,   599] loss: 0.001712\n",
      "[54,   699] loss: 0.005357\n",
      "[55,    99] loss: 0.002839\n",
      "[55,   199] loss: 0.002021\n",
      "[55,   299] loss: 0.002308\n",
      "[55,   399] loss: 0.001156\n",
      "[55,   499] loss: 0.001779\n",
      "[55,   599] loss: 0.001297\n",
      "[55,   699] loss: 0.004063\n",
      "[56,    99] loss: 0.002164\n",
      "[56,   199] loss: 0.001424\n",
      "[56,   299] loss: 0.001825\n",
      "[56,   399] loss: 0.000970\n",
      "[56,   499] loss: 0.001269\n",
      "[56,   599] loss: 0.000990\n",
      "[56,   699] loss: 0.003290\n",
      "[57,    99] loss: 0.001993\n",
      "[57,   199] loss: 0.001203\n",
      "[57,   299] loss: 0.001305\n",
      "[57,   399] loss: 0.000886\n",
      "[57,   499] loss: 0.001013\n",
      "[57,   599] loss: 0.000797\n",
      "[57,   699] loss: 0.003134\n",
      "[58,    99] loss: 0.001563\n",
      "[58,   199] loss: 0.001015\n",
      "[58,   299] loss: 0.001086\n",
      "[58,   399] loss: 0.000870\n",
      "[58,   499] loss: 0.000740\n",
      "[58,   599] loss: 0.000593\n",
      "[58,   699] loss: 0.002418\n",
      "[59,    99] loss: 0.001644\n",
      "[59,   199] loss: 0.001331\n",
      "[59,   299] loss: 0.001537\n",
      "[59,   399] loss: 0.217237\n",
      "[59,   499] loss: 0.011054\n",
      "[59,   599] loss: 0.011267\n",
      "[59,   699] loss: 0.077710\n",
      "[60,    99] loss: 0.364892\n",
      "[60,   199] loss: 0.468268\n",
      "[60,   299] loss: 0.081548\n",
      "[60,   399] loss: 0.053291\n",
      "[60,   499] loss: 0.068105\n",
      "[60,   599] loss: 0.013226\n",
      "[60,   699] loss: 0.041086\n",
      "[61,    99] loss: 0.022440\n",
      "[61,   199] loss: 0.009349\n",
      "[61,   299] loss: 0.039985\n",
      "[61,   399] loss: 0.005937\n",
      "[61,   499] loss: 0.003315\n",
      "[61,   599] loss: 0.003584\n",
      "[61,   699] loss: 0.003794\n",
      "[62,    99] loss: 0.004681\n",
      "[62,   199] loss: 0.005367\n",
      "[62,   299] loss: 0.009736\n",
      "[62,   399] loss: 0.039497\n",
      "[62,   499] loss: 0.003513\n",
      "[62,   599] loss: 0.040696\n",
      "[62,   699] loss: 0.055737\n",
      "[63,    99] loss: 0.014328\n",
      "[63,   199] loss: 0.002857\n",
      "[63,   299] loss: 0.009554\n",
      "[63,   399] loss: 0.037158\n",
      "[63,   499] loss: 0.002789\n",
      "[63,   599] loss: 0.031931\n",
      "[63,   699] loss: 0.023208\n",
      "[64,    99] loss: 0.003753\n",
      "[64,   199] loss: 0.006534\n",
      "[64,   299] loss: 0.009031\n",
      "[64,   399] loss: 0.005022\n",
      "[64,   499] loss: 0.002031\n",
      "[64,   599] loss: 0.001149\n",
      "[64,   699] loss: 0.001674\n",
      "[65,    99] loss: 0.001557\n",
      "[65,   199] loss: 0.004209\n",
      "[65,   299] loss: 0.060160\n",
      "[65,   399] loss: 0.215844\n",
      "[65,   499] loss: 0.011705\n",
      "[65,   599] loss: 0.001705\n",
      "[65,   699] loss: 0.003262\n",
      "[66,    99] loss: 0.116204\n",
      "[66,   199] loss: 0.040232\n",
      "[66,   299] loss: 0.012482\n",
      "[66,   399] loss: 0.005100\n",
      "[66,   499] loss: 0.001994\n",
      "[66,   599] loss: 0.001378\n",
      "[66,   699] loss: 0.003663\n",
      "[67,    99] loss: 0.002184\n",
      "[67,   199] loss: 0.002707\n",
      "[67,   299] loss: 0.002862\n",
      "[67,   399] loss: 0.001284\n",
      "[67,   499] loss: 0.000997\n",
      "[67,   599] loss: 0.000676\n",
      "[67,   699] loss: 0.002172\n",
      "[68,    99] loss: 0.001332\n",
      "[68,   199] loss: 0.001450\n",
      "[68,   299] loss: 0.000910\n",
      "[68,   399] loss: 0.000928\n",
      "[68,   499] loss: 0.000685\n",
      "[68,   599] loss: 0.000449\n",
      "[68,   699] loss: 0.001785\n",
      "[69,    99] loss: 0.001496\n",
      "[69,   199] loss: 0.001008\n",
      "[69,   299] loss: 0.000695\n",
      "[69,   399] loss: 0.000718\n",
      "[69,   499] loss: 0.000579\n",
      "[69,   599] loss: 0.000350\n",
      "[69,   699] loss: 0.003884\n",
      "[70,    99] loss: 0.011353\n",
      "[70,   199] loss: 0.025485\n",
      "[70,   299] loss: 0.096392\n",
      "[70,   399] loss: 0.004496\n",
      "[70,   499] loss: 0.158632\n",
      "[70,   599] loss: 0.569774\n",
      "[70,   699] loss: 0.298654\n",
      "[71,    99] loss: 0.067450\n",
      "[71,   199] loss: 0.021955\n",
      "[71,   299] loss: 0.018669\n",
      "[71,   399] loss: 0.056411\n",
      "[71,   499] loss: 0.057162\n",
      "[71,   599] loss: 0.008469\n",
      "[71,   699] loss: 0.022566\n",
      "[72,    99] loss: 0.034129\n",
      "[72,   199] loss: 0.030011\n",
      "[72,   299] loss: 0.005390\n",
      "[72,   399] loss: 0.005489\n",
      "[72,   499] loss: 0.002391\n",
      "[72,   599] loss: 0.001508\n",
      "[72,   699] loss: 0.002927\n",
      "[73,    99] loss: 0.001541\n",
      "[73,   199] loss: 0.001423\n",
      "[73,   299] loss: 0.000870\n",
      "[73,   399] loss: 0.001141\n",
      "[73,   499] loss: 0.000725\n",
      "[73,   599] loss: 0.000660\n",
      "[73,   699] loss: 0.001356\n",
      "[74,    99] loss: 0.000960\n",
      "[74,   199] loss: 0.000789\n",
      "[74,   299] loss: 0.000801\n",
      "[74,   399] loss: 0.000853\n",
      "[74,   499] loss: 0.000614\n",
      "[74,   599] loss: 0.000541\n",
      "[74,   699] loss: 0.001182\n",
      "[75,    99] loss: 0.000760\n",
      "[75,   199] loss: 0.000630\n",
      "[75,   299] loss: 0.000706\n",
      "[75,   399] loss: 0.000680\n",
      "[75,   499] loss: 0.000525\n",
      "[75,   599] loss: 0.000462\n",
      "[75,   699] loss: 0.001027\n",
      "[76,    99] loss: 0.000651\n",
      "[76,   199] loss: 0.000502\n",
      "[76,   299] loss: 0.000593\n",
      "[76,   399] loss: 0.000550\n",
      "[76,   499] loss: 0.000450\n",
      "[76,   599] loss: 0.000388\n",
      "[76,   699] loss: 0.000931\n",
      "[77,    99] loss: 0.000604\n",
      "[77,   199] loss: 0.000390\n",
      "[77,   299] loss: 0.000488\n",
      "[77,   399] loss: 0.000456\n",
      "[77,   499] loss: 0.000409\n",
      "[77,   599] loss: 0.000312\n",
      "[77,   699] loss: 0.000973\n",
      "[78,    99] loss: 0.000791\n",
      "[78,   199] loss: 0.000355\n",
      "[78,   299] loss: 0.000356\n",
      "[78,   399] loss: 0.000393\n",
      "[78,   499] loss: 0.000380\n",
      "[78,   599] loss: 0.000248\n",
      "[78,   699] loss: 0.004364\n",
      "[79,    99] loss: 0.056273\n",
      "[79,   199] loss: 0.266714\n",
      "[79,   299] loss: 0.329727\n",
      "[79,   399] loss: 0.168466\n",
      "[79,   499] loss: 0.420982\n",
      "[79,   599] loss: 0.186320\n",
      "[79,   699] loss: 0.091584\n",
      "[80,    99] loss: 0.022960\n",
      "[80,   199] loss: 0.051737\n",
      "[80,   299] loss: 0.051236\n",
      "[80,   399] loss: 0.032803\n",
      "[80,   499] loss: 0.002413\n",
      "[80,   599] loss: 0.000675\n",
      "[80,   699] loss: 0.027994\n",
      "[81,    99] loss: 0.006227\n",
      "[81,   199] loss: 0.006590\n",
      "[81,   299] loss: 0.007522\n",
      "[81,   399] loss: 0.006719\n",
      "[81,   499] loss: 0.000721\n",
      "[81,   599] loss: 0.000833\n",
      "[81,   699] loss: 0.002705\n",
      "[82,    99] loss: 0.001381\n",
      "[82,   199] loss: 0.000902\n",
      "[82,   299] loss: 0.113055\n",
      "[82,   399] loss: 0.001348\n",
      "[82,   499] loss: 0.001050\n",
      "[82,   599] loss: 0.000568\n",
      "[82,   699] loss: 0.006077\n",
      "[83,    99] loss: 0.002266\n",
      "[83,   199] loss: 0.000725\n",
      "[83,   299] loss: 0.002272\n",
      "[83,   399] loss: 0.000823\n",
      "[83,   499] loss: 0.000644\n",
      "[83,   599] loss: 0.000436\n",
      "[83,   699] loss: 0.001882\n",
      "[84,    99] loss: 0.000892\n",
      "[84,   199] loss: 0.000493\n",
      "[84,   299] loss: 0.000666\n",
      "[84,   399] loss: 0.000634\n",
      "[84,   499] loss: 0.000548\n",
      "[84,   599] loss: 0.000401\n",
      "[84,   699] loss: 0.001259\n",
      "[85,    99] loss: 0.000660\n",
      "[85,   199] loss: 0.000395\n",
      "[85,   299] loss: 0.000513\n",
      "[85,   399] loss: 0.000510\n",
      "[85,   499] loss: 0.000461\n",
      "[85,   599] loss: 0.000333\n",
      "[85,   699] loss: 0.001040\n",
      "[86,    99] loss: 0.000609\n",
      "[86,   199] loss: 0.000320\n",
      "[86,   299] loss: 0.000405\n",
      "[86,   399] loss: 0.000442\n",
      "[86,   499] loss: 0.000387\n",
      "[86,   599] loss: 0.000270\n",
      "[86,   699] loss: 0.000888\n",
      "[87,    99] loss: 0.000563\n",
      "[87,   199] loss: 0.000268\n",
      "[87,   299] loss: 0.000326\n",
      "[87,   399] loss: 0.000363\n",
      "[87,   499] loss: 0.000320\n",
      "[87,   599] loss: 0.000222\n",
      "[87,   699] loss: 0.000765\n",
      "[88,    99] loss: 0.000746\n",
      "[88,   199] loss: 0.000288\n",
      "[88,   299] loss: 0.000247\n",
      "[88,   399] loss: 0.000367\n",
      "[88,   499] loss: 0.000227\n",
      "[88,   599] loss: 0.000186\n",
      "[88,   699] loss: 0.006066\n",
      "[89,    99] loss: 0.149708\n",
      "[89,   199] loss: 0.830598\n",
      "[89,   299] loss: 0.256914\n",
      "[89,   399] loss: 0.026297\n",
      "[89,   499] loss: 0.087881\n",
      "[89,   599] loss: 0.052998\n",
      "[89,   699] loss: 0.033191\n",
      "[90,    99] loss: 0.003171\n",
      "[90,   199] loss: 0.005881\n",
      "[90,   299] loss: 0.059912\n",
      "[90,   399] loss: 0.063477\n",
      "[90,   499] loss: 0.012889\n",
      "[90,   599] loss: 0.004218\n",
      "[90,   699] loss: 0.004100\n",
      "[91,    99] loss: 0.001945\n",
      "[91,   199] loss: 0.004129\n",
      "[91,   299] loss: 0.048167\n",
      "[91,   399] loss: 0.002288\n",
      "[91,   499] loss: 0.003435\n",
      "[91,   599] loss: 0.001991\n",
      "[91,   699] loss: 0.002314\n",
      "[92,    99] loss: 0.001187\n",
      "[92,   199] loss: 0.001846\n",
      "[92,   299] loss: 0.060308\n",
      "[92,   399] loss: 0.001231\n",
      "[92,   499] loss: 0.001266\n",
      "[92,   599] loss: 0.000874\n",
      "[92,   699] loss: 0.001777\n",
      "[93,    99] loss: 0.000990\n",
      "[93,   199] loss: 0.000967\n",
      "[93,   299] loss: 0.003788\n",
      "[93,   399] loss: 0.013811\n",
      "[93,   499] loss: 0.009733\n",
      "[93,   599] loss: 0.090520\n",
      "[93,   699] loss: 0.036352\n",
      "[94,    99] loss: 0.048567\n",
      "[94,   199] loss: 0.097422\n",
      "[94,   299] loss: 0.196789\n",
      "[94,   399] loss: 0.141761\n",
      "[94,   499] loss: 0.027325\n",
      "[94,   599] loss: 0.001953\n",
      "[94,   699] loss: 0.034478\n",
      "[95,    99] loss: 0.126082\n",
      "[95,   199] loss: 0.109738\n",
      "[95,   299] loss: 0.007180\n",
      "[95,   399] loss: 0.001777\n",
      "[95,   499] loss: 0.004472\n",
      "[95,   599] loss: 0.002410\n",
      "[95,   699] loss: 0.002760\n",
      "[96,    99] loss: 0.001366\n",
      "[96,   199] loss: 0.001903\n",
      "[96,   299] loss: 0.001477\n",
      "[96,   399] loss: 0.001174\n",
      "[96,   499] loss: 0.000882\n",
      "[96,   599] loss: 0.000905\n",
      "[96,   699] loss: 0.001324\n",
      "[97,    99] loss: 0.000757\n",
      "[97,   199] loss: 0.000500\n",
      "[97,   299] loss: 0.000423\n",
      "[97,   399] loss: 0.000594\n",
      "[97,   499] loss: 0.000537\n",
      "[97,   599] loss: 0.000605\n",
      "[97,   699] loss: 0.001016\n",
      "[98,    99] loss: 0.000568\n",
      "[98,   199] loss: 0.000400\n",
      "[98,   299] loss: 0.000365\n",
      "[98,   399] loss: 0.000474\n",
      "[98,   499] loss: 0.000416\n",
      "[98,   599] loss: 0.000429\n",
      "[98,   699] loss: 0.000840\n",
      "[99,    99] loss: 0.000475\n",
      "[99,   199] loss: 0.000325\n",
      "[99,   299] loss: 0.000316\n",
      "[99,   399] loss: 0.000382\n",
      "[99,   499] loss: 0.000333\n",
      "[99,   599] loss: 0.000330\n",
      "[99,   699] loss: 0.000684\n",
      "[100,    99] loss: 0.000361\n",
      "[100,   199] loss: 0.000262\n",
      "[100,   299] loss: 0.000263\n",
      "[100,   399] loss: 0.000315\n",
      "[100,   499] loss: 0.000257\n",
      "[100,   599] loss: 0.000252\n",
      "[100,   699] loss: 0.000573\n",
      "Finished Training\n",
      "[1,    99] loss: 0.694264\n",
      "[1,   199] loss: 0.687983\n",
      "[1,   299] loss: 0.688626\n",
      "[1,   399] loss: 0.680096\n",
      "[1,   499] loss: 0.667377\n",
      "[1,   599] loss: 0.678496\n",
      "[1,   699] loss: 0.678721\n",
      "[2,    99] loss: 0.679846\n",
      "[2,   199] loss: 0.672217\n",
      "[2,   299] loss: 0.665881\n",
      "[2,   399] loss: 0.659041\n",
      "[2,   499] loss: 0.639490\n",
      "[2,   599] loss: 0.657584\n",
      "[2,   699] loss: 0.659491\n",
      "[3,    99] loss: 0.667279\n",
      "[3,   199] loss: 0.654437\n",
      "[3,   299] loss: 0.640640\n",
      "[3,   399] loss: 0.637027\n",
      "[3,   499] loss: 0.606443\n",
      "[3,   599] loss: 0.632291\n",
      "[3,   699] loss: 0.637247\n",
      "[4,    99] loss: 0.656057\n",
      "[4,   199] loss: 0.636264\n",
      "[4,   299] loss: 0.617660\n",
      "[4,   399] loss: 0.614926\n",
      "[4,   499] loss: 0.576951\n",
      "[4,   599] loss: 0.608798\n",
      "[4,   699] loss: 0.616342\n",
      "[5,    99] loss: 0.647217\n",
      "[5,   199] loss: 0.620065\n",
      "[5,   299] loss: 0.597755\n",
      "[5,   399] loss: 0.594374\n",
      "[5,   499] loss: 0.551975\n",
      "[5,   599] loss: 0.587517\n",
      "[5,   699] loss: 0.596075\n",
      "[6,    99] loss: 0.639263\n",
      "[6,   199] loss: 0.605025\n",
      "[6,   299] loss: 0.580430\n",
      "[6,   399] loss: 0.574945\n",
      "[6,   499] loss: 0.528541\n",
      "[6,   599] loss: 0.568299\n",
      "[6,   699] loss: 0.576078\n",
      "[7,    99] loss: 0.630684\n",
      "[7,   199] loss: 0.588913\n",
      "[7,   299] loss: 0.564546\n",
      "[7,   399] loss: 0.556310\n",
      "[7,   499] loss: 0.507711\n",
      "[7,   599] loss: 0.550230\n",
      "[7,   699] loss: 0.556624\n",
      "[8,    99] loss: 0.621154\n",
      "[8,   199] loss: 0.573724\n",
      "[8,   299] loss: 0.549277\n",
      "[8,   399] loss: 0.538285\n",
      "[8,   499] loss: 0.487938\n",
      "[8,   599] loss: 0.533723\n",
      "[8,   699] loss: 0.537557\n",
      "[9,    99] loss: 0.611428\n",
      "[9,   199] loss: 0.557885\n",
      "[9,   299] loss: 0.534628\n",
      "[9,   399] loss: 0.521156\n",
      "[9,   499] loss: 0.468116\n",
      "[9,   599] loss: 0.517968\n",
      "[9,   699] loss: 0.519207\n",
      "[10,    99] loss: 0.600930\n",
      "[10,   199] loss: 0.541791\n",
      "[10,   299] loss: 0.521213\n",
      "[10,   399] loss: 0.504195\n",
      "[10,   499] loss: 0.448352\n",
      "[10,   599] loss: 0.502878\n",
      "[10,   699] loss: 0.501391\n",
      "[11,    99] loss: 0.589763\n",
      "[11,   199] loss: 0.525383\n",
      "[11,   299] loss: 0.507326\n",
      "[11,   399] loss: 0.487593\n",
      "[11,   499] loss: 0.429196\n",
      "[11,   599] loss: 0.487966\n",
      "[11,   699] loss: 0.483663\n",
      "[12,    99] loss: 0.577146\n",
      "[12,   199] loss: 0.509234\n",
      "[12,   299] loss: 0.493399\n",
      "[12,   399] loss: 0.471763\n",
      "[12,   499] loss: 0.410628\n",
      "[12,   599] loss: 0.473208\n",
      "[12,   699] loss: 0.465862\n",
      "[13,    99] loss: 0.564576\n",
      "[13,   199] loss: 0.492840\n",
      "[13,   299] loss: 0.479706\n",
      "[13,   399] loss: 0.456216\n",
      "[13,   499] loss: 0.392733\n",
      "[13,   599] loss: 0.458008\n",
      "[13,   699] loss: 0.448057\n",
      "[14,    99] loss: 0.550495\n",
      "[14,   199] loss: 0.476278\n",
      "[14,   299] loss: 0.465952\n",
      "[14,   399] loss: 0.441052\n",
      "[14,   499] loss: 0.375292\n",
      "[14,   599] loss: 0.442840\n",
      "[14,   699] loss: 0.431188\n",
      "[15,    99] loss: 0.535329\n",
      "[15,   199] loss: 0.460261\n",
      "[15,   299] loss: 0.452541\n",
      "[15,   399] loss: 0.426037\n",
      "[15,   499] loss: 0.359117\n",
      "[15,   599] loss: 0.428069\n",
      "[15,   699] loss: 0.415419\n",
      "[16,    99] loss: 0.520616\n",
      "[16,   199] loss: 0.444602\n",
      "[16,   299] loss: 0.439366\n",
      "[16,   399] loss: 0.410962\n",
      "[16,   499] loss: 0.343906\n",
      "[16,   599] loss: 0.413470\n",
      "[16,   699] loss: 0.400914\n",
      "[17,    99] loss: 0.505781\n",
      "[17,   199] loss: 0.429344\n",
      "[17,   299] loss: 0.426175\n",
      "[17,   399] loss: 0.396107\n",
      "[17,   499] loss: 0.329118\n",
      "[17,   599] loss: 0.399232\n",
      "[17,   699] loss: 0.387154\n",
      "[18,    99] loss: 0.490279\n",
      "[18,   199] loss: 0.413990\n",
      "[18,   299] loss: 0.413245\n",
      "[18,   399] loss: 0.382099\n",
      "[18,   499] loss: 0.314544\n",
      "[18,   599] loss: 0.385138\n",
      "[18,   699] loss: 0.373677\n",
      "[19,    99] loss: 0.474787\n",
      "[19,   199] loss: 0.399653\n",
      "[19,   299] loss: 0.400956\n",
      "[19,   399] loss: 0.368381\n",
      "[19,   499] loss: 0.300811\n",
      "[19,   599] loss: 0.371307\n",
      "[19,   699] loss: 0.360373\n",
      "[20,    99] loss: 0.460171\n",
      "[20,   199] loss: 0.385479\n",
      "[20,   299] loss: 0.388807\n",
      "[20,   399] loss: 0.354923\n",
      "[20,   499] loss: 0.287978\n",
      "[20,   599] loss: 0.358002\n",
      "[20,   699] loss: 0.348649\n",
      "[21,    99] loss: 0.446034\n",
      "[21,   199] loss: 0.371798\n",
      "[21,   299] loss: 0.376283\n",
      "[21,   399] loss: 0.341111\n",
      "[21,   499] loss: 0.275967\n",
      "[21,   599] loss: 0.345109\n",
      "[21,   699] loss: 0.337527\n",
      "[22,    99] loss: 0.432190\n",
      "[22,   199] loss: 0.358395\n",
      "[22,   299] loss: 0.364470\n",
      "[22,   399] loss: 0.327711\n",
      "[22,   499] loss: 0.264442\n",
      "[22,   599] loss: 0.332709\n",
      "[22,   699] loss: 0.326743\n",
      "[23,    99] loss: 0.417817\n",
      "[23,   199] loss: 0.345393\n",
      "[23,   299] loss: 0.352733\n",
      "[23,   399] loss: 0.315576\n",
      "[23,   499] loss: 0.253423\n",
      "[23,   599] loss: 0.321043\n",
      "[23,   699] loss: 0.316437\n",
      "[24,    99] loss: 0.404461\n",
      "[24,   199] loss: 0.332783\n",
      "[24,   299] loss: 0.340243\n",
      "[24,   399] loss: 0.303851\n",
      "[24,   499] loss: 0.243256\n",
      "[24,   599] loss: 0.309893\n",
      "[24,   699] loss: 0.306950\n",
      "[25,    99] loss: 0.391183\n",
      "[25,   199] loss: 0.320066\n",
      "[25,   299] loss: 0.329088\n",
      "[25,   399] loss: 0.292686\n",
      "[25,   499] loss: 0.233717\n",
      "[25,   599] loss: 0.299195\n",
      "[25,   699] loss: 0.297102\n",
      "[26,    99] loss: 0.377978\n",
      "[26,   199] loss: 0.308235\n",
      "[26,   299] loss: 0.318312\n",
      "[26,   399] loss: 0.281652\n",
      "[26,   499] loss: 0.224419\n",
      "[26,   599] loss: 0.288754\n",
      "[26,   699] loss: 0.287426\n",
      "[27,    99] loss: 0.365456\n",
      "[27,   199] loss: 0.296620\n",
      "[27,   299] loss: 0.307813\n",
      "[27,   399] loss: 0.271775\n",
      "[27,   499] loss: 0.215395\n",
      "[27,   599] loss: 0.278534\n",
      "[27,   699] loss: 0.278046\n",
      "[28,    99] loss: 0.353288\n",
      "[28,   199] loss: 0.285291\n",
      "[28,   299] loss: 0.296722\n",
      "[28,   399] loss: 0.261689\n",
      "[28,   499] loss: 0.206827\n",
      "[28,   599] loss: 0.268666\n",
      "[28,   699] loss: 0.270009\n",
      "[29,    99] loss: 0.341332\n",
      "[29,   199] loss: 0.273492\n",
      "[29,   299] loss: 0.286665\n",
      "[29,   399] loss: 0.252735\n",
      "[29,   499] loss: 0.198518\n",
      "[29,   599] loss: 0.259519\n",
      "[29,   699] loss: 0.261153\n",
      "[30,    99] loss: 0.330146\n",
      "[30,   199] loss: 0.262706\n",
      "[30,   299] loss: 0.276595\n",
      "[30,   399] loss: 0.243647\n",
      "[30,   499] loss: 0.190942\n",
      "[30,   599] loss: 0.250439\n",
      "[30,   699] loss: 0.253032\n",
      "[31,    99] loss: 0.319806\n",
      "[31,   199] loss: 0.252999\n",
      "[31,   299] loss: 0.267954\n",
      "[31,   399] loss: 0.235632\n",
      "[31,   499] loss: 0.183595\n",
      "[31,   599] loss: 0.242386\n",
      "[31,   699] loss: 0.244643\n",
      "[32,    99] loss: 0.309998\n",
      "[32,   199] loss: 0.243059\n",
      "[32,   299] loss: 0.259215\n",
      "[32,   399] loss: 0.227073\n",
      "[32,   499] loss: 0.175966\n",
      "[32,   599] loss: 0.234158\n",
      "[32,   699] loss: 0.237697\n",
      "[33,    99] loss: 0.300717\n",
      "[33,   199] loss: 0.233984\n",
      "[33,   299] loss: 0.250987\n",
      "[33,   399] loss: 0.219276\n",
      "[33,   499] loss: 0.168917\n",
      "[33,   599] loss: 0.226800\n",
      "[33,   699] loss: 0.231522\n",
      "[34,    99] loss: 0.290973\n",
      "[34,   199] loss: 0.225455\n",
      "[34,   299] loss: 0.243185\n",
      "[34,   399] loss: 0.212478\n",
      "[34,   499] loss: 0.162397\n",
      "[34,   599] loss: 0.219930\n",
      "[34,   699] loss: 0.225225\n",
      "[35,    99] loss: 0.281991\n",
      "[35,   199] loss: 0.216979\n",
      "[35,   299] loss: 0.236035\n",
      "[35,   399] loss: 0.206095\n",
      "[35,   499] loss: 0.156624\n",
      "[35,   599] loss: 0.212478\n",
      "[35,   699] loss: 0.218999\n",
      "[36,    99] loss: 0.272398\n",
      "[36,   199] loss: 0.209244\n",
      "[36,   299] loss: 0.229525\n",
      "[36,   399] loss: 0.199028\n",
      "[36,   499] loss: 0.150940\n",
      "[36,   599] loss: 0.205595\n",
      "[36,   699] loss: 0.213339\n",
      "[37,    99] loss: 0.263601\n",
      "[37,   199] loss: 0.201960\n",
      "[37,   299] loss: 0.222677\n",
      "[37,   399] loss: 0.193508\n",
      "[37,   499] loss: 0.144922\n",
      "[37,   599] loss: 0.199495\n",
      "[37,   699] loss: 0.207647\n",
      "[38,    99] loss: 0.255063\n",
      "[38,   199] loss: 0.194818\n",
      "[38,   299] loss: 0.215912\n",
      "[38,   399] loss: 0.186557\n",
      "[38,   499] loss: 0.139475\n",
      "[38,   599] loss: 0.193319\n",
      "[38,   699] loss: 0.202426\n",
      "[39,    99] loss: 0.247062\n",
      "[39,   199] loss: 0.188142\n",
      "[39,   299] loss: 0.209679\n",
      "[39,   399] loss: 0.181593\n",
      "[39,   499] loss: 0.133962\n",
      "[39,   599] loss: 0.188224\n",
      "[39,   699] loss: 0.197229\n",
      "[40,    99] loss: 0.239287\n",
      "[40,   199] loss: 0.181405\n",
      "[40,   299] loss: 0.203027\n",
      "[40,   399] loss: 0.175732\n",
      "[40,   499] loss: 0.129289\n",
      "[40,   599] loss: 0.182836\n",
      "[40,   699] loss: 0.192170\n",
      "[41,    99] loss: 0.231834\n",
      "[41,   199] loss: 0.175126\n",
      "[41,   299] loss: 0.196514\n",
      "[41,   399] loss: 0.170339\n",
      "[41,   499] loss: 0.124430\n",
      "[41,   599] loss: 0.177829\n",
      "[41,   699] loss: 0.187659\n",
      "[42,    99] loss: 0.224250\n",
      "[42,   199] loss: 0.169775\n",
      "[42,   299] loss: 0.189100\n",
      "[42,   399] loss: 0.165035\n",
      "[42,   499] loss: 0.119790\n",
      "[42,   599] loss: 0.173309\n",
      "[42,   699] loss: 0.183407\n",
      "[43,    99] loss: 0.216464\n",
      "[43,   199] loss: 0.163744\n",
      "[43,   299] loss: 0.183446\n",
      "[43,   399] loss: 0.161219\n",
      "[43,   499] loss: 0.114958\n",
      "[43,   599] loss: 0.168940\n",
      "[43,   699] loss: 0.178441\n",
      "[44,    99] loss: 0.209829\n",
      "[44,   199] loss: 0.157725\n",
      "[44,   299] loss: 0.177940\n",
      "[44,   399] loss: 0.156265\n",
      "[44,   499] loss: 0.111211\n",
      "[44,   599] loss: 0.164298\n",
      "[44,   699] loss: 0.174473\n",
      "[45,    99] loss: 0.202612\n",
      "[45,   199] loss: 0.152799\n",
      "[45,   299] loss: 0.172118\n",
      "[45,   399] loss: 0.151729\n",
      "[45,   499] loss: 0.106689\n",
      "[45,   599] loss: 0.159987\n",
      "[45,   699] loss: 0.170049\n",
      "[46,    99] loss: 0.196795\n",
      "[46,   199] loss: 0.147516\n",
      "[46,   299] loss: 0.167198\n",
      "[46,   399] loss: 0.147054\n",
      "[46,   499] loss: 0.102878\n",
      "[46,   599] loss: 0.155401\n",
      "[46,   699] loss: 0.165444\n",
      "[47,    99] loss: 0.190505\n",
      "[47,   199] loss: 0.142366\n",
      "[47,   299] loss: 0.162508\n",
      "[47,   399] loss: 0.142373\n",
      "[47,   499] loss: 0.099134\n",
      "[47,   599] loss: 0.151242\n",
      "[47,   699] loss: 0.161388\n",
      "[48,    99] loss: 0.183957\n",
      "[48,   199] loss: 0.137840\n",
      "[48,   299] loss: 0.157522\n",
      "[48,   399] loss: 0.138542\n",
      "[48,   499] loss: 0.095329\n",
      "[48,   599] loss: 0.147771\n",
      "[48,   699] loss: 0.157670\n",
      "[49,    99] loss: 0.178369\n",
      "[49,   199] loss: 0.133474\n",
      "[49,   299] loss: 0.153544\n",
      "[49,   399] loss: 0.134919\n",
      "[49,   499] loss: 0.091845\n",
      "[49,   599] loss: 0.144289\n",
      "[49,   699] loss: 0.153431\n",
      "[50,    99] loss: 0.172671\n",
      "[50,   199] loss: 0.128957\n",
      "[50,   299] loss: 0.148700\n",
      "[50,   399] loss: 0.131058\n",
      "[50,   499] loss: 0.088415\n",
      "[50,   599] loss: 0.140480\n",
      "[50,   699] loss: 0.149237\n",
      "[51,    99] loss: 0.167233\n",
      "[51,   199] loss: 0.125427\n",
      "[51,   299] loss: 0.144133\n",
      "[51,   399] loss: 0.126805\n",
      "[51,   499] loss: 0.085230\n",
      "[51,   599] loss: 0.137983\n",
      "[51,   699] loss: 0.145257\n",
      "[52,    99] loss: 0.162905\n",
      "[52,   199] loss: 0.120897\n",
      "[52,   299] loss: 0.140010\n",
      "[52,   399] loss: 0.123740\n",
      "[52,   499] loss: 0.082028\n",
      "[52,   599] loss: 0.134035\n",
      "[52,   699] loss: 0.141229\n",
      "[53,    99] loss: 0.157365\n",
      "[53,   199] loss: 0.117546\n",
      "[53,   299] loss: 0.135119\n",
      "[53,   399] loss: 0.119025\n",
      "[53,   499] loss: 0.078861\n",
      "[53,   599] loss: 0.130664\n",
      "[53,   699] loss: 0.137287\n",
      "[54,    99] loss: 0.153402\n",
      "[54,   199] loss: 0.113815\n",
      "[54,   299] loss: 0.131658\n",
      "[54,   399] loss: 0.116508\n",
      "[54,   499] loss: 0.076099\n",
      "[54,   599] loss: 0.127041\n",
      "[54,   699] loss: 0.133700\n",
      "[55,    99] loss: 0.148382\n",
      "[55,   199] loss: 0.110720\n",
      "[55,   299] loss: 0.127792\n",
      "[55,   399] loss: 0.113834\n",
      "[55,   499] loss: 0.073192\n",
      "[55,   599] loss: 0.124662\n",
      "[55,   699] loss: 0.130151\n",
      "[56,    99] loss: 0.143727\n",
      "[56,   199] loss: 0.107850\n",
      "[56,   299] loss: 0.123634\n",
      "[56,   399] loss: 0.109404\n",
      "[56,   499] loss: 0.070425\n",
      "[56,   599] loss: 0.121712\n",
      "[56,   699] loss: 0.126950\n",
      "[57,    99] loss: 0.139708\n",
      "[57,   199] loss: 0.104586\n",
      "[57,   299] loss: 0.120931\n",
      "[57,   399] loss: 0.107230\n",
      "[57,   499] loss: 0.068065\n",
      "[57,   599] loss: 0.118536\n",
      "[57,   699] loss: 0.123539\n",
      "[58,    99] loss: 0.135610\n",
      "[58,   199] loss: 0.101989\n",
      "[58,   299] loss: 0.115410\n",
      "[58,   399] loss: 0.103604\n",
      "[58,   499] loss: 0.065373\n",
      "[58,   599] loss: 0.115753\n",
      "[58,   699] loss: 0.120265\n",
      "[59,    99] loss: 0.132856\n",
      "[59,   199] loss: 0.098404\n",
      "[59,   299] loss: 0.113090\n",
      "[59,   399] loss: 0.100725\n",
      "[59,   499] loss: 0.063052\n",
      "[59,   599] loss: 0.112909\n",
      "[59,   699] loss: 0.117045\n",
      "[60,    99] loss: 0.128411\n",
      "[60,   199] loss: 0.095290\n",
      "[60,   299] loss: 0.109033\n",
      "[60,   399] loss: 0.096695\n",
      "[60,   499] loss: 0.061011\n",
      "[60,   599] loss: 0.109875\n",
      "[60,   699] loss: 0.113612\n",
      "[61,    99] loss: 0.125504\n",
      "[61,   199] loss: 0.092757\n",
      "[61,   299] loss: 0.106554\n",
      "[61,   399] loss: 0.095515\n",
      "[61,   499] loss: 0.058730\n",
      "[61,   599] loss: 0.107013\n",
      "[61,   699] loss: 0.110697\n",
      "[62,    99] loss: 0.121100\n",
      "[62,   199] loss: 0.089791\n",
      "[62,   299] loss: 0.102401\n",
      "[62,   399] loss: 0.092264\n",
      "[62,   499] loss: 0.056467\n",
      "[62,   599] loss: 0.104232\n",
      "[62,   699] loss: 0.107085\n",
      "[63,    99] loss: 0.118504\n",
      "[63,   199] loss: 0.086902\n",
      "[63,   299] loss: 0.098465\n",
      "[63,   399] loss: 0.089257\n",
      "[63,   499] loss: 0.054293\n",
      "[63,   599] loss: 0.101538\n",
      "[63,   699] loss: 0.104471\n",
      "[64,    99] loss: 0.115161\n",
      "[64,   199] loss: 0.084499\n",
      "[64,   299] loss: 0.095425\n",
      "[64,   399] loss: 0.086419\n",
      "[64,   499] loss: 0.052346\n",
      "[64,   599] loss: 0.098992\n",
      "[64,   699] loss: 0.101140\n",
      "[65,    99] loss: 0.112017\n",
      "[65,   199] loss: 0.082129\n",
      "[65,   299] loss: 0.092795\n",
      "[65,   399] loss: 0.084264\n",
      "[65,   499] loss: 0.050397\n",
      "[65,   599] loss: 0.096420\n",
      "[65,   699] loss: 0.097820\n",
      "[66,    99] loss: 0.109227\n",
      "[66,   199] loss: 0.079788\n",
      "[66,   299] loss: 0.089453\n",
      "[66,   399] loss: 0.081750\n",
      "[66,   499] loss: 0.048239\n",
      "[66,   599] loss: 0.093780\n",
      "[66,   699] loss: 0.095060\n",
      "[67,    99] loss: 0.106502\n",
      "[67,   199] loss: 0.077383\n",
      "[67,   299] loss: 0.086160\n",
      "[67,   399] loss: 0.079353\n",
      "[67,   499] loss: 0.046717\n",
      "[67,   599] loss: 0.092345\n",
      "[67,   699] loss: 0.092588\n",
      "[68,    99] loss: 0.104033\n",
      "[68,   199] loss: 0.075193\n",
      "[68,   299] loss: 0.083303\n",
      "[68,   399] loss: 0.076597\n",
      "[68,   499] loss: 0.045029\n",
      "[68,   599] loss: 0.089149\n",
      "[68,   699] loss: 0.089740\n",
      "[69,    99] loss: 0.100698\n",
      "[69,   199] loss: 0.072514\n",
      "[69,   299] loss: 0.080210\n",
      "[69,   399] loss: 0.074587\n",
      "[69,   499] loss: 0.043554\n",
      "[69,   599] loss: 0.086788\n",
      "[69,   699] loss: 0.087338\n",
      "[70,    99] loss: 0.098597\n",
      "[70,   199] loss: 0.070422\n",
      "[70,   299] loss: 0.076633\n",
      "[70,   399] loss: 0.071631\n",
      "[70,   499] loss: 0.041978\n",
      "[70,   599] loss: 0.084890\n",
      "[70,   699] loss: 0.085045\n",
      "[71,    99] loss: 0.094062\n",
      "[71,   199] loss: 0.067353\n",
      "[71,   299] loss: 0.073880\n",
      "[71,   399] loss: 0.070703\n",
      "[71,   499] loss: 0.040187\n",
      "[71,   599] loss: 0.082841\n",
      "[71,   699] loss: 0.082622\n",
      "[72,    99] loss: 0.092788\n",
      "[72,   199] loss: 0.065755\n",
      "[72,   299] loss: 0.070850\n",
      "[72,   399] loss: 0.067761\n",
      "[72,   499] loss: 0.038633\n",
      "[72,   599] loss: 0.080117\n",
      "[72,   699] loss: 0.080381\n",
      "[73,    99] loss: 0.090138\n",
      "[73,   199] loss: 0.063577\n",
      "[73,   299] loss: 0.067818\n",
      "[73,   399] loss: 0.065626\n",
      "[73,   499] loss: 0.037324\n",
      "[73,   599] loss: 0.078724\n",
      "[73,   699] loss: 0.078479\n",
      "[74,    99] loss: 0.086916\n",
      "[74,   199] loss: 0.061674\n",
      "[74,   299] loss: 0.065211\n",
      "[74,   399] loss: 0.063705\n",
      "[74,   499] loss: 0.035654\n",
      "[74,   599] loss: 0.076687\n",
      "[74,   699] loss: 0.076023\n",
      "[75,    99] loss: 0.085345\n",
      "[75,   199] loss: 0.060446\n",
      "[75,   299] loss: 0.063271\n",
      "[75,   399] loss: 0.061365\n",
      "[75,   499] loss: 0.034201\n",
      "[75,   599] loss: 0.074748\n",
      "[75,   699] loss: 0.073864\n",
      "[76,    99] loss: 0.083220\n",
      "[76,   199] loss: 0.058149\n",
      "[76,   299] loss: 0.060955\n",
      "[76,   399] loss: 0.059837\n",
      "[76,   499] loss: 0.033085\n",
      "[76,   599] loss: 0.072736\n",
      "[76,   699] loss: 0.071270\n",
      "[77,    99] loss: 0.080410\n",
      "[77,   199] loss: 0.056573\n",
      "[77,   299] loss: 0.058406\n",
      "[77,   399] loss: 0.057746\n",
      "[77,   499] loss: 0.031573\n",
      "[77,   599] loss: 0.071085\n",
      "[77,   699] loss: 0.069538\n",
      "[78,    99] loss: 0.078636\n",
      "[78,   199] loss: 0.054379\n",
      "[78,   299] loss: 0.057113\n",
      "[78,   399] loss: 0.056804\n",
      "[78,   499] loss: 0.030311\n",
      "[78,   599] loss: 0.069101\n",
      "[78,   699] loss: 0.067312\n",
      "[79,    99] loss: 0.076493\n",
      "[79,   199] loss: 0.053134\n",
      "[79,   299] loss: 0.053092\n",
      "[79,   399] loss: 0.053027\n",
      "[79,   499] loss: 0.029346\n",
      "[79,   599] loss: 0.067781\n",
      "[79,   699] loss: 0.065192\n",
      "[80,    99] loss: 0.073787\n",
      "[80,   199] loss: 0.051158\n",
      "[80,   299] loss: 0.052217\n",
      "[80,   399] loss: 0.052596\n",
      "[80,   499] loss: 0.028262\n",
      "[80,   599] loss: 0.065788\n",
      "[80,   699] loss: 0.063255\n",
      "[81,    99] loss: 0.071635\n",
      "[81,   199] loss: 0.050070\n",
      "[81,   299] loss: 0.049968\n",
      "[81,   399] loss: 0.049725\n",
      "[81,   499] loss: 0.026907\n",
      "[81,   599] loss: 0.064704\n",
      "[81,   699] loss: 0.061600\n",
      "[82,    99] loss: 0.069202\n",
      "[82,   199] loss: 0.048449\n",
      "[82,   299] loss: 0.047969\n",
      "[82,   399] loss: 0.048771\n",
      "[82,   499] loss: 0.025834\n",
      "[82,   599] loss: 0.063051\n",
      "[82,   699] loss: 0.059395\n",
      "[83,    99] loss: 0.067469\n",
      "[83,   199] loss: 0.046753\n",
      "[83,   299] loss: 0.046199\n",
      "[83,   399] loss: 0.046959\n",
      "[83,   499] loss: 0.024977\n",
      "[83,   599] loss: 0.061504\n",
      "[83,   699] loss: 0.058690\n",
      "[84,    99] loss: 0.064506\n",
      "[84,   199] loss: 0.045262\n",
      "[84,   299] loss: 0.044625\n",
      "[84,   399] loss: 0.045077\n",
      "[84,   499] loss: 0.024176\n",
      "[84,   599] loss: 0.059555\n",
      "[84,   699] loss: 0.056160\n",
      "[85,    99] loss: 0.064081\n",
      "[85,   199] loss: 0.044511\n",
      "[85,   299] loss: 0.042329\n",
      "[85,   399] loss: 0.042621\n",
      "[85,   499] loss: 0.023233\n",
      "[85,   599] loss: 0.058383\n",
      "[85,   699] loss: 0.054196\n",
      "[86,    99] loss: 0.061435\n",
      "[86,   199] loss: 0.042551\n",
      "[86,   299] loss: 0.041005\n",
      "[86,   399] loss: 0.041726\n",
      "[86,   499] loss: 0.022496\n",
      "[86,   599] loss: 0.056676\n",
      "[86,   699] loss: 0.052001\n",
      "[87,    99] loss: 0.059727\n",
      "[87,   199] loss: 0.041991\n",
      "[87,   299] loss: 0.041357\n",
      "[87,   399] loss: 0.040792\n",
      "[87,   499] loss: 0.021200\n",
      "[87,   599] loss: 0.055293\n",
      "[87,   699] loss: 0.050995\n",
      "[88,    99] loss: 0.057176\n",
      "[88,   199] loss: 0.039288\n",
      "[88,   299] loss: 0.038168\n",
      "[88,   399] loss: 0.038685\n",
      "[88,   499] loss: 0.020946\n",
      "[88,   599] loss: 0.052729\n",
      "[88,   699] loss: 0.049082\n",
      "[89,    99] loss: 0.055459\n",
      "[89,   199] loss: 0.038356\n",
      "[89,   299] loss: 0.036519\n",
      "[89,   399] loss: 0.036996\n",
      "[89,   499] loss: 0.020120\n",
      "[89,   599] loss: 0.051424\n",
      "[89,   699] loss: 0.047639\n",
      "[90,    99] loss: 0.054587\n",
      "[90,   199] loss: 0.037588\n",
      "[90,   299] loss: 0.034712\n",
      "[90,   399] loss: 0.035199\n",
      "[90,   499] loss: 0.019359\n",
      "[90,   599] loss: 0.049748\n",
      "[90,   699] loss: 0.046444\n",
      "[91,    99] loss: 0.052093\n",
      "[91,   199] loss: 0.035831\n",
      "[91,   299] loss: 0.033482\n",
      "[91,   399] loss: 0.034292\n",
      "[91,   499] loss: 0.018781\n",
      "[91,   599] loss: 0.048137\n",
      "[91,   699] loss: 0.044060\n",
      "[92,    99] loss: 0.049598\n",
      "[92,   199] loss: 0.035141\n",
      "[92,   299] loss: 0.032363\n",
      "[92,   399] loss: 0.031709\n",
      "[92,   499] loss: 0.018273\n",
      "[92,   599] loss: 0.046456\n",
      "[92,   699] loss: 0.043189\n",
      "[93,    99] loss: 0.050008\n",
      "[93,   199] loss: 0.032980\n",
      "[93,   299] loss: 0.030549\n",
      "[93,   399] loss: 0.031460\n",
      "[93,   499] loss: 0.017376\n",
      "[93,   599] loss: 0.044801\n",
      "[93,   699] loss: 0.042434\n",
      "[94,    99] loss: 0.047823\n",
      "[94,   199] loss: 0.032983\n",
      "[94,   299] loss: 0.029989\n",
      "[94,   399] loss: 0.029456\n",
      "[94,   499] loss: 0.016600\n",
      "[94,   599] loss: 0.043332\n",
      "[94,   699] loss: 0.040523\n",
      "[95,    99] loss: 0.046447\n",
      "[95,   199] loss: 0.031462\n",
      "[95,   299] loss: 0.028832\n",
      "[95,   399] loss: 0.028503\n",
      "[95,   499] loss: 0.016092\n",
      "[95,   599] loss: 0.042094\n",
      "[95,   699] loss: 0.038993\n",
      "[96,    99] loss: 0.044546\n",
      "[96,   199] loss: 0.030556\n",
      "[96,   299] loss: 0.027368\n",
      "[96,   399] loss: 0.027044\n",
      "[96,   499] loss: 0.015598\n",
      "[96,   599] loss: 0.040031\n",
      "[96,   699] loss: 0.038236\n",
      "[97,    99] loss: 0.043167\n",
      "[97,   199] loss: 0.029240\n",
      "[97,   299] loss: 0.026683\n",
      "[97,   399] loss: 0.025042\n",
      "[97,   499] loss: 0.015206\n",
      "[97,   599] loss: 0.038517\n",
      "[97,   699] loss: 0.036890\n",
      "[98,    99] loss: 0.041824\n",
      "[98,   199] loss: 0.028661\n",
      "[98,   299] loss: 0.026061\n",
      "[98,   399] loss: 0.023808\n",
      "[98,   499] loss: 0.014554\n",
      "[98,   599] loss: 0.037131\n",
      "[98,   699] loss: 0.035446\n",
      "[99,    99] loss: 0.040867\n",
      "[99,   199] loss: 0.026962\n",
      "[99,   299] loss: 0.023216\n",
      "[99,   399] loss: 0.022667\n",
      "[99,   499] loss: 0.014083\n",
      "[99,   599] loss: 0.036050\n",
      "[99,   699] loss: 0.034529\n",
      "[100,    99] loss: 0.039724\n",
      "[100,   199] loss: 0.027000\n",
      "[100,   299] loss: 0.022992\n",
      "[100,   399] loss: 0.021727\n",
      "[100,   499] loss: 0.013561\n",
      "[100,   599] loss: 0.034037\n",
      "[100,   699] loss: 0.033646\n",
      "Finished Training\n",
      "[1,    99] loss: 0.699039\n",
      "[1,   199] loss: 0.701914\n",
      "[1,   299] loss: 0.694610\n",
      "[1,   399] loss: 0.691126\n",
      "[1,   499] loss: 0.686957\n",
      "[1,   599] loss: 0.686470\n",
      "[1,   699] loss: 0.682236\n",
      "[2,    99] loss: 0.677363\n",
      "[2,   199] loss: 0.673946\n",
      "[2,   299] loss: 0.676552\n",
      "[2,   399] loss: 0.676446\n",
      "[2,   499] loss: 0.669089\n",
      "[2,   599] loss: 0.658964\n",
      "[2,   699] loss: 0.669774\n",
      "[3,    99] loss: 0.660765\n",
      "[3,   199] loss: 0.652405\n",
      "[3,   299] loss: 0.661814\n",
      "[3,   399] loss: 0.663255\n",
      "[3,   499] loss: 0.650407\n",
      "[3,   599] loss: 0.641809\n",
      "[3,   699] loss: 0.655202\n",
      "[4,    99] loss: 0.642109\n",
      "[4,   199] loss: 0.632680\n",
      "[4,   299] loss: 0.646639\n",
      "[4,   399] loss: 0.649712\n",
      "[4,   499] loss: 0.630557\n",
      "[4,   599] loss: 0.626177\n",
      "[4,   699] loss: 0.639856\n",
      "[5,    99] loss: 0.622637\n",
      "[5,   199] loss: 0.614159\n",
      "[5,   299] loss: 0.631447\n",
      "[5,   399] loss: 0.635240\n",
      "[5,   499] loss: 0.610760\n",
      "[5,   599] loss: 0.611263\n",
      "[5,   699] loss: 0.624614\n",
      "[6,    99] loss: 0.603689\n",
      "[6,   199] loss: 0.597695\n",
      "[6,   299] loss: 0.614838\n",
      "[6,   399] loss: 0.621071\n",
      "[6,   499] loss: 0.592394\n",
      "[6,   599] loss: 0.598863\n",
      "[6,   699] loss: 0.610827\n",
      "[7,    99] loss: 0.586860\n",
      "[7,   199] loss: 0.583541\n",
      "[7,   299] loss: 0.598883\n",
      "[7,   399] loss: 0.608328\n",
      "[7,   499] loss: 0.574999\n",
      "[7,   599] loss: 0.586912\n",
      "[7,   699] loss: 0.597812\n",
      "[8,    99] loss: 0.570488\n",
      "[8,   199] loss: 0.570299\n",
      "[8,   299] loss: 0.582435\n",
      "[8,   399] loss: 0.595290\n",
      "[8,   499] loss: 0.558884\n",
      "[8,   599] loss: 0.574550\n",
      "[8,   699] loss: 0.586594\n",
      "[9,    99] loss: 0.555403\n",
      "[9,   199] loss: 0.557600\n",
      "[9,   299] loss: 0.565709\n",
      "[9,   399] loss: 0.581597\n",
      "[9,   499] loss: 0.543840\n",
      "[9,   599] loss: 0.562481\n",
      "[9,   699] loss: 0.576246\n",
      "[10,    99] loss: 0.541244\n",
      "[10,   199] loss: 0.545223\n",
      "[10,   299] loss: 0.549118\n",
      "[10,   399] loss: 0.567350\n",
      "[10,   499] loss: 0.529413\n",
      "[10,   599] loss: 0.549878\n",
      "[10,   699] loss: 0.566682\n",
      "[11,    99] loss: 0.528107\n",
      "[11,   199] loss: 0.533250\n",
      "[11,   299] loss: 0.532609\n",
      "[11,   399] loss: 0.551939\n",
      "[11,   499] loss: 0.515606\n",
      "[11,   599] loss: 0.536931\n",
      "[11,   699] loss: 0.556694\n",
      "[12,    99] loss: 0.515055\n",
      "[12,   199] loss: 0.521367\n",
      "[12,   299] loss: 0.515980\n",
      "[12,   399] loss: 0.536105\n",
      "[12,   499] loss: 0.502753\n",
      "[12,   599] loss: 0.523248\n",
      "[12,   699] loss: 0.546357\n",
      "[13,    99] loss: 0.502868\n",
      "[13,   199] loss: 0.509445\n",
      "[13,   299] loss: 0.500241\n",
      "[13,   399] loss: 0.520738\n",
      "[13,   499] loss: 0.489834\n",
      "[13,   599] loss: 0.510597\n",
      "[13,   699] loss: 0.536525\n",
      "[14,    99] loss: 0.491671\n",
      "[14,   199] loss: 0.497564\n",
      "[14,   299] loss: 0.484484\n",
      "[14,   399] loss: 0.505356\n",
      "[14,   499] loss: 0.477602\n",
      "[14,   599] loss: 0.498107\n",
      "[14,   699] loss: 0.527023\n",
      "[15,    99] loss: 0.481012\n",
      "[15,   199] loss: 0.486380\n",
      "[15,   299] loss: 0.468949\n",
      "[15,   399] loss: 0.490483\n",
      "[15,   499] loss: 0.465392\n",
      "[15,   599] loss: 0.485529\n",
      "[15,   699] loss: 0.517403\n",
      "[16,    99] loss: 0.471172\n",
      "[16,   199] loss: 0.474941\n",
      "[16,   299] loss: 0.453400\n",
      "[16,   399] loss: 0.475154\n",
      "[16,   499] loss: 0.452911\n",
      "[16,   599] loss: 0.473370\n",
      "[16,   699] loss: 0.507000\n",
      "[17,    99] loss: 0.461849\n",
      "[17,   199] loss: 0.463770\n",
      "[17,   299] loss: 0.437548\n",
      "[17,   399] loss: 0.459950\n",
      "[17,   499] loss: 0.441072\n",
      "[17,   599] loss: 0.460994\n",
      "[17,   699] loss: 0.496162\n",
      "[18,    99] loss: 0.451985\n",
      "[18,   199] loss: 0.452947\n",
      "[18,   299] loss: 0.422153\n",
      "[18,   399] loss: 0.445295\n",
      "[18,   499] loss: 0.429134\n",
      "[18,   599] loss: 0.448964\n",
      "[18,   699] loss: 0.485414\n",
      "[19,    99] loss: 0.442493\n",
      "[19,   199] loss: 0.443103\n",
      "[19,   299] loss: 0.406617\n",
      "[19,   399] loss: 0.431922\n",
      "[19,   499] loss: 0.416692\n",
      "[19,   599] loss: 0.437960\n",
      "[19,   699] loss: 0.474825\n",
      "[20,    99] loss: 0.433225\n",
      "[20,   199] loss: 0.432537\n",
      "[20,   299] loss: 0.392069\n",
      "[20,   399] loss: 0.418924\n",
      "[20,   499] loss: 0.405049\n",
      "[20,   599] loss: 0.427081\n",
      "[20,   699] loss: 0.462955\n",
      "[21,    99] loss: 0.424427\n",
      "[21,   199] loss: 0.422980\n",
      "[21,   299] loss: 0.377862\n",
      "[21,   399] loss: 0.406531\n",
      "[21,   499] loss: 0.394008\n",
      "[21,   599] loss: 0.416732\n",
      "[21,   699] loss: 0.451723\n",
      "[22,    99] loss: 0.415607\n",
      "[22,   199] loss: 0.413415\n",
      "[22,   299] loss: 0.363458\n",
      "[22,   399] loss: 0.394408\n",
      "[22,   499] loss: 0.383950\n",
      "[22,   599] loss: 0.406513\n",
      "[22,   699] loss: 0.440241\n",
      "[23,    99] loss: 0.406997\n",
      "[23,   199] loss: 0.403441\n",
      "[23,   299] loss: 0.349890\n",
      "[23,   399] loss: 0.383113\n",
      "[23,   499] loss: 0.372608\n",
      "[23,   599] loss: 0.397077\n",
      "[23,   699] loss: 0.429448\n",
      "[24,    99] loss: 0.398039\n",
      "[24,   199] loss: 0.393518\n",
      "[24,   299] loss: 0.336391\n",
      "[24,   399] loss: 0.372040\n",
      "[24,   499] loss: 0.362351\n",
      "[24,   599] loss: 0.387426\n",
      "[24,   699] loss: 0.418739\n",
      "[25,    99] loss: 0.389339\n",
      "[25,   199] loss: 0.384023\n",
      "[25,   299] loss: 0.323979\n",
      "[25,   399] loss: 0.361228\n",
      "[25,   499] loss: 0.353133\n",
      "[25,   599] loss: 0.377984\n",
      "[25,   699] loss: 0.407244\n",
      "[26,    99] loss: 0.380406\n",
      "[26,   199] loss: 0.374392\n",
      "[26,   299] loss: 0.311258\n",
      "[26,   399] loss: 0.351003\n",
      "[26,   499] loss: 0.342284\n",
      "[26,   599] loss: 0.368740\n",
      "[26,   699] loss: 0.397156\n",
      "[27,    99] loss: 0.371944\n",
      "[27,   199] loss: 0.364481\n",
      "[27,   299] loss: 0.298910\n",
      "[27,   399] loss: 0.340487\n",
      "[27,   499] loss: 0.334314\n",
      "[27,   599] loss: 0.359424\n",
      "[27,   699] loss: 0.386597\n",
      "[28,    99] loss: 0.363035\n",
      "[28,   199] loss: 0.354532\n",
      "[28,   299] loss: 0.287600\n",
      "[28,   399] loss: 0.330571\n",
      "[28,   499] loss: 0.324098\n",
      "[28,   599] loss: 0.350990\n",
      "[28,   699] loss: 0.376535\n",
      "[29,    99] loss: 0.354007\n",
      "[29,   199] loss: 0.345671\n",
      "[29,   299] loss: 0.276675\n",
      "[29,   399] loss: 0.321125\n",
      "[29,   499] loss: 0.316282\n",
      "[29,   599] loss: 0.343578\n",
      "[29,   699] loss: 0.366032\n",
      "[30,    99] loss: 0.346449\n",
      "[30,   199] loss: 0.336770\n",
      "[30,   299] loss: 0.267001\n",
      "[30,   399] loss: 0.311221\n",
      "[30,   499] loss: 0.306838\n",
      "[30,   599] loss: 0.335972\n",
      "[30,   699] loss: 0.355995\n",
      "[31,    99] loss: 0.338167\n",
      "[31,   199] loss: 0.327669\n",
      "[31,   299] loss: 0.257207\n",
      "[31,   399] loss: 0.302175\n",
      "[31,   499] loss: 0.297370\n",
      "[31,   599] loss: 0.329107\n",
      "[31,   699] loss: 0.347499\n",
      "[32,    99] loss: 0.330175\n",
      "[32,   199] loss: 0.319506\n",
      "[32,   299] loss: 0.248887\n",
      "[32,   399] loss: 0.293037\n",
      "[32,   499] loss: 0.289146\n",
      "[32,   599] loss: 0.321541\n",
      "[32,   699] loss: 0.338051\n",
      "[33,    99] loss: 0.322280\n",
      "[33,   199] loss: 0.310711\n",
      "[33,   299] loss: 0.240572\n",
      "[33,   399] loss: 0.284737\n",
      "[33,   499] loss: 0.280315\n",
      "[33,   599] loss: 0.314396\n",
      "[33,   699] loss: 0.328544\n",
      "[34,    99] loss: 0.314417\n",
      "[34,   199] loss: 0.302557\n",
      "[34,   299] loss: 0.232997\n",
      "[34,   399] loss: 0.276562\n",
      "[34,   499] loss: 0.272987\n",
      "[34,   599] loss: 0.306971\n",
      "[34,   699] loss: 0.319012\n",
      "[35,    99] loss: 0.306294\n",
      "[35,   199] loss: 0.293918\n",
      "[35,   299] loss: 0.225472\n",
      "[35,   399] loss: 0.268481\n",
      "[35,   499] loss: 0.264661\n",
      "[35,   599] loss: 0.299509\n",
      "[35,   699] loss: 0.309400\n",
      "[36,    99] loss: 0.298344\n",
      "[36,   199] loss: 0.285246\n",
      "[36,   299] loss: 0.218383\n",
      "[36,   399] loss: 0.260403\n",
      "[36,   499] loss: 0.257709\n",
      "[36,   599] loss: 0.291673\n",
      "[36,   699] loss: 0.299510\n",
      "[37,    99] loss: 0.290271\n",
      "[37,   199] loss: 0.276865\n",
      "[37,   299] loss: 0.211828\n",
      "[37,   399] loss: 0.253015\n",
      "[37,   499] loss: 0.248878\n",
      "[37,   599] loss: 0.284880\n",
      "[37,   699] loss: 0.290546\n",
      "[38,    99] loss: 0.281611\n",
      "[38,   199] loss: 0.269314\n",
      "[38,   299] loss: 0.205394\n",
      "[38,   399] loss: 0.245607\n",
      "[38,   499] loss: 0.241024\n",
      "[38,   599] loss: 0.277572\n",
      "[38,   699] loss: 0.281141\n",
      "[39,    99] loss: 0.273378\n",
      "[39,   199] loss: 0.261485\n",
      "[39,   299] loss: 0.199718\n",
      "[39,   399] loss: 0.238085\n",
      "[39,   499] loss: 0.232315\n",
      "[39,   599] loss: 0.270767\n",
      "[39,   699] loss: 0.271796\n",
      "[40,    99] loss: 0.265555\n",
      "[40,   199] loss: 0.253647\n",
      "[40,   299] loss: 0.193851\n",
      "[40,   399] loss: 0.230914\n",
      "[40,   499] loss: 0.223686\n",
      "[40,   599] loss: 0.264628\n",
      "[40,   699] loss: 0.260956\n",
      "[41,    99] loss: 0.258132\n",
      "[41,   199] loss: 0.246209\n",
      "[41,   299] loss: 0.188394\n",
      "[41,   399] loss: 0.223293\n",
      "[41,   499] loss: 0.214614\n",
      "[41,   599] loss: 0.257845\n",
      "[41,   699] loss: 0.252483\n",
      "[42,    99] loss: 0.249958\n",
      "[42,   199] loss: 0.238937\n",
      "[42,   299] loss: 0.182899\n",
      "[42,   399] loss: 0.216376\n",
      "[42,   499] loss: 0.207881\n",
      "[42,   599] loss: 0.250857\n",
      "[42,   699] loss: 0.242907\n",
      "[43,    99] loss: 0.241971\n",
      "[43,   199] loss: 0.231944\n",
      "[43,   299] loss: 0.177980\n",
      "[43,   399] loss: 0.209479\n",
      "[43,   499] loss: 0.201947\n",
      "[43,   599] loss: 0.244387\n",
      "[43,   699] loss: 0.234586\n",
      "[44,    99] loss: 0.234855\n",
      "[44,   199] loss: 0.224825\n",
      "[44,   299] loss: 0.173123\n",
      "[44,   399] loss: 0.202898\n",
      "[44,   499] loss: 0.195716\n",
      "[44,   599] loss: 0.237459\n",
      "[44,   699] loss: 0.225882\n",
      "[45,    99] loss: 0.228140\n",
      "[45,   199] loss: 0.218640\n",
      "[45,   299] loss: 0.168305\n",
      "[45,   399] loss: 0.196350\n",
      "[45,   499] loss: 0.189447\n",
      "[45,   599] loss: 0.230968\n",
      "[45,   699] loss: 0.218733\n",
      "[46,    99] loss: 0.220763\n",
      "[46,   199] loss: 0.211795\n",
      "[46,   299] loss: 0.163582\n",
      "[46,   399] loss: 0.189847\n",
      "[46,   499] loss: 0.184199\n",
      "[46,   599] loss: 0.224741\n",
      "[46,   699] loss: 0.210882\n",
      "[47,    99] loss: 0.214751\n",
      "[47,   199] loss: 0.205824\n",
      "[47,   299] loss: 0.158983\n",
      "[47,   399] loss: 0.183571\n",
      "[47,   499] loss: 0.178317\n",
      "[47,   599] loss: 0.218002\n",
      "[47,   699] loss: 0.203461\n",
      "[48,    99] loss: 0.207935\n",
      "[48,   199] loss: 0.199618\n",
      "[48,   299] loss: 0.154613\n",
      "[48,   399] loss: 0.177619\n",
      "[48,   499] loss: 0.172801\n",
      "[48,   599] loss: 0.212486\n",
      "[48,   699] loss: 0.195811\n",
      "[49,    99] loss: 0.201374\n",
      "[49,   199] loss: 0.193806\n",
      "[49,   299] loss: 0.150350\n",
      "[49,   399] loss: 0.172244\n",
      "[49,   499] loss: 0.168331\n",
      "[49,   599] loss: 0.206077\n",
      "[49,   699] loss: 0.188053\n",
      "[50,    99] loss: 0.196183\n",
      "[50,   199] loss: 0.187475\n",
      "[50,   299] loss: 0.145871\n",
      "[50,   399] loss: 0.166812\n",
      "[50,   499] loss: 0.162695\n",
      "[50,   599] loss: 0.201042\n",
      "[50,   699] loss: 0.181625\n",
      "[51,    99] loss: 0.189374\n",
      "[51,   199] loss: 0.182197\n",
      "[51,   299] loss: 0.141592\n",
      "[51,   399] loss: 0.161778\n",
      "[51,   499] loss: 0.155819\n",
      "[51,   599] loss: 0.195369\n",
      "[51,   699] loss: 0.175335\n",
      "[52,    99] loss: 0.183749\n",
      "[52,   199] loss: 0.176979\n",
      "[52,   299] loss: 0.137525\n",
      "[52,   399] loss: 0.156746\n",
      "[52,   499] loss: 0.151262\n",
      "[52,   599] loss: 0.190152\n",
      "[52,   699] loss: 0.168945\n",
      "[53,    99] loss: 0.177905\n",
      "[53,   199] loss: 0.171925\n",
      "[53,   299] loss: 0.133446\n",
      "[53,   399] loss: 0.152316\n",
      "[53,   499] loss: 0.146993\n",
      "[53,   599] loss: 0.184127\n",
      "[53,   699] loss: 0.162558\n",
      "[54,    99] loss: 0.171474\n",
      "[54,   199] loss: 0.166237\n",
      "[54,   299] loss: 0.129946\n",
      "[54,   399] loss: 0.147374\n",
      "[54,   499] loss: 0.140990\n",
      "[54,   599] loss: 0.179377\n",
      "[54,   699] loss: 0.157016\n",
      "[55,    99] loss: 0.165775\n",
      "[55,   199] loss: 0.161688\n",
      "[55,   299] loss: 0.126065\n",
      "[55,   399] loss: 0.143039\n",
      "[55,   499] loss: 0.137055\n",
      "[55,   599] loss: 0.172980\n",
      "[55,   699] loss: 0.151446\n",
      "[56,    99] loss: 0.160558\n",
      "[56,   199] loss: 0.156762\n",
      "[56,   299] loss: 0.122444\n",
      "[56,   399] loss: 0.138774\n",
      "[56,   499] loss: 0.132429\n",
      "[56,   599] loss: 0.168516\n",
      "[56,   699] loss: 0.145999\n",
      "[57,    99] loss: 0.155162\n",
      "[57,   199] loss: 0.151579\n",
      "[57,   299] loss: 0.118802\n",
      "[57,   399] loss: 0.134633\n",
      "[57,   499] loss: 0.128500\n",
      "[57,   599] loss: 0.163331\n",
      "[57,   699] loss: 0.141004\n",
      "[58,    99] loss: 0.150391\n",
      "[58,   199] loss: 0.147368\n",
      "[58,   299] loss: 0.115079\n",
      "[58,   399] loss: 0.130336\n",
      "[58,   499] loss: 0.124089\n",
      "[58,   599] loss: 0.158843\n",
      "[58,   699] loss: 0.136263\n",
      "[59,    99] loss: 0.145633\n",
      "[59,   199] loss: 0.142353\n",
      "[59,   299] loss: 0.111294\n",
      "[59,   399] loss: 0.126604\n",
      "[59,   499] loss: 0.119381\n",
      "[59,   599] loss: 0.154656\n",
      "[59,   699] loss: 0.131783\n",
      "[60,    99] loss: 0.140711\n",
      "[60,   199] loss: 0.138002\n",
      "[60,   299] loss: 0.107425\n",
      "[60,   399] loss: 0.122178\n",
      "[60,   499] loss: 0.117241\n",
      "[60,   599] loss: 0.149465\n",
      "[60,   699] loss: 0.126553\n",
      "[61,    99] loss: 0.136110\n",
      "[61,   199] loss: 0.133770\n",
      "[61,   299] loss: 0.104487\n",
      "[61,   399] loss: 0.119539\n",
      "[61,   499] loss: 0.112857\n",
      "[61,   599] loss: 0.144024\n",
      "[61,   699] loss: 0.122130\n",
      "[62,    99] loss: 0.132157\n",
      "[62,   199] loss: 0.129357\n",
      "[62,   299] loss: 0.100958\n",
      "[62,   399] loss: 0.115358\n",
      "[62,   499] loss: 0.109734\n",
      "[62,   599] loss: 0.140485\n",
      "[62,   699] loss: 0.117384\n",
      "[63,    99] loss: 0.127352\n",
      "[63,   199] loss: 0.125080\n",
      "[63,   299] loss: 0.097887\n",
      "[63,   399] loss: 0.112384\n",
      "[63,   499] loss: 0.105745\n",
      "[63,   599] loss: 0.136003\n",
      "[63,   699] loss: 0.113468\n",
      "[64,    99] loss: 0.123696\n",
      "[64,   199] loss: 0.120983\n",
      "[64,   299] loss: 0.094410\n",
      "[64,   399] loss: 0.107897\n",
      "[64,   499] loss: 0.103897\n",
      "[64,   599] loss: 0.132005\n",
      "[64,   699] loss: 0.109537\n",
      "[65,    99] loss: 0.118925\n",
      "[65,   199] loss: 0.116897\n",
      "[65,   299] loss: 0.091392\n",
      "[65,   399] loss: 0.105284\n",
      "[65,   499] loss: 0.100128\n",
      "[65,   599] loss: 0.127778\n",
      "[65,   699] loss: 0.104853\n",
      "[66,    99] loss: 0.115341\n",
      "[66,   199] loss: 0.113600\n",
      "[66,   299] loss: 0.088551\n",
      "[66,   399] loss: 0.102023\n",
      "[66,   499] loss: 0.097417\n",
      "[66,   599] loss: 0.124277\n",
      "[66,   699] loss: 0.100941\n",
      "[67,    99] loss: 0.110868\n",
      "[67,   199] loss: 0.109524\n",
      "[67,   299] loss: 0.085507\n",
      "[67,   399] loss: 0.098654\n",
      "[67,   499] loss: 0.094315\n",
      "[67,   599] loss: 0.120322\n",
      "[67,   699] loss: 0.097362\n",
      "[68,    99] loss: 0.107961\n",
      "[68,   199] loss: 0.106423\n",
      "[68,   299] loss: 0.083028\n",
      "[68,   399] loss: 0.096313\n",
      "[68,   499] loss: 0.092208\n",
      "[68,   599] loss: 0.117023\n",
      "[68,   699] loss: 0.093615\n",
      "[69,    99] loss: 0.103758\n",
      "[69,   199] loss: 0.102164\n",
      "[69,   299] loss: 0.079784\n",
      "[69,   399] loss: 0.092640\n",
      "[69,   499] loss: 0.089216\n",
      "[69,   599] loss: 0.113132\n",
      "[69,   699] loss: 0.090271\n",
      "[70,    99] loss: 0.100676\n",
      "[70,   199] loss: 0.099443\n",
      "[70,   299] loss: 0.077124\n",
      "[70,   399] loss: 0.090094\n",
      "[70,   499] loss: 0.087312\n",
      "[70,   599] loss: 0.109755\n",
      "[70,   699] loss: 0.086781\n",
      "[71,    99] loss: 0.097124\n",
      "[71,   199] loss: 0.095679\n",
      "[71,   299] loss: 0.074322\n",
      "[71,   399] loss: 0.087533\n",
      "[71,   499] loss: 0.084229\n",
      "[71,   599] loss: 0.106647\n",
      "[71,   699] loss: 0.083482\n",
      "[72,    99] loss: 0.094053\n",
      "[72,   199] loss: 0.092558\n",
      "[72,   299] loss: 0.071962\n",
      "[72,   399] loss: 0.084439\n",
      "[72,   499] loss: 0.082726\n",
      "[72,   599] loss: 0.102757\n",
      "[72,   699] loss: 0.080847\n",
      "[73,    99] loss: 0.091309\n",
      "[73,   199] loss: 0.089056\n",
      "[73,   299] loss: 0.069111\n",
      "[73,   399] loss: 0.080936\n",
      "[73,   499] loss: 0.080202\n",
      "[73,   599] loss: 0.099720\n",
      "[73,   699] loss: 0.077543\n",
      "[74,    99] loss: 0.088435\n",
      "[74,   199] loss: 0.086819\n",
      "[74,   299] loss: 0.066943\n",
      "[74,   399] loss: 0.078919\n",
      "[74,   499] loss: 0.078250\n",
      "[74,   599] loss: 0.097277\n",
      "[74,   699] loss: 0.074406\n",
      "[75,    99] loss: 0.085531\n",
      "[75,   199] loss: 0.083501\n",
      "[75,   299] loss: 0.064295\n",
      "[75,   399] loss: 0.076707\n",
      "[75,   499] loss: 0.076002\n",
      "[75,   599] loss: 0.093373\n",
      "[75,   699] loss: 0.071812\n",
      "[76,    99] loss: 0.082428\n",
      "[76,   199] loss: 0.080919\n",
      "[76,   299] loss: 0.061964\n",
      "[76,   399] loss: 0.073755\n",
      "[76,   499] loss: 0.073878\n",
      "[76,   599] loss: 0.091081\n",
      "[76,   699] loss: 0.069184\n",
      "[77,    99] loss: 0.080371\n",
      "[77,   199] loss: 0.078066\n",
      "[77,   299] loss: 0.059720\n",
      "[77,   399] loss: 0.071527\n",
      "[77,   499] loss: 0.071562\n",
      "[77,   599] loss: 0.087640\n",
      "[77,   699] loss: 0.066386\n",
      "[78,    99] loss: 0.078060\n",
      "[78,   199] loss: 0.075596\n",
      "[78,   299] loss: 0.057794\n",
      "[78,   399] loss: 0.069271\n",
      "[78,   499] loss: 0.069962\n",
      "[78,   599] loss: 0.085247\n",
      "[78,   699] loss: 0.063893\n",
      "[79,    99] loss: 0.075721\n",
      "[79,   199] loss: 0.073064\n",
      "[79,   299] loss: 0.055844\n",
      "[79,   399] loss: 0.067020\n",
      "[79,   499] loss: 0.068357\n",
      "[79,   599] loss: 0.082726\n",
      "[79,   699] loss: 0.061375\n",
      "[80,    99] loss: 0.073400\n",
      "[80,   199] loss: 0.070329\n",
      "[80,   299] loss: 0.053447\n",
      "[80,   399] loss: 0.065476\n",
      "[80,   499] loss: 0.066105\n",
      "[80,   599] loss: 0.079657\n",
      "[80,   699] loss: 0.058837\n",
      "[81,    99] loss: 0.071012\n",
      "[81,   199] loss: 0.068302\n",
      "[81,   299] loss: 0.051118\n",
      "[81,   399] loss: 0.063540\n",
      "[81,   499] loss: 0.064794\n",
      "[81,   599] loss: 0.076951\n",
      "[81,   699] loss: 0.056541\n",
      "[82,    99] loss: 0.068738\n",
      "[82,   199] loss: 0.065893\n",
      "[82,   299] loss: 0.049603\n",
      "[82,   399] loss: 0.060783\n",
      "[82,   499] loss: 0.062812\n",
      "[82,   599] loss: 0.074391\n",
      "[82,   699] loss: 0.054234\n",
      "[83,    99] loss: 0.067312\n",
      "[83,   199] loss: 0.063581\n",
      "[83,   299] loss: 0.047935\n",
      "[83,   399] loss: 0.059512\n",
      "[83,   499] loss: 0.060856\n",
      "[83,   599] loss: 0.071312\n",
      "[83,   699] loss: 0.052339\n",
      "[84,    99] loss: 0.065103\n",
      "[84,   199] loss: 0.061696\n",
      "[84,   299] loss: 0.046253\n",
      "[84,   399] loss: 0.057902\n",
      "[84,   499] loss: 0.059359\n",
      "[84,   599] loss: 0.069636\n",
      "[84,   699] loss: 0.050167\n",
      "[85,    99] loss: 0.063089\n",
      "[85,   199] loss: 0.059066\n",
      "[85,   299] loss: 0.044320\n",
      "[85,   399] loss: 0.055778\n",
      "[85,   499] loss: 0.057905\n",
      "[85,   599] loss: 0.066726\n",
      "[85,   699] loss: 0.048364\n",
      "[86,    99] loss: 0.061235\n",
      "[86,   199] loss: 0.057199\n",
      "[86,   299] loss: 0.043154\n",
      "[86,   399] loss: 0.055053\n",
      "[86,   499] loss: 0.056682\n",
      "[86,   599] loss: 0.064498\n",
      "[86,   699] loss: 0.046410\n",
      "[87,    99] loss: 0.059378\n",
      "[87,   199] loss: 0.054983\n",
      "[87,   299] loss: 0.041281\n",
      "[87,   399] loss: 0.052466\n",
      "[87,   499] loss: 0.055056\n",
      "[87,   599] loss: 0.062373\n",
      "[87,   699] loss: 0.044329\n",
      "[88,    99] loss: 0.057481\n",
      "[88,   199] loss: 0.052727\n",
      "[88,   299] loss: 0.039897\n",
      "[88,   399] loss: 0.051329\n",
      "[88,   499] loss: 0.053654\n",
      "[88,   599] loss: 0.060379\n",
      "[88,   699] loss: 0.042257\n",
      "[89,    99] loss: 0.055955\n",
      "[89,   199] loss: 0.051344\n",
      "[89,   299] loss: 0.038442\n",
      "[89,   399] loss: 0.049847\n",
      "[89,   499] loss: 0.051858\n",
      "[89,   599] loss: 0.058281\n",
      "[89,   699] loss: 0.040610\n",
      "[90,    99] loss: 0.054326\n",
      "[90,   199] loss: 0.049541\n",
      "[90,   299] loss: 0.036954\n",
      "[90,   399] loss: 0.048406\n",
      "[90,   499] loss: 0.050930\n",
      "[90,   599] loss: 0.056141\n",
      "[90,   699] loss: 0.038528\n",
      "[91,    99] loss: 0.053341\n",
      "[91,   199] loss: 0.048222\n",
      "[91,   299] loss: 0.036209\n",
      "[91,   399] loss: 0.046963\n",
      "[91,   499] loss: 0.049914\n",
      "[91,   599] loss: 0.054361\n",
      "[91,   699] loss: 0.036558\n",
      "[92,    99] loss: 0.050909\n",
      "[92,   199] loss: 0.045959\n",
      "[92,   299] loss: 0.034373\n",
      "[92,   399] loss: 0.045197\n",
      "[92,   499] loss: 0.048794\n",
      "[92,   599] loss: 0.052460\n",
      "[92,   699] loss: 0.035516\n",
      "[93,    99] loss: 0.050151\n",
      "[93,   199] loss: 0.044900\n",
      "[93,   299] loss: 0.033482\n",
      "[93,   399] loss: 0.044310\n",
      "[93,   499] loss: 0.047466\n",
      "[93,   599] loss: 0.050469\n",
      "[93,   699] loss: 0.033466\n",
      "[94,    99] loss: 0.048359\n",
      "[94,   199] loss: 0.043433\n",
      "[94,   299] loss: 0.031929\n",
      "[94,   399] loss: 0.043581\n",
      "[94,   499] loss: 0.046116\n",
      "[94,   599] loss: 0.049007\n",
      "[94,   699] loss: 0.032205\n",
      "[95,    99] loss: 0.047510\n",
      "[95,   199] loss: 0.041838\n",
      "[95,   299] loss: 0.030554\n",
      "[95,   399] loss: 0.042348\n",
      "[95,   499] loss: 0.045225\n",
      "[95,   599] loss: 0.047149\n",
      "[95,   699] loss: 0.030659\n",
      "[96,    99] loss: 0.045559\n",
      "[96,   199] loss: 0.040510\n",
      "[96,   299] loss: 0.029828\n",
      "[96,   399] loss: 0.040597\n",
      "[96,   499] loss: 0.043979\n",
      "[96,   599] loss: 0.045831\n",
      "[96,   699] loss: 0.029454\n",
      "[97,    99] loss: 0.044229\n",
      "[97,   199] loss: 0.039004\n",
      "[97,   299] loss: 0.028935\n",
      "[97,   399] loss: 0.039912\n",
      "[97,   499] loss: 0.042762\n",
      "[97,   599] loss: 0.044144\n",
      "[97,   699] loss: 0.028217\n",
      "[98,    99] loss: 0.042829\n",
      "[98,   199] loss: 0.037607\n",
      "[98,   299] loss: 0.028173\n",
      "[98,   399] loss: 0.039403\n",
      "[98,   499] loss: 0.041269\n",
      "[98,   599] loss: 0.042983\n",
      "[98,   699] loss: 0.026987\n",
      "[99,    99] loss: 0.041504\n",
      "[99,   199] loss: 0.036735\n",
      "[99,   299] loss: 0.027096\n",
      "[99,   399] loss: 0.038116\n",
      "[99,   499] loss: 0.040429\n",
      "[99,   599] loss: 0.041144\n",
      "[99,   699] loss: 0.025973\n",
      "[100,    99] loss: 0.040133\n",
      "[100,   199] loss: 0.035137\n",
      "[100,   299] loss: 0.025882\n",
      "[100,   399] loss: 0.037294\n",
      "[100,   499] loss: 0.039406\n",
      "[100,   599] loss: 0.039890\n",
      "[100,   699] loss: 0.024782\n",
      "Finished Training\n",
      "[1,    99] loss: 0.725205\n",
      "[1,   199] loss: 0.749198\n",
      "[1,   299] loss: 0.707182\n",
      "[1,   399] loss: 0.692536\n",
      "[1,   499] loss: 0.696667\n",
      "[1,   599] loss: 0.699633\n",
      "[1,   699] loss: 0.694838\n",
      "[2,    99] loss: 0.691479\n",
      "[2,   199] loss: 0.681196\n",
      "[2,   299] loss: 0.665911\n",
      "[2,   399] loss: 0.663370\n",
      "[2,   499] loss: 0.666242\n",
      "[2,   599] loss: 0.682210\n",
      "[2,   699] loss: 0.670367\n",
      "[3,    99] loss: 0.675927\n",
      "[3,   199] loss: 0.658567\n",
      "[3,   299] loss: 0.648556\n",
      "[3,   399] loss: 0.645655\n",
      "[3,   499] loss: 0.645359\n",
      "[3,   599] loss: 0.671268\n",
      "[3,   699] loss: 0.651229\n",
      "[4,    99] loss: 0.661270\n",
      "[4,   199] loss: 0.647328\n",
      "[4,   299] loss: 0.634735\n",
      "[4,   399] loss: 0.629821\n",
      "[4,   499] loss: 0.623937\n",
      "[4,   599] loss: 0.659618\n",
      "[4,   699] loss: 0.631020\n",
      "[5,    99] loss: 0.646297\n",
      "[5,   199] loss: 0.639280\n",
      "[5,   299] loss: 0.620085\n",
      "[5,   399] loss: 0.613383\n",
      "[5,   499] loss: 0.601981\n",
      "[5,   599] loss: 0.647332\n",
      "[5,   699] loss: 0.610119\n",
      "[6,    99] loss: 0.632367\n",
      "[6,   199] loss: 0.631901\n",
      "[6,   299] loss: 0.603342\n",
      "[6,   399] loss: 0.596774\n",
      "[6,   499] loss: 0.580146\n",
      "[6,   599] loss: 0.636071\n",
      "[6,   699] loss: 0.590212\n",
      "[7,    99] loss: 0.618675\n",
      "[7,   199] loss: 0.624265\n",
      "[7,   299] loss: 0.586540\n",
      "[7,   399] loss: 0.581095\n",
      "[7,   499] loss: 0.560282\n",
      "[7,   599] loss: 0.624989\n",
      "[7,   699] loss: 0.571538\n",
      "[8,    99] loss: 0.605320\n",
      "[8,   199] loss: 0.615892\n",
      "[8,   299] loss: 0.570954\n",
      "[8,   399] loss: 0.566934\n",
      "[8,   499] loss: 0.542008\n",
      "[8,   599] loss: 0.614367\n",
      "[8,   699] loss: 0.554014\n",
      "[9,    99] loss: 0.591653\n",
      "[9,   199] loss: 0.607838\n",
      "[9,   299] loss: 0.556170\n",
      "[9,   399] loss: 0.552823\n",
      "[9,   499] loss: 0.525492\n",
      "[9,   599] loss: 0.603866\n",
      "[9,   699] loss: 0.537365\n",
      "[10,    99] loss: 0.577214\n",
      "[10,   199] loss: 0.599032\n",
      "[10,   299] loss: 0.541359\n",
      "[10,   399] loss: 0.538468\n",
      "[10,   499] loss: 0.509322\n",
      "[10,   599] loss: 0.592622\n",
      "[10,   699] loss: 0.520961\n",
      "[11,    99] loss: 0.563193\n",
      "[11,   199] loss: 0.588401\n",
      "[11,   299] loss: 0.526272\n",
      "[11,   399] loss: 0.524151\n",
      "[11,   499] loss: 0.493440\n",
      "[11,   599] loss: 0.582180\n",
      "[11,   699] loss: 0.506063\n",
      "[12,    99] loss: 0.549142\n",
      "[12,   199] loss: 0.576373\n",
      "[12,   299] loss: 0.511288\n",
      "[12,   399] loss: 0.509984\n",
      "[12,   499] loss: 0.478144\n",
      "[12,   599] loss: 0.571424\n",
      "[12,   699] loss: 0.491517\n",
      "[13,    99] loss: 0.534546\n",
      "[13,   199] loss: 0.562958\n",
      "[13,   299] loss: 0.496018\n",
      "[13,   399] loss: 0.495622\n",
      "[13,   499] loss: 0.462374\n",
      "[13,   599] loss: 0.560051\n",
      "[13,   699] loss: 0.477208\n",
      "[14,    99] loss: 0.518756\n",
      "[14,   199] loss: 0.548894\n",
      "[14,   299] loss: 0.481330\n",
      "[14,   399] loss: 0.480966\n",
      "[14,   499] loss: 0.446681\n",
      "[14,   599] loss: 0.548321\n",
      "[14,   699] loss: 0.463495\n",
      "[15,    99] loss: 0.503207\n",
      "[15,   199] loss: 0.534195\n",
      "[15,   299] loss: 0.466919\n",
      "[15,   399] loss: 0.466324\n",
      "[15,   499] loss: 0.431293\n",
      "[15,   599] loss: 0.536600\n",
      "[15,   699] loss: 0.450094\n",
      "[16,    99] loss: 0.487972\n",
      "[16,   199] loss: 0.519266\n",
      "[16,   299] loss: 0.452985\n",
      "[16,   399] loss: 0.451756\n",
      "[16,   499] loss: 0.415977\n",
      "[16,   599] loss: 0.524650\n",
      "[16,   699] loss: 0.437512\n",
      "[17,    99] loss: 0.472618\n",
      "[17,   199] loss: 0.503628\n",
      "[17,   299] loss: 0.438800\n",
      "[17,   399] loss: 0.437206\n",
      "[17,   499] loss: 0.401337\n",
      "[17,   599] loss: 0.513249\n",
      "[17,   699] loss: 0.425460\n",
      "[18,    99] loss: 0.457251\n",
      "[18,   199] loss: 0.487273\n",
      "[18,   299] loss: 0.424226\n",
      "[18,   399] loss: 0.422437\n",
      "[18,   499] loss: 0.387415\n",
      "[18,   599] loss: 0.502250\n",
      "[18,   699] loss: 0.413315\n",
      "[19,    99] loss: 0.442110\n",
      "[19,   199] loss: 0.471034\n",
      "[19,   299] loss: 0.410677\n",
      "[19,   399] loss: 0.408339\n",
      "[19,   499] loss: 0.373701\n",
      "[19,   599] loss: 0.490602\n",
      "[19,   699] loss: 0.402272\n",
      "[20,    99] loss: 0.426971\n",
      "[20,   199] loss: 0.455945\n",
      "[20,   299] loss: 0.397116\n",
      "[20,   399] loss: 0.394176\n",
      "[20,   499] loss: 0.360316\n",
      "[20,   599] loss: 0.479114\n",
      "[20,   699] loss: 0.390714\n",
      "[21,    99] loss: 0.412634\n",
      "[21,   199] loss: 0.441145\n",
      "[21,   299] loss: 0.383219\n",
      "[21,   399] loss: 0.380063\n",
      "[21,   499] loss: 0.346967\n",
      "[21,   599] loss: 0.466962\n",
      "[21,   699] loss: 0.380516\n",
      "[22,    99] loss: 0.399042\n",
      "[22,   199] loss: 0.426652\n",
      "[22,   299] loss: 0.369901\n",
      "[22,   399] loss: 0.366673\n",
      "[22,   499] loss: 0.333746\n",
      "[22,   599] loss: 0.454301\n",
      "[22,   699] loss: 0.370569\n",
      "[23,    99] loss: 0.386067\n",
      "[23,   199] loss: 0.412355\n",
      "[23,   299] loss: 0.356605\n",
      "[23,   399] loss: 0.353501\n",
      "[23,   499] loss: 0.321486\n",
      "[23,   599] loss: 0.442299\n",
      "[23,   699] loss: 0.360601\n",
      "[24,    99] loss: 0.373055\n",
      "[24,   199] loss: 0.398716\n",
      "[24,   299] loss: 0.344535\n",
      "[24,   399] loss: 0.341233\n",
      "[24,   499] loss: 0.309566\n",
      "[24,   599] loss: 0.430270\n",
      "[24,   699] loss: 0.351365\n",
      "[25,    99] loss: 0.360179\n",
      "[25,   199] loss: 0.386380\n",
      "[25,   299] loss: 0.332437\n",
      "[25,   399] loss: 0.329293\n",
      "[25,   499] loss: 0.298046\n",
      "[25,   599] loss: 0.419103\n",
      "[25,   699] loss: 0.341085\n",
      "[26,    99] loss: 0.347986\n",
      "[26,   199] loss: 0.374034\n",
      "[26,   299] loss: 0.321105\n",
      "[26,   399] loss: 0.318268\n",
      "[26,   499] loss: 0.287328\n",
      "[26,   599] loss: 0.407919\n",
      "[26,   699] loss: 0.331121\n",
      "[27,    99] loss: 0.335542\n",
      "[27,   199] loss: 0.362853\n",
      "[27,   299] loss: 0.310019\n",
      "[27,   399] loss: 0.307432\n",
      "[27,   499] loss: 0.276860\n",
      "[27,   599] loss: 0.396620\n",
      "[27,   699] loss: 0.322061\n",
      "[28,    99] loss: 0.324707\n",
      "[28,   199] loss: 0.350111\n",
      "[28,   299] loss: 0.299077\n",
      "[28,   399] loss: 0.297030\n",
      "[28,   499] loss: 0.266898\n",
      "[28,   599] loss: 0.385273\n",
      "[28,   699] loss: 0.312497\n",
      "[29,    99] loss: 0.313413\n",
      "[29,   199] loss: 0.339152\n",
      "[29,   299] loss: 0.288663\n",
      "[29,   399] loss: 0.287556\n",
      "[29,   499] loss: 0.257106\n",
      "[29,   599] loss: 0.374480\n",
      "[29,   699] loss: 0.302909\n",
      "[30,    99] loss: 0.302880\n",
      "[30,   199] loss: 0.327358\n",
      "[30,   299] loss: 0.278839\n",
      "[30,   399] loss: 0.278047\n",
      "[30,   499] loss: 0.247344\n",
      "[30,   599] loss: 0.362493\n",
      "[30,   699] loss: 0.294216\n",
      "[31,    99] loss: 0.292065\n",
      "[31,   199] loss: 0.317105\n",
      "[31,   299] loss: 0.268815\n",
      "[31,   399] loss: 0.269137\n",
      "[31,   499] loss: 0.238803\n",
      "[31,   599] loss: 0.351756\n",
      "[31,   699] loss: 0.285411\n",
      "[32,    99] loss: 0.281998\n",
      "[32,   199] loss: 0.306613\n",
      "[32,   299] loss: 0.259659\n",
      "[32,   399] loss: 0.260599\n",
      "[32,   499] loss: 0.230819\n",
      "[32,   599] loss: 0.341305\n",
      "[32,   699] loss: 0.276373\n",
      "[33,    99] loss: 0.271598\n",
      "[33,   199] loss: 0.297517\n",
      "[33,   299] loss: 0.251359\n",
      "[33,   399] loss: 0.252055\n",
      "[33,   499] loss: 0.223052\n",
      "[33,   599] loss: 0.330667\n",
      "[33,   699] loss: 0.268925\n",
      "[34,    99] loss: 0.261817\n",
      "[34,   199] loss: 0.288107\n",
      "[34,   299] loss: 0.242197\n",
      "[34,   399] loss: 0.244182\n",
      "[34,   499] loss: 0.215532\n",
      "[34,   599] loss: 0.320248\n",
      "[34,   699] loss: 0.260539\n",
      "[35,    99] loss: 0.252101\n",
      "[35,   199] loss: 0.279396\n",
      "[35,   299] loss: 0.233968\n",
      "[35,   399] loss: 0.236102\n",
      "[35,   499] loss: 0.208691\n",
      "[35,   599] loss: 0.310358\n",
      "[35,   699] loss: 0.252916\n",
      "[36,    99] loss: 0.243665\n",
      "[36,   199] loss: 0.270032\n",
      "[36,   299] loss: 0.226230\n",
      "[36,   399] loss: 0.228264\n",
      "[36,   499] loss: 0.202022\n",
      "[36,   599] loss: 0.301241\n",
      "[36,   699] loss: 0.244888\n",
      "[37,    99] loss: 0.233557\n",
      "[37,   199] loss: 0.262397\n",
      "[37,   299] loss: 0.218206\n",
      "[37,   399] loss: 0.221483\n",
      "[37,   499] loss: 0.195497\n",
      "[37,   599] loss: 0.291385\n",
      "[37,   699] loss: 0.237476\n",
      "[38,    99] loss: 0.225082\n",
      "[38,   199] loss: 0.253709\n",
      "[38,   299] loss: 0.211382\n",
      "[38,   399] loss: 0.213990\n",
      "[38,   499] loss: 0.189136\n",
      "[38,   599] loss: 0.281916\n",
      "[38,   699] loss: 0.230399\n",
      "[39,    99] loss: 0.217105\n",
      "[39,   199] loss: 0.245945\n",
      "[39,   299] loss: 0.204129\n",
      "[39,   399] loss: 0.207587\n",
      "[39,   499] loss: 0.183487\n",
      "[39,   599] loss: 0.272825\n",
      "[39,   699] loss: 0.223008\n",
      "[40,    99] loss: 0.209325\n",
      "[40,   199] loss: 0.238264\n",
      "[40,   299] loss: 0.198134\n",
      "[40,   399] loss: 0.200791\n",
      "[40,   499] loss: 0.177515\n",
      "[40,   599] loss: 0.264104\n",
      "[40,   699] loss: 0.215688\n",
      "[41,    99] loss: 0.201080\n",
      "[41,   199] loss: 0.230884\n",
      "[41,   299] loss: 0.191769\n",
      "[41,   399] loss: 0.194893\n",
      "[41,   499] loss: 0.171748\n",
      "[41,   599] loss: 0.255004\n",
      "[41,   699] loss: 0.208966\n",
      "[42,    99] loss: 0.193380\n",
      "[42,   199] loss: 0.223805\n",
      "[42,   299] loss: 0.185987\n",
      "[42,   399] loss: 0.188868\n",
      "[42,   499] loss: 0.166182\n",
      "[42,   599] loss: 0.246797\n",
      "[42,   699] loss: 0.202245\n",
      "[43,    99] loss: 0.185889\n",
      "[43,   199] loss: 0.217104\n",
      "[43,   299] loss: 0.179829\n",
      "[43,   399] loss: 0.183090\n",
      "[43,   499] loss: 0.161357\n",
      "[43,   599] loss: 0.238658\n",
      "[43,   699] loss: 0.195084\n",
      "[44,    99] loss: 0.179461\n",
      "[44,   199] loss: 0.210182\n",
      "[44,   299] loss: 0.174810\n",
      "[44,   399] loss: 0.177587\n",
      "[44,   499] loss: 0.156039\n",
      "[44,   599] loss: 0.230461\n",
      "[44,   699] loss: 0.189019\n",
      "[45,    99] loss: 0.172477\n",
      "[45,   199] loss: 0.204370\n",
      "[45,   299] loss: 0.169555\n",
      "[45,   399] loss: 0.171943\n",
      "[45,   499] loss: 0.151104\n",
      "[45,   599] loss: 0.222518\n",
      "[45,   699] loss: 0.182827\n",
      "[46,    99] loss: 0.166104\n",
      "[46,   199] loss: 0.198044\n",
      "[46,   299] loss: 0.164440\n",
      "[46,   399] loss: 0.166565\n",
      "[46,   499] loss: 0.146421\n",
      "[46,   599] loss: 0.215272\n",
      "[46,   699] loss: 0.176559\n",
      "[47,    99] loss: 0.159568\n",
      "[47,   199] loss: 0.192328\n",
      "[47,   299] loss: 0.159508\n",
      "[47,   399] loss: 0.161127\n",
      "[47,   499] loss: 0.141811\n",
      "[47,   599] loss: 0.208416\n",
      "[47,   699] loss: 0.170876\n",
      "[48,    99] loss: 0.153610\n",
      "[48,   199] loss: 0.187047\n",
      "[48,   299] loss: 0.155001\n",
      "[48,   399] loss: 0.155663\n",
      "[48,   499] loss: 0.137040\n",
      "[48,   599] loss: 0.201363\n",
      "[48,   699] loss: 0.164918\n",
      "[49,    99] loss: 0.148391\n",
      "[49,   199] loss: 0.181729\n",
      "[49,   299] loss: 0.150240\n",
      "[49,   399] loss: 0.150718\n",
      "[49,   499] loss: 0.132867\n",
      "[49,   599] loss: 0.194659\n",
      "[49,   699] loss: 0.160095\n",
      "[50,    99] loss: 0.142883\n",
      "[50,   199] loss: 0.176554\n",
      "[50,   299] loss: 0.146380\n",
      "[50,   399] loss: 0.145699\n",
      "[50,   499] loss: 0.128828\n",
      "[50,   599] loss: 0.188108\n",
      "[50,   699] loss: 0.154485\n",
      "[51,    99] loss: 0.137362\n",
      "[51,   199] loss: 0.171950\n",
      "[51,   299] loss: 0.142562\n",
      "[51,   399] loss: 0.141137\n",
      "[51,   499] loss: 0.124977\n",
      "[51,   599] loss: 0.181719\n",
      "[51,   699] loss: 0.150228\n",
      "[52,    99] loss: 0.133343\n",
      "[52,   199] loss: 0.167342\n",
      "[52,   299] loss: 0.138582\n",
      "[52,   399] loss: 0.136407\n",
      "[52,   499] loss: 0.121294\n",
      "[52,   599] loss: 0.175430\n",
      "[52,   699] loss: 0.145261\n",
      "[53,    99] loss: 0.127422\n",
      "[53,   199] loss: 0.162894\n",
      "[53,   299] loss: 0.135252\n",
      "[53,   399] loss: 0.132076\n",
      "[53,   499] loss: 0.116929\n",
      "[53,   599] loss: 0.169174\n",
      "[53,   699] loss: 0.141628\n",
      "[54,    99] loss: 0.123791\n",
      "[54,   199] loss: 0.158559\n",
      "[54,   299] loss: 0.131652\n",
      "[54,   399] loss: 0.127800\n",
      "[54,   499] loss: 0.113323\n",
      "[54,   599] loss: 0.164090\n",
      "[54,   699] loss: 0.136371\n",
      "[55,    99] loss: 0.119321\n",
      "[55,   199] loss: 0.154272\n",
      "[55,   299] loss: 0.128318\n",
      "[55,   399] loss: 0.123684\n",
      "[55,   499] loss: 0.110116\n",
      "[55,   599] loss: 0.157917\n",
      "[55,   699] loss: 0.132704\n",
      "[56,    99] loss: 0.114833\n",
      "[56,   199] loss: 0.149682\n",
      "[56,   299] loss: 0.124912\n",
      "[56,   399] loss: 0.119745\n",
      "[56,   499] loss: 0.106523\n",
      "[56,   599] loss: 0.152568\n",
      "[56,   699] loss: 0.127969\n",
      "[57,    99] loss: 0.111764\n",
      "[57,   199] loss: 0.146158\n",
      "[57,   299] loss: 0.121850\n",
      "[57,   399] loss: 0.115290\n",
      "[57,   499] loss: 0.103548\n",
      "[57,   599] loss: 0.146963\n",
      "[57,   699] loss: 0.124497\n",
      "[58,    99] loss: 0.108182\n",
      "[58,   199] loss: 0.141903\n",
      "[58,   299] loss: 0.118778\n",
      "[58,   399] loss: 0.111390\n",
      "[58,   499] loss: 0.100013\n",
      "[58,   599] loss: 0.142157\n",
      "[58,   699] loss: 0.120252\n",
      "[59,    99] loss: 0.103495\n",
      "[59,   199] loss: 0.138746\n",
      "[59,   299] loss: 0.115740\n",
      "[59,   399] loss: 0.107519\n",
      "[59,   499] loss: 0.097558\n",
      "[59,   599] loss: 0.137723\n",
      "[59,   699] loss: 0.116155\n",
      "[60,    99] loss: 0.100856\n",
      "[60,   199] loss: 0.134329\n",
      "[60,   299] loss: 0.112864\n",
      "[60,   399] loss: 0.104198\n",
      "[60,   499] loss: 0.094411\n",
      "[60,   599] loss: 0.132892\n",
      "[60,   699] loss: 0.112535\n",
      "[61,    99] loss: 0.096912\n",
      "[61,   199] loss: 0.130866\n",
      "[61,   299] loss: 0.109746\n",
      "[61,   399] loss: 0.100640\n",
      "[61,   499] loss: 0.092200\n",
      "[61,   599] loss: 0.128236\n",
      "[61,   699] loss: 0.109171\n",
      "[62,    99] loss: 0.094531\n",
      "[62,   199] loss: 0.127595\n",
      "[62,   299] loss: 0.107063\n",
      "[62,   399] loss: 0.096953\n",
      "[62,   499] loss: 0.089747\n",
      "[62,   599] loss: 0.124352\n",
      "[62,   699] loss: 0.105443\n",
      "[63,    99] loss: 0.090909\n",
      "[63,   199] loss: 0.123733\n",
      "[63,   299] loss: 0.104278\n",
      "[63,   399] loss: 0.093757\n",
      "[63,   499] loss: 0.087262\n",
      "[63,   599] loss: 0.120647\n",
      "[63,   699] loss: 0.102293\n",
      "[64,    99] loss: 0.088117\n",
      "[64,   199] loss: 0.119905\n",
      "[64,   299] loss: 0.101744\n",
      "[64,   399] loss: 0.090165\n",
      "[64,   499] loss: 0.084920\n",
      "[64,   599] loss: 0.116749\n",
      "[64,   699] loss: 0.099069\n",
      "[65,    99] loss: 0.085336\n",
      "[65,   199] loss: 0.116428\n",
      "[65,   299] loss: 0.099091\n",
      "[65,   399] loss: 0.087244\n",
      "[65,   499] loss: 0.082720\n",
      "[65,   599] loss: 0.113460\n",
      "[65,   699] loss: 0.096048\n",
      "[66,    99] loss: 0.083005\n",
      "[66,   199] loss: 0.113237\n",
      "[66,   299] loss: 0.096363\n",
      "[66,   399] loss: 0.084164\n",
      "[66,   499] loss: 0.081092\n",
      "[66,   599] loss: 0.109020\n",
      "[66,   699] loss: 0.092616\n",
      "[67,    99] loss: 0.079813\n",
      "[67,   199] loss: 0.109649\n",
      "[67,   299] loss: 0.094185\n",
      "[67,   399] loss: 0.081128\n",
      "[67,   499] loss: 0.078571\n",
      "[67,   599] loss: 0.105738\n",
      "[67,   699] loss: 0.089574\n",
      "[68,    99] loss: 0.078405\n",
      "[68,   199] loss: 0.106259\n",
      "[68,   299] loss: 0.091885\n",
      "[68,   399] loss: 0.078003\n",
      "[68,   499] loss: 0.076811\n",
      "[68,   599] loss: 0.102294\n",
      "[68,   699] loss: 0.086688\n",
      "[69,    99] loss: 0.075218\n",
      "[69,   199] loss: 0.102867\n",
      "[69,   299] loss: 0.089414\n",
      "[69,   399] loss: 0.075434\n",
      "[69,   499] loss: 0.074933\n",
      "[69,   599] loss: 0.099397\n",
      "[69,   699] loss: 0.083864\n",
      "[70,    99] loss: 0.073280\n",
      "[70,   199] loss: 0.099715\n",
      "[70,   299] loss: 0.087303\n",
      "[70,   399] loss: 0.072478\n",
      "[70,   499] loss: 0.073188\n",
      "[70,   599] loss: 0.096148\n",
      "[70,   699] loss: 0.081635\n",
      "[71,    99] loss: 0.070601\n",
      "[71,   199] loss: 0.096667\n",
      "[71,   299] loss: 0.085237\n",
      "[71,   399] loss: 0.070215\n",
      "[71,   499] loss: 0.071395\n",
      "[71,   599] loss: 0.093065\n",
      "[71,   699] loss: 0.078625\n",
      "[72,    99] loss: 0.068075\n",
      "[72,   199] loss: 0.093449\n",
      "[72,   299] loss: 0.082917\n",
      "[72,   399] loss: 0.067615\n",
      "[72,   499] loss: 0.069262\n",
      "[72,   599] loss: 0.090033\n",
      "[72,   699] loss: 0.076277\n",
      "[73,    99] loss: 0.066961\n",
      "[73,   199] loss: 0.090370\n",
      "[73,   299] loss: 0.081075\n",
      "[73,   399] loss: 0.065282\n",
      "[73,   499] loss: 0.067564\n",
      "[73,   599] loss: 0.086782\n",
      "[73,   699] loss: 0.073520\n",
      "[74,    99] loss: 0.064235\n",
      "[74,   199] loss: 0.087318\n",
      "[74,   299] loss: 0.079283\n",
      "[74,   399] loss: 0.063134\n",
      "[74,   499] loss: 0.065970\n",
      "[74,   599] loss: 0.084698\n",
      "[74,   699] loss: 0.071406\n",
      "[75,    99] loss: 0.062837\n",
      "[75,   199] loss: 0.084519\n",
      "[75,   299] loss: 0.077259\n",
      "[75,   399] loss: 0.060765\n",
      "[75,   499] loss: 0.063958\n",
      "[75,   599] loss: 0.081414\n",
      "[75,   699] loss: 0.068896\n",
      "[76,    99] loss: 0.060224\n",
      "[76,   199] loss: 0.081671\n",
      "[76,   299] loss: 0.075482\n",
      "[76,   399] loss: 0.058245\n",
      "[76,   499] loss: 0.062226\n",
      "[76,   599] loss: 0.078376\n",
      "[76,   699] loss: 0.066652\n",
      "[77,    99] loss: 0.059473\n",
      "[77,   199] loss: 0.079195\n",
      "[77,   299] loss: 0.074180\n",
      "[77,   399] loss: 0.056132\n",
      "[77,   499] loss: 0.061303\n",
      "[77,   599] loss: 0.075676\n",
      "[77,   699] loss: 0.065074\n",
      "[78,    99] loss: 0.058357\n",
      "[78,   199] loss: 0.076289\n",
      "[78,   299] loss: 0.072009\n",
      "[78,   399] loss: 0.054046\n",
      "[78,   499] loss: 0.059212\n",
      "[78,   599] loss: 0.073131\n",
      "[78,   699] loss: 0.062206\n",
      "[79,    99] loss: 0.055179\n",
      "[79,   199] loss: 0.074632\n",
      "[79,   299] loss: 0.070645\n",
      "[79,   399] loss: 0.052054\n",
      "[79,   499] loss: 0.057729\n",
      "[79,   599] loss: 0.070124\n",
      "[79,   699] loss: 0.060116\n",
      "[80,    99] loss: 0.053501\n",
      "[80,   199] loss: 0.071748\n",
      "[80,   299] loss: 0.068557\n",
      "[80,   399] loss: 0.049841\n",
      "[80,   499] loss: 0.056481\n",
      "[80,   599] loss: 0.067181\n",
      "[80,   699] loss: 0.057732\n",
      "[81,    99] loss: 0.052499\n",
      "[81,   199] loss: 0.069460\n",
      "[81,   299] loss: 0.067067\n",
      "[81,   399] loss: 0.048145\n",
      "[81,   499] loss: 0.055111\n",
      "[81,   599] loss: 0.065674\n",
      "[81,   699] loss: 0.055780\n",
      "[82,    99] loss: 0.050784\n",
      "[82,   199] loss: 0.067263\n",
      "[82,   299] loss: 0.065544\n",
      "[82,   399] loss: 0.046478\n",
      "[82,   499] loss: 0.053763\n",
      "[82,   599] loss: 0.063431\n",
      "[82,   699] loss: 0.053821\n",
      "[83,    99] loss: 0.049529\n",
      "[83,   199] loss: 0.064857\n",
      "[83,   299] loss: 0.063970\n",
      "[83,   399] loss: 0.044309\n",
      "[83,   499] loss: 0.052499\n",
      "[83,   599] loss: 0.061703\n",
      "[83,   699] loss: 0.051935\n",
      "[84,    99] loss: 0.048062\n",
      "[84,   199] loss: 0.062601\n",
      "[84,   299] loss: 0.062131\n",
      "[84,   399] loss: 0.042746\n",
      "[84,   499] loss: 0.051455\n",
      "[84,   599] loss: 0.059349\n",
      "[84,   699] loss: 0.050444\n",
      "[85,    99] loss: 0.047429\n",
      "[85,   199] loss: 0.060624\n",
      "[85,   299] loss: 0.061134\n",
      "[85,   399] loss: 0.041963\n",
      "[85,   499] loss: 0.050394\n",
      "[85,   599] loss: 0.056921\n",
      "[85,   699] loss: 0.048413\n",
      "[86,    99] loss: 0.045097\n",
      "[86,   199] loss: 0.058350\n",
      "[86,   299] loss: 0.059687\n",
      "[86,   399] loss: 0.039654\n",
      "[86,   499] loss: 0.048887\n",
      "[86,   599] loss: 0.054928\n",
      "[86,   699] loss: 0.046618\n",
      "[87,    99] loss: 0.043518\n",
      "[87,   199] loss: 0.056027\n",
      "[87,   299] loss: 0.057885\n",
      "[87,   399] loss: 0.038240\n",
      "[87,   499] loss: 0.046798\n",
      "[87,   599] loss: 0.052663\n",
      "[87,   699] loss: 0.045437\n",
      "[88,    99] loss: 0.043787\n",
      "[88,   199] loss: 0.054294\n",
      "[88,   299] loss: 0.056480\n",
      "[88,   399] loss: 0.037749\n",
      "[88,   499] loss: 0.046882\n",
      "[88,   599] loss: 0.052052\n",
      "[88,   699] loss: 0.044732\n",
      "[89,    99] loss: 0.042150\n",
      "[89,   199] loss: 0.051973\n",
      "[89,   299] loss: 0.055167\n",
      "[89,   399] loss: 0.036577\n",
      "[89,   499] loss: 0.045188\n",
      "[89,   599] loss: 0.049568\n",
      "[89,   699] loss: 0.042026\n",
      "[90,    99] loss: 0.040172\n",
      "[90,   199] loss: 0.049933\n",
      "[90,   299] loss: 0.053456\n",
      "[90,   399] loss: 0.034388\n",
      "[90,   499] loss: 0.043387\n",
      "[90,   599] loss: 0.048746\n",
      "[90,   699] loss: 0.041098\n",
      "[91,    99] loss: 0.039787\n",
      "[91,   199] loss: 0.048632\n",
      "[91,   299] loss: 0.052483\n",
      "[91,   399] loss: 0.033911\n",
      "[91,   499] loss: 0.042726\n",
      "[91,   599] loss: 0.046814\n",
      "[91,   699] loss: 0.039362\n",
      "[92,    99] loss: 0.037690\n",
      "[92,   199] loss: 0.046680\n",
      "[92,   299] loss: 0.050813\n",
      "[92,   399] loss: 0.032787\n",
      "[92,   499] loss: 0.041363\n",
      "[92,   599] loss: 0.046002\n",
      "[92,   699] loss: 0.037816\n",
      "[93,    99] loss: 0.036135\n",
      "[93,   199] loss: 0.044682\n",
      "[93,   299] loss: 0.049782\n",
      "[93,   399] loss: 0.031398\n",
      "[93,   499] loss: 0.039161\n",
      "[93,   599] loss: 0.043933\n",
      "[93,   699] loss: 0.035966\n",
      "[94,    99] loss: 0.035993\n",
      "[94,   199] loss: 0.043144\n",
      "[94,   299] loss: 0.048542\n",
      "[94,   399] loss: 0.030185\n",
      "[94,   499] loss: 0.037795\n",
      "[94,   599] loss: 0.043031\n",
      "[94,   699] loss: 0.035010\n",
      "[95,    99] loss: 0.033729\n",
      "[95,   199] loss: 0.041724\n",
      "[95,   299] loss: 0.047167\n",
      "[95,   399] loss: 0.029092\n",
      "[95,   499] loss: 0.037194\n",
      "[95,   599] loss: 0.042491\n",
      "[95,   699] loss: 0.034116\n",
      "[96,    99] loss: 0.033177\n",
      "[96,   199] loss: 0.039877\n",
      "[96,   299] loss: 0.046252\n",
      "[96,   399] loss: 0.028440\n",
      "[96,   499] loss: 0.035078\n",
      "[96,   599] loss: 0.039910\n",
      "[96,   699] loss: 0.032049\n",
      "[97,    99] loss: 0.031940\n",
      "[97,   199] loss: 0.038827\n",
      "[97,   299] loss: 0.045114\n",
      "[97,   399] loss: 0.027271\n",
      "[97,   499] loss: 0.034431\n",
      "[97,   599] loss: 0.039199\n",
      "[97,   699] loss: 0.030934\n",
      "[98,    99] loss: 0.031330\n",
      "[98,   199] loss: 0.037029\n",
      "[98,   299] loss: 0.043844\n",
      "[98,   399] loss: 0.026430\n",
      "[98,   499] loss: 0.032569\n",
      "[98,   599] loss: 0.037883\n",
      "[98,   699] loss: 0.029342\n",
      "[99,    99] loss: 0.030262\n",
      "[99,   199] loss: 0.035583\n",
      "[99,   299] loss: 0.041914\n",
      "[99,   399] loss: 0.025101\n",
      "[99,   499] loss: 0.031712\n",
      "[99,   599] loss: 0.036705\n",
      "[99,   699] loss: 0.028344\n",
      "[100,    99] loss: 0.029692\n",
      "[100,   199] loss: 0.034329\n",
      "[100,   299] loss: 0.041379\n",
      "[100,   399] loss: 0.024284\n",
      "[100,   499] loss: 0.030629\n",
      "[100,   599] loss: 0.036485\n",
      "[100,   699] loss: 0.027370\n",
      "Finished Training\n",
      "[1,    99] loss: 0.702871\n",
      "[1,   199] loss: 0.692036\n",
      "[1,   299] loss: 0.690868\n",
      "[1,   399] loss: 0.691509\n",
      "[1,   499] loss: 0.684084\n",
      "[1,   599] loss: 0.678347\n",
      "[1,   699] loss: 0.684874\n",
      "[2,    99] loss: 0.676071\n",
      "[2,   199] loss: 0.681106\n",
      "[2,   299] loss: 0.677717\n",
      "[2,   399] loss: 0.679263\n",
      "[2,   499] loss: 0.671949\n",
      "[2,   599] loss: 0.660736\n",
      "[2,   699] loss: 0.668024\n",
      "[3,    99] loss: 0.656026\n",
      "[3,   199] loss: 0.667855\n",
      "[3,   299] loss: 0.664685\n",
      "[3,   399] loss: 0.665726\n",
      "[3,   499] loss: 0.657726\n",
      "[3,   599] loss: 0.637575\n",
      "[3,   699] loss: 0.648905\n",
      "[4,    99] loss: 0.633557\n",
      "[4,   199] loss: 0.650449\n",
      "[4,   299] loss: 0.649884\n",
      "[4,   399] loss: 0.649337\n",
      "[4,   499] loss: 0.639761\n",
      "[4,   599] loss: 0.608779\n",
      "[4,   699] loss: 0.630305\n",
      "[5,    99] loss: 0.611189\n",
      "[5,   199] loss: 0.629481\n",
      "[5,   299] loss: 0.632816\n",
      "[5,   399] loss: 0.631826\n",
      "[5,   499] loss: 0.618063\n",
      "[5,   599] loss: 0.577145\n",
      "[5,   699] loss: 0.610436\n",
      "[6,    99] loss: 0.589066\n",
      "[6,   199] loss: 0.605037\n",
      "[6,   299] loss: 0.613163\n",
      "[6,   399] loss: 0.612562\n",
      "[6,   499] loss: 0.594177\n",
      "[6,   599] loss: 0.542778\n",
      "[6,   699] loss: 0.589511\n",
      "[7,    99] loss: 0.567022\n",
      "[7,   199] loss: 0.579340\n",
      "[7,   299] loss: 0.592280\n",
      "[7,   399] loss: 0.593199\n",
      "[7,   499] loss: 0.569812\n",
      "[7,   599] loss: 0.508747\n",
      "[7,   699] loss: 0.567481\n",
      "[8,    99] loss: 0.544069\n",
      "[8,   199] loss: 0.552709\n",
      "[8,   299] loss: 0.570779\n",
      "[8,   399] loss: 0.572924\n",
      "[8,   499] loss: 0.544378\n",
      "[8,   599] loss: 0.476008\n",
      "[8,   699] loss: 0.545376\n",
      "[9,    99] loss: 0.521805\n",
      "[9,   199] loss: 0.526403\n",
      "[9,   299] loss: 0.549017\n",
      "[9,   399] loss: 0.551675\n",
      "[9,   499] loss: 0.519959\n",
      "[9,   599] loss: 0.445920\n",
      "[9,   699] loss: 0.523618\n",
      "[10,    99] loss: 0.500116\n",
      "[10,   199] loss: 0.500729\n",
      "[10,   299] loss: 0.527683\n",
      "[10,   399] loss: 0.530417\n",
      "[10,   499] loss: 0.496337\n",
      "[10,   599] loss: 0.418858\n",
      "[10,   699] loss: 0.501848\n",
      "[11,    99] loss: 0.479690\n",
      "[11,   199] loss: 0.475720\n",
      "[11,   299] loss: 0.506554\n",
      "[11,   399] loss: 0.509524\n",
      "[11,   499] loss: 0.473404\n",
      "[11,   599] loss: 0.394007\n",
      "[11,   699] loss: 0.480248\n",
      "[12,    99] loss: 0.459307\n",
      "[12,   199] loss: 0.452182\n",
      "[12,   299] loss: 0.486720\n",
      "[12,   399] loss: 0.489213\n",
      "[12,   499] loss: 0.451627\n",
      "[12,   599] loss: 0.371186\n",
      "[12,   699] loss: 0.459570\n",
      "[13,    99] loss: 0.440476\n",
      "[13,   199] loss: 0.429786\n",
      "[13,   299] loss: 0.468021\n",
      "[13,   399] loss: 0.469932\n",
      "[13,   499] loss: 0.430905\n",
      "[13,   599] loss: 0.350549\n",
      "[13,   699] loss: 0.439603\n",
      "[14,    99] loss: 0.422329\n",
      "[14,   199] loss: 0.408419\n",
      "[14,   299] loss: 0.449895\n",
      "[14,   399] loss: 0.451444\n",
      "[14,   499] loss: 0.411209\n",
      "[14,   599] loss: 0.331430\n",
      "[14,   699] loss: 0.420611\n",
      "[15,    99] loss: 0.404762\n",
      "[15,   199] loss: 0.388123\n",
      "[15,   299] loss: 0.432611\n",
      "[15,   399] loss: 0.433525\n",
      "[15,   499] loss: 0.393067\n",
      "[15,   599] loss: 0.313792\n",
      "[15,   699] loss: 0.402202\n",
      "[16,    99] loss: 0.387934\n",
      "[16,   199] loss: 0.369354\n",
      "[16,   299] loss: 0.416426\n",
      "[16,   399] loss: 0.416384\n",
      "[16,   499] loss: 0.376187\n",
      "[16,   599] loss: 0.297237\n",
      "[16,   699] loss: 0.384487\n",
      "[17,    99] loss: 0.371611\n",
      "[17,   199] loss: 0.351167\n",
      "[17,   299] loss: 0.400502\n",
      "[17,   399] loss: 0.400259\n",
      "[17,   499] loss: 0.360941\n",
      "[17,   599] loss: 0.282460\n",
      "[17,   699] loss: 0.367535\n",
      "[18,    99] loss: 0.356030\n",
      "[18,   199] loss: 0.334112\n",
      "[18,   299] loss: 0.384603\n",
      "[18,   399] loss: 0.385126\n",
      "[18,   499] loss: 0.346785\n",
      "[18,   599] loss: 0.268423\n",
      "[18,   699] loss: 0.350964\n",
      "[19,    99] loss: 0.341242\n",
      "[19,   199] loss: 0.317971\n",
      "[19,   299] loss: 0.369676\n",
      "[19,   399] loss: 0.370115\n",
      "[19,   499] loss: 0.333279\n",
      "[19,   599] loss: 0.255771\n",
      "[19,   699] loss: 0.334847\n",
      "[20,    99] loss: 0.326451\n",
      "[20,   199] loss: 0.303200\n",
      "[20,   299] loss: 0.355414\n",
      "[20,   399] loss: 0.355774\n",
      "[20,   499] loss: 0.320445\n",
      "[20,   599] loss: 0.243780\n",
      "[20,   699] loss: 0.319307\n",
      "[21,    99] loss: 0.311543\n",
      "[21,   199] loss: 0.288684\n",
      "[21,   299] loss: 0.341922\n",
      "[21,   399] loss: 0.341588\n",
      "[21,   499] loss: 0.308019\n",
      "[21,   599] loss: 0.232521\n",
      "[21,   699] loss: 0.305020\n",
      "[22,    99] loss: 0.297623\n",
      "[22,   199] loss: 0.275444\n",
      "[22,   299] loss: 0.329398\n",
      "[22,   399] loss: 0.329667\n",
      "[22,   499] loss: 0.296928\n",
      "[22,   599] loss: 0.221459\n",
      "[22,   699] loss: 0.290689\n",
      "[23,    99] loss: 0.284629\n",
      "[23,   199] loss: 0.262700\n",
      "[23,   299] loss: 0.316985\n",
      "[23,   399] loss: 0.316562\n",
      "[23,   499] loss: 0.286384\n",
      "[23,   599] loss: 0.210953\n",
      "[23,   699] loss: 0.276564\n",
      "[24,    99] loss: 0.272053\n",
      "[24,   199] loss: 0.251503\n",
      "[24,   299] loss: 0.305460\n",
      "[24,   399] loss: 0.304063\n",
      "[24,   499] loss: 0.276167\n",
      "[24,   599] loss: 0.200799\n",
      "[24,   699] loss: 0.263301\n",
      "[25,    99] loss: 0.259751\n",
      "[25,   199] loss: 0.240108\n",
      "[25,   299] loss: 0.293988\n",
      "[25,   399] loss: 0.291946\n",
      "[25,   499] loss: 0.266046\n",
      "[25,   599] loss: 0.191681\n",
      "[25,   699] loss: 0.250847\n",
      "[26,    99] loss: 0.248369\n",
      "[26,   199] loss: 0.229421\n",
      "[26,   299] loss: 0.283847\n",
      "[26,   399] loss: 0.280636\n",
      "[26,   499] loss: 0.255822\n",
      "[26,   599] loss: 0.183138\n",
      "[26,   699] loss: 0.238238\n",
      "[27,    99] loss: 0.237339\n",
      "[27,   199] loss: 0.218803\n",
      "[27,   299] loss: 0.273980\n",
      "[27,   399] loss: 0.269767\n",
      "[27,   499] loss: 0.245524\n",
      "[27,   599] loss: 0.175376\n",
      "[27,   699] loss: 0.227223\n",
      "[28,    99] loss: 0.226778\n",
      "[28,   199] loss: 0.208480\n",
      "[28,   299] loss: 0.263430\n",
      "[28,   399] loss: 0.260819\n",
      "[28,   499] loss: 0.235799\n",
      "[28,   599] loss: 0.167605\n",
      "[28,   699] loss: 0.216299\n",
      "[29,    99] loss: 0.216939\n",
      "[29,   199] loss: 0.198513\n",
      "[29,   299] loss: 0.253292\n",
      "[29,   399] loss: 0.251243\n",
      "[29,   499] loss: 0.226083\n",
      "[29,   599] loss: 0.160168\n",
      "[29,   699] loss: 0.205795\n",
      "[30,    99] loss: 0.207960\n",
      "[30,   199] loss: 0.188736\n",
      "[30,   299] loss: 0.243549\n",
      "[30,   399] loss: 0.242424\n",
      "[30,   499] loss: 0.216528\n",
      "[30,   599] loss: 0.153014\n",
      "[30,   699] loss: 0.196135\n",
      "[31,    99] loss: 0.199232\n",
      "[31,   199] loss: 0.179762\n",
      "[31,   299] loss: 0.233974\n",
      "[31,   399] loss: 0.234494\n",
      "[31,   499] loss: 0.207459\n",
      "[31,   599] loss: 0.146047\n",
      "[31,   699] loss: 0.186942\n",
      "[32,    99] loss: 0.191241\n",
      "[32,   199] loss: 0.171149\n",
      "[32,   299] loss: 0.225441\n",
      "[32,   399] loss: 0.226715\n",
      "[32,   499] loss: 0.198810\n",
      "[32,   599] loss: 0.139322\n",
      "[32,   699] loss: 0.178490\n",
      "[33,    99] loss: 0.183640\n",
      "[33,   199] loss: 0.163215\n",
      "[33,   299] loss: 0.217440\n",
      "[33,   399] loss: 0.219481\n",
      "[33,   499] loss: 0.190602\n",
      "[33,   599] loss: 0.132937\n",
      "[33,   699] loss: 0.170565\n",
      "[34,    99] loss: 0.176307\n",
      "[34,   199] loss: 0.155529\n",
      "[34,   299] loss: 0.210768\n",
      "[34,   399] loss: 0.212073\n",
      "[34,   499] loss: 0.183018\n",
      "[34,   599] loss: 0.125918\n",
      "[34,   699] loss: 0.162481\n",
      "[35,    99] loss: 0.169475\n",
      "[35,   199] loss: 0.148288\n",
      "[35,   299] loss: 0.202580\n",
      "[35,   399] loss: 0.204957\n",
      "[35,   499] loss: 0.175796\n",
      "[35,   599] loss: 0.120288\n",
      "[35,   699] loss: 0.155274\n",
      "[36,    99] loss: 0.162495\n",
      "[36,   199] loss: 0.141487\n",
      "[36,   299] loss: 0.195524\n",
      "[36,   399] loss: 0.199001\n",
      "[36,   499] loss: 0.169082\n",
      "[36,   599] loss: 0.114455\n",
      "[36,   699] loss: 0.148474\n",
      "[37,    99] loss: 0.156359\n",
      "[37,   199] loss: 0.134497\n",
      "[37,   299] loss: 0.188337\n",
      "[37,   399] loss: 0.192158\n",
      "[37,   499] loss: 0.162205\n",
      "[37,   599] loss: 0.109112\n",
      "[37,   699] loss: 0.142071\n",
      "[38,    99] loss: 0.150548\n",
      "[38,   199] loss: 0.128457\n",
      "[38,   299] loss: 0.181230\n",
      "[38,   399] loss: 0.186858\n",
      "[38,   499] loss: 0.156223\n",
      "[38,   599] loss: 0.103250\n",
      "[38,   699] loss: 0.135604\n",
      "[39,    99] loss: 0.144510\n",
      "[39,   199] loss: 0.122576\n",
      "[39,   299] loss: 0.174680\n",
      "[39,   399] loss: 0.180120\n",
      "[39,   499] loss: 0.149931\n",
      "[39,   599] loss: 0.098021\n",
      "[39,   699] loss: 0.129231\n",
      "[40,    99] loss: 0.139481\n",
      "[40,   199] loss: 0.117160\n",
      "[40,   299] loss: 0.168023\n",
      "[40,   399] loss: 0.175058\n",
      "[40,   499] loss: 0.144264\n",
      "[40,   599] loss: 0.092703\n",
      "[40,   699] loss: 0.123435\n",
      "[41,    99] loss: 0.134745\n",
      "[41,   199] loss: 0.111639\n",
      "[41,   299] loss: 0.161413\n",
      "[41,   399] loss: 0.170493\n",
      "[41,   499] loss: 0.138662\n",
      "[41,   599] loss: 0.088217\n",
      "[41,   699] loss: 0.116975\n",
      "[42,    99] loss: 0.130329\n",
      "[42,   199] loss: 0.105996\n",
      "[42,   299] loss: 0.155608\n",
      "[42,   399] loss: 0.165127\n",
      "[42,   499] loss: 0.133981\n",
      "[42,   599] loss: 0.083507\n",
      "[42,   699] loss: 0.112406\n",
      "[43,    99] loss: 0.125711\n",
      "[43,   199] loss: 0.101562\n",
      "[43,   299] loss: 0.150153\n",
      "[43,   399] loss: 0.161399\n",
      "[43,   499] loss: 0.128896\n",
      "[43,   599] loss: 0.079293\n",
      "[43,   699] loss: 0.106842\n",
      "[44,    99] loss: 0.121383\n",
      "[44,   199] loss: 0.096633\n",
      "[44,   299] loss: 0.144314\n",
      "[44,   399] loss: 0.156662\n",
      "[44,   499] loss: 0.124506\n",
      "[44,   599] loss: 0.075341\n",
      "[44,   699] loss: 0.102095\n",
      "[45,    99] loss: 0.117101\n",
      "[45,   199] loss: 0.092762\n",
      "[45,   299] loss: 0.139511\n",
      "[45,   399] loss: 0.150617\n",
      "[45,   499] loss: 0.119793\n",
      "[45,   599] loss: 0.071371\n",
      "[45,   699] loss: 0.097656\n",
      "[46,    99] loss: 0.113328\n",
      "[46,   199] loss: 0.088412\n",
      "[46,   299] loss: 0.134303\n",
      "[46,   399] loss: 0.147029\n",
      "[46,   499] loss: 0.115882\n",
      "[46,   599] loss: 0.067565\n",
      "[46,   699] loss: 0.092757\n",
      "[47,    99] loss: 0.109629\n",
      "[47,   199] loss: 0.084385\n",
      "[47,   299] loss: 0.129408\n",
      "[47,   399] loss: 0.141579\n",
      "[47,   499] loss: 0.112295\n",
      "[47,   599] loss: 0.064303\n",
      "[47,   699] loss: 0.089177\n",
      "[48,    99] loss: 0.105524\n",
      "[48,   199] loss: 0.080367\n",
      "[48,   299] loss: 0.125457\n",
      "[48,   399] loss: 0.135832\n",
      "[48,   499] loss: 0.108214\n",
      "[48,   599] loss: 0.061029\n",
      "[48,   699] loss: 0.085503\n",
      "[49,    99] loss: 0.101575\n",
      "[49,   199] loss: 0.077081\n",
      "[49,   299] loss: 0.120929\n",
      "[49,   399] loss: 0.132176\n",
      "[49,   499] loss: 0.104941\n",
      "[49,   599] loss: 0.057613\n",
      "[49,   699] loss: 0.082059\n",
      "[50,    99] loss: 0.098244\n",
      "[50,   199] loss: 0.073877\n",
      "[50,   299] loss: 0.116871\n",
      "[50,   399] loss: 0.127387\n",
      "[50,   499] loss: 0.101331\n",
      "[50,   599] loss: 0.054647\n",
      "[50,   699] loss: 0.078125\n",
      "[51,    99] loss: 0.094328\n",
      "[51,   199] loss: 0.070463\n",
      "[51,   299] loss: 0.112327\n",
      "[51,   399] loss: 0.123030\n",
      "[51,   499] loss: 0.098124\n",
      "[51,   599] loss: 0.052055\n",
      "[51,   699] loss: 0.074677\n",
      "[52,    99] loss: 0.090781\n",
      "[52,   199] loss: 0.067601\n",
      "[52,   299] loss: 0.108414\n",
      "[52,   399] loss: 0.118535\n",
      "[52,   499] loss: 0.094677\n",
      "[52,   599] loss: 0.049481\n",
      "[52,   699] loss: 0.071809\n",
      "[53,    99] loss: 0.087315\n",
      "[53,   199] loss: 0.064696\n",
      "[53,   299] loss: 0.104836\n",
      "[53,   399] loss: 0.113221\n",
      "[53,   499] loss: 0.091751\n",
      "[53,   599] loss: 0.046926\n",
      "[53,   699] loss: 0.068551\n",
      "[54,    99] loss: 0.083802\n",
      "[54,   199] loss: 0.062254\n",
      "[54,   299] loss: 0.101023\n",
      "[54,   399] loss: 0.108652\n",
      "[54,   499] loss: 0.088625\n",
      "[54,   599] loss: 0.044515\n",
      "[54,   699] loss: 0.066386\n",
      "[55,    99] loss: 0.080177\n",
      "[55,   199] loss: 0.059228\n",
      "[55,   299] loss: 0.097940\n",
      "[55,   399] loss: 0.104260\n",
      "[55,   499] loss: 0.086074\n",
      "[55,   599] loss: 0.042497\n",
      "[55,   699] loss: 0.063148\n",
      "[56,    99] loss: 0.077298\n",
      "[56,   199] loss: 0.056922\n",
      "[56,   299] loss: 0.094069\n",
      "[56,   399] loss: 0.100179\n",
      "[56,   499] loss: 0.083160\n",
      "[56,   599] loss: 0.040469\n",
      "[56,   699] loss: 0.060313\n",
      "[57,    99] loss: 0.074068\n",
      "[57,   199] loss: 0.054658\n",
      "[57,   299] loss: 0.090687\n",
      "[57,   399] loss: 0.096563\n",
      "[57,   499] loss: 0.080530\n",
      "[57,   599] loss: 0.038840\n",
      "[57,   699] loss: 0.057385\n",
      "[58,    99] loss: 0.071243\n",
      "[58,   199] loss: 0.052096\n",
      "[58,   299] loss: 0.087952\n",
      "[58,   399] loss: 0.092268\n",
      "[58,   499] loss: 0.077555\n",
      "[58,   599] loss: 0.036795\n",
      "[58,   699] loss: 0.055201\n",
      "[59,    99] loss: 0.068302\n",
      "[59,   199] loss: 0.049620\n",
      "[59,   299] loss: 0.084754\n",
      "[59,   399] loss: 0.088790\n",
      "[59,   499] loss: 0.074817\n",
      "[59,   599] loss: 0.034867\n",
      "[59,   699] loss: 0.052924\n",
      "[60,    99] loss: 0.065684\n",
      "[60,   199] loss: 0.047762\n",
      "[60,   299] loss: 0.081560\n",
      "[60,   399] loss: 0.085031\n",
      "[60,   499] loss: 0.072163\n",
      "[60,   599] loss: 0.033481\n",
      "[60,   699] loss: 0.050309\n",
      "[61,    99] loss: 0.063115\n",
      "[61,   199] loss: 0.045702\n",
      "[61,   299] loss: 0.079164\n",
      "[61,   399] loss: 0.081484\n",
      "[61,   499] loss: 0.069610\n",
      "[61,   599] loss: 0.031639\n",
      "[61,   699] loss: 0.048258\n",
      "[62,    99] loss: 0.060983\n",
      "[62,   199] loss: 0.043710\n",
      "[62,   299] loss: 0.076463\n",
      "[62,   399] loss: 0.077138\n",
      "[62,   499] loss: 0.067120\n",
      "[62,   599] loss: 0.030382\n",
      "[62,   699] loss: 0.046214\n",
      "[63,    99] loss: 0.058312\n",
      "[63,   199] loss: 0.041685\n",
      "[63,   299] loss: 0.073294\n",
      "[63,   399] loss: 0.074719\n",
      "[63,   499] loss: 0.064742\n",
      "[63,   599] loss: 0.028993\n",
      "[63,   699] loss: 0.042977\n",
      "[64,    99] loss: 0.055881\n",
      "[64,   199] loss: 0.039961\n",
      "[64,   299] loss: 0.070573\n",
      "[64,   399] loss: 0.070335\n",
      "[64,   499] loss: 0.062700\n",
      "[64,   599] loss: 0.027741\n",
      "[64,   699] loss: 0.041277\n",
      "[65,    99] loss: 0.054315\n",
      "[65,   199] loss: 0.037952\n",
      "[65,   299] loss: 0.067844\n",
      "[65,   399] loss: 0.068275\n",
      "[65,   499] loss: 0.060141\n",
      "[65,   599] loss: 0.026389\n",
      "[65,   699] loss: 0.039289\n",
      "[66,    99] loss: 0.051724\n",
      "[66,   199] loss: 0.036653\n",
      "[66,   299] loss: 0.065230\n",
      "[66,   399] loss: 0.064688\n",
      "[66,   499] loss: 0.058415\n",
      "[66,   599] loss: 0.025243\n",
      "[66,   699] loss: 0.037180\n",
      "[67,    99] loss: 0.048565\n",
      "[67,   199] loss: 0.035009\n",
      "[67,   299] loss: 0.062315\n",
      "[67,   399] loss: 0.061456\n",
      "[67,   499] loss: 0.056087\n",
      "[67,   599] loss: 0.024214\n",
      "[67,   699] loss: 0.035390\n",
      "[68,    99] loss: 0.048021\n",
      "[68,   199] loss: 0.033361\n",
      "[68,   299] loss: 0.059890\n",
      "[68,   399] loss: 0.059389\n",
      "[68,   499] loss: 0.054175\n",
      "[68,   599] loss: 0.022987\n",
      "[68,   699] loss: 0.033367\n",
      "[69,    99] loss: 0.045749\n",
      "[69,   199] loss: 0.032064\n",
      "[69,   299] loss: 0.057658\n",
      "[69,   399] loss: 0.056481\n",
      "[69,   499] loss: 0.052125\n",
      "[69,   599] loss: 0.022209\n",
      "[69,   699] loss: 0.032090\n",
      "[70,    99] loss: 0.043109\n",
      "[70,   199] loss: 0.030620\n",
      "[70,   299] loss: 0.055376\n",
      "[70,   399] loss: 0.054196\n",
      "[70,   499] loss: 0.050122\n",
      "[70,   599] loss: 0.020885\n",
      "[70,   699] loss: 0.030510\n",
      "[71,    99] loss: 0.041713\n",
      "[71,   199] loss: 0.029112\n",
      "[71,   299] loss: 0.053267\n",
      "[71,   399] loss: 0.052437\n",
      "[71,   499] loss: 0.048352\n",
      "[71,   599] loss: 0.019966\n",
      "[71,   699] loss: 0.029149\n",
      "[72,    99] loss: 0.040006\n",
      "[72,   199] loss: 0.027791\n",
      "[72,   299] loss: 0.051616\n",
      "[72,   399] loss: 0.049442\n",
      "[72,   499] loss: 0.046273\n",
      "[72,   599] loss: 0.019162\n",
      "[72,   699] loss: 0.027958\n",
      "[73,    99] loss: 0.039204\n",
      "[73,   199] loss: 0.026414\n",
      "[73,   299] loss: 0.049169\n",
      "[73,   399] loss: 0.046906\n",
      "[73,   499] loss: 0.044608\n",
      "[73,   599] loss: 0.018511\n",
      "[73,   699] loss: 0.026270\n",
      "[74,    99] loss: 0.038322\n",
      "[74,   199] loss: 0.025256\n",
      "[74,   299] loss: 0.047570\n",
      "[74,   399] loss: 0.044399\n",
      "[74,   499] loss: 0.042921\n",
      "[74,   599] loss: 0.017879\n",
      "[74,   699] loss: 0.025163\n",
      "[75,    99] loss: 0.035309\n",
      "[75,   199] loss: 0.024055\n",
      "[75,   299] loss: 0.045456\n",
      "[75,   399] loss: 0.042973\n",
      "[75,   499] loss: 0.041043\n",
      "[75,   599] loss: 0.017015\n",
      "[75,   699] loss: 0.023725\n",
      "[76,    99] loss: 0.034046\n",
      "[76,   199] loss: 0.023113\n",
      "[76,   299] loss: 0.043873\n",
      "[76,   399] loss: 0.040459\n",
      "[76,   499] loss: 0.040093\n",
      "[76,   599] loss: 0.016220\n",
      "[76,   699] loss: 0.022887\n",
      "[77,    99] loss: 0.033014\n",
      "[77,   199] loss: 0.021884\n",
      "[77,   299] loss: 0.042127\n",
      "[77,   399] loss: 0.038023\n",
      "[77,   499] loss: 0.038673\n",
      "[77,   599] loss: 0.015710\n",
      "[77,   699] loss: 0.021612\n",
      "[78,    99] loss: 0.031874\n",
      "[78,   199] loss: 0.020896\n",
      "[78,   299] loss: 0.040239\n",
      "[78,   399] loss: 0.036458\n",
      "[78,   499] loss: 0.036711\n",
      "[78,   599] loss: 0.015091\n",
      "[78,   699] loss: 0.020507\n",
      "[79,    99] loss: 0.030325\n",
      "[79,   199] loss: 0.020214\n",
      "[79,   299] loss: 0.039110\n",
      "[79,   399] loss: 0.035118\n",
      "[79,   499] loss: 0.035551\n",
      "[79,   599] loss: 0.014492\n",
      "[79,   699] loss: 0.019576\n",
      "[80,    99] loss: 0.028975\n",
      "[80,   199] loss: 0.019418\n",
      "[80,   299] loss: 0.037632\n",
      "[80,   399] loss: 0.033099\n",
      "[80,   499] loss: 0.033955\n",
      "[80,   599] loss: 0.013793\n",
      "[80,   699] loss: 0.018734\n",
      "[81,    99] loss: 0.029025\n",
      "[81,   199] loss: 0.018652\n",
      "[81,   299] loss: 0.036963\n",
      "[81,   399] loss: 0.030598\n",
      "[81,   499] loss: 0.032337\n",
      "[81,   599] loss: 0.013685\n",
      "[81,   699] loss: 0.017839\n",
      "[82,    99] loss: 0.026683\n",
      "[82,   199] loss: 0.017504\n",
      "[82,   299] loss: 0.034935\n",
      "[82,   399] loss: 0.029910\n",
      "[82,   499] loss: 0.031593\n",
      "[82,   599] loss: 0.013041\n",
      "[82,   699] loss: 0.017006\n",
      "[83,    99] loss: 0.025309\n",
      "[83,   199] loss: 0.016745\n",
      "[83,   299] loss: 0.033697\n",
      "[83,   399] loss: 0.028425\n",
      "[83,   499] loss: 0.030055\n",
      "[83,   599] loss: 0.012421\n",
      "[83,   699] loss: 0.016249\n",
      "[84,    99] loss: 0.024877\n",
      "[84,   199] loss: 0.015884\n",
      "[84,   299] loss: 0.032512\n",
      "[84,   399] loss: 0.027199\n",
      "[84,   499] loss: 0.029117\n",
      "[84,   599] loss: 0.012104\n",
      "[84,   699] loss: 0.015433\n",
      "[85,    99] loss: 0.023783\n",
      "[85,   199] loss: 0.015268\n",
      "[85,   299] loss: 0.030964\n",
      "[85,   399] loss: 0.025181\n",
      "[85,   499] loss: 0.028153\n",
      "[85,   599] loss: 0.011602\n",
      "[85,   699] loss: 0.014500\n",
      "[86,    99] loss: 0.022770\n",
      "[86,   199] loss: 0.014504\n",
      "[86,   299] loss: 0.029961\n",
      "[86,   399] loss: 0.024825\n",
      "[86,   499] loss: 0.026927\n",
      "[86,   599] loss: 0.011197\n",
      "[86,   699] loss: 0.013863\n",
      "[87,    99] loss: 0.021543\n",
      "[87,   199] loss: 0.013752\n",
      "[87,   299] loss: 0.028970\n",
      "[87,   399] loss: 0.023494\n",
      "[87,   499] loss: 0.025759\n",
      "[87,   599] loss: 0.010940\n",
      "[87,   699] loss: 0.013242\n",
      "[88,    99] loss: 0.021011\n",
      "[88,   199] loss: 0.013153\n",
      "[88,   299] loss: 0.026796\n",
      "[88,   399] loss: 0.022415\n",
      "[88,   499] loss: 0.025110\n",
      "[88,   599] loss: 0.010488\n",
      "[88,   699] loss: 0.012557\n",
      "[89,    99] loss: 0.019843\n",
      "[89,   199] loss: 0.012333\n",
      "[89,   299] loss: 0.026198\n",
      "[89,   399] loss: 0.020959\n",
      "[89,   499] loss: 0.024005\n",
      "[89,   599] loss: 0.010192\n",
      "[89,   699] loss: 0.011920\n",
      "[90,    99] loss: 0.019118\n",
      "[90,   199] loss: 0.012063\n",
      "[90,   299] loss: 0.025389\n",
      "[90,   399] loss: 0.020236\n",
      "[90,   499] loss: 0.022717\n",
      "[90,   599] loss: 0.009841\n",
      "[90,   699] loss: 0.011461\n",
      "[91,    99] loss: 0.018545\n",
      "[91,   199] loss: 0.011424\n",
      "[91,   299] loss: 0.024188\n",
      "[91,   399] loss: 0.019514\n",
      "[91,   499] loss: 0.022246\n",
      "[91,   599] loss: 0.009673\n",
      "[91,   699] loss: 0.010938\n",
      "[92,    99] loss: 0.017647\n",
      "[92,   199] loss: 0.010678\n",
      "[92,   299] loss: 0.023235\n",
      "[92,   399] loss: 0.018865\n",
      "[92,   499] loss: 0.021453\n",
      "[92,   599] loss: 0.008987\n",
      "[92,   699] loss: 0.010171\n",
      "[93,    99] loss: 0.016674\n",
      "[93,   199] loss: 0.010087\n",
      "[93,   299] loss: 0.022750\n",
      "[93,   399] loss: 0.018602\n",
      "[93,   499] loss: 0.021078\n",
      "[93,   599] loss: 0.009170\n",
      "[93,   699] loss: 0.009842\n",
      "[94,    99] loss: 0.017126\n",
      "[94,   199] loss: 0.010327\n",
      "[94,   299] loss: 0.022319\n",
      "[94,   399] loss: 0.016715\n",
      "[94,   499] loss: 0.019348\n",
      "[94,   599] loss: 0.008868\n",
      "[94,   699] loss: 0.009436\n",
      "[95,    99] loss: 0.015659\n",
      "[95,   199] loss: 0.009343\n",
      "[95,   299] loss: 0.020941\n",
      "[95,   399] loss: 0.016356\n",
      "[95,   499] loss: 0.018884\n",
      "[95,   599] loss: 0.008573\n",
      "[95,   699] loss: 0.008929\n",
      "[96,    99] loss: 0.014881\n",
      "[96,   199] loss: 0.008870\n",
      "[96,   299] loss: 0.020145\n",
      "[96,   399] loss: 0.015784\n",
      "[96,   499] loss: 0.018816\n",
      "[96,   599] loss: 0.008290\n",
      "[96,   699] loss: 0.008481\n",
      "[97,    99] loss: 0.014316\n",
      "[97,   199] loss: 0.008546\n",
      "[97,   299] loss: 0.018785\n",
      "[97,   399] loss: 0.014792\n",
      "[97,   499] loss: 0.017823\n",
      "[97,   599] loss: 0.008132\n",
      "[97,   699] loss: 0.007981\n",
      "[98,    99] loss: 0.013677\n",
      "[98,   199] loss: 0.008030\n",
      "[98,   299] loss: 0.018927\n",
      "[98,   399] loss: 0.014105\n",
      "[98,   499] loss: 0.016949\n",
      "[98,   599] loss: 0.007925\n",
      "[98,   699] loss: 0.007631\n",
      "[99,    99] loss: 0.012942\n",
      "[99,   199] loss: 0.007763\n",
      "[99,   299] loss: 0.018893\n",
      "[99,   399] loss: 0.013314\n",
      "[99,   499] loss: 0.015960\n",
      "[99,   599] loss: 0.007847\n",
      "[99,   699] loss: 0.007292\n",
      "[100,    99] loss: 0.012881\n",
      "[100,   199] loss: 0.007370\n",
      "[100,   299] loss: 0.017008\n",
      "[100,   399] loss: 0.012704\n",
      "[100,   499] loss: 0.015863\n",
      "[100,   599] loss: 0.007324\n",
      "[100,   699] loss: 0.006950\n",
      "Finished Training\n",
      "[1,    99] loss: 0.688344\n",
      "[1,   199] loss: 0.702079\n",
      "[1,   299] loss: 0.685212\n",
      "[1,   399] loss: 0.682670\n",
      "[1,   499] loss: 0.690992\n",
      "[1,   599] loss: 0.685413\n",
      "[1,   699] loss: 0.685035\n",
      "[2,    99] loss: 0.668761\n",
      "[2,   199] loss: 0.685180\n",
      "[2,   299] loss: 0.669497\n",
      "[2,   399] loss: 0.668830\n",
      "[2,   499] loss: 0.675150\n",
      "[2,   599] loss: 0.667822\n",
      "[2,   699] loss: 0.668864\n",
      "[3,    99] loss: 0.653325\n",
      "[3,   199] loss: 0.671150\n",
      "[3,   299] loss: 0.654499\n",
      "[3,   399] loss: 0.653409\n",
      "[3,   499] loss: 0.661049\n",
      "[3,   599] loss: 0.649029\n",
      "[3,   699] loss: 0.653374\n",
      "[4,    99] loss: 0.638597\n",
      "[4,   199] loss: 0.658871\n",
      "[4,   299] loss: 0.639161\n",
      "[4,   399] loss: 0.637890\n",
      "[4,   499] loss: 0.647229\n",
      "[4,   599] loss: 0.630162\n",
      "[4,   699] loss: 0.638112\n",
      "[5,    99] loss: 0.624224\n",
      "[5,   199] loss: 0.648723\n",
      "[5,   299] loss: 0.624375\n",
      "[5,   399] loss: 0.622123\n",
      "[5,   499] loss: 0.634555\n",
      "[5,   599] loss: 0.612248\n",
      "[5,   699] loss: 0.624371\n",
      "[6,    99] loss: 0.610926\n",
      "[6,   199] loss: 0.639838\n",
      "[6,   299] loss: 0.610303\n",
      "[6,   399] loss: 0.606502\n",
      "[6,   499] loss: 0.622656\n",
      "[6,   599] loss: 0.595287\n",
      "[6,   699] loss: 0.611167\n",
      "[7,    99] loss: 0.597551\n",
      "[7,   199] loss: 0.631142\n",
      "[7,   299] loss: 0.596606\n",
      "[7,   399] loss: 0.591435\n",
      "[7,   499] loss: 0.609944\n",
      "[7,   599] loss: 0.578793\n",
      "[7,   699] loss: 0.598360\n",
      "[8,    99] loss: 0.583794\n",
      "[8,   199] loss: 0.622669\n",
      "[8,   299] loss: 0.582874\n",
      "[8,   399] loss: 0.576289\n",
      "[8,   499] loss: 0.596720\n",
      "[8,   599] loss: 0.563499\n",
      "[8,   699] loss: 0.585483\n",
      "[9,    99] loss: 0.569490\n",
      "[9,   199] loss: 0.613314\n",
      "[9,   299] loss: 0.569432\n",
      "[9,   399] loss: 0.561252\n",
      "[9,   499] loss: 0.582978\n",
      "[9,   599] loss: 0.548605\n",
      "[9,   699] loss: 0.572308\n",
      "[10,    99] loss: 0.554994\n",
      "[10,   199] loss: 0.603235\n",
      "[10,   299] loss: 0.555507\n",
      "[10,   399] loss: 0.546866\n",
      "[10,   499] loss: 0.568760\n",
      "[10,   599] loss: 0.533912\n",
      "[10,   699] loss: 0.559237\n",
      "[11,    99] loss: 0.539862\n",
      "[11,   199] loss: 0.592971\n",
      "[11,   299] loss: 0.541027\n",
      "[11,   399] loss: 0.531875\n",
      "[11,   499] loss: 0.554704\n",
      "[11,   599] loss: 0.518906\n",
      "[11,   699] loss: 0.546020\n",
      "[12,    99] loss: 0.524332\n",
      "[12,   199] loss: 0.581590\n",
      "[12,   299] loss: 0.525946\n",
      "[12,   399] loss: 0.516998\n",
      "[12,   499] loss: 0.540186\n",
      "[12,   599] loss: 0.503929\n",
      "[12,   699] loss: 0.532143\n",
      "[13,    99] loss: 0.508094\n",
      "[13,   199] loss: 0.568810\n",
      "[13,   299] loss: 0.510515\n",
      "[13,   399] loss: 0.501379\n",
      "[13,   499] loss: 0.525577\n",
      "[13,   599] loss: 0.489307\n",
      "[13,   699] loss: 0.518076\n",
      "[14,    99] loss: 0.491326\n",
      "[14,   199] loss: 0.555163\n",
      "[14,   299] loss: 0.494518\n",
      "[14,   399] loss: 0.485275\n",
      "[14,   499] loss: 0.510559\n",
      "[14,   599] loss: 0.474333\n",
      "[14,   699] loss: 0.503830\n",
      "[15,    99] loss: 0.474485\n",
      "[15,   199] loss: 0.540307\n",
      "[15,   299] loss: 0.477496\n",
      "[15,   399] loss: 0.469889\n",
      "[15,   499] loss: 0.494781\n",
      "[15,   599] loss: 0.459313\n",
      "[15,   699] loss: 0.489305\n",
      "[16,    99] loss: 0.456398\n",
      "[16,   199] loss: 0.524967\n",
      "[16,   299] loss: 0.460792\n",
      "[16,   399] loss: 0.454318\n",
      "[16,   499] loss: 0.479449\n",
      "[16,   599] loss: 0.444694\n",
      "[16,   699] loss: 0.474804\n",
      "[17,    99] loss: 0.439330\n",
      "[17,   199] loss: 0.509273\n",
      "[17,   299] loss: 0.444009\n",
      "[17,   399] loss: 0.438936\n",
      "[17,   499] loss: 0.463831\n",
      "[17,   599] loss: 0.430529\n",
      "[17,   699] loss: 0.460202\n",
      "[18,    99] loss: 0.422204\n",
      "[18,   199] loss: 0.493808\n",
      "[18,   299] loss: 0.426555\n",
      "[18,   399] loss: 0.423312\n",
      "[18,   499] loss: 0.448257\n",
      "[18,   599] loss: 0.416612\n",
      "[18,   699] loss: 0.445833\n",
      "[19,    99] loss: 0.405375\n",
      "[19,   199] loss: 0.478257\n",
      "[19,   299] loss: 0.409073\n",
      "[19,   399] loss: 0.407754\n",
      "[19,   499] loss: 0.433310\n",
      "[19,   599] loss: 0.403442\n",
      "[19,   699] loss: 0.431688\n",
      "[20,    99] loss: 0.388708\n",
      "[20,   199] loss: 0.462340\n",
      "[20,   299] loss: 0.392332\n",
      "[20,   399] loss: 0.392761\n",
      "[20,   499] loss: 0.418814\n",
      "[20,   599] loss: 0.390590\n",
      "[20,   699] loss: 0.417949\n",
      "[21,    99] loss: 0.373251\n",
      "[21,   199] loss: 0.446658\n",
      "[21,   299] loss: 0.375938\n",
      "[21,   399] loss: 0.378215\n",
      "[21,   499] loss: 0.404574\n",
      "[21,   599] loss: 0.378285\n",
      "[21,   699] loss: 0.404438\n",
      "[22,    99] loss: 0.358533\n",
      "[22,   199] loss: 0.430185\n",
      "[22,   299] loss: 0.359233\n",
      "[22,   399] loss: 0.364596\n",
      "[22,   499] loss: 0.390343\n",
      "[22,   599] loss: 0.366607\n",
      "[22,   699] loss: 0.390564\n",
      "[23,    99] loss: 0.344540\n",
      "[23,   199] loss: 0.413495\n",
      "[23,   299] loss: 0.343607\n",
      "[23,   399] loss: 0.351374\n",
      "[23,   499] loss: 0.376989\n",
      "[23,   599] loss: 0.355271\n",
      "[23,   699] loss: 0.376870\n",
      "[24,    99] loss: 0.330697\n",
      "[24,   199] loss: 0.397812\n",
      "[24,   299] loss: 0.329165\n",
      "[24,   399] loss: 0.338883\n",
      "[24,   499] loss: 0.363527\n",
      "[24,   599] loss: 0.343801\n",
      "[24,   699] loss: 0.364189\n",
      "[25,    99] loss: 0.317805\n",
      "[25,   199] loss: 0.382194\n",
      "[25,   299] loss: 0.314991\n",
      "[25,   399] loss: 0.327136\n",
      "[25,   499] loss: 0.350749\n",
      "[25,   599] loss: 0.332591\n",
      "[25,   699] loss: 0.351795\n",
      "[26,    99] loss: 0.305477\n",
      "[26,   199] loss: 0.367356\n",
      "[26,   299] loss: 0.301573\n",
      "[26,   399] loss: 0.315750\n",
      "[26,   499] loss: 0.338518\n",
      "[26,   599] loss: 0.321854\n",
      "[26,   699] loss: 0.340088\n",
      "[27,    99] loss: 0.293569\n",
      "[27,   199] loss: 0.353268\n",
      "[27,   299] loss: 0.289107\n",
      "[27,   399] loss: 0.304961\n",
      "[27,   499] loss: 0.326421\n",
      "[27,   599] loss: 0.311625\n",
      "[27,   699] loss: 0.329043\n",
      "[28,    99] loss: 0.282201\n",
      "[28,   199] loss: 0.339197\n",
      "[28,   299] loss: 0.277307\n",
      "[28,   399] loss: 0.294698\n",
      "[28,   499] loss: 0.314857\n",
      "[28,   599] loss: 0.301836\n",
      "[28,   699] loss: 0.318511\n",
      "[29,    99] loss: 0.271042\n",
      "[29,   199] loss: 0.325137\n",
      "[29,   299] loss: 0.266104\n",
      "[29,   399] loss: 0.285022\n",
      "[29,   499] loss: 0.303075\n",
      "[29,   599] loss: 0.292530\n",
      "[29,   699] loss: 0.307899\n",
      "[30,    99] loss: 0.261332\n",
      "[30,   199] loss: 0.311998\n",
      "[30,   299] loss: 0.256232\n",
      "[30,   399] loss: 0.275227\n",
      "[30,   499] loss: 0.291509\n",
      "[30,   599] loss: 0.283727\n",
      "[30,   699] loss: 0.297065\n",
      "[31,    99] loss: 0.250467\n",
      "[31,   199] loss: 0.299156\n",
      "[31,   299] loss: 0.246387\n",
      "[31,   399] loss: 0.266619\n",
      "[31,   499] loss: 0.280554\n",
      "[31,   599] loss: 0.275084\n",
      "[31,   699] loss: 0.286800\n",
      "[32,    99] loss: 0.241249\n",
      "[32,   199] loss: 0.286153\n",
      "[32,   299] loss: 0.237299\n",
      "[32,   399] loss: 0.256738\n",
      "[32,   499] loss: 0.269978\n",
      "[32,   599] loss: 0.267543\n",
      "[32,   699] loss: 0.277730\n",
      "[33,    99] loss: 0.232131\n",
      "[33,   199] loss: 0.273953\n",
      "[33,   299] loss: 0.227914\n",
      "[33,   399] loss: 0.247383\n",
      "[33,   499] loss: 0.259471\n",
      "[33,   599] loss: 0.259462\n",
      "[33,   699] loss: 0.268347\n",
      "[34,    99] loss: 0.223503\n",
      "[34,   199] loss: 0.261093\n",
      "[34,   299] loss: 0.219795\n",
      "[34,   399] loss: 0.238681\n",
      "[34,   499] loss: 0.249531\n",
      "[34,   599] loss: 0.251384\n",
      "[34,   699] loss: 0.259504\n",
      "[35,    99] loss: 0.215155\n",
      "[35,   199] loss: 0.249774\n",
      "[35,   299] loss: 0.211590\n",
      "[35,   399] loss: 0.229895\n",
      "[35,   499] loss: 0.240352\n",
      "[35,   599] loss: 0.243511\n",
      "[35,   699] loss: 0.250909\n",
      "[36,    99] loss: 0.206720\n",
      "[36,   199] loss: 0.237644\n",
      "[36,   299] loss: 0.203993\n",
      "[36,   399] loss: 0.221234\n",
      "[36,   499] loss: 0.231712\n",
      "[36,   599] loss: 0.235946\n",
      "[36,   699] loss: 0.243282\n",
      "[37,    99] loss: 0.198946\n",
      "[37,   199] loss: 0.226154\n",
      "[37,   299] loss: 0.196530\n",
      "[37,   399] loss: 0.213262\n",
      "[37,   499] loss: 0.223075\n",
      "[37,   599] loss: 0.228431\n",
      "[37,   699] loss: 0.234185\n",
      "[38,    99] loss: 0.191402\n",
      "[38,   199] loss: 0.215672\n",
      "[38,   299] loss: 0.189545\n",
      "[38,   399] loss: 0.205888\n",
      "[38,   499] loss: 0.214426\n",
      "[38,   599] loss: 0.221793\n",
      "[38,   699] loss: 0.225912\n",
      "[39,    99] loss: 0.183750\n",
      "[39,   199] loss: 0.205040\n",
      "[39,   299] loss: 0.182791\n",
      "[39,   399] loss: 0.198682\n",
      "[39,   499] loss: 0.206030\n",
      "[39,   599] loss: 0.215024\n",
      "[39,   699] loss: 0.218769\n",
      "[40,    99] loss: 0.176302\n",
      "[40,   199] loss: 0.194845\n",
      "[40,   299] loss: 0.176381\n",
      "[40,   399] loss: 0.192236\n",
      "[40,   499] loss: 0.198611\n",
      "[40,   599] loss: 0.208538\n",
      "[40,   699] loss: 0.211282\n",
      "[41,    99] loss: 0.169601\n",
      "[41,   199] loss: 0.185324\n",
      "[41,   299] loss: 0.169712\n",
      "[41,   399] loss: 0.185884\n",
      "[41,   499] loss: 0.191163\n",
      "[41,   599] loss: 0.201931\n",
      "[41,   699] loss: 0.204419\n",
      "[42,    99] loss: 0.163044\n",
      "[42,   199] loss: 0.176641\n",
      "[42,   299] loss: 0.163529\n",
      "[42,   399] loss: 0.179888\n",
      "[42,   499] loss: 0.184627\n",
      "[42,   599] loss: 0.196183\n",
      "[42,   699] loss: 0.197280\n",
      "[43,    99] loss: 0.156872\n",
      "[43,   199] loss: 0.167995\n",
      "[43,   299] loss: 0.158471\n",
      "[43,   399] loss: 0.173627\n",
      "[43,   499] loss: 0.178194\n",
      "[43,   599] loss: 0.190605\n",
      "[43,   699] loss: 0.190135\n",
      "[44,    99] loss: 0.151291\n",
      "[44,   199] loss: 0.159826\n",
      "[44,   299] loss: 0.153117\n",
      "[44,   399] loss: 0.167496\n",
      "[44,   499] loss: 0.172253\n",
      "[44,   599] loss: 0.185525\n",
      "[44,   699] loss: 0.183525\n",
      "[45,    99] loss: 0.146420\n",
      "[45,   199] loss: 0.152887\n",
      "[45,   299] loss: 0.147260\n",
      "[45,   399] loss: 0.161772\n",
      "[45,   499] loss: 0.166367\n",
      "[45,   599] loss: 0.179573\n",
      "[45,   699] loss: 0.177477\n",
      "[46,    99] loss: 0.140923\n",
      "[46,   199] loss: 0.145910\n",
      "[46,   299] loss: 0.142189\n",
      "[46,   399] loss: 0.155627\n",
      "[46,   499] loss: 0.161172\n",
      "[46,   599] loss: 0.175125\n",
      "[46,   699] loss: 0.171516\n",
      "[47,    99] loss: 0.136469\n",
      "[47,   199] loss: 0.139969\n",
      "[47,   299] loss: 0.137298\n",
      "[47,   399] loss: 0.150263\n",
      "[47,   499] loss: 0.156103\n",
      "[47,   599] loss: 0.169928\n",
      "[47,   699] loss: 0.165369\n",
      "[48,    99] loss: 0.131999\n",
      "[48,   199] loss: 0.132805\n",
      "[48,   299] loss: 0.132271\n",
      "[48,   399] loss: 0.145712\n",
      "[48,   499] loss: 0.150964\n",
      "[48,   599] loss: 0.164819\n",
      "[48,   699] loss: 0.159382\n",
      "[49,    99] loss: 0.127268\n",
      "[49,   199] loss: 0.127455\n",
      "[49,   299] loss: 0.127473\n",
      "[49,   399] loss: 0.140578\n",
      "[49,   499] loss: 0.146291\n",
      "[49,   599] loss: 0.160258\n",
      "[49,   699] loss: 0.154392\n",
      "[50,    99] loss: 0.122700\n",
      "[50,   199] loss: 0.122099\n",
      "[50,   299] loss: 0.123084\n",
      "[50,   399] loss: 0.136191\n",
      "[50,   499] loss: 0.141574\n",
      "[50,   599] loss: 0.156335\n",
      "[50,   699] loss: 0.148571\n",
      "[51,    99] loss: 0.118766\n",
      "[51,   199] loss: 0.115807\n",
      "[51,   299] loss: 0.118498\n",
      "[51,   399] loss: 0.131365\n",
      "[51,   499] loss: 0.136823\n",
      "[51,   599] loss: 0.151470\n",
      "[51,   699] loss: 0.144005\n",
      "[52,    99] loss: 0.115002\n",
      "[52,   199] loss: 0.110717\n",
      "[52,   299] loss: 0.114269\n",
      "[52,   399] loss: 0.127571\n",
      "[52,   499] loss: 0.132213\n",
      "[52,   599] loss: 0.146846\n",
      "[52,   699] loss: 0.140026\n",
      "[53,    99] loss: 0.110751\n",
      "[53,   199] loss: 0.105499\n",
      "[53,   299] loss: 0.110021\n",
      "[53,   399] loss: 0.123080\n",
      "[53,   499] loss: 0.128116\n",
      "[53,   599] loss: 0.142526\n",
      "[53,   699] loss: 0.135264\n",
      "[54,    99] loss: 0.107064\n",
      "[54,   199] loss: 0.100968\n",
      "[54,   299] loss: 0.106050\n",
      "[54,   399] loss: 0.119088\n",
      "[54,   499] loss: 0.123604\n",
      "[54,   599] loss: 0.139139\n",
      "[54,   699] loss: 0.130314\n",
      "[55,    99] loss: 0.103690\n",
      "[55,   199] loss: 0.096423\n",
      "[55,   299] loss: 0.102180\n",
      "[55,   399] loss: 0.114921\n",
      "[55,   499] loss: 0.119540\n",
      "[55,   599] loss: 0.134721\n",
      "[55,   699] loss: 0.125985\n",
      "[56,    99] loss: 0.100241\n",
      "[56,   199] loss: 0.092388\n",
      "[56,   299] loss: 0.098264\n",
      "[56,   399] loss: 0.110763\n",
      "[56,   499] loss: 0.115889\n",
      "[56,   599] loss: 0.130985\n",
      "[56,   699] loss: 0.122534\n",
      "[57,    99] loss: 0.096847\n",
      "[57,   199] loss: 0.088445\n",
      "[57,   299] loss: 0.094281\n",
      "[57,   399] loss: 0.107297\n",
      "[57,   499] loss: 0.112221\n",
      "[57,   599] loss: 0.127336\n",
      "[57,   699] loss: 0.118267\n",
      "[58,    99] loss: 0.093663\n",
      "[58,   199] loss: 0.084753\n",
      "[58,   299] loss: 0.090357\n",
      "[58,   399] loss: 0.103500\n",
      "[58,   499] loss: 0.108936\n",
      "[58,   599] loss: 0.123745\n",
      "[58,   699] loss: 0.114893\n",
      "[59,    99] loss: 0.089737\n",
      "[59,   199] loss: 0.081630\n",
      "[59,   299] loss: 0.086796\n",
      "[59,   399] loss: 0.100380\n",
      "[59,   499] loss: 0.105109\n",
      "[59,   599] loss: 0.120275\n",
      "[59,   699] loss: 0.110861\n",
      "[60,    99] loss: 0.087337\n",
      "[60,   199] loss: 0.078241\n",
      "[60,   299] loss: 0.083327\n",
      "[60,   399] loss: 0.096305\n",
      "[60,   499] loss: 0.101716\n",
      "[60,   599] loss: 0.116915\n",
      "[60,   699] loss: 0.107679\n",
      "[61,    99] loss: 0.083815\n",
      "[61,   199] loss: 0.074589\n",
      "[61,   299] loss: 0.079759\n",
      "[61,   399] loss: 0.094237\n",
      "[61,   499] loss: 0.098871\n",
      "[61,   599] loss: 0.113617\n",
      "[61,   699] loss: 0.104135\n",
      "[62,    99] loss: 0.081724\n",
      "[62,   199] loss: 0.071542\n",
      "[62,   299] loss: 0.076477\n",
      "[62,   399] loss: 0.090646\n",
      "[62,   499] loss: 0.095561\n",
      "[62,   599] loss: 0.109905\n",
      "[62,   699] loss: 0.100548\n",
      "[63,    99] loss: 0.078543\n",
      "[63,   199] loss: 0.068990\n",
      "[63,   299] loss: 0.073660\n",
      "[63,   399] loss: 0.087911\n",
      "[63,   499] loss: 0.092554\n",
      "[63,   599] loss: 0.106315\n",
      "[63,   699] loss: 0.097027\n",
      "[64,    99] loss: 0.076228\n",
      "[64,   199] loss: 0.065879\n",
      "[64,   299] loss: 0.070643\n",
      "[64,   399] loss: 0.085010\n",
      "[64,   499] loss: 0.089005\n",
      "[64,   599] loss: 0.103562\n",
      "[64,   699] loss: 0.094103\n",
      "[65,    99] loss: 0.073318\n",
      "[65,   199] loss: 0.062845\n",
      "[65,   299] loss: 0.067904\n",
      "[65,   399] loss: 0.082157\n",
      "[65,   499] loss: 0.086187\n",
      "[65,   599] loss: 0.100487\n",
      "[65,   699] loss: 0.091275\n",
      "[66,    99] loss: 0.071505\n",
      "[66,   199] loss: 0.060031\n",
      "[66,   299] loss: 0.064936\n",
      "[66,   399] loss: 0.079493\n",
      "[66,   499] loss: 0.083351\n",
      "[66,   599] loss: 0.097300\n",
      "[66,   699] loss: 0.088480\n",
      "[67,    99] loss: 0.069693\n",
      "[67,   199] loss: 0.057488\n",
      "[67,   299] loss: 0.062763\n",
      "[67,   399] loss: 0.076875\n",
      "[67,   499] loss: 0.080994\n",
      "[67,   599] loss: 0.094409\n",
      "[67,   699] loss: 0.085598\n",
      "[68,    99] loss: 0.067332\n",
      "[68,   199] loss: 0.055106\n",
      "[68,   299] loss: 0.059800\n",
      "[68,   399] loss: 0.073915\n",
      "[68,   499] loss: 0.078441\n",
      "[68,   599] loss: 0.091699\n",
      "[68,   699] loss: 0.083150\n",
      "[69,    99] loss: 0.065006\n",
      "[69,   199] loss: 0.052517\n",
      "[69,   299] loss: 0.057838\n",
      "[69,   399] loss: 0.071369\n",
      "[69,   499] loss: 0.075857\n",
      "[69,   599] loss: 0.088636\n",
      "[69,   699] loss: 0.080911\n",
      "[70,    99] loss: 0.063327\n",
      "[70,   199] loss: 0.050353\n",
      "[70,   299] loss: 0.055133\n",
      "[70,   399] loss: 0.068935\n",
      "[70,   499] loss: 0.073860\n",
      "[70,   599] loss: 0.085898\n",
      "[70,   699] loss: 0.078479\n",
      "[71,    99] loss: 0.061277\n",
      "[71,   199] loss: 0.048627\n",
      "[71,   299] loss: 0.053039\n",
      "[71,   399] loss: 0.067480\n",
      "[71,   499] loss: 0.071833\n",
      "[71,   599] loss: 0.083228\n",
      "[71,   699] loss: 0.075667\n",
      "[72,    99] loss: 0.059565\n",
      "[72,   199] loss: 0.046056\n",
      "[72,   299] loss: 0.050759\n",
      "[72,   399] loss: 0.063484\n",
      "[72,   499] loss: 0.069349\n",
      "[72,   599] loss: 0.080668\n",
      "[72,   699] loss: 0.072999\n",
      "[73,    99] loss: 0.058426\n",
      "[73,   199] loss: 0.044055\n",
      "[73,   299] loss: 0.049119\n",
      "[73,   399] loss: 0.061945\n",
      "[73,   499] loss: 0.066965\n",
      "[73,   599] loss: 0.077766\n",
      "[73,   699] loss: 0.071674\n",
      "[74,    99] loss: 0.056057\n",
      "[74,   199] loss: 0.042406\n",
      "[74,   299] loss: 0.046853\n",
      "[74,   399] loss: 0.059207\n",
      "[74,   499] loss: 0.064554\n",
      "[74,   599] loss: 0.075281\n",
      "[74,   699] loss: 0.068938\n",
      "[75,    99] loss: 0.054829\n",
      "[75,   199] loss: 0.041097\n",
      "[75,   299] loss: 0.045520\n",
      "[75,   399] loss: 0.057359\n",
      "[75,   499] loss: 0.062761\n",
      "[75,   599] loss: 0.072361\n",
      "[75,   699] loss: 0.066860\n",
      "[76,    99] loss: 0.053283\n",
      "[76,   199] loss: 0.038818\n",
      "[76,   299] loss: 0.043594\n",
      "[76,   399] loss: 0.054957\n",
      "[76,   499] loss: 0.060753\n",
      "[76,   599] loss: 0.069835\n",
      "[76,   699] loss: 0.064757\n",
      "[77,    99] loss: 0.051796\n",
      "[77,   199] loss: 0.037353\n",
      "[77,   299] loss: 0.041962\n",
      "[77,   399] loss: 0.053375\n",
      "[77,   499] loss: 0.058636\n",
      "[77,   599] loss: 0.067041\n",
      "[77,   699] loss: 0.063336\n",
      "[78,    99] loss: 0.049870\n",
      "[78,   199] loss: 0.035638\n",
      "[78,   299] loss: 0.040534\n",
      "[78,   399] loss: 0.051365\n",
      "[78,   499] loss: 0.056642\n",
      "[78,   599] loss: 0.064362\n",
      "[78,   699] loss: 0.060890\n",
      "[79,    99] loss: 0.048921\n",
      "[79,   199] loss: 0.034229\n",
      "[79,   299] loss: 0.039194\n",
      "[79,   399] loss: 0.049253\n",
      "[79,   499] loss: 0.054862\n",
      "[79,   599] loss: 0.061988\n",
      "[79,   699] loss: 0.059434\n",
      "[80,    99] loss: 0.047139\n",
      "[80,   199] loss: 0.032563\n",
      "[80,   299] loss: 0.037744\n",
      "[80,   399] loss: 0.047672\n",
      "[80,   499] loss: 0.052843\n",
      "[80,   599] loss: 0.058896\n",
      "[80,   699] loss: 0.056720\n",
      "[81,    99] loss: 0.045917\n",
      "[81,   199] loss: 0.030990\n",
      "[81,   299] loss: 0.036526\n",
      "[81,   399] loss: 0.046704\n",
      "[81,   499] loss: 0.051076\n",
      "[81,   599] loss: 0.056607\n",
      "[81,   699] loss: 0.055723\n",
      "[82,    99] loss: 0.044678\n",
      "[82,   199] loss: 0.030007\n",
      "[82,   299] loss: 0.035339\n",
      "[82,   399] loss: 0.043825\n",
      "[82,   499] loss: 0.049079\n",
      "[82,   599] loss: 0.054308\n",
      "[82,   699] loss: 0.054350\n",
      "[83,    99] loss: 0.042928\n",
      "[83,   199] loss: 0.028366\n",
      "[83,   299] loss: 0.033963\n",
      "[83,   399] loss: 0.042899\n",
      "[83,   499] loss: 0.047418\n",
      "[83,   599] loss: 0.052646\n",
      "[83,   699] loss: 0.052430\n",
      "[84,    99] loss: 0.042138\n",
      "[84,   199] loss: 0.027399\n",
      "[84,   299] loss: 0.032403\n",
      "[84,   399] loss: 0.040814\n",
      "[84,   499] loss: 0.045193\n",
      "[84,   599] loss: 0.050927\n",
      "[84,   699] loss: 0.050949\n",
      "[85,    99] loss: 0.040282\n",
      "[85,   199] loss: 0.025913\n",
      "[85,   299] loss: 0.031443\n",
      "[85,   399] loss: 0.039668\n",
      "[85,   499] loss: 0.043335\n",
      "[85,   599] loss: 0.049608\n",
      "[85,   699] loss: 0.049147\n",
      "[86,    99] loss: 0.039408\n",
      "[86,   199] loss: 0.025131\n",
      "[86,   299] loss: 0.030300\n",
      "[86,   399] loss: 0.037613\n",
      "[86,   499] loss: 0.041753\n",
      "[86,   599] loss: 0.047412\n",
      "[86,   699] loss: 0.047381\n",
      "[87,    99] loss: 0.037718\n",
      "[87,   199] loss: 0.023649\n",
      "[87,   299] loss: 0.029069\n",
      "[87,   399] loss: 0.037157\n",
      "[87,   499] loss: 0.040207\n",
      "[87,   599] loss: 0.045810\n",
      "[87,   699] loss: 0.045336\n",
      "[88,    99] loss: 0.036594\n",
      "[88,   199] loss: 0.022765\n",
      "[88,   299] loss: 0.027960\n",
      "[88,   399] loss: 0.036064\n",
      "[88,   499] loss: 0.038365\n",
      "[88,   599] loss: 0.043763\n",
      "[88,   699] loss: 0.043679\n",
      "[89,    99] loss: 0.035480\n",
      "[89,   199] loss: 0.021679\n",
      "[89,   299] loss: 0.026579\n",
      "[89,   399] loss: 0.034056\n",
      "[89,   499] loss: 0.036909\n",
      "[89,   599] loss: 0.042770\n",
      "[89,   699] loss: 0.041855\n",
      "[90,    99] loss: 0.034519\n",
      "[90,   199] loss: 0.020686\n",
      "[90,   299] loss: 0.026013\n",
      "[90,   399] loss: 0.032971\n",
      "[90,   499] loss: 0.035267\n",
      "[90,   599] loss: 0.040498\n",
      "[90,   699] loss: 0.041060\n",
      "[91,    99] loss: 0.033031\n",
      "[91,   199] loss: 0.019930\n",
      "[91,   299] loss: 0.025528\n",
      "[91,   399] loss: 0.032250\n",
      "[91,   499] loss: 0.034046\n",
      "[91,   599] loss: 0.038874\n",
      "[91,   699] loss: 0.039544\n",
      "[92,    99] loss: 0.032816\n",
      "[92,   199] loss: 0.019127\n",
      "[92,   299] loss: 0.024620\n",
      "[92,   399] loss: 0.031142\n",
      "[92,   499] loss: 0.032873\n",
      "[92,   599] loss: 0.037382\n",
      "[92,   699] loss: 0.038284\n",
      "[93,    99] loss: 0.031386\n",
      "[93,   199] loss: 0.018258\n",
      "[93,   299] loss: 0.023569\n",
      "[93,   399] loss: 0.029146\n",
      "[93,   499] loss: 0.031553\n",
      "[93,   599] loss: 0.035853\n",
      "[93,   699] loss: 0.036924\n",
      "[94,    99] loss: 0.030269\n",
      "[94,   199] loss: 0.017701\n",
      "[94,   299] loss: 0.022765\n",
      "[94,   399] loss: 0.029273\n",
      "[94,   499] loss: 0.030397\n",
      "[94,   599] loss: 0.034419\n",
      "[94,   699] loss: 0.035289\n",
      "[95,    99] loss: 0.029452\n",
      "[95,   199] loss: 0.017010\n",
      "[95,   299] loss: 0.021979\n",
      "[95,   399] loss: 0.027154\n",
      "[95,   499] loss: 0.029305\n",
      "[95,   599] loss: 0.033539\n",
      "[95,   699] loss: 0.034484\n",
      "[96,    99] loss: 0.028648\n",
      "[96,   199] loss: 0.016302\n",
      "[96,   299] loss: 0.021105\n",
      "[96,   399] loss: 0.025987\n",
      "[96,   499] loss: 0.027901\n",
      "[96,   599] loss: 0.031865\n",
      "[96,   699] loss: 0.033417\n",
      "[97,    99] loss: 0.027160\n",
      "[97,   199] loss: 0.015594\n",
      "[97,   299] loss: 0.020718\n",
      "[97,   399] loss: 0.026503\n",
      "[97,   499] loss: 0.026712\n",
      "[97,   599] loss: 0.031413\n",
      "[97,   699] loss: 0.031749\n",
      "[98,    99] loss: 0.026794\n",
      "[98,   199] loss: 0.014922\n",
      "[98,   299] loss: 0.019900\n",
      "[98,   399] loss: 0.023843\n",
      "[98,   499] loss: 0.025422\n",
      "[98,   599] loss: 0.029782\n",
      "[98,   699] loss: 0.031965\n",
      "[99,    99] loss: 0.025570\n",
      "[99,   199] loss: 0.014313\n",
      "[99,   299] loss: 0.019614\n",
      "[99,   399] loss: 0.025151\n",
      "[99,   499] loss: 0.024467\n",
      "[99,   599] loss: 0.029174\n",
      "[99,   699] loss: 0.029663\n",
      "[100,    99] loss: 0.025076\n",
      "[100,   199] loss: 0.013754\n",
      "[100,   299] loss: 0.018302\n",
      "[100,   399] loss: 0.021570\n",
      "[100,   499] loss: 0.023285\n",
      "[100,   599] loss: 0.027477\n",
      "[100,   699] loss: 0.029263\n",
      "Finished Training\n",
      "[1,    99] loss: 1.371864\n",
      "[1,   199] loss: 0.717342\n",
      "[1,   299] loss: 0.710829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    99] loss: 0.699951\n",
      "[2,   199] loss: 0.716554\n",
      "[2,   299] loss: 0.709825\n",
      "[3,    99] loss: 0.700132\n",
      "[3,   199] loss: 0.716693\n",
      "[3,   299] loss: 0.709938\n",
      "[4,    99] loss: 0.700179\n",
      "[4,   199] loss: 0.716746\n",
      "[4,   299] loss: 0.709989\n",
      "[5,    99] loss: 0.700202\n",
      "[5,   199] loss: 0.716772\n",
      "[5,   299] loss: 0.710017\n",
      "[6,    99] loss: 0.700214\n",
      "[6,   199] loss: 0.716787\n",
      "[6,   299] loss: 0.710033\n",
      "[7,    99] loss: 0.700222\n",
      "[7,   199] loss: 0.716796\n",
      "[7,   299] loss: 0.710044\n",
      "[8,    99] loss: 0.700226\n",
      "[8,   199] loss: 0.716802\n",
      "[8,   299] loss: 0.710050\n",
      "[9,    99] loss: 0.700229\n",
      "[9,   199] loss: 0.716805\n",
      "[9,   299] loss: 0.710054\n",
      "[10,    99] loss: 0.700231\n",
      "[10,   199] loss: 0.716808\n",
      "[10,   299] loss: 0.710057\n",
      "[11,    99] loss: 0.700233\n",
      "[11,   199] loss: 0.716810\n",
      "[11,   299] loss: 0.710059\n",
      "[12,    99] loss: 0.700234\n",
      "[12,   199] loss: 0.716811\n",
      "[12,   299] loss: 0.710061\n",
      "[13,    99] loss: 0.700234\n",
      "[13,   199] loss: 0.716812\n",
      "[13,   299] loss: 0.710062\n",
      "[14,    99] loss: 0.700235\n",
      "[14,   199] loss: 0.716812\n",
      "[14,   299] loss: 0.710062\n",
      "[15,    99] loss: 0.700235\n",
      "[15,   199] loss: 0.716813\n",
      "[15,   299] loss: 0.710063\n",
      "[16,    99] loss: 0.700235\n",
      "[16,   199] loss: 0.716813\n",
      "[16,   299] loss: 0.710063\n",
      "[17,    99] loss: 0.700235\n",
      "[17,   199] loss: 0.716813\n",
      "[17,   299] loss: 0.710063\n",
      "[18,    99] loss: 0.700236\n",
      "[18,   199] loss: 0.716813\n",
      "[18,   299] loss: 0.710063\n",
      "[19,    99] loss: 0.700236\n",
      "[19,   199] loss: 0.716813\n",
      "[19,   299] loss: 0.710064\n",
      "[20,    99] loss: 0.700236\n",
      "[20,   199] loss: 0.716813\n",
      "[20,   299] loss: 0.710064\n",
      "[21,    99] loss: 0.700236\n",
      "[21,   199] loss: 0.716813\n",
      "[21,   299] loss: 0.710064\n",
      "[22,    99] loss: 0.700236\n",
      "[22,   199] loss: 0.716813\n",
      "[22,   299] loss: 0.710064\n",
      "[23,    99] loss: 0.700236\n",
      "[23,   199] loss: 0.716813\n",
      "[23,   299] loss: 0.710064\n",
      "[24,    99] loss: 0.700236\n",
      "[24,   199] loss: 0.716813\n",
      "[24,   299] loss: 0.710064\n",
      "[25,    99] loss: 0.700236\n",
      "[25,   199] loss: 0.716813\n",
      "[25,   299] loss: 0.710064\n",
      "[26,    99] loss: 0.700236\n",
      "[26,   199] loss: 0.716813\n",
      "[26,   299] loss: 0.710064\n",
      "[27,    99] loss: 0.700236\n",
      "[27,   199] loss: 0.716813\n",
      "[27,   299] loss: 0.710064\n",
      "[28,    99] loss: 0.700236\n",
      "[28,   199] loss: 0.716813\n",
      "[28,   299] loss: 0.710064\n",
      "[29,    99] loss: 0.700236\n",
      "[29,   199] loss: 0.716813\n",
      "[29,   299] loss: 0.710064\n",
      "[30,    99] loss: 0.700236\n",
      "[30,   199] loss: 0.716813\n",
      "[30,   299] loss: 0.710064\n",
      "[31,    99] loss: 0.700236\n",
      "[31,   199] loss: 0.716813\n",
      "[31,   299] loss: 0.710064\n",
      "[32,    99] loss: 0.700236\n",
      "[32,   199] loss: 0.716813\n",
      "[32,   299] loss: 0.710064\n",
      "[33,    99] loss: 0.700236\n",
      "[33,   199] loss: 0.716813\n",
      "[33,   299] loss: 0.710064\n",
      "[34,    99] loss: 0.700236\n",
      "[34,   199] loss: 0.716813\n",
      "[34,   299] loss: 0.710064\n",
      "[35,    99] loss: 0.700236\n",
      "[35,   199] loss: 0.716813\n",
      "[35,   299] loss: 0.710064\n",
      "[36,    99] loss: 0.700236\n",
      "[36,   199] loss: 0.716813\n",
      "[36,   299] loss: 0.710064\n",
      "[37,    99] loss: 0.700236\n",
      "[37,   199] loss: 0.716813\n",
      "[37,   299] loss: 0.710064\n",
      "[38,    99] loss: 0.700236\n",
      "[38,   199] loss: 0.716813\n",
      "[38,   299] loss: 0.710064\n",
      "[39,    99] loss: 0.700236\n",
      "[39,   199] loss: 0.716813\n",
      "[39,   299] loss: 0.710064\n",
      "[40,    99] loss: 0.700236\n",
      "[40,   199] loss: 0.716813\n",
      "[40,   299] loss: 0.710064\n",
      "[41,    99] loss: 0.700236\n",
      "[41,   199] loss: 0.716813\n",
      "[41,   299] loss: 0.710064\n",
      "[42,    99] loss: 0.700236\n",
      "[42,   199] loss: 0.716813\n",
      "[42,   299] loss: 0.710064\n",
      "[43,    99] loss: 0.700236\n",
      "[43,   199] loss: 0.716813\n",
      "[43,   299] loss: 0.710064\n",
      "[44,    99] loss: 0.700236\n",
      "[44,   199] loss: 0.716813\n",
      "[44,   299] loss: 0.710064\n",
      "[45,    99] loss: 0.700236\n",
      "[45,   199] loss: 0.716813\n",
      "[45,   299] loss: 0.710064\n",
      "[46,    99] loss: 0.700236\n",
      "[46,   199] loss: 0.716813\n",
      "[46,   299] loss: 0.710064\n",
      "[47,    99] loss: 0.700236\n",
      "[47,   199] loss: 0.716813\n",
      "[47,   299] loss: 0.710064\n",
      "[48,    99] loss: 0.700236\n",
      "[48,   199] loss: 0.716813\n",
      "[48,   299] loss: 0.710064\n",
      "[49,    99] loss: 0.700236\n",
      "[49,   199] loss: 0.716813\n",
      "[49,   299] loss: 0.710064\n",
      "[50,    99] loss: 0.700236\n",
      "[50,   199] loss: 0.716813\n",
      "[50,   299] loss: 0.710064\n",
      "[51,    99] loss: 0.700236\n",
      "[51,   199] loss: 0.716813\n",
      "[51,   299] loss: 0.710064\n",
      "[52,    99] loss: 0.700236\n",
      "[52,   199] loss: 0.716813\n",
      "[52,   299] loss: 0.710064\n",
      "[53,    99] loss: 0.700236\n",
      "[53,   199] loss: 0.716813\n",
      "[53,   299] loss: 0.710064\n",
      "[54,    99] loss: 0.700236\n",
      "[54,   199] loss: 0.716813\n",
      "[54,   299] loss: 0.710064\n",
      "[55,    99] loss: 0.700236\n",
      "[55,   199] loss: 0.716813\n",
      "[55,   299] loss: 0.710064\n",
      "[56,    99] loss: 0.700236\n",
      "[56,   199] loss: 0.716813\n",
      "[56,   299] loss: 0.710064\n",
      "[57,    99] loss: 0.700236\n",
      "[57,   199] loss: 0.716813\n",
      "[57,   299] loss: 0.710064\n",
      "[58,    99] loss: 0.700236\n",
      "[58,   199] loss: 0.716813\n",
      "[58,   299] loss: 0.710064\n",
      "[59,    99] loss: 0.700236\n",
      "[59,   199] loss: 0.716813\n",
      "[59,   299] loss: 0.710064\n",
      "[60,    99] loss: 0.700236\n",
      "[60,   199] loss: 0.716813\n",
      "[60,   299] loss: 0.710064\n",
      "[61,    99] loss: 0.700236\n",
      "[61,   199] loss: 0.716813\n",
      "[61,   299] loss: 0.710064\n",
      "[62,    99] loss: 0.700236\n",
      "[62,   199] loss: 0.716813\n",
      "[62,   299] loss: 0.710064\n",
      "[63,    99] loss: 0.700236\n",
      "[63,   199] loss: 0.716813\n",
      "[63,   299] loss: 0.710064\n",
      "[64,    99] loss: 0.700236\n",
      "[64,   199] loss: 0.716813\n",
      "[64,   299] loss: 0.710064\n",
      "[65,    99] loss: 0.700236\n",
      "[65,   199] loss: 0.716813\n",
      "[65,   299] loss: 0.710064\n",
      "[66,    99] loss: 0.700236\n",
      "[66,   199] loss: 0.716813\n",
      "[66,   299] loss: 0.710064\n",
      "[67,    99] loss: 0.700236\n",
      "[67,   199] loss: 0.716813\n",
      "[67,   299] loss: 0.710064\n",
      "[68,    99] loss: 0.700236\n",
      "[68,   199] loss: 0.716813\n",
      "[68,   299] loss: 0.710064\n",
      "[69,    99] loss: 0.700236\n",
      "[69,   199] loss: 0.716813\n",
      "[69,   299] loss: 0.710064\n",
      "[70,    99] loss: 0.700236\n",
      "[70,   199] loss: 0.716813\n",
      "[70,   299] loss: 0.710064\n",
      "[71,    99] loss: 0.700236\n",
      "[71,   199] loss: 0.716813\n",
      "[71,   299] loss: 0.710064\n",
      "[72,    99] loss: 0.700236\n",
      "[72,   199] loss: 0.716813\n",
      "[72,   299] loss: 0.710064\n",
      "[73,    99] loss: 0.700236\n",
      "[73,   199] loss: 0.716813\n",
      "[73,   299] loss: 0.710064\n",
      "[74,    99] loss: 0.700236\n",
      "[74,   199] loss: 0.716813\n",
      "[74,   299] loss: 0.710064\n",
      "[75,    99] loss: 0.700236\n",
      "[75,   199] loss: 0.716813\n",
      "[75,   299] loss: 0.710064\n",
      "[76,    99] loss: 0.700236\n",
      "[76,   199] loss: 0.716813\n",
      "[76,   299] loss: 0.710064\n",
      "[77,    99] loss: 0.700236\n",
      "[77,   199] loss: 0.716813\n",
      "[77,   299] loss: 0.710064\n",
      "[78,    99] loss: 0.700236\n",
      "[78,   199] loss: 0.716813\n",
      "[78,   299] loss: 0.710064\n",
      "[79,    99] loss: 0.700236\n",
      "[79,   199] loss: 0.716813\n",
      "[79,   299] loss: 0.710064\n",
      "[80,    99] loss: 0.700236\n",
      "[80,   199] loss: 0.716813\n",
      "[80,   299] loss: 0.710064\n",
      "[81,    99] loss: 0.700236\n",
      "[81,   199] loss: 0.716813\n",
      "[81,   299] loss: 0.710064\n",
      "[82,    99] loss: 0.700236\n",
      "[82,   199] loss: 0.716813\n",
      "[82,   299] loss: 0.710064\n",
      "[83,    99] loss: 0.700236\n",
      "[83,   199] loss: 0.716813\n",
      "[83,   299] loss: 0.710064\n",
      "[84,    99] loss: 0.700236\n",
      "[84,   199] loss: 0.716813\n",
      "[84,   299] loss: 0.710064\n",
      "[85,    99] loss: 0.700236\n",
      "[85,   199] loss: 0.716813\n",
      "[85,   299] loss: 0.710064\n",
      "[86,    99] loss: 0.700236\n",
      "[86,   199] loss: 0.716813\n",
      "[86,   299] loss: 0.710064\n",
      "[87,    99] loss: 0.700236\n",
      "[87,   199] loss: 0.716813\n",
      "[87,   299] loss: 0.710064\n",
      "[88,    99] loss: 0.700236\n",
      "[88,   199] loss: 0.716813\n",
      "[88,   299] loss: 0.710064\n",
      "[89,    99] loss: 0.700236\n",
      "[89,   199] loss: 0.716813\n",
      "[89,   299] loss: 0.710064\n",
      "[90,    99] loss: 0.700236\n",
      "[90,   199] loss: 0.716813\n",
      "[90,   299] loss: 0.710064\n",
      "[91,    99] loss: 0.700236\n",
      "[91,   199] loss: 0.716813\n",
      "[91,   299] loss: 0.710064\n",
      "[92,    99] loss: 0.700236\n",
      "[92,   199] loss: 0.716813\n",
      "[92,   299] loss: 0.710064\n",
      "[93,    99] loss: 0.700236\n",
      "[93,   199] loss: 0.716813\n",
      "[93,   299] loss: 0.710064\n",
      "[94,    99] loss: 0.700236\n",
      "[94,   199] loss: 0.716813\n",
      "[94,   299] loss: 0.710064\n",
      "[95,    99] loss: 0.700236\n",
      "[95,   199] loss: 0.716813\n",
      "[95,   299] loss: 0.710064\n",
      "[96,    99] loss: 0.700236\n",
      "[96,   199] loss: 0.716813\n",
      "[96,   299] loss: 0.710064\n",
      "[97,    99] loss: 0.700236\n",
      "[97,   199] loss: 0.716813\n",
      "[97,   299] loss: 0.710064\n",
      "[98,    99] loss: 0.700236\n",
      "[98,   199] loss: 0.716813\n",
      "[98,   299] loss: 0.710064\n",
      "[99,    99] loss: 0.700236\n",
      "[99,   199] loss: 0.716813\n",
      "[99,   299] loss: 0.710064\n",
      "[100,    99] loss: 0.700236\n",
      "[100,   199] loss: 0.716813\n",
      "[100,   299] loss: 0.710064\n",
      "Finished Training\n",
      "[1,    99] loss: 1.910588\n",
      "[1,   199] loss: 0.703177\n",
      "[1,   299] loss: 0.707460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    99] loss: 0.874264\n",
      "[2,   199] loss: 0.697979\n",
      "[2,   299] loss: 1.526479\n",
      "[3,    99] loss: 0.711936\n",
      "[3,   199] loss: 0.703281\n",
      "[3,   299] loss: 0.707548\n",
      "[4,    99] loss: 0.711998\n",
      "[4,   199] loss: 0.703304\n",
      "[4,   299] loss: 0.707572\n",
      "[5,    99] loss: 0.712028\n",
      "[5,   199] loss: 0.703316\n",
      "[5,   299] loss: 0.707584\n",
      "[6,    99] loss: 0.712044\n",
      "[6,   199] loss: 0.703323\n",
      "[6,   299] loss: 0.707592\n",
      "[7,    99] loss: 0.712054\n",
      "[7,   199] loss: 0.703327\n",
      "[7,   299] loss: 0.707596\n",
      "[8,    99] loss: 0.712060\n",
      "[8,   199] loss: 0.703330\n",
      "[8,   299] loss: 0.707599\n",
      "[9,    99] loss: 0.712065\n",
      "[9,   199] loss: 0.703331\n",
      "[9,   299] loss: 0.707601\n",
      "[10,    99] loss: 0.712067\n",
      "[10,   199] loss: 0.703333\n",
      "[10,   299] loss: 0.707602\n",
      "[11,    99] loss: 0.712069\n",
      "[11,   199] loss: 0.703333\n",
      "[11,   299] loss: 0.707603\n",
      "[12,    99] loss: 0.712070\n",
      "[12,   199] loss: 0.703334\n",
      "[12,   299] loss: 0.707604\n",
      "[13,    99] loss: 0.712071\n",
      "[13,   199] loss: 0.703334\n",
      "[13,   299] loss: 0.707604\n",
      "[14,    99] loss: 0.712072\n",
      "[14,   199] loss: 0.703334\n",
      "[14,   299] loss: 0.707605\n",
      "[15,    99] loss: 0.712072\n",
      "[15,   199] loss: 0.703335\n",
      "[15,   299] loss: 0.707605\n",
      "[16,    99] loss: 0.712072\n",
      "[16,   199] loss: 0.703335\n",
      "[16,   299] loss: 0.707605\n",
      "[17,    99] loss: 0.712072\n",
      "[17,   199] loss: 0.703335\n",
      "[17,   299] loss: 0.707605\n",
      "[18,    99] loss: 0.712073\n",
      "[18,   199] loss: 0.703335\n",
      "[18,   299] loss: 0.707605\n",
      "[19,    99] loss: 0.712073\n",
      "[19,   199] loss: 0.703335\n",
      "[19,   299] loss: 0.707605\n",
      "[20,    99] loss: 0.712073\n",
      "[20,   199] loss: 0.703335\n",
      "[20,   299] loss: 0.707605\n",
      "[21,    99] loss: 0.712073\n",
      "[21,   199] loss: 0.703335\n",
      "[21,   299] loss: 0.707605\n",
      "[22,    99] loss: 0.712073\n",
      "[22,   199] loss: 0.703335\n",
      "[22,   299] loss: 0.707605\n",
      "[23,    99] loss: 0.712073\n",
      "[23,   199] loss: 0.703335\n",
      "[23,   299] loss: 0.707605\n",
      "[24,    99] loss: 0.712073\n",
      "[24,   199] loss: 0.703335\n",
      "[24,   299] loss: 0.707605\n",
      "[25,    99] loss: 0.712073\n",
      "[25,   199] loss: 0.703335\n",
      "[25,   299] loss: 0.707605\n",
      "[26,    99] loss: 0.712073\n",
      "[26,   199] loss: 0.703335\n",
      "[26,   299] loss: 0.707605\n",
      "[27,    99] loss: 0.712073\n",
      "[27,   199] loss: 0.703335\n",
      "[27,   299] loss: 0.707605\n",
      "[28,    99] loss: 0.712073\n",
      "[28,   199] loss: 0.703335\n",
      "[28,   299] loss: 0.707605\n",
      "[29,    99] loss: 0.712073\n",
      "[29,   199] loss: 0.703335\n",
      "[29,   299] loss: 0.707605\n",
      "[30,    99] loss: 0.712073\n",
      "[30,   199] loss: 0.703335\n",
      "[30,   299] loss: 0.707605\n",
      "[31,    99] loss: 0.712073\n",
      "[31,   199] loss: 0.703335\n",
      "[31,   299] loss: 0.707605\n",
      "[32,    99] loss: 0.712073\n",
      "[32,   199] loss: 0.703335\n",
      "[32,   299] loss: 0.707605\n",
      "[33,    99] loss: 0.712073\n",
      "[33,   199] loss: 0.703335\n",
      "[33,   299] loss: 0.707605\n",
      "[34,    99] loss: 0.712073\n",
      "[34,   199] loss: 0.703335\n",
      "[34,   299] loss: 0.707605\n",
      "[35,    99] loss: 0.712073\n",
      "[35,   199] loss: 0.703335\n",
      "[35,   299] loss: 0.707605\n",
      "[36,    99] loss: 0.712073\n",
      "[36,   199] loss: 0.703335\n",
      "[36,   299] loss: 0.707605\n",
      "[37,    99] loss: 0.712073\n",
      "[37,   199] loss: 0.703335\n",
      "[37,   299] loss: 0.707605\n",
      "[38,    99] loss: 0.712073\n",
      "[38,   199] loss: 0.703335\n",
      "[38,   299] loss: 0.707605\n",
      "[39,    99] loss: 0.712073\n",
      "[39,   199] loss: 0.703335\n",
      "[39,   299] loss: 0.707605\n",
      "[40,    99] loss: 0.712073\n",
      "[40,   199] loss: 0.703335\n",
      "[40,   299] loss: 0.707605\n",
      "[41,    99] loss: 0.712073\n",
      "[41,   199] loss: 0.703335\n",
      "[41,   299] loss: 0.707605\n",
      "[42,    99] loss: 0.712073\n",
      "[42,   199] loss: 0.703335\n",
      "[42,   299] loss: 0.707605\n",
      "[43,    99] loss: 0.712073\n",
      "[43,   199] loss: 0.703335\n",
      "[43,   299] loss: 0.707605\n",
      "[44,    99] loss: 0.712073\n",
      "[44,   199] loss: 0.703335\n",
      "[44,   299] loss: 0.707605\n",
      "[45,    99] loss: 0.712073\n",
      "[45,   199] loss: 0.703335\n",
      "[45,   299] loss: 0.707605\n",
      "[46,    99] loss: 0.712073\n",
      "[46,   199] loss: 0.703335\n",
      "[46,   299] loss: 0.707605\n",
      "[47,    99] loss: 0.712073\n",
      "[47,   199] loss: 0.703335\n",
      "[47,   299] loss: 0.707605\n",
      "[48,    99] loss: 0.712073\n",
      "[48,   199] loss: 0.703335\n",
      "[48,   299] loss: 0.707605\n",
      "[49,    99] loss: 0.712073\n",
      "[49,   199] loss: 0.703335\n",
      "[49,   299] loss: 0.707605\n",
      "[50,    99] loss: 0.712073\n",
      "[50,   199] loss: 0.703335\n",
      "[50,   299] loss: 0.707605\n",
      "[51,    99] loss: 0.712073\n",
      "[51,   199] loss: 0.703335\n",
      "[51,   299] loss: 0.707605\n",
      "[52,    99] loss: 0.712073\n",
      "[52,   199] loss: 0.703335\n",
      "[52,   299] loss: 0.707605\n",
      "[53,    99] loss: 0.712073\n",
      "[53,   199] loss: 0.703335\n",
      "[53,   299] loss: 0.707605\n",
      "[54,    99] loss: 0.712073\n",
      "[54,   199] loss: 0.703335\n",
      "[54,   299] loss: 0.707605\n",
      "[55,    99] loss: 0.712073\n",
      "[55,   199] loss: 0.703335\n",
      "[55,   299] loss: 0.707605\n",
      "[56,    99] loss: 0.712073\n",
      "[56,   199] loss: 0.703335\n",
      "[56,   299] loss: 0.707605\n",
      "[57,    99] loss: 0.712073\n",
      "[57,   199] loss: 0.703335\n",
      "[57,   299] loss: 0.707605\n",
      "[58,    99] loss: 0.712073\n",
      "[58,   199] loss: 0.703335\n",
      "[58,   299] loss: 0.707605\n",
      "[59,    99] loss: 0.712073\n",
      "[59,   199] loss: 0.703335\n",
      "[59,   299] loss: 0.707605\n",
      "[60,    99] loss: 0.712073\n",
      "[60,   199] loss: 0.703335\n",
      "[60,   299] loss: 0.707605\n",
      "[61,    99] loss: 0.712073\n",
      "[61,   199] loss: 0.703335\n",
      "[61,   299] loss: 0.707605\n",
      "[62,    99] loss: 0.712073\n",
      "[62,   199] loss: 0.703335\n",
      "[62,   299] loss: 0.707605\n",
      "[63,    99] loss: 0.712073\n",
      "[63,   199] loss: 0.703335\n",
      "[63,   299] loss: 0.707605\n",
      "[64,    99] loss: 0.712073\n",
      "[64,   199] loss: 0.703335\n",
      "[64,   299] loss: 0.707605\n",
      "[65,    99] loss: 0.712073\n",
      "[65,   199] loss: 0.703335\n",
      "[65,   299] loss: 0.707605\n",
      "[66,    99] loss: 0.712073\n",
      "[66,   199] loss: 0.703335\n",
      "[66,   299] loss: 0.707605\n",
      "[67,    99] loss: 0.712073\n",
      "[67,   199] loss: 0.703335\n",
      "[67,   299] loss: 0.707605\n",
      "[68,    99] loss: 0.712073\n",
      "[68,   199] loss: 0.703335\n",
      "[68,   299] loss: 0.707605\n",
      "[69,    99] loss: 0.712073\n",
      "[69,   199] loss: 0.703335\n",
      "[69,   299] loss: 0.707605\n",
      "[70,    99] loss: 0.712073\n",
      "[70,   199] loss: 0.703335\n",
      "[70,   299] loss: 0.707605\n",
      "[71,    99] loss: 0.712073\n",
      "[71,   199] loss: 0.703335\n",
      "[71,   299] loss: 0.707605\n",
      "[72,    99] loss: 0.712073\n",
      "[72,   199] loss: 0.703335\n",
      "[72,   299] loss: 0.707605\n",
      "[73,    99] loss: 0.712073\n",
      "[73,   199] loss: 0.703335\n",
      "[73,   299] loss: 0.707605\n",
      "[74,    99] loss: 0.712073\n",
      "[74,   199] loss: 0.703335\n",
      "[74,   299] loss: 0.707605\n",
      "[75,    99] loss: 0.712073\n",
      "[75,   199] loss: 0.703335\n",
      "[75,   299] loss: 0.707605\n",
      "[76,    99] loss: 0.712073\n",
      "[76,   199] loss: 0.703335\n",
      "[76,   299] loss: 0.707605\n",
      "[77,    99] loss: 0.712073\n",
      "[77,   199] loss: 0.703335\n",
      "[77,   299] loss: 0.707605\n",
      "[78,    99] loss: 0.712073\n",
      "[78,   199] loss: 0.703335\n",
      "[78,   299] loss: 0.707605\n",
      "[79,    99] loss: 0.712073\n",
      "[79,   199] loss: 0.703335\n",
      "[79,   299] loss: 0.707605\n",
      "[80,    99] loss: 0.712073\n",
      "[80,   199] loss: 0.703335\n",
      "[80,   299] loss: 0.707605\n",
      "[81,    99] loss: 0.712073\n",
      "[81,   199] loss: 0.703335\n",
      "[81,   299] loss: 0.707605\n",
      "[82,    99] loss: 0.712073\n",
      "[82,   199] loss: 0.703335\n",
      "[82,   299] loss: 0.707605\n",
      "[83,    99] loss: 0.712073\n",
      "[83,   199] loss: 0.703335\n",
      "[83,   299] loss: 0.707605\n",
      "[84,    99] loss: 0.712073\n",
      "[84,   199] loss: 0.703335\n",
      "[84,   299] loss: 0.707605\n",
      "[85,    99] loss: 0.712073\n",
      "[85,   199] loss: 0.703335\n",
      "[85,   299] loss: 0.707605\n",
      "[86,    99] loss: 0.712073\n",
      "[86,   199] loss: 0.703335\n",
      "[86,   299] loss: 0.707605\n",
      "[87,    99] loss: 0.712073\n",
      "[87,   199] loss: 0.703335\n",
      "[87,   299] loss: 0.707605\n",
      "[88,    99] loss: 0.712073\n",
      "[88,   199] loss: 0.703335\n",
      "[88,   299] loss: 0.707605\n",
      "[89,    99] loss: 0.712073\n",
      "[89,   199] loss: 0.703335\n",
      "[89,   299] loss: 0.707605\n",
      "[90,    99] loss: 0.712073\n",
      "[90,   199] loss: 0.703335\n",
      "[90,   299] loss: 0.707605\n",
      "[91,    99] loss: 0.712073\n",
      "[91,   199] loss: 0.703335\n",
      "[91,   299] loss: 0.707605\n",
      "[92,    99] loss: 0.712073\n",
      "[92,   199] loss: 0.703335\n",
      "[92,   299] loss: 0.707605\n",
      "[93,    99] loss: 0.712073\n",
      "[93,   199] loss: 0.703335\n",
      "[93,   299] loss: 0.707605\n",
      "[94,    99] loss: 0.712073\n",
      "[94,   199] loss: 0.703335\n",
      "[94,   299] loss: 0.707605\n",
      "[95,    99] loss: 0.712073\n",
      "[95,   199] loss: 0.703335\n",
      "[95,   299] loss: 0.707605\n",
      "[96,    99] loss: 0.712073\n",
      "[96,   199] loss: 0.703335\n",
      "[96,   299] loss: 0.707605\n",
      "[97,    99] loss: 0.712073\n",
      "[97,   199] loss: 0.703335\n",
      "[97,   299] loss: 0.707605\n",
      "[98,    99] loss: 0.712073\n",
      "[98,   199] loss: 0.703335\n",
      "[98,   299] loss: 0.707605\n",
      "[99,    99] loss: 0.712073\n",
      "[99,   199] loss: 0.703335\n",
      "[99,   299] loss: 0.707605\n",
      "[100,    99] loss: 0.712073\n",
      "[100,   199] loss: 0.703335\n",
      "[100,   299] loss: 0.707605\n",
      "Finished Training\n",
      "[1,    99] loss: 1.226012\n",
      "[1,   199] loss: 0.696547\n",
      "[1,   299] loss: 0.716759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    99] loss: 0.727571\n",
      "[2,   199] loss: 0.697652\n",
      "[2,   299] loss: 0.716979\n",
      "[3,    99] loss: 0.727922\n",
      "[3,   199] loss: 0.697824\n",
      "[3,   299] loss: 0.717031\n",
      "[4,    99] loss: 0.728036\n",
      "[4,   199] loss: 0.697890\n",
      "[4,   299] loss: 0.717053\n",
      "[5,    99] loss: 0.728089\n",
      "[5,   199] loss: 0.697923\n",
      "[5,   299] loss: 0.717064\n",
      "[6,    99] loss: 0.728118\n",
      "[6,   199] loss: 0.697942\n",
      "[6,   299] loss: 0.717070\n",
      "[7,    99] loss: 0.728136\n",
      "[7,   199] loss: 0.697954\n",
      "[7,   299] loss: 0.717074\n",
      "[8,    99] loss: 0.728147\n",
      "[8,   199] loss: 0.697961\n",
      "[8,   299] loss: 0.717077\n",
      "[9,    99] loss: 0.728154\n",
      "[9,   199] loss: 0.697966\n",
      "[9,   299] loss: 0.717078\n",
      "[10,    99] loss: 0.728159\n",
      "[10,   199] loss: 0.697969\n",
      "[10,   299] loss: 0.717079\n",
      "[11,    99] loss: 0.728162\n",
      "[11,   199] loss: 0.697971\n",
      "[11,   299] loss: 0.717080\n",
      "[12,    99] loss: 0.728164\n",
      "[12,   199] loss: 0.697973\n",
      "[12,   299] loss: 0.717080\n",
      "[13,    99] loss: 0.728165\n",
      "[13,   199] loss: 0.697974\n",
      "[13,   299] loss: 0.717081\n",
      "[14,    99] loss: 0.728166\n",
      "[14,   199] loss: 0.697974\n",
      "[14,   299] loss: 0.717081\n",
      "[15,    99] loss: 0.728167\n",
      "[15,   199] loss: 0.697975\n",
      "[15,   299] loss: 0.717081\n",
      "[16,    99] loss: 0.728168\n",
      "[16,   199] loss: 0.697975\n",
      "[16,   299] loss: 0.717081\n",
      "[17,    99] loss: 0.728168\n",
      "[17,   199] loss: 0.697976\n",
      "[17,   299] loss: 0.717081\n",
      "[18,    99] loss: 0.728168\n",
      "[18,   199] loss: 0.697976\n",
      "[18,   299] loss: 0.717081\n",
      "[19,    99] loss: 0.728168\n",
      "[19,   199] loss: 0.697976\n",
      "[19,   299] loss: 0.717081\n",
      "[20,    99] loss: 0.728168\n",
      "[20,   199] loss: 0.697976\n",
      "[20,   299] loss: 0.717081\n",
      "[21,    99] loss: 0.728168\n",
      "[21,   199] loss: 0.697976\n",
      "[21,   299] loss: 0.717081\n",
      "[22,    99] loss: 0.728168\n",
      "[22,   199] loss: 0.697976\n",
      "[22,   299] loss: 0.717081\n",
      "[23,    99] loss: 0.728169\n",
      "[23,   199] loss: 0.697976\n",
      "[23,   299] loss: 0.717081\n",
      "[24,    99] loss: 0.728169\n",
      "[24,   199] loss: 0.697976\n",
      "[24,   299] loss: 0.717081\n",
      "[25,    99] loss: 0.728169\n",
      "[25,   199] loss: 0.697976\n",
      "[25,   299] loss: 0.717081\n",
      "[26,    99] loss: 0.728169\n",
      "[26,   199] loss: 0.697976\n",
      "[26,   299] loss: 0.717081\n",
      "[27,    99] loss: 0.728169\n",
      "[27,   199] loss: 0.697976\n",
      "[27,   299] loss: 0.717081\n",
      "[28,    99] loss: 0.728169\n",
      "[28,   199] loss: 0.697976\n",
      "[28,   299] loss: 0.717081\n",
      "[29,    99] loss: 0.728169\n",
      "[29,   199] loss: 0.697976\n",
      "[29,   299] loss: 0.717081\n",
      "[30,    99] loss: 0.728169\n",
      "[30,   199] loss: 0.697976\n",
      "[30,   299] loss: 0.717081\n",
      "[31,    99] loss: 0.728169\n",
      "[31,   199] loss: 0.697976\n",
      "[31,   299] loss: 0.717081\n",
      "[32,    99] loss: 0.728169\n",
      "[32,   199] loss: 0.697976\n",
      "[32,   299] loss: 0.717081\n",
      "[33,    99] loss: 0.728169\n",
      "[33,   199] loss: 0.697976\n",
      "[33,   299] loss: 0.717081\n",
      "[34,    99] loss: 0.728169\n",
      "[34,   199] loss: 0.697976\n",
      "[34,   299] loss: 0.717081\n",
      "[35,    99] loss: 0.728169\n",
      "[35,   199] loss: 0.697976\n",
      "[35,   299] loss: 0.717081\n",
      "[36,    99] loss: 0.728169\n",
      "[36,   199] loss: 0.697976\n",
      "[36,   299] loss: 0.717081\n",
      "[37,    99] loss: 0.728169\n",
      "[37,   199] loss: 0.697976\n",
      "[37,   299] loss: 0.717081\n",
      "[38,    99] loss: 0.728169\n",
      "[38,   199] loss: 0.697976\n",
      "[38,   299] loss: 0.717081\n",
      "[39,    99] loss: 0.728169\n",
      "[39,   199] loss: 0.697976\n",
      "[39,   299] loss: 0.717081\n",
      "[40,    99] loss: 0.728169\n",
      "[40,   199] loss: 0.697976\n",
      "[40,   299] loss: 0.717081\n",
      "[41,    99] loss: 0.728169\n",
      "[41,   199] loss: 0.697976\n",
      "[41,   299] loss: 0.717081\n",
      "[42,    99] loss: 0.728169\n",
      "[42,   199] loss: 0.697976\n",
      "[42,   299] loss: 0.717081\n",
      "[43,    99] loss: 0.728169\n",
      "[43,   199] loss: 0.697976\n",
      "[43,   299] loss: 0.717081\n",
      "[44,    99] loss: 0.728169\n",
      "[44,   199] loss: 0.697976\n",
      "[44,   299] loss: 0.717081\n",
      "[45,    99] loss: 0.728169\n",
      "[45,   199] loss: 0.697976\n",
      "[45,   299] loss: 0.717081\n",
      "[46,    99] loss: 0.728169\n",
      "[46,   199] loss: 0.697976\n",
      "[46,   299] loss: 0.717081\n",
      "[47,    99] loss: 0.728169\n",
      "[47,   199] loss: 0.697976\n",
      "[47,   299] loss: 0.717081\n",
      "[48,    99] loss: 0.728169\n",
      "[48,   199] loss: 0.697976\n",
      "[48,   299] loss: 0.717081\n",
      "[49,    99] loss: 0.728169\n",
      "[49,   199] loss: 0.697976\n",
      "[49,   299] loss: 0.717081\n",
      "[50,    99] loss: 0.728169\n",
      "[50,   199] loss: 0.697976\n",
      "[50,   299] loss: 0.717081\n",
      "[51,    99] loss: 0.728169\n",
      "[51,   199] loss: 0.697976\n",
      "[51,   299] loss: 0.717081\n",
      "[52,    99] loss: 0.728169\n",
      "[52,   199] loss: 0.697976\n",
      "[52,   299] loss: 0.717081\n",
      "[53,    99] loss: 0.728169\n",
      "[53,   199] loss: 0.697976\n",
      "[53,   299] loss: 0.717081\n",
      "[54,    99] loss: 0.728169\n",
      "[54,   199] loss: 0.697976\n",
      "[54,   299] loss: 0.717081\n",
      "[55,    99] loss: 0.728169\n",
      "[55,   199] loss: 0.697976\n",
      "[55,   299] loss: 0.717081\n",
      "[56,    99] loss: 0.728169\n",
      "[56,   199] loss: 0.697976\n",
      "[56,   299] loss: 0.717081\n",
      "[57,    99] loss: 0.728169\n",
      "[57,   199] loss: 0.697976\n",
      "[57,   299] loss: 0.717081\n",
      "[58,    99] loss: 0.728169\n",
      "[58,   199] loss: 0.697976\n",
      "[58,   299] loss: 0.717081\n",
      "[59,    99] loss: 0.728169\n",
      "[59,   199] loss: 0.697976\n",
      "[59,   299] loss: 0.717081\n",
      "[60,    99] loss: 0.728169\n",
      "[60,   199] loss: 0.697976\n",
      "[60,   299] loss: 0.717081\n",
      "[61,    99] loss: 0.728169\n",
      "[61,   199] loss: 0.697976\n",
      "[61,   299] loss: 0.717081\n",
      "[62,    99] loss: 0.728169\n",
      "[62,   199] loss: 0.697976\n",
      "[62,   299] loss: 0.717081\n",
      "[63,    99] loss: 0.728169\n",
      "[63,   199] loss: 0.697976\n",
      "[63,   299] loss: 0.717081\n",
      "[64,    99] loss: 0.728169\n",
      "[64,   199] loss: 0.697976\n",
      "[64,   299] loss: 0.717081\n",
      "[65,    99] loss: 0.728169\n",
      "[65,   199] loss: 0.697976\n",
      "[65,   299] loss: 0.717081\n",
      "[66,    99] loss: 0.728169\n",
      "[66,   199] loss: 0.697976\n",
      "[66,   299] loss: 0.717081\n",
      "[67,    99] loss: 0.728169\n",
      "[67,   199] loss: 0.697976\n",
      "[67,   299] loss: 0.717081\n",
      "[68,    99] loss: 0.728169\n",
      "[68,   199] loss: 0.697976\n",
      "[68,   299] loss: 0.717081\n",
      "[69,    99] loss: 0.728169\n",
      "[69,   199] loss: 0.697976\n",
      "[69,   299] loss: 0.717081\n",
      "[70,    99] loss: 0.728169\n",
      "[70,   199] loss: 0.697976\n",
      "[70,   299] loss: 0.717081\n",
      "[71,    99] loss: 0.728169\n",
      "[71,   199] loss: 0.697976\n",
      "[71,   299] loss: 0.717081\n",
      "[72,    99] loss: 0.728169\n",
      "[72,   199] loss: 0.697976\n",
      "[72,   299] loss: 0.717081\n",
      "[73,    99] loss: 0.728169\n",
      "[73,   199] loss: 0.697976\n",
      "[73,   299] loss: 0.717081\n",
      "[74,    99] loss: 0.728169\n",
      "[74,   199] loss: 0.697976\n",
      "[74,   299] loss: 0.717081\n",
      "[75,    99] loss: 0.728169\n",
      "[75,   199] loss: 0.697976\n",
      "[75,   299] loss: 0.717081\n",
      "[76,    99] loss: 0.728169\n",
      "[76,   199] loss: 0.697976\n",
      "[76,   299] loss: 0.717081\n",
      "[77,    99] loss: 0.728169\n",
      "[77,   199] loss: 0.697976\n",
      "[77,   299] loss: 0.717081\n",
      "[78,    99] loss: 0.728169\n",
      "[78,   199] loss: 0.697976\n",
      "[78,   299] loss: 0.717081\n",
      "[79,    99] loss: 0.728169\n",
      "[79,   199] loss: 0.697976\n",
      "[79,   299] loss: 0.717081\n",
      "[80,    99] loss: 0.728169\n",
      "[80,   199] loss: 0.697976\n",
      "[80,   299] loss: 0.717081\n",
      "[81,    99] loss: 0.728169\n",
      "[81,   199] loss: 0.697976\n",
      "[81,   299] loss: 0.717081\n",
      "[82,    99] loss: 0.728169\n",
      "[82,   199] loss: 0.697976\n",
      "[82,   299] loss: 0.717081\n",
      "[83,    99] loss: 0.728169\n",
      "[83,   199] loss: 0.697976\n",
      "[83,   299] loss: 0.717081\n",
      "[84,    99] loss: 0.728169\n",
      "[84,   199] loss: 0.697976\n",
      "[84,   299] loss: 0.717081\n",
      "[85,    99] loss: 0.728169\n",
      "[85,   199] loss: 0.697976\n",
      "[85,   299] loss: 0.717081\n",
      "[86,    99] loss: 0.728169\n",
      "[86,   199] loss: 0.697976\n",
      "[86,   299] loss: 0.717081\n",
      "[87,    99] loss: 0.728169\n",
      "[87,   199] loss: 0.697976\n",
      "[87,   299] loss: 0.717081\n",
      "[88,    99] loss: 0.728169\n",
      "[88,   199] loss: 0.697976\n",
      "[88,   299] loss: 0.717081\n",
      "[89,    99] loss: 0.728169\n",
      "[89,   199] loss: 0.697976\n",
      "[89,   299] loss: 0.717081\n",
      "[90,    99] loss: 0.728169\n",
      "[90,   199] loss: 0.697976\n",
      "[90,   299] loss: 0.717081\n",
      "[91,    99] loss: 0.728169\n",
      "[91,   199] loss: 0.697976\n",
      "[91,   299] loss: 0.717081\n",
      "[92,    99] loss: 0.728169\n",
      "[92,   199] loss: 0.697976\n",
      "[92,   299] loss: 0.717081\n",
      "[93,    99] loss: 0.728169\n",
      "[93,   199] loss: 0.697976\n",
      "[93,   299] loss: 0.717081\n",
      "[94,    99] loss: 0.728169\n",
      "[94,   199] loss: 0.697976\n",
      "[94,   299] loss: 0.717081\n",
      "[95,    99] loss: 0.728169\n",
      "[95,   199] loss: 0.697976\n",
      "[95,   299] loss: 0.717081\n",
      "[96,    99] loss: 0.728169\n",
      "[96,   199] loss: 0.697976\n",
      "[96,   299] loss: 0.717081\n",
      "[97,    99] loss: 0.728169\n",
      "[97,   199] loss: 0.697976\n",
      "[97,   299] loss: 0.717081\n",
      "[98,    99] loss: 0.728169\n",
      "[98,   199] loss: 0.697976\n",
      "[98,   299] loss: 0.717081\n",
      "[99,    99] loss: 0.728169\n",
      "[99,   199] loss: 0.697976\n",
      "[99,   299] loss: 0.717081\n",
      "[100,    99] loss: 0.728169\n",
      "[100,   199] loss: 0.697976\n",
      "[100,   299] loss: 0.717081\n",
      "Finished Training\n",
      "[1,    99] loss: 2.858674\n",
      "[1,   199] loss: 0.730865\n",
      "[1,   299] loss: 0.738832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    99] loss: 0.692216\n",
      "[2,   199] loss: 0.693975\n",
      "[2,   299] loss: 0.750606\n",
      "[3,    99] loss: 0.694028\n",
      "[3,   199] loss: 0.697357\n",
      "[3,   299] loss: 0.706655\n",
      "[4,    99] loss: 0.692528\n",
      "[4,   199] loss: 0.696677\n",
      "[4,   299] loss: 0.706750\n",
      "[5,    99] loss: 0.692629\n",
      "[5,   199] loss: 0.696786\n",
      "[5,   299] loss: 0.706800\n",
      "[6,    99] loss: 0.692685\n",
      "[6,   199] loss: 0.696849\n",
      "[6,   299] loss: 0.706830\n",
      "[7,    99] loss: 0.692719\n",
      "[7,   199] loss: 0.696888\n",
      "[7,   299] loss: 0.706849\n",
      "[8,    99] loss: 0.692740\n",
      "[8,   199] loss: 0.696912\n",
      "[8,   299] loss: 0.706860\n",
      "[9,    99] loss: 0.692754\n",
      "[9,   199] loss: 0.696928\n",
      "[9,   299] loss: 0.706868\n",
      "[10,    99] loss: 0.692763\n",
      "[10,   199] loss: 0.696939\n",
      "[10,   299] loss: 0.706874\n",
      "[11,    99] loss: 0.692769\n",
      "[11,   199] loss: 0.696946\n",
      "[11,   299] loss: 0.706877\n",
      "[12,    99] loss: 0.692773\n",
      "[12,   199] loss: 0.696951\n",
      "[12,   299] loss: 0.706880\n",
      "[13,    99] loss: 0.692776\n",
      "[13,   199] loss: 0.696954\n",
      "[13,   299] loss: 0.706881\n",
      "[14,    99] loss: 0.692778\n",
      "[14,   199] loss: 0.696957\n",
      "[14,   299] loss: 0.706882\n",
      "[15,    99] loss: 0.692779\n",
      "[15,   199] loss: 0.696958\n",
      "[15,   299] loss: 0.706883\n",
      "[16,    99] loss: 0.692780\n",
      "[16,   199] loss: 0.696959\n",
      "[16,   299] loss: 0.706884\n",
      "[17,    99] loss: 0.692781\n",
      "[17,   199] loss: 0.696960\n",
      "[17,   299] loss: 0.706884\n",
      "[18,    99] loss: 0.692781\n",
      "[18,   199] loss: 0.696960\n",
      "[18,   299] loss: 0.706884\n",
      "[19,    99] loss: 0.692782\n",
      "[19,   199] loss: 0.696961\n",
      "[19,   299] loss: 0.706884\n",
      "[20,    99] loss: 0.692782\n",
      "[20,   199] loss: 0.696961\n",
      "[20,   299] loss: 0.706884\n",
      "[21,    99] loss: 0.692782\n",
      "[21,   199] loss: 0.696961\n",
      "[21,   299] loss: 0.706885\n",
      "[22,    99] loss: 0.692782\n",
      "[22,   199] loss: 0.696961\n",
      "[22,   299] loss: 0.706885\n",
      "[23,    99] loss: 0.692782\n",
      "[23,   199] loss: 0.696961\n",
      "[23,   299] loss: 0.706885\n",
      "[24,    99] loss: 0.692782\n",
      "[24,   199] loss: 0.696961\n",
      "[24,   299] loss: 0.706885\n",
      "[25,    99] loss: 0.692782\n",
      "[25,   199] loss: 0.696961\n",
      "[25,   299] loss: 0.706885\n",
      "[26,    99] loss: 0.692782\n",
      "[26,   199] loss: 0.696961\n",
      "[26,   299] loss: 0.706885\n",
      "[27,    99] loss: 0.692782\n",
      "[27,   199] loss: 0.696961\n",
      "[27,   299] loss: 0.706885\n",
      "[28,    99] loss: 0.692782\n",
      "[28,   199] loss: 0.696961\n",
      "[28,   299] loss: 0.706885\n",
      "[29,    99] loss: 0.692782\n",
      "[29,   199] loss: 0.696961\n",
      "[29,   299] loss: 0.706885\n",
      "[30,    99] loss: 0.692782\n",
      "[30,   199] loss: 0.696961\n",
      "[30,   299] loss: 0.706885\n",
      "[31,    99] loss: 0.692782\n",
      "[31,   199] loss: 0.696961\n",
      "[31,   299] loss: 0.706885\n",
      "[32,    99] loss: 0.692782\n",
      "[32,   199] loss: 0.696961\n",
      "[32,   299] loss: 0.706885\n",
      "[33,    99] loss: 0.692782\n",
      "[33,   199] loss: 0.696961\n",
      "[33,   299] loss: 0.706885\n",
      "[34,    99] loss: 0.692782\n",
      "[34,   199] loss: 0.696961\n",
      "[34,   299] loss: 0.706885\n",
      "[35,    99] loss: 0.692782\n",
      "[35,   199] loss: 0.696961\n",
      "[35,   299] loss: 0.706885\n",
      "[36,    99] loss: 0.692782\n",
      "[36,   199] loss: 0.696961\n",
      "[36,   299] loss: 0.706885\n",
      "[37,    99] loss: 0.692782\n",
      "[37,   199] loss: 0.696961\n",
      "[37,   299] loss: 0.706885\n",
      "[38,    99] loss: 0.692782\n",
      "[38,   199] loss: 0.696961\n",
      "[38,   299] loss: 0.706885\n",
      "[39,    99] loss: 0.692782\n",
      "[39,   199] loss: 0.696961\n",
      "[39,   299] loss: 0.706885\n",
      "[40,    99] loss: 0.692782\n",
      "[40,   199] loss: 0.696961\n",
      "[40,   299] loss: 0.706885\n",
      "[41,    99] loss: 0.692782\n",
      "[41,   199] loss: 0.696961\n",
      "[41,   299] loss: 0.706885\n",
      "[42,    99] loss: 0.692782\n",
      "[42,   199] loss: 0.696961\n",
      "[42,   299] loss: 0.706885\n",
      "[43,    99] loss: 0.692782\n",
      "[43,   199] loss: 0.696961\n",
      "[43,   299] loss: 0.706885\n",
      "[44,    99] loss: 0.692782\n",
      "[44,   199] loss: 0.696961\n",
      "[44,   299] loss: 0.706885\n",
      "[45,    99] loss: 0.692782\n",
      "[45,   199] loss: 0.696961\n",
      "[45,   299] loss: 0.706885\n",
      "[46,    99] loss: 0.692782\n",
      "[46,   199] loss: 0.696961\n",
      "[46,   299] loss: 0.706885\n",
      "[47,    99] loss: 0.692782\n",
      "[47,   199] loss: 0.696961\n",
      "[47,   299] loss: 0.706885\n",
      "[48,    99] loss: 0.692782\n",
      "[48,   199] loss: 0.696961\n",
      "[48,   299] loss: 0.706885\n",
      "[49,    99] loss: 0.692782\n",
      "[49,   199] loss: 0.696961\n",
      "[49,   299] loss: 0.706885\n",
      "[50,    99] loss: 0.692782\n",
      "[50,   199] loss: 0.696961\n",
      "[50,   299] loss: 0.706885\n",
      "[51,    99] loss: 0.692782\n",
      "[51,   199] loss: 0.696961\n",
      "[51,   299] loss: 0.706885\n",
      "[52,    99] loss: 0.692782\n",
      "[52,   199] loss: 0.696961\n",
      "[52,   299] loss: 0.706885\n",
      "[53,    99] loss: 0.692782\n",
      "[53,   199] loss: 0.696961\n",
      "[53,   299] loss: 0.706885\n",
      "[54,    99] loss: 0.692782\n",
      "[54,   199] loss: 0.696961\n",
      "[54,   299] loss: 0.706885\n",
      "[55,    99] loss: 0.692782\n",
      "[55,   199] loss: 0.696961\n",
      "[55,   299] loss: 0.706885\n",
      "[56,    99] loss: 0.692782\n",
      "[56,   199] loss: 0.696961\n",
      "[56,   299] loss: 0.706885\n",
      "[57,    99] loss: 0.692782\n",
      "[57,   199] loss: 0.696961\n",
      "[57,   299] loss: 0.706885\n",
      "[58,    99] loss: 0.692782\n",
      "[58,   199] loss: 0.696961\n",
      "[58,   299] loss: 0.706885\n",
      "[59,    99] loss: 0.692782\n",
      "[59,   199] loss: 0.696961\n",
      "[59,   299] loss: 0.706885\n",
      "[60,    99] loss: 0.692782\n",
      "[60,   199] loss: 0.696961\n",
      "[60,   299] loss: 0.706885\n",
      "[61,    99] loss: 0.692782\n",
      "[61,   199] loss: 0.696961\n",
      "[61,   299] loss: 0.706885\n",
      "[62,    99] loss: 0.692782\n",
      "[62,   199] loss: 0.696961\n",
      "[62,   299] loss: 0.706885\n",
      "[63,    99] loss: 0.692782\n",
      "[63,   199] loss: 0.696961\n",
      "[63,   299] loss: 0.706885\n",
      "[64,    99] loss: 0.692782\n",
      "[64,   199] loss: 0.696961\n",
      "[64,   299] loss: 0.706885\n",
      "[65,    99] loss: 0.692782\n",
      "[65,   199] loss: 0.696961\n",
      "[65,   299] loss: 0.706885\n",
      "[66,    99] loss: 0.692782\n",
      "[66,   199] loss: 0.696961\n",
      "[66,   299] loss: 0.706885\n",
      "[67,    99] loss: 0.692782\n",
      "[67,   199] loss: 0.696961\n",
      "[67,   299] loss: 0.706885\n",
      "[68,    99] loss: 0.692782\n",
      "[68,   199] loss: 0.696961\n",
      "[68,   299] loss: 0.706885\n",
      "[69,    99] loss: 0.692782\n",
      "[69,   199] loss: 0.696961\n",
      "[69,   299] loss: 0.706885\n",
      "[70,    99] loss: 0.692782\n",
      "[70,   199] loss: 0.696961\n",
      "[70,   299] loss: 0.706885\n",
      "[71,    99] loss: 0.692782\n",
      "[71,   199] loss: 0.696961\n",
      "[71,   299] loss: 0.706885\n",
      "[72,    99] loss: 0.692782\n",
      "[72,   199] loss: 0.696961\n",
      "[72,   299] loss: 0.706885\n",
      "[73,    99] loss: 0.692782\n",
      "[73,   199] loss: 0.696961\n",
      "[73,   299] loss: 0.706885\n",
      "[74,    99] loss: 0.692782\n",
      "[74,   199] loss: 0.696961\n",
      "[74,   299] loss: 0.706885\n",
      "[75,    99] loss: 0.692782\n",
      "[75,   199] loss: 0.696961\n",
      "[75,   299] loss: 0.706885\n",
      "[76,    99] loss: 0.692782\n",
      "[76,   199] loss: 0.696961\n",
      "[76,   299] loss: 0.706885\n",
      "[77,    99] loss: 0.692782\n",
      "[77,   199] loss: 0.696961\n",
      "[77,   299] loss: 0.706885\n",
      "[78,    99] loss: 0.692782\n",
      "[78,   199] loss: 0.696961\n",
      "[78,   299] loss: 0.706885\n",
      "[79,    99] loss: 0.692782\n",
      "[79,   199] loss: 0.696961\n",
      "[79,   299] loss: 0.706885\n",
      "[80,    99] loss: 0.692782\n",
      "[80,   199] loss: 0.696961\n",
      "[80,   299] loss: 0.706885\n",
      "[81,    99] loss: 0.692782\n",
      "[81,   199] loss: 0.696961\n",
      "[81,   299] loss: 0.706885\n",
      "[82,    99] loss: 0.692782\n",
      "[82,   199] loss: 0.696961\n",
      "[82,   299] loss: 0.706885\n",
      "[83,    99] loss: 0.692782\n",
      "[83,   199] loss: 0.696961\n",
      "[83,   299] loss: 0.706885\n",
      "[84,    99] loss: 0.692782\n",
      "[84,   199] loss: 0.696961\n",
      "[84,   299] loss: 0.706885\n",
      "[85,    99] loss: 0.692782\n",
      "[85,   199] loss: 0.696961\n",
      "[85,   299] loss: 0.706885\n",
      "[86,    99] loss: 0.692782\n",
      "[86,   199] loss: 0.696961\n",
      "[86,   299] loss: 0.706885\n",
      "[87,    99] loss: 0.692782\n",
      "[87,   199] loss: 0.696961\n",
      "[87,   299] loss: 0.706885\n",
      "[88,    99] loss: 0.692782\n",
      "[88,   199] loss: 0.696961\n",
      "[88,   299] loss: 0.706885\n",
      "[89,    99] loss: 0.692782\n",
      "[89,   199] loss: 0.696961\n",
      "[89,   299] loss: 0.706885\n",
      "[90,    99] loss: 0.692782\n",
      "[90,   199] loss: 0.696961\n",
      "[90,   299] loss: 0.706885\n",
      "[91,    99] loss: 0.692782\n",
      "[91,   199] loss: 0.696961\n",
      "[91,   299] loss: 0.706885\n",
      "[92,    99] loss: 0.692782\n",
      "[92,   199] loss: 0.696961\n",
      "[92,   299] loss: 0.706885\n",
      "[93,    99] loss: 0.692782\n",
      "[93,   199] loss: 0.696961\n",
      "[93,   299] loss: 0.706885\n",
      "[94,    99] loss: 0.692782\n",
      "[94,   199] loss: 0.696961\n",
      "[94,   299] loss: 0.706885\n",
      "[95,    99] loss: 0.692782\n",
      "[95,   199] loss: 0.696961\n",
      "[95,   299] loss: 0.706885\n",
      "[96,    99] loss: 0.692782\n",
      "[96,   199] loss: 0.696961\n",
      "[96,   299] loss: 0.706885\n",
      "[97,    99] loss: 0.692782\n",
      "[97,   199] loss: 0.696961\n",
      "[97,   299] loss: 0.706885\n",
      "[98,    99] loss: 0.692782\n",
      "[98,   199] loss: 0.696961\n",
      "[98,   299] loss: 0.706885\n",
      "[99,    99] loss: 0.692782\n",
      "[99,   199] loss: 0.696961\n",
      "[99,   299] loss: 0.706885\n",
      "[100,    99] loss: 0.692782\n",
      "[100,   199] loss: 0.696961\n",
      "[100,   299] loss: 0.706885\n",
      "Finished Training\n",
      "[1,    99] loss: 2.011932\n",
      "[1,   199] loss: 0.743503\n",
      "[1,   299] loss: 0.719076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    99] loss: 0.712313\n",
      "[2,   199] loss: 2.693222\n",
      "[2,   299] loss: 0.719140\n",
      "[3,    99] loss: 0.715815\n",
      "[3,   199] loss: 0.705643\n",
      "[3,   299] loss: 0.719342\n",
      "[4,    99] loss: 0.716040\n",
      "[4,   199] loss: 0.705711\n",
      "[4,   299] loss: 0.719504\n",
      "[5,    99] loss: 0.716149\n",
      "[5,   199] loss: 0.705746\n",
      "[5,   299] loss: 0.719589\n",
      "[6,    99] loss: 0.716210\n",
      "[6,   199] loss: 0.705765\n",
      "[6,   299] loss: 0.719639\n",
      "[7,    99] loss: 0.716246\n",
      "[7,   199] loss: 0.705777\n",
      "[7,   299] loss: 0.719670\n",
      "[8,    99] loss: 0.716270\n",
      "[8,   199] loss: 0.705785\n",
      "[8,   299] loss: 0.719691\n",
      "[9,    99] loss: 0.716285\n",
      "[9,   199] loss: 0.705790\n",
      "[9,   299] loss: 0.719704\n",
      "[10,    99] loss: 0.716295\n",
      "[10,   199] loss: 0.705793\n",
      "[10,   299] loss: 0.719713\n",
      "[11,    99] loss: 0.716302\n",
      "[11,   199] loss: 0.705795\n",
      "[11,   299] loss: 0.719719\n",
      "[12,    99] loss: 0.716306\n",
      "[12,   199] loss: 0.705797\n",
      "[12,   299] loss: 0.719723\n",
      "[13,    99] loss: 0.716310\n",
      "[13,   199] loss: 0.705798\n",
      "[13,   299] loss: 0.719726\n",
      "[14,    99] loss: 0.716312\n",
      "[14,   199] loss: 0.705799\n",
      "[14,   299] loss: 0.719728\n",
      "[15,    99] loss: 0.716313\n",
      "[15,   199] loss: 0.705799\n",
      "[15,   299] loss: 0.719729\n",
      "[16,    99] loss: 0.716314\n",
      "[16,   199] loss: 0.705800\n",
      "[16,   299] loss: 0.719730\n",
      "[17,    99] loss: 0.716315\n",
      "[17,   199] loss: 0.705800\n",
      "[17,   299] loss: 0.719731\n",
      "[18,    99] loss: 0.716315\n",
      "[18,   199] loss: 0.705800\n",
      "[18,   299] loss: 0.719731\n",
      "[19,    99] loss: 0.716316\n",
      "[19,   199] loss: 0.705800\n",
      "[19,   299] loss: 0.719731\n",
      "[20,    99] loss: 0.716316\n",
      "[20,   199] loss: 0.705800\n",
      "[20,   299] loss: 0.719732\n",
      "[21,    99] loss: 0.716316\n",
      "[21,   199] loss: 0.705800\n",
      "[21,   299] loss: 0.719732\n",
      "[22,    99] loss: 0.716316\n",
      "[22,   199] loss: 0.705800\n",
      "[22,   299] loss: 0.719732\n",
      "[23,    99] loss: 0.716316\n",
      "[23,   199] loss: 0.705800\n",
      "[23,   299] loss: 0.719732\n",
      "[24,    99] loss: 0.716316\n",
      "[24,   199] loss: 0.705800\n",
      "[24,   299] loss: 0.719732\n",
      "[25,    99] loss: 0.716316\n",
      "[25,   199] loss: 0.705800\n",
      "[25,   299] loss: 0.719732\n",
      "[26,    99] loss: 0.716316\n",
      "[26,   199] loss: 0.705800\n",
      "[26,   299] loss: 0.719732\n",
      "[27,    99] loss: 0.716316\n",
      "[27,   199] loss: 0.705800\n",
      "[27,   299] loss: 0.719732\n",
      "[28,    99] loss: 0.716317\n",
      "[28,   199] loss: 0.705800\n",
      "[28,   299] loss: 0.719732\n",
      "[29,    99] loss: 0.716317\n",
      "[29,   199] loss: 0.705800\n",
      "[29,   299] loss: 0.719732\n",
      "[30,    99] loss: 0.716317\n",
      "[30,   199] loss: 0.705800\n",
      "[30,   299] loss: 0.719732\n",
      "[31,    99] loss: 0.716317\n",
      "[31,   199] loss: 0.705800\n",
      "[31,   299] loss: 0.719732\n",
      "[32,    99] loss: 0.716317\n",
      "[32,   199] loss: 0.705800\n",
      "[32,   299] loss: 0.719732\n",
      "[33,    99] loss: 0.716317\n",
      "[33,   199] loss: 0.705800\n",
      "[33,   299] loss: 0.719732\n",
      "[34,    99] loss: 0.716317\n",
      "[34,   199] loss: 0.705800\n",
      "[34,   299] loss: 0.719732\n",
      "[35,    99] loss: 0.716317\n",
      "[35,   199] loss: 0.705800\n",
      "[35,   299] loss: 0.719732\n",
      "[36,    99] loss: 0.716317\n",
      "[36,   199] loss: 0.705800\n",
      "[36,   299] loss: 0.719732\n",
      "[37,    99] loss: 0.716317\n",
      "[37,   199] loss: 0.705800\n",
      "[37,   299] loss: 0.719732\n",
      "[38,    99] loss: 0.716317\n",
      "[38,   199] loss: 0.705800\n",
      "[38,   299] loss: 0.719732\n",
      "[39,    99] loss: 0.716317\n",
      "[39,   199] loss: 0.705800\n",
      "[39,   299] loss: 0.719732\n",
      "[40,    99] loss: 0.716317\n",
      "[40,   199] loss: 0.705800\n",
      "[40,   299] loss: 0.719732\n",
      "[41,    99] loss: 0.716317\n",
      "[41,   199] loss: 0.705800\n",
      "[41,   299] loss: 0.719732\n",
      "[42,    99] loss: 0.716317\n",
      "[42,   199] loss: 0.705800\n",
      "[42,   299] loss: 0.719732\n",
      "[43,    99] loss: 0.716317\n",
      "[43,   199] loss: 0.705800\n",
      "[43,   299] loss: 0.719732\n",
      "[44,    99] loss: 0.716317\n",
      "[44,   199] loss: 0.705800\n",
      "[44,   299] loss: 0.719732\n",
      "[45,    99] loss: 0.716317\n",
      "[45,   199] loss: 0.705800\n",
      "[45,   299] loss: 0.719732\n",
      "[46,    99] loss: 0.716317\n",
      "[46,   199] loss: 0.705800\n",
      "[46,   299] loss: 0.719732\n",
      "[47,    99] loss: 0.716317\n",
      "[47,   199] loss: 0.705800\n",
      "[47,   299] loss: 0.719732\n",
      "[48,    99] loss: 0.716317\n",
      "[48,   199] loss: 0.705800\n",
      "[48,   299] loss: 0.719732\n",
      "[49,    99] loss: 0.716317\n",
      "[49,   199] loss: 0.705800\n",
      "[49,   299] loss: 0.719732\n",
      "[50,    99] loss: 0.716317\n",
      "[50,   199] loss: 0.705800\n",
      "[50,   299] loss: 0.719732\n",
      "[51,    99] loss: 0.716317\n",
      "[51,   199] loss: 0.705800\n",
      "[51,   299] loss: 0.719732\n",
      "[52,    99] loss: 0.716317\n",
      "[52,   199] loss: 0.705800\n",
      "[52,   299] loss: 0.719732\n",
      "[53,    99] loss: 0.716317\n",
      "[53,   199] loss: 0.705800\n",
      "[53,   299] loss: 0.719732\n",
      "[54,    99] loss: 0.716317\n",
      "[54,   199] loss: 0.705800\n",
      "[54,   299] loss: 0.719732\n",
      "[55,    99] loss: 0.716317\n",
      "[55,   199] loss: 0.705800\n",
      "[55,   299] loss: 0.719732\n",
      "[56,    99] loss: 0.716317\n",
      "[56,   199] loss: 0.705800\n",
      "[56,   299] loss: 0.719732\n",
      "[57,    99] loss: 0.716317\n",
      "[57,   199] loss: 0.705800\n",
      "[57,   299] loss: 0.719732\n",
      "[58,    99] loss: 0.716317\n",
      "[58,   199] loss: 0.705800\n",
      "[58,   299] loss: 0.719732\n",
      "[59,    99] loss: 0.716317\n",
      "[59,   199] loss: 0.705800\n",
      "[59,   299] loss: 0.719732\n",
      "[60,    99] loss: 0.716317\n",
      "[60,   199] loss: 0.705800\n",
      "[60,   299] loss: 0.719732\n",
      "[61,    99] loss: 0.716317\n",
      "[61,   199] loss: 0.705800\n",
      "[61,   299] loss: 0.719732\n",
      "[62,    99] loss: 0.716317\n",
      "[62,   199] loss: 0.705800\n",
      "[62,   299] loss: 0.719732\n",
      "[63,    99] loss: 0.716317\n",
      "[63,   199] loss: 0.705800\n",
      "[63,   299] loss: 0.719732\n",
      "[64,    99] loss: 0.716317\n",
      "[64,   199] loss: 0.705800\n",
      "[64,   299] loss: 0.719732\n",
      "[65,    99] loss: 0.716317\n",
      "[65,   199] loss: 0.705800\n",
      "[65,   299] loss: 0.719732\n",
      "[66,    99] loss: 0.716317\n",
      "[66,   199] loss: 0.705800\n",
      "[66,   299] loss: 0.719732\n",
      "[67,    99] loss: 0.716317\n",
      "[67,   199] loss: 0.705800\n",
      "[67,   299] loss: 0.719732\n",
      "[68,    99] loss: 0.716317\n",
      "[68,   199] loss: 0.705800\n",
      "[68,   299] loss: 0.719732\n",
      "[69,    99] loss: 0.716317\n",
      "[69,   199] loss: 0.705800\n",
      "[69,   299] loss: 0.719732\n",
      "[70,    99] loss: 0.716317\n",
      "[70,   199] loss: 0.705800\n",
      "[70,   299] loss: 0.719732\n",
      "[71,    99] loss: 0.716317\n",
      "[71,   199] loss: 0.705800\n",
      "[71,   299] loss: 0.719732\n",
      "[72,    99] loss: 0.716317\n",
      "[72,   199] loss: 0.705800\n",
      "[72,   299] loss: 0.719732\n",
      "[73,    99] loss: 0.716317\n",
      "[73,   199] loss: 0.705800\n",
      "[73,   299] loss: 0.719732\n",
      "[74,    99] loss: 0.716317\n",
      "[74,   199] loss: 0.705800\n",
      "[74,   299] loss: 0.719732\n",
      "[75,    99] loss: 0.716317\n",
      "[75,   199] loss: 0.705800\n",
      "[75,   299] loss: 0.719732\n",
      "[76,    99] loss: 0.716317\n",
      "[76,   199] loss: 0.705800\n",
      "[76,   299] loss: 0.719732\n",
      "[77,    99] loss: 0.716317\n",
      "[77,   199] loss: 0.705800\n",
      "[77,   299] loss: 0.719732\n",
      "[78,    99] loss: 0.716317\n",
      "[78,   199] loss: 0.705800\n",
      "[78,   299] loss: 0.719732\n",
      "[79,    99] loss: 0.716317\n",
      "[79,   199] loss: 0.705800\n",
      "[79,   299] loss: 0.719732\n",
      "[80,    99] loss: 0.716317\n",
      "[80,   199] loss: 0.705800\n",
      "[80,   299] loss: 0.719732\n",
      "[81,    99] loss: 0.716317\n",
      "[81,   199] loss: 0.705800\n",
      "[81,   299] loss: 0.719732\n",
      "[82,    99] loss: 0.716317\n",
      "[82,   199] loss: 0.705800\n",
      "[82,   299] loss: 0.719732\n",
      "[83,    99] loss: 0.716317\n",
      "[83,   199] loss: 0.705800\n",
      "[83,   299] loss: 0.719732\n",
      "[84,    99] loss: 0.716317\n",
      "[84,   199] loss: 0.705800\n",
      "[84,   299] loss: 0.719732\n",
      "[85,    99] loss: 0.716317\n",
      "[85,   199] loss: 0.705800\n",
      "[85,   299] loss: 0.719732\n",
      "[86,    99] loss: 0.716317\n",
      "[86,   199] loss: 0.705800\n",
      "[86,   299] loss: 0.719732\n",
      "[87,    99] loss: 0.716317\n",
      "[87,   199] loss: 0.705800\n",
      "[87,   299] loss: 0.719732\n",
      "[88,    99] loss: 0.716317\n",
      "[88,   199] loss: 0.705800\n",
      "[88,   299] loss: 0.719732\n",
      "[89,    99] loss: 0.716317\n",
      "[89,   199] loss: 0.705800\n",
      "[89,   299] loss: 0.719732\n",
      "[90,    99] loss: 0.716317\n",
      "[90,   199] loss: 0.705800\n",
      "[90,   299] loss: 0.719732\n",
      "[91,    99] loss: 0.716317\n",
      "[91,   199] loss: 0.705800\n",
      "[91,   299] loss: 0.719732\n",
      "[92,    99] loss: 0.716317\n",
      "[92,   199] loss: 0.705800\n",
      "[92,   299] loss: 0.719732\n",
      "[93,    99] loss: 0.716317\n",
      "[93,   199] loss: 0.705800\n",
      "[93,   299] loss: 0.719732\n",
      "[94,    99] loss: 0.716317\n",
      "[94,   199] loss: 0.705800\n",
      "[94,   299] loss: 0.719732\n",
      "[95,    99] loss: 0.716317\n",
      "[95,   199] loss: 0.705800\n",
      "[95,   299] loss: 0.719732\n",
      "[96,    99] loss: 0.716317\n",
      "[96,   199] loss: 0.705800\n",
      "[96,   299] loss: 0.719732\n",
      "[97,    99] loss: 0.716317\n",
      "[97,   199] loss: 0.705800\n",
      "[97,   299] loss: 0.719732\n",
      "[98,    99] loss: 0.716317\n",
      "[98,   199] loss: 0.705800\n",
      "[98,   299] loss: 0.719732\n",
      "[99,    99] loss: 0.716317\n",
      "[99,   199] loss: 0.705800\n",
      "[99,   299] loss: 0.719732\n",
      "[100,    99] loss: 0.716317\n",
      "[100,   199] loss: 0.705800\n",
      "[100,   299] loss: 0.719732\n",
      "Finished Training\n",
      "[1,    99] loss: 0.680566\n",
      "[1,   199] loss: 0.666431\n",
      "[1,   299] loss: 0.728837\n",
      "[2,    99] loss: 0.609658\n",
      "[2,   199] loss: 0.609818\n",
      "[2,   299] loss: 0.653114\n",
      "[3,    99] loss: 0.558807\n",
      "[3,   199] loss: 0.561358\n",
      "[3,   299] loss: 0.583191\n",
      "[4,    99] loss: 0.515585\n",
      "[4,   199] loss: 0.568066\n",
      "[4,   299] loss: 0.587144\n",
      "[5,    99] loss: 0.454889\n",
      "[5,   199] loss: 0.505221\n",
      "[5,   299] loss: 0.528558\n",
      "[6,    99] loss: 0.421498\n",
      "[6,   199] loss: 0.430909\n",
      "[6,   299] loss: 0.472286\n",
      "[7,    99] loss: 0.405303\n",
      "[7,   199] loss: 0.408359\n",
      "[7,   299] loss: 0.469231\n",
      "[8,    99] loss: 0.347925\n",
      "[8,   199] loss: 0.343495\n",
      "[8,   299] loss: 0.420487\n",
      "[9,    99] loss: 0.321249\n",
      "[9,   199] loss: 0.278653\n",
      "[9,   299] loss: 0.487758\n",
      "[10,    99] loss: 0.330028\n",
      "[10,   199] loss: 0.261964\n",
      "[10,   299] loss: 0.405385\n",
      "[11,    99] loss: 0.291521\n",
      "[11,   199] loss: 0.230743\n",
      "[11,   299] loss: 0.331926\n",
      "[12,    99] loss: 0.324292\n",
      "[12,   199] loss: 0.177754\n",
      "[12,   299] loss: 0.335734\n",
      "[13,    99] loss: 0.277332\n",
      "[13,   199] loss: 0.183162\n",
      "[13,   299] loss: 0.339724\n",
      "[14,    99] loss: 0.258588\n",
      "[14,   199] loss: 0.165172\n",
      "[14,   299] loss: 0.286859\n",
      "[15,    99] loss: 0.269225\n",
      "[15,   199] loss: 0.209892\n",
      "[15,   299] loss: 0.292392\n",
      "[16,    99] loss: 0.266081\n",
      "[16,   199] loss: 0.190882\n",
      "[16,   299] loss: 0.220710\n",
      "[17,    99] loss: 0.241574\n",
      "[17,   199] loss: 0.146218\n",
      "[17,   299] loss: 0.243508\n",
      "[18,    99] loss: 0.243877\n",
      "[18,   199] loss: 0.209193\n",
      "[18,   299] loss: 0.261769\n",
      "[19,    99] loss: 0.271224\n",
      "[19,   199] loss: 0.142712\n",
      "[19,   299] loss: 0.293240\n",
      "[20,    99] loss: 0.221706\n",
      "[20,   199] loss: 0.149145\n",
      "[20,   299] loss: 0.250118\n",
      "[21,    99] loss: 0.217473\n",
      "[21,   199] loss: 0.158143\n",
      "[21,   299] loss: 0.248925\n",
      "[22,    99] loss: 0.234826\n",
      "[22,   199] loss: 0.149539\n",
      "[22,   299] loss: 0.210036\n",
      "[23,    99] loss: 0.219624\n",
      "[23,   199] loss: 0.117607\n",
      "[23,   299] loss: 0.198101\n",
      "[24,    99] loss: 0.238752\n",
      "[24,   199] loss: 0.142370\n",
      "[24,   299] loss: 0.171239\n",
      "[25,    99] loss: 0.257194\n",
      "[25,   199] loss: 0.139138\n",
      "[25,   299] loss: 0.175797\n",
      "[26,    99] loss: 0.156502\n",
      "[26,   199] loss: 0.105395\n",
      "[26,   299] loss: 0.193079\n",
      "[27,    99] loss: 0.229627\n",
      "[27,   199] loss: 0.118743\n",
      "[27,   299] loss: 0.185251\n",
      "[28,    99] loss: 0.202192\n",
      "[28,   199] loss: 0.152278\n",
      "[28,   299] loss: 0.223472\n",
      "[29,    99] loss: 0.189862\n",
      "[29,   199] loss: 0.117227\n",
      "[29,   299] loss: 0.169147\n",
      "[30,    99] loss: 0.159234\n",
      "[30,   199] loss: 0.114654\n",
      "[30,   299] loss: 0.356262\n",
      "[31,    99] loss: 0.180876\n",
      "[31,   199] loss: 0.066132\n",
      "[31,   299] loss: 0.155777\n",
      "[32,    99] loss: 0.176692\n",
      "[32,   199] loss: 0.075740\n",
      "[32,   299] loss: 0.153694\n",
      "[33,    99] loss: 0.110405\n",
      "[33,   199] loss: 0.076458\n",
      "[33,   299] loss: 0.136781\n",
      "[34,    99] loss: 0.192632\n",
      "[34,   199] loss: 0.139853\n",
      "[34,   299] loss: 0.162097\n",
      "[35,    99] loss: 0.084576\n",
      "[35,   199] loss: 0.137289\n",
      "[35,   299] loss: 0.370989\n",
      "[36,    99] loss: 0.166116\n",
      "[36,   199] loss: 0.131710\n",
      "[36,   299] loss: 0.124724\n",
      "[37,    99] loss: 0.149198\n",
      "[37,   199] loss: 0.082922\n",
      "[37,   299] loss: 0.125722\n",
      "[38,    99] loss: 0.244603\n",
      "[38,   199] loss: 0.109779\n",
      "[38,   299] loss: 0.188138\n",
      "[39,    99] loss: 0.212471\n",
      "[39,   199] loss: 0.122315\n",
      "[39,   299] loss: 0.146610\n",
      "[40,    99] loss: 0.142448\n",
      "[40,   199] loss: 0.064012\n",
      "[40,   299] loss: 0.133358\n",
      "[41,    99] loss: 0.093758\n",
      "[41,   199] loss: 0.047730\n",
      "[41,   299] loss: 0.087715\n",
      "[42,    99] loss: 0.078553\n",
      "[42,   199] loss: 0.045643\n",
      "[42,   299] loss: 0.179237\n",
      "[43,    99] loss: 0.192907\n",
      "[43,   199] loss: 0.201015\n",
      "[43,   299] loss: 0.153531\n",
      "[44,    99] loss: 0.104077\n",
      "[44,   199] loss: 0.073322\n",
      "[44,   299] loss: 0.111200\n",
      "[45,    99] loss: 0.190750\n",
      "[45,   199] loss: 0.080401\n",
      "[45,   299] loss: 0.102627\n",
      "[46,    99] loss: 0.191108\n",
      "[46,   199] loss: 0.049930\n",
      "[46,   299] loss: 0.098535\n",
      "[47,    99] loss: 0.080564\n",
      "[47,   199] loss: 0.039972\n",
      "[47,   299] loss: 0.157420\n",
      "[48,    99] loss: 0.239367\n",
      "[48,   199] loss: 0.141311\n",
      "[48,   299] loss: 0.126353\n",
      "[49,    99] loss: 0.172834\n",
      "[49,   199] loss: 0.092057\n",
      "[49,   299] loss: 0.092404\n",
      "[50,    99] loss: 0.096795\n",
      "[50,   199] loss: 0.050777\n",
      "[50,   299] loss: 0.063509\n",
      "[51,    99] loss: 0.120658\n",
      "[51,   199] loss: 0.155519\n",
      "[51,   299] loss: 0.106828\n",
      "[52,    99] loss: 0.142560\n",
      "[52,   199] loss: 0.077754\n",
      "[52,   299] loss: 0.069112\n",
      "[53,    99] loss: 0.093798\n",
      "[53,   199] loss: 0.100744\n",
      "[53,   299] loss: 0.095917\n",
      "[54,    99] loss: 0.077689\n",
      "[54,   199] loss: 0.129652\n",
      "[54,   299] loss: 0.091594\n",
      "[55,    99] loss: 0.157970\n",
      "[55,   199] loss: 0.051142\n",
      "[55,   299] loss: 0.058090\n",
      "[56,    99] loss: 0.085277\n",
      "[56,   199] loss: 0.148824\n",
      "[56,   299] loss: 0.061879\n",
      "[57,    99] loss: 0.043455\n",
      "[57,   199] loss: 0.102411\n",
      "[57,   299] loss: 0.123912\n",
      "[58,    99] loss: 0.089701\n",
      "[58,   199] loss: 0.037606\n",
      "[58,   299] loss: 0.121681\n",
      "[59,    99] loss: 0.121290\n",
      "[59,   199] loss: 0.063202\n",
      "[59,   299] loss: 0.053928\n",
      "[60,    99] loss: 0.028856\n",
      "[60,   199] loss: 0.068278\n",
      "[60,   299] loss: 0.172742\n",
      "[61,    99] loss: 0.088900\n",
      "[61,   199] loss: 0.125939\n",
      "[61,   299] loss: 0.150633\n",
      "[62,    99] loss: 0.197394\n",
      "[62,   199] loss: 0.082884\n",
      "[62,   299] loss: 0.126673\n",
      "[63,    99] loss: 0.052952\n",
      "[63,   199] loss: 0.090070\n",
      "[63,   299] loss: 0.104971\n",
      "[64,    99] loss: 0.070561\n",
      "[64,   199] loss: 0.055956\n",
      "[64,   299] loss: 0.177237\n",
      "[65,    99] loss: 0.056732\n",
      "[65,   199] loss: 0.029821\n",
      "[65,   299] loss: 0.163429\n",
      "[66,    99] loss: 0.063700\n",
      "[66,   199] loss: 0.018210\n",
      "[66,   299] loss: 0.097827\n",
      "[67,    99] loss: 0.095575\n",
      "[67,   199] loss: 0.075193\n",
      "[67,   299] loss: 0.126387\n",
      "[68,    99] loss: 0.111913\n",
      "[68,   199] loss: 0.090081\n",
      "[68,   299] loss: 0.075281\n",
      "[69,    99] loss: 0.204118\n",
      "[69,   199] loss: 0.111039\n",
      "[69,   299] loss: 0.282318\n",
      "[70,    99] loss: 0.079435\n",
      "[70,   199] loss: 0.113344\n",
      "[70,   299] loss: 0.157961\n",
      "[71,    99] loss: 0.105752\n",
      "[71,   199] loss: 0.191611\n",
      "[71,   299] loss: 0.070920\n",
      "[72,    99] loss: 0.078480\n",
      "[72,   199] loss: 0.036004\n",
      "[72,   299] loss: 0.035490\n",
      "[73,    99] loss: 0.017949\n",
      "[73,   199] loss: 0.012410\n",
      "[73,   299] loss: 0.031423\n",
      "[74,    99] loss: 0.010347\n",
      "[74,   199] loss: 0.020158\n",
      "[74,   299] loss: 0.045923\n",
      "[75,    99] loss: 0.061202\n",
      "[75,   199] loss: 0.073323\n",
      "[75,   299] loss: 0.169882\n",
      "[76,    99] loss: 0.116473\n",
      "[76,   199] loss: 0.057423\n",
      "[76,   299] loss: 0.123459\n",
      "[77,    99] loss: 0.087152\n",
      "[77,   199] loss: 0.073278\n",
      "[77,   299] loss: 0.064308\n",
      "[78,    99] loss: 0.144722\n",
      "[78,   199] loss: 0.104998\n",
      "[78,   299] loss: 0.037703\n",
      "[79,    99] loss: 0.072883\n",
      "[79,   199] loss: 0.080160\n",
      "[79,   299] loss: 0.185029\n",
      "[80,    99] loss: 0.126965\n",
      "[80,   199] loss: 0.121640\n",
      "[80,   299] loss: 0.110203\n",
      "[81,    99] loss: 0.112650\n",
      "[81,   199] loss: 0.057638\n",
      "[81,   299] loss: 0.083587\n",
      "[82,    99] loss: 0.106400\n",
      "[82,   199] loss: 0.065463\n",
      "[82,   299] loss: 0.037505\n",
      "[83,    99] loss: 0.058036\n",
      "[83,   199] loss: 0.184493\n",
      "[83,   299] loss: 0.042755\n",
      "[84,    99] loss: 0.040050\n",
      "[84,   199] loss: 0.015494\n",
      "[84,   299] loss: 0.083317\n",
      "[85,    99] loss: 0.078942\n",
      "[85,   199] loss: 0.067104\n",
      "[85,   299] loss: 0.028942\n",
      "[86,    99] loss: 0.010707\n",
      "[86,   199] loss: 0.019287\n",
      "[86,   299] loss: 0.036562\n",
      "[87,    99] loss: 0.138391\n",
      "[87,   199] loss: 0.099414\n",
      "[87,   299] loss: 0.098457\n",
      "[88,    99] loss: 0.107742\n",
      "[88,   199] loss: 0.151470\n",
      "[88,   299] loss: 0.108480\n",
      "[89,    99] loss: 0.016848\n",
      "[89,   199] loss: 0.078798\n",
      "[89,   299] loss: 0.045855\n",
      "[90,    99] loss: 0.036064\n",
      "[90,   199] loss: 0.063452\n",
      "[90,   299] loss: 0.122209\n",
      "[91,    99] loss: 0.078503\n",
      "[91,   199] loss: 0.076401\n",
      "[91,   299] loss: 0.041655\n",
      "[92,    99] loss: 0.042318\n",
      "[92,   199] loss: 0.007920\n",
      "[92,   299] loss: 0.006733\n",
      "[93,    99] loss: 0.039787\n",
      "[93,   199] loss: 0.005699\n",
      "[93,   299] loss: 0.006291\n",
      "[94,    99] loss: 0.024275\n",
      "[94,   199] loss: 0.249914\n",
      "[94,   299] loss: 0.177431\n",
      "[95,    99] loss: 0.232462\n",
      "[95,   199] loss: 0.100585\n",
      "[95,   299] loss: 0.126058\n",
      "[96,    99] loss: 0.103255\n",
      "[96,   199] loss: 0.101131\n",
      "[96,   299] loss: 0.039832\n",
      "[97,    99] loss: 0.112431\n",
      "[97,   199] loss: 0.056171\n",
      "[97,   299] loss: 0.054631\n",
      "[98,    99] loss: 0.122713\n",
      "[98,   199] loss: 0.084949\n",
      "[98,   299] loss: 0.091531\n",
      "[99,    99] loss: 0.018199\n",
      "[99,   199] loss: 0.010728\n",
      "[99,   299] loss: 0.098668\n",
      "[100,    99] loss: 0.144440\n",
      "[100,   199] loss: 0.235374\n",
      "[100,   299] loss: 0.039822\n",
      "Finished Training\n",
      "[1,    99] loss: 0.698257\n",
      "[1,   199] loss: 0.662225\n",
      "[1,   299] loss: 0.724494\n",
      "[2,    99] loss: 0.635300\n",
      "[2,   199] loss: 0.659602\n",
      "[2,   299] loss: 0.644647\n",
      "[3,    99] loss: 0.596834\n",
      "[3,   199] loss: 0.559194\n",
      "[3,   299] loss: 0.568391\n",
      "[4,    99] loss: 0.512559\n",
      "[4,   199] loss: 0.500149\n",
      "[4,   299] loss: 0.523807\n",
      "[5,    99] loss: 0.546750\n",
      "[5,   199] loss: 0.484353\n",
      "[5,   299] loss: 0.511086\n",
      "[6,    99] loss: 0.470848\n",
      "[6,   199] loss: 0.440937\n",
      "[6,   299] loss: 0.435260\n",
      "[7,    99] loss: 0.420214\n",
      "[7,   199] loss: 0.507587\n",
      "[7,   299] loss: 0.471195\n",
      "[8,    99] loss: 0.411404\n",
      "[8,   199] loss: 0.417713\n",
      "[8,   299] loss: 0.422140\n",
      "[9,    99] loss: 0.383273\n",
      "[9,   199] loss: 0.392134\n",
      "[9,   299] loss: 0.464428\n",
      "[10,    99] loss: 0.369904\n",
      "[10,   199] loss: 0.372142\n",
      "[10,   299] loss: 0.387493\n",
      "[11,    99] loss: 0.407430\n",
      "[11,   199] loss: 0.397935\n",
      "[11,   299] loss: 0.347418\n",
      "[12,    99] loss: 0.344856\n",
      "[12,   199] loss: 0.372288\n",
      "[12,   299] loss: 0.453330\n",
      "[13,    99] loss: 0.338154\n",
      "[13,   199] loss: 0.309393\n",
      "[13,   299] loss: 0.352229\n",
      "[14,    99] loss: 0.271357\n",
      "[14,   199] loss: 0.357368\n",
      "[14,   299] loss: 0.342257\n",
      "[15,    99] loss: 0.280444\n",
      "[15,   199] loss: 0.265366\n",
      "[15,   299] loss: 0.373180\n",
      "[16,    99] loss: 0.248759\n",
      "[16,   199] loss: 0.306663\n",
      "[16,   299] loss: 0.368074\n",
      "[17,    99] loss: 0.233050\n",
      "[17,   199] loss: 0.307250\n",
      "[17,   299] loss: 0.312665\n",
      "[18,    99] loss: 0.283394\n",
      "[18,   199] loss: 0.275386\n",
      "[18,   299] loss: 0.236243\n",
      "[19,    99] loss: 0.211093\n",
      "[19,   199] loss: 0.237648\n",
      "[19,   299] loss: 0.502924\n",
      "[20,    99] loss: 0.265534\n",
      "[20,   199] loss: 0.232606\n",
      "[20,   299] loss: 0.213308\n",
      "[21,    99] loss: 0.224945\n",
      "[21,   199] loss: 0.236495\n",
      "[21,   299] loss: 0.189846\n",
      "[22,    99] loss: 0.178039\n",
      "[22,   199] loss: 0.290074\n",
      "[22,   299] loss: 0.178151\n",
      "[23,    99] loss: 0.128895\n",
      "[23,   199] loss: 0.218738\n",
      "[23,   299] loss: 0.360705\n",
      "[24,    99] loss: 0.236817\n",
      "[24,   199] loss: 0.261544\n",
      "[24,   299] loss: 0.287372\n",
      "[25,    99] loss: 0.160451\n",
      "[25,   199] loss: 0.216367\n",
      "[25,   299] loss: 0.353188\n",
      "[26,    99] loss: 0.165814\n",
      "[26,   199] loss: 0.221692\n",
      "[26,   299] loss: 0.170259\n",
      "[27,    99] loss: 0.142507\n",
      "[27,   199] loss: 0.215889\n",
      "[27,   299] loss: 0.150876\n",
      "[28,    99] loss: 0.177912\n",
      "[28,   199] loss: 0.185732\n",
      "[28,   299] loss: 0.174940\n",
      "[29,    99] loss: 0.225478\n",
      "[29,   199] loss: 0.237382\n",
      "[29,   299] loss: 0.285614\n",
      "[30,    99] loss: 0.168119\n",
      "[30,   199] loss: 0.190953\n",
      "[30,   299] loss: 0.222341\n",
      "[31,    99] loss: 0.151514\n",
      "[31,   199] loss: 0.188179\n",
      "[31,   299] loss: 0.275249\n",
      "[32,    99] loss: 0.167147\n",
      "[32,   199] loss: 0.232464\n",
      "[32,   299] loss: 0.184932\n",
      "[33,    99] loss: 0.104567\n",
      "[33,   199] loss: 0.259982\n",
      "[33,   299] loss: 0.156348\n",
      "[34,    99] loss: 0.091880\n",
      "[34,   199] loss: 0.185765\n",
      "[34,   299] loss: 0.098550\n",
      "[35,    99] loss: 0.090491\n",
      "[35,   199] loss: 0.148707\n",
      "[35,   299] loss: 0.156375\n",
      "[36,    99] loss: 0.120261\n",
      "[36,   199] loss: 0.237956\n",
      "[36,   299] loss: 0.087600\n",
      "[37,    99] loss: 0.138826\n",
      "[37,   199] loss: 0.158599\n",
      "[37,   299] loss: 0.077815\n",
      "[38,    99] loss: 0.134655\n",
      "[38,   199] loss: 0.102193\n",
      "[38,   299] loss: 0.063892\n",
      "[39,    99] loss: 0.095124\n",
      "[39,   199] loss: 0.131470\n",
      "[39,   299] loss: 0.131459\n",
      "[40,    99] loss: 0.067282\n",
      "[40,   199] loss: 0.164942\n",
      "[40,   299] loss: 0.114914\n",
      "[41,    99] loss: 0.140887\n",
      "[41,   199] loss: 0.127327\n",
      "[41,   299] loss: 0.105202\n",
      "[42,    99] loss: 0.109261\n",
      "[42,   199] loss: 0.129108\n",
      "[42,   299] loss: 0.159526\n",
      "[43,    99] loss: 0.124895\n",
      "[43,   199] loss: 0.134116\n",
      "[43,   299] loss: 0.157509\n",
      "[44,    99] loss: 0.091624\n",
      "[44,   199] loss: 0.107807\n",
      "[44,   299] loss: 0.086705\n",
      "[45,    99] loss: 0.144288\n",
      "[45,   199] loss: 0.138851\n",
      "[45,   299] loss: 0.088537\n",
      "[46,    99] loss: 0.069766\n",
      "[46,   199] loss: 0.096310\n",
      "[46,   299] loss: 0.245986\n",
      "[47,    99] loss: 0.207054\n",
      "[47,   199] loss: 0.136069\n",
      "[47,   299] loss: 0.216375\n",
      "[48,    99] loss: 0.182979\n",
      "[48,   199] loss: 0.130311\n",
      "[48,   299] loss: 0.175068\n",
      "[49,    99] loss: 0.084533\n",
      "[49,   199] loss: 0.138249\n",
      "[49,   299] loss: 0.033099\n",
      "[50,    99] loss: 0.103092\n",
      "[50,   199] loss: 0.104176\n",
      "[50,   299] loss: 0.157909\n",
      "[51,    99] loss: 0.088947\n",
      "[51,   199] loss: 0.186148\n",
      "[51,   299] loss: 0.064922\n",
      "[52,    99] loss: 0.092458\n",
      "[52,   199] loss: 0.088261\n",
      "[52,   299] loss: 0.063588\n",
      "[53,    99] loss: 0.071656\n",
      "[53,   199] loss: 0.122610\n",
      "[53,   299] loss: 0.151108\n",
      "[54,    99] loss: 0.077690\n",
      "[54,   199] loss: 0.131827\n",
      "[54,   299] loss: 0.192069\n",
      "[55,    99] loss: 0.110213\n",
      "[55,   199] loss: 0.315120\n",
      "[55,   299] loss: 0.086671\n",
      "[56,    99] loss: 0.107529\n",
      "[56,   199] loss: 0.104149\n",
      "[56,   299] loss: 0.038212\n",
      "[57,    99] loss: 0.060047\n",
      "[57,   199] loss: 0.064613\n",
      "[57,   299] loss: 0.018112\n",
      "[58,    99] loss: 0.041166\n",
      "[58,   199] loss: 0.174393\n",
      "[58,   299] loss: 0.324839\n",
      "[59,    99] loss: 0.076068\n",
      "[59,   199] loss: 0.100870\n",
      "[59,   299] loss: 0.056133\n",
      "[60,    99] loss: 0.055746\n",
      "[60,   199] loss: 0.088340\n",
      "[60,   299] loss: 0.126324\n",
      "[61,    99] loss: 0.130148\n",
      "[61,   199] loss: 0.227627\n",
      "[61,   299] loss: 0.189087\n",
      "[62,    99] loss: 0.074739\n",
      "[62,   199] loss: 0.165117\n",
      "[62,   299] loss: 0.114237\n",
      "[63,    99] loss: 0.045570\n",
      "[63,   199] loss: 0.090494\n",
      "[63,   299] loss: 0.053604\n",
      "[64,    99] loss: 0.051017\n",
      "[64,   199] loss: 0.091655\n",
      "[64,   299] loss: 0.053325\n",
      "[65,    99] loss: 0.117679\n",
      "[65,   199] loss: 0.129865\n",
      "[65,   299] loss: 0.089428\n",
      "[66,    99] loss: 0.131450\n",
      "[66,   199] loss: 0.111521\n",
      "[66,   299] loss: 0.069732\n",
      "[67,    99] loss: 0.200745\n",
      "[67,   199] loss: 0.120104\n",
      "[67,   299] loss: 0.064247\n",
      "[68,    99] loss: 0.063453\n",
      "[68,   199] loss: 0.072511\n",
      "[68,   299] loss: 0.324921\n",
      "[69,    99] loss: 0.196211\n",
      "[69,   199] loss: 0.180170\n",
      "[69,   299] loss: 0.085456\n",
      "[70,    99] loss: 0.091369\n",
      "[70,   199] loss: 0.095243\n",
      "[70,   299] loss: 0.952010\n",
      "[71,    99] loss: 0.102066\n",
      "[71,   199] loss: 0.092289\n",
      "[71,   299] loss: 0.094512\n",
      "[72,    99] loss: 0.170121\n",
      "[72,   199] loss: 0.193149\n",
      "[72,   299] loss: 0.054429\n",
      "[73,    99] loss: 0.075000\n",
      "[73,   199] loss: 0.114691\n",
      "[73,   299] loss: 0.168895\n",
      "[74,    99] loss: 0.133857\n",
      "[74,   199] loss: 0.156523\n",
      "[74,   299] loss: 0.041372\n",
      "[75,    99] loss: 0.062738\n",
      "[75,   199] loss: 0.086107\n",
      "[75,   299] loss: 0.038890\n",
      "[76,    99] loss: 0.046935\n",
      "[76,   199] loss: 0.092384\n",
      "[76,   299] loss: 0.049690\n",
      "[77,    99] loss: 0.159250\n",
      "[77,   199] loss: 0.078490\n",
      "[77,   299] loss: 0.043360\n",
      "[78,    99] loss: 0.050547\n",
      "[78,   199] loss: 0.091126\n",
      "[78,   299] loss: 0.027933\n",
      "[79,    99] loss: 0.157775\n",
      "[79,   199] loss: 0.239541\n",
      "[79,   299] loss: 0.342024\n",
      "[80,    99] loss: 0.179669\n",
      "[80,   199] loss: 0.577620\n",
      "[80,   299] loss: 0.086724\n",
      "[81,    99] loss: 0.084540\n",
      "[81,   199] loss: 0.098495\n",
      "[81,   299] loss: 0.050478\n",
      "[82,    99] loss: 0.057781\n",
      "[82,   199] loss: 0.108189\n",
      "[82,   299] loss: 0.065471\n",
      "[83,    99] loss: 0.084301\n",
      "[83,   199] loss: 0.180057\n",
      "[83,   299] loss: 0.176805\n",
      "[84,    99] loss: 0.071131\n",
      "[84,   199] loss: 0.131087\n",
      "[84,   299] loss: 0.219954\n",
      "[85,    99] loss: 0.115192\n",
      "[85,   199] loss: 0.107124\n",
      "[85,   299] loss: 0.022563\n",
      "[86,    99] loss: 0.174546\n",
      "[86,   199] loss: 0.092694\n",
      "[86,   299] loss: 0.032740\n",
      "[87,    99] loss: 0.093695\n",
      "[87,   199] loss: 1.395539\n",
      "[87,   299] loss: 0.364112\n",
      "[88,    99] loss: 0.123377\n",
      "[88,   199] loss: 0.182131\n",
      "[88,   299] loss: 0.065208\n",
      "[89,    99] loss: 0.086064\n",
      "[89,   199] loss: 0.108423\n",
      "[89,   299] loss: 0.049937\n",
      "[90,    99] loss: 0.073500\n",
      "[90,   199] loss: 0.077487\n",
      "[90,   299] loss: 0.026278\n",
      "[91,    99] loss: 0.075292\n",
      "[91,   199] loss: 0.159540\n",
      "[91,   299] loss: 0.043079\n",
      "[92,    99] loss: 0.084515\n",
      "[92,   199] loss: 0.129001\n",
      "[92,   299] loss: 0.411017\n",
      "[93,    99] loss: 0.054786\n",
      "[93,   199] loss: 0.135435\n",
      "[93,   299] loss: 0.032635\n",
      "[94,    99] loss: 0.060875\n",
      "[94,   199] loss: 0.094235\n",
      "[94,   299] loss: 0.187883\n",
      "[95,    99] loss: 0.071985\n",
      "[95,   199] loss: 0.097956\n",
      "[95,   299] loss: 0.021929\n",
      "[96,    99] loss: 0.043994\n",
      "[96,   199] loss: 0.110901\n",
      "[96,   299] loss: 0.012388\n",
      "[97,    99] loss: 0.046848\n",
      "[97,   199] loss: 0.108976\n",
      "[97,   299] loss: 0.056609\n",
      "[98,    99] loss: 0.023232\n",
      "[98,   199] loss: 0.089200\n",
      "[98,   299] loss: 0.157890\n",
      "[99,    99] loss: 0.035284\n",
      "[99,   199] loss: 0.112706\n",
      "[99,   299] loss: 0.024968\n",
      "[100,    99] loss: 0.112647\n",
      "[100,   199] loss: 0.079918\n",
      "[100,   299] loss: 0.009458\n",
      "Finished Training\n",
      "[1,    99] loss: 0.730246\n",
      "[1,   199] loss: 0.692479\n",
      "[1,   299] loss: 0.666871\n",
      "[2,    99] loss: 0.692891\n",
      "[2,   199] loss: 0.648025\n",
      "[2,   299] loss: 0.625413\n",
      "[3,    99] loss: 0.661019\n",
      "[3,   199] loss: 0.555507\n",
      "[3,   299] loss: 0.584073\n",
      "[4,    99] loss: 0.641766\n",
      "[4,   199] loss: 0.521870\n",
      "[4,   299] loss: 0.537655\n",
      "[5,    99] loss: 0.631655\n",
      "[5,   199] loss: 0.425127\n",
      "[5,   299] loss: 0.463440\n",
      "[6,    99] loss: 0.518036\n",
      "[6,   199] loss: 0.395727\n",
      "[6,   299] loss: 0.406387\n",
      "[7,    99] loss: 0.454761\n",
      "[7,   199] loss: 0.372884\n",
      "[7,   299] loss: 0.428846\n",
      "[8,    99] loss: 0.431004\n",
      "[8,   199] loss: 0.356472\n",
      "[8,   299] loss: 0.408184\n",
      "[9,    99] loss: 0.346100\n",
      "[9,   199] loss: 0.332550\n",
      "[9,   299] loss: 0.398899\n",
      "[10,    99] loss: 0.375031\n",
      "[10,   199] loss: 0.346343\n",
      "[10,   299] loss: 0.367098\n",
      "[11,    99] loss: 0.360433\n",
      "[11,   199] loss: 0.310381\n",
      "[11,   299] loss: 0.331951\n",
      "[12,    99] loss: 0.282502\n",
      "[12,   199] loss: 0.305086\n",
      "[12,   299] loss: 0.319608\n",
      "[13,    99] loss: 0.299228\n",
      "[13,   199] loss: 0.294374\n",
      "[13,   299] loss: 0.316816\n",
      "[14,    99] loss: 0.292623\n",
      "[14,   199] loss: 0.241785\n",
      "[14,   299] loss: 0.325457\n",
      "[15,    99] loss: 0.248863\n",
      "[15,   199] loss: 0.263560\n",
      "[15,   299] loss: 0.298696\n",
      "[16,    99] loss: 0.268055\n",
      "[16,   199] loss: 0.193614\n",
      "[16,   299] loss: 0.288522\n",
      "[17,    99] loss: 0.280964\n",
      "[17,   199] loss: 0.193884\n",
      "[17,   299] loss: 0.255267\n",
      "[18,    99] loss: 0.191876\n",
      "[18,   199] loss: 0.216682\n",
      "[18,   299] loss: 0.209904\n",
      "[19,    99] loss: 0.245153\n",
      "[19,   199] loss: 0.203801\n",
      "[19,   299] loss: 0.200519\n",
      "[20,    99] loss: 0.152980\n",
      "[20,   199] loss: 0.158942\n",
      "[20,   299] loss: 0.177705\n",
      "[21,    99] loss: 0.200004\n",
      "[21,   199] loss: 0.227606\n",
      "[21,   299] loss: 0.156937\n",
      "[22,    99] loss: 0.165244\n",
      "[22,   199] loss: 0.188157\n",
      "[22,   299] loss: 0.264198\n",
      "[23,    99] loss: 0.178071\n",
      "[23,   199] loss: 0.175436\n",
      "[23,   299] loss: 0.174756\n",
      "[24,    99] loss: 0.260494\n",
      "[24,   199] loss: 0.159357\n",
      "[24,   299] loss: 0.131167\n",
      "[25,    99] loss: 0.159347\n",
      "[25,   199] loss: 0.148694\n",
      "[25,   299] loss: 0.154227\n",
      "[26,    99] loss: 0.217250\n",
      "[26,   199] loss: 0.183893\n",
      "[26,   299] loss: 0.167560\n",
      "[27,    99] loss: 0.163652\n",
      "[27,   199] loss: 0.117834\n",
      "[27,   299] loss: 0.298208\n",
      "[28,    99] loss: 0.273851\n",
      "[28,   199] loss: 0.147390\n",
      "[28,   299] loss: 0.195224\n",
      "[29,    99] loss: 0.276509\n",
      "[29,   199] loss: 0.124862\n",
      "[29,   299] loss: 0.194448\n",
      "[30,    99] loss: 0.294184\n",
      "[30,   199] loss: 0.169406\n",
      "[30,   299] loss: 0.246577\n",
      "[31,    99] loss: 0.168104\n",
      "[31,   199] loss: 0.117897\n",
      "[31,   299] loss: 0.140965\n",
      "[32,    99] loss: 0.103273\n",
      "[32,   199] loss: 0.222516\n",
      "[32,   299] loss: 0.154200\n",
      "[33,    99] loss: 0.138108\n",
      "[33,   199] loss: 0.138813\n",
      "[33,   299] loss: 0.172291\n",
      "[34,    99] loss: 0.189757\n",
      "[34,   199] loss: 0.153195\n",
      "[34,   299] loss: 0.131497\n",
      "[35,    99] loss: 0.184697\n",
      "[35,   199] loss: 0.136366\n",
      "[35,   299] loss: 0.150785\n",
      "[36,    99] loss: 0.233543\n",
      "[36,   199] loss: 0.116459\n",
      "[36,   299] loss: 0.178765\n",
      "[37,    99] loss: 0.133838\n",
      "[37,   199] loss: 0.135467\n",
      "[37,   299] loss: 0.085992\n",
      "[38,    99] loss: 0.447056\n",
      "[38,   199] loss: 0.244677\n",
      "[38,   299] loss: 0.148995\n",
      "[39,    99] loss: 0.148552\n",
      "[39,   199] loss: 0.066055\n",
      "[39,   299] loss: 0.098547\n",
      "[40,    99] loss: 0.086309\n",
      "[40,   199] loss: 0.176645\n",
      "[40,   299] loss: 0.291366\n",
      "[41,    99] loss: 0.125900\n",
      "[41,   199] loss: 0.134518\n",
      "[41,   299] loss: 0.145781\n",
      "[42,    99] loss: 0.063814\n",
      "[42,   199] loss: 0.146526\n",
      "[42,   299] loss: 0.225878\n",
      "[43,    99] loss: 0.179259\n",
      "[43,   199] loss: 0.105612\n",
      "[43,   299] loss: 0.091964\n",
      "[44,    99] loss: 0.203395\n",
      "[44,   199] loss: 0.098021\n",
      "[44,   299] loss: 0.102844\n",
      "[45,    99] loss: 0.088119\n",
      "[45,   199] loss: 0.083057\n",
      "[45,   299] loss: 0.075681\n",
      "[46,    99] loss: 0.216080\n",
      "[46,   199] loss: 0.081021\n",
      "[46,   299] loss: 0.142336\n",
      "[47,    99] loss: 0.110967\n",
      "[47,   199] loss: 0.086153\n",
      "[47,   299] loss: 0.051716\n",
      "[48,    99] loss: 0.163092\n",
      "[48,   199] loss: 0.186429\n",
      "[48,   299] loss: 0.138807\n",
      "[49,    99] loss: 0.222234\n",
      "[49,   199] loss: 0.120605\n",
      "[49,   299] loss: 0.102375\n",
      "[50,    99] loss: 0.061516\n",
      "[50,   199] loss: 0.100217\n",
      "[50,   299] loss: 0.094715\n",
      "[51,    99] loss: 0.110859\n",
      "[51,   199] loss: 0.101137\n",
      "[51,   299] loss: 0.181560\n",
      "[52,    99] loss: 0.062671\n",
      "[52,   199] loss: 0.124197\n",
      "[52,   299] loss: 0.114818\n",
      "[53,    99] loss: 0.070654\n",
      "[53,   199] loss: 0.187574\n",
      "[53,   299] loss: 0.162457\n",
      "[54,    99] loss: 0.088785\n",
      "[54,   199] loss: 0.149181\n",
      "[54,   299] loss: 0.118152\n",
      "[55,    99] loss: 0.113843\n",
      "[55,   199] loss: 0.144995\n",
      "[55,   299] loss: 0.159774\n",
      "[56,    99] loss: 0.112702\n",
      "[56,   199] loss: 0.075580\n",
      "[56,   299] loss: 0.143549\n",
      "[57,    99] loss: 0.152742\n",
      "[57,   199] loss: 0.056283\n",
      "[57,   299] loss: 0.095412\n",
      "[58,    99] loss: 0.078668\n",
      "[58,   199] loss: 0.168136\n",
      "[58,   299] loss: 0.094039\n",
      "[59,    99] loss: 0.106368\n",
      "[59,   199] loss: 0.090802\n",
      "[59,   299] loss: 0.062792\n",
      "[60,    99] loss: 0.083038\n",
      "[60,   199] loss: 0.088664\n",
      "[60,   299] loss: 0.205774\n",
      "[61,    99] loss: 0.113301\n",
      "[61,   199] loss: 0.035058\n",
      "[61,   299] loss: 0.048518\n",
      "[62,    99] loss: 0.045120\n",
      "[62,   199] loss: 0.039442\n",
      "[62,   299] loss: 0.082921\n",
      "[63,    99] loss: 0.109586\n",
      "[63,   199] loss: 0.110446\n",
      "[63,   299] loss: 0.072525\n",
      "[64,    99] loss: 0.160756\n",
      "[64,   199] loss: 0.127758\n",
      "[64,   299] loss: 0.094247\n",
      "[65,    99] loss: 0.146027\n",
      "[65,   199] loss: 0.301369\n",
      "[65,   299] loss: 0.105081\n",
      "[66,    99] loss: 0.081634\n",
      "[66,   199] loss: 0.076328\n",
      "[66,   299] loss: 0.102672\n",
      "[67,    99] loss: 0.042633\n",
      "[67,   199] loss: 0.048795\n",
      "[67,   299] loss: 0.067082\n",
      "[68,    99] loss: 0.020706\n",
      "[68,   199] loss: 0.049955\n",
      "[68,   299] loss: 0.070692\n",
      "[69,    99] loss: 0.127890\n",
      "[69,   199] loss: 0.084988\n",
      "[69,   299] loss: 0.047909\n",
      "[70,    99] loss: 0.295967\n",
      "[70,   199] loss: 0.193771\n",
      "[70,   299] loss: 0.289397\n",
      "[71,    99] loss: 0.072741\n",
      "[71,   199] loss: 0.121878\n",
      "[71,   299] loss: 0.069554\n",
      "[72,    99] loss: 0.070895\n",
      "[72,   199] loss: 0.113295\n",
      "[72,   299] loss: 0.065377\n",
      "[73,    99] loss: 0.103168\n",
      "[73,   199] loss: 0.046463\n",
      "[73,   299] loss: 0.086627\n",
      "[74,    99] loss: 0.045332\n",
      "[74,   199] loss: 0.044673\n",
      "[74,   299] loss: 0.047850\n",
      "[75,    99] loss: 0.016027\n",
      "[75,   199] loss: 0.037338\n",
      "[75,   299] loss: 0.045967\n",
      "[76,    99] loss: 0.149530\n",
      "[76,   199] loss: 0.058761\n",
      "[76,   299] loss: 0.088923\n",
      "[77,    99] loss: 0.227914\n",
      "[77,   199] loss: 0.211756\n",
      "[77,   299] loss: 0.135147\n",
      "[78,    99] loss: 0.186789\n",
      "[78,   199] loss: 0.064705\n",
      "[78,   299] loss: 0.061163\n",
      "[79,    99] loss: 0.126039\n",
      "[79,   199] loss: 0.134778\n",
      "[79,   299] loss: 0.173372\n",
      "[80,    99] loss: 0.211354\n",
      "[80,   199] loss: 0.139354\n",
      "[80,   299] loss: 0.122606\n",
      "[81,    99] loss: 0.076388\n",
      "[81,   199] loss: 0.060078\n",
      "[81,   299] loss: 0.097805\n",
      "[82,    99] loss: 0.034720\n",
      "[82,   199] loss: 0.044961\n",
      "[82,   299] loss: 0.063881\n",
      "[83,    99] loss: 0.010248\n",
      "[83,   199] loss: 0.034164\n",
      "[83,   299] loss: 0.128085\n",
      "[84,    99] loss: 0.115013\n",
      "[84,   199] loss: 0.056583\n",
      "[84,   299] loss: 0.100294\n",
      "[85,    99] loss: 0.122191\n",
      "[85,   199] loss: 0.078860\n",
      "[85,   299] loss: 0.331885\n",
      "[86,    99] loss: 0.220835\n",
      "[86,   199] loss: 0.260739\n",
      "[86,   299] loss: 0.131093\n",
      "[87,    99] loss: 0.084328\n",
      "[87,   199] loss: 0.084328\n",
      "[87,   299] loss: 0.075537\n",
      "[88,    99] loss: 0.040850\n",
      "[88,   199] loss: 0.216547\n",
      "[88,   299] loss: 0.152449\n",
      "[89,    99] loss: 0.045869\n",
      "[89,   199] loss: 0.087607\n",
      "[89,   299] loss: 0.178224\n",
      "[90,    99] loss: 0.085952\n",
      "[90,   199] loss: 0.114840\n",
      "[90,   299] loss: 0.122734\n",
      "[91,    99] loss: 0.020478\n",
      "[91,   199] loss: 0.170135\n",
      "[91,   299] loss: 0.055728\n",
      "[92,    99] loss: 0.014283\n",
      "[92,   199] loss: 0.017189\n",
      "[92,   299] loss: 0.101029\n",
      "[93,    99] loss: 0.077536\n",
      "[93,   199] loss: 0.072753\n",
      "[93,   299] loss: 0.070620\n",
      "[94,    99] loss: 0.082312\n",
      "[94,   199] loss: 0.129095\n",
      "[94,   299] loss: 0.153054\n",
      "[95,    99] loss: 0.182547\n",
      "[95,   199] loss: 0.057751\n",
      "[95,   299] loss: 0.098599\n",
      "[96,    99] loss: 0.032315\n",
      "[96,   199] loss: 0.015981\n",
      "[96,   299] loss: 0.047678\n",
      "[97,    99] loss: 0.318937\n",
      "[97,   199] loss: 0.067317\n",
      "[97,   299] loss: 0.112581\n",
      "[98,    99] loss: 0.010720\n",
      "[98,   199] loss: 0.066035\n",
      "[98,   299] loss: 0.050886\n",
      "[99,    99] loss: 0.011914\n",
      "[99,   199] loss: 0.028688\n",
      "[99,   299] loss: 0.050002\n",
      "[100,    99] loss: 0.046688\n",
      "[100,   199] loss: 0.018884\n",
      "[100,   299] loss: 0.049670\n",
      "Finished Training\n",
      "[1,    99] loss: 0.721020\n",
      "[1,   199] loss: 0.720454\n",
      "[1,   299] loss: 0.671254\n",
      "[2,    99] loss: 0.670462\n",
      "[2,   199] loss: 0.614113\n",
      "[2,   299] loss: 0.628727\n",
      "[3,    99] loss: 0.563174\n",
      "[3,   199] loss: 0.562231\n",
      "[3,   299] loss: 0.553583\n",
      "[4,    99] loss: 0.549302\n",
      "[4,   199] loss: 0.565683\n",
      "[4,   299] loss: 0.491930\n",
      "[5,    99] loss: 0.502338\n",
      "[5,   199] loss: 0.442083\n",
      "[5,   299] loss: 0.476302\n",
      "[6,    99] loss: 0.420854\n",
      "[6,   199] loss: 0.347574\n",
      "[6,   299] loss: 0.357701\n",
      "[7,    99] loss: 0.354289\n",
      "[7,   199] loss: 0.277189\n",
      "[7,   299] loss: 0.335924\n",
      "[8,    99] loss: 0.354942\n",
      "[8,   199] loss: 0.269124\n",
      "[8,   299] loss: 0.263289\n",
      "[9,    99] loss: 0.310794\n",
      "[9,   199] loss: 0.447386\n",
      "[9,   299] loss: 0.298226\n",
      "[10,    99] loss: 0.291846\n",
      "[10,   199] loss: 0.217661\n",
      "[10,   299] loss: 0.193301\n",
      "[11,    99] loss: 0.289173\n",
      "[11,   199] loss: 0.199721\n",
      "[11,   299] loss: 0.171276\n",
      "[12,    99] loss: 0.378646\n",
      "[12,   199] loss: 0.244515\n",
      "[12,   299] loss: 0.199849\n",
      "[13,    99] loss: 0.228679\n",
      "[13,   199] loss: 0.145999\n",
      "[13,   299] loss: 0.207850\n",
      "[14,    99] loss: 0.343157\n",
      "[14,   199] loss: 0.286925\n",
      "[14,   299] loss: 0.176435\n",
      "[15,    99] loss: 0.250372\n",
      "[15,   199] loss: 0.124998\n",
      "[15,   299] loss: 0.128713\n",
      "[16,    99] loss: 0.234312\n",
      "[16,   199] loss: 0.170327\n",
      "[16,   299] loss: 0.152870\n",
      "[17,    99] loss: 0.173616\n",
      "[17,   199] loss: 0.164694\n",
      "[17,   299] loss: 0.164380\n",
      "[18,    99] loss: 0.297672\n",
      "[18,   199] loss: 0.158789\n",
      "[18,   299] loss: 0.199652\n",
      "[19,    99] loss: 0.180721\n",
      "[19,   199] loss: 0.153202\n",
      "[19,   299] loss: 0.152491\n",
      "[20,    99] loss: 0.208606\n",
      "[20,   199] loss: 0.076851\n",
      "[20,   299] loss: 0.086923\n",
      "[21,    99] loss: 0.199408\n",
      "[21,   199] loss: 0.169190\n",
      "[21,   299] loss: 0.176939\n",
      "[22,    99] loss: 0.160061\n",
      "[22,   199] loss: 0.129729\n",
      "[22,   299] loss: 0.133237\n",
      "[23,    99] loss: 0.245773\n",
      "[23,   199] loss: 0.109154\n",
      "[23,   299] loss: 0.091039\n",
      "[24,    99] loss: 0.163724\n",
      "[24,   199] loss: 0.063620\n",
      "[24,   299] loss: 0.091000\n",
      "[25,    99] loss: 0.123749\n",
      "[25,   199] loss: 0.075010\n",
      "[25,   299] loss: 0.166562\n",
      "[26,    99] loss: 0.147881\n",
      "[26,   199] loss: 0.138312\n",
      "[26,   299] loss: 0.248554\n",
      "[27,    99] loss: 0.153947\n",
      "[27,   199] loss: 0.198750\n",
      "[27,   299] loss: 0.106973\n",
      "[28,    99] loss: 0.202217\n",
      "[28,   199] loss: 0.128681\n",
      "[28,   299] loss: 0.081404\n",
      "[29,    99] loss: 0.213614\n",
      "[29,   199] loss: 0.093719\n",
      "[29,   299] loss: 0.129870\n",
      "[30,    99] loss: 0.204229\n",
      "[30,   199] loss: 0.087826\n",
      "[30,   299] loss: 0.123752\n",
      "[31,    99] loss: 0.116006\n",
      "[31,   199] loss: 0.043673\n",
      "[31,   299] loss: 0.150423\n",
      "[32,    99] loss: 0.061788\n",
      "[32,   199] loss: 0.050835\n",
      "[32,   299] loss: 0.105175\n",
      "[33,    99] loss: 0.041116\n",
      "[33,   199] loss: 0.181595\n",
      "[33,   299] loss: 0.124557\n",
      "[34,    99] loss: 0.167786\n",
      "[34,   199] loss: 0.033810\n",
      "[34,   299] loss: 0.088773\n",
      "[35,    99] loss: 0.105536\n",
      "[35,   199] loss: 0.103259\n",
      "[35,   299] loss: 0.072710\n",
      "[36,    99] loss: 0.156425\n",
      "[36,   199] loss: 0.071443\n",
      "[36,   299] loss: 0.174732\n",
      "[37,    99] loss: 0.200705\n",
      "[37,   199] loss: 0.201489\n",
      "[37,   299] loss: 0.075349\n",
      "[38,    99] loss: 0.089798\n",
      "[38,   199] loss: 0.148412\n",
      "[38,   299] loss: 0.069056\n",
      "[39,    99] loss: 0.055511\n",
      "[39,   199] loss: 0.037974\n",
      "[39,   299] loss: 0.218184\n",
      "[40,    99] loss: 0.157352\n",
      "[40,   199] loss: 0.076582\n",
      "[40,   299] loss: 0.068215\n",
      "[41,    99] loss: 0.134470\n",
      "[41,   199] loss: 0.117091\n",
      "[41,   299] loss: 0.057285\n",
      "[42,    99] loss: 0.154479\n",
      "[42,   199] loss: 0.092219\n",
      "[42,   299] loss: 0.064939\n",
      "[43,    99] loss: 0.038266\n",
      "[43,   199] loss: 0.092736\n",
      "[43,   299] loss: 0.071178\n",
      "[44,    99] loss: 0.132462\n",
      "[44,   199] loss: 0.086439\n",
      "[44,   299] loss: 0.169968\n",
      "[45,    99] loss: 0.170899\n",
      "[45,   199] loss: 0.087155\n",
      "[45,   299] loss: 0.147318\n",
      "[46,    99] loss: 0.072060\n",
      "[46,   199] loss: 0.063387\n",
      "[46,   299] loss: 0.064474\n",
      "[47,    99] loss: 0.113718\n",
      "[47,   199] loss: 0.062403\n",
      "[47,   299] loss: 0.090520\n",
      "[48,    99] loss: 0.080479\n",
      "[48,   199] loss: 0.113356\n",
      "[48,   299] loss: 0.077817\n",
      "[49,    99] loss: 0.068366\n",
      "[49,   199] loss: 0.160794\n",
      "[49,   299] loss: 0.509224\n",
      "[50,    99] loss: 0.072593\n",
      "[50,   199] loss: 0.095863\n",
      "[50,   299] loss: 0.178523\n",
      "[51,    99] loss: 0.086522\n",
      "[51,   199] loss: 0.108580\n",
      "[51,   299] loss: 0.110942\n",
      "[52,    99] loss: 0.092326\n",
      "[52,   199] loss: 0.067618\n",
      "[52,   299] loss: 0.051910\n",
      "[53,    99] loss: 0.079546\n",
      "[53,   199] loss: 0.040337\n",
      "[53,   299] loss: 0.047493\n",
      "[54,    99] loss: 0.120986\n",
      "[54,   199] loss: 0.072394\n",
      "[54,   299] loss: 0.049328\n",
      "[55,    99] loss: 0.070781\n",
      "[55,   199] loss: 0.022419\n",
      "[55,   299] loss: 0.039613\n",
      "[56,    99] loss: 0.126052\n",
      "[56,   199] loss: 0.042936\n",
      "[56,   299] loss: 0.063908\n",
      "[57,    99] loss: 0.250506\n",
      "[57,   199] loss: 0.091033\n",
      "[57,   299] loss: 0.154788\n",
      "[58,    99] loss: 0.053734\n",
      "[58,   199] loss: 0.048623\n",
      "[58,   299] loss: 0.126268\n",
      "[59,    99] loss: 0.064973\n",
      "[59,   199] loss: 0.038642\n",
      "[59,   299] loss: 0.051549\n",
      "[60,    99] loss: 0.100370\n",
      "[60,   199] loss: 0.097267\n",
      "[60,   299] loss: 0.053126\n",
      "[61,    99] loss: 0.198493\n",
      "[61,   199] loss: 0.046254\n",
      "[61,   299] loss: 0.222003\n",
      "[62,    99] loss: 0.047785\n",
      "[62,   199] loss: 0.095207\n",
      "[62,   299] loss: 0.160245\n",
      "[63,    99] loss: 0.104247\n",
      "[63,   199] loss: 0.064789\n",
      "[63,   299] loss: 0.108040\n",
      "[64,    99] loss: 0.047613\n",
      "[64,   199] loss: 0.080813\n",
      "[64,   299] loss: 0.044786\n",
      "[65,    99] loss: 0.062926\n",
      "[65,   199] loss: 0.033074\n",
      "[65,   299] loss: 0.051455\n",
      "[66,    99] loss: 0.067823\n",
      "[66,   199] loss: 0.013151\n",
      "[66,   299] loss: 0.113093\n",
      "[67,    99] loss: 0.036891\n",
      "[67,   199] loss: 0.031311\n",
      "[67,   299] loss: 0.058844\n",
      "[68,    99] loss: 0.018436\n",
      "[68,   199] loss: 0.038256\n",
      "[68,   299] loss: 0.036258\n",
      "[69,    99] loss: 0.168896\n",
      "[69,   199] loss: 0.068705\n",
      "[69,   299] loss: 0.089734\n",
      "[70,    99] loss: 0.089603\n",
      "[70,   199] loss: 0.039227\n",
      "[70,   299] loss: 0.034817\n",
      "[71,    99] loss: 0.147835\n",
      "[71,   199] loss: 0.176411\n",
      "[71,   299] loss: 0.061175\n",
      "[72,    99] loss: 0.085982\n",
      "[72,   199] loss: 0.023743\n",
      "[72,   299] loss: 0.189499\n",
      "[73,    99] loss: 0.023222\n",
      "[73,   199] loss: 0.166751\n",
      "[73,   299] loss: 0.085144\n",
      "[74,    99] loss: 0.072557\n",
      "[74,   199] loss: 0.049960\n",
      "[74,   299] loss: 0.258164\n",
      "[75,    99] loss: 0.117582\n",
      "[75,   199] loss: 0.075804\n",
      "[75,   299] loss: 0.103870\n",
      "[76,    99] loss: 0.055093\n",
      "[76,   199] loss: 0.033989\n",
      "[76,   299] loss: 0.065823\n",
      "[77,    99] loss: 0.049279\n",
      "[77,   199] loss: 0.035762\n",
      "[77,   299] loss: 0.019327\n",
      "[78,    99] loss: 0.066354\n",
      "[78,   199] loss: 0.034924\n",
      "[78,   299] loss: 0.025543\n",
      "[79,    99] loss: 0.017293\n",
      "[79,   199] loss: 0.010583\n",
      "[79,   299] loss: 0.030466\n",
      "[80,    99] loss: 0.008447\n",
      "[80,   199] loss: 0.006344\n",
      "[80,   299] loss: 0.018592\n",
      "[81,    99] loss: 0.003509\n",
      "[81,   199] loss: 0.004035\n",
      "[81,   299] loss: 0.020113\n",
      "[82,    99] loss: 0.002746\n",
      "[82,   199] loss: 0.004377\n",
      "[82,   299] loss: 0.017968\n",
      "[83,    99] loss: 0.002487\n",
      "[83,   199] loss: 0.004606\n",
      "[83,   299] loss: 0.018866\n",
      "[84,    99] loss: 0.028479\n",
      "[84,   199] loss: 0.024038\n",
      "[84,   299] loss: 0.035038\n",
      "[85,    99] loss: 0.124908\n",
      "[85,   199] loss: 0.176682\n",
      "[85,   299] loss: 0.487785\n",
      "[86,    99] loss: 0.233685\n",
      "[86,   199] loss: 0.230431\n",
      "[86,   299] loss: 0.210745\n",
      "[87,    99] loss: 0.493873\n",
      "[87,   199] loss: 0.153063\n",
      "[87,   299] loss: 0.068177\n",
      "[88,    99] loss: 0.098621\n",
      "[88,   199] loss: 0.174962\n",
      "[88,   299] loss: 0.057369\n",
      "[89,    99] loss: 0.030835\n",
      "[89,   199] loss: 0.014322\n",
      "[89,   299] loss: 0.032859\n",
      "[90,    99] loss: 0.050593\n",
      "[90,   199] loss: 0.019779\n",
      "[90,   299] loss: 0.042078\n",
      "[91,    99] loss: 0.050422\n",
      "[91,   199] loss: 0.030467\n",
      "[91,   299] loss: 0.057094\n",
      "[92,    99] loss: 0.031650\n",
      "[92,   199] loss: 0.029352\n",
      "[92,   299] loss: 0.041895\n",
      "[93,    99] loss: 0.032896\n",
      "[93,   199] loss: 0.030768\n",
      "[93,   299] loss: 0.027699\n",
      "[94,    99] loss: 0.246844\n",
      "[94,   199] loss: 0.173685\n",
      "[94,   299] loss: 0.124248\n",
      "[95,    99] loss: 0.106613\n",
      "[95,   199] loss: 0.109740\n",
      "[95,   299] loss: 0.044007\n",
      "[96,    99] loss: 0.033450\n",
      "[96,   199] loss: 0.107831\n",
      "[96,   299] loss: 0.162438\n",
      "[97,    99] loss: 0.081145\n",
      "[97,   199] loss: 0.040529\n",
      "[97,   299] loss: 0.036030\n",
      "[98,    99] loss: 0.021337\n",
      "[98,   199] loss: 0.262709\n",
      "[98,   299] loss: 0.390740\n",
      "[99,    99] loss: 0.070986\n",
      "[99,   199] loss: 0.020920\n",
      "[99,   299] loss: 0.013501\n",
      "[100,    99] loss: 0.008616\n",
      "[100,   199] loss: 0.009628\n",
      "[100,   299] loss: 0.023230\n",
      "Finished Training\n",
      "[1,    99] loss: 0.713563\n",
      "[1,   199] loss: 0.705947\n",
      "[1,   299] loss: 0.677945\n",
      "[2,    99] loss: 0.664801\n",
      "[2,   199] loss: 0.700278\n",
      "[2,   299] loss: 0.620494\n",
      "[3,    99] loss: 0.669537\n",
      "[3,   199] loss: 0.644957\n",
      "[3,   299] loss: 0.584479\n",
      "[4,    99] loss: 0.622205\n",
      "[4,   199] loss: 0.570956\n",
      "[4,   299] loss: 0.542570\n",
      "[5,    99] loss: 0.577790\n",
      "[5,   199] loss: 0.519548\n",
      "[5,   299] loss: 0.480217\n",
      "[6,    99] loss: 0.535549\n",
      "[6,   199] loss: 0.430861\n",
      "[6,   299] loss: 0.408842\n",
      "[7,    99] loss: 0.430730\n",
      "[7,   199] loss: 0.479231\n",
      "[7,   299] loss: 0.406236\n",
      "[8,    99] loss: 0.487192\n",
      "[8,   199] loss: 0.379308\n",
      "[8,   299] loss: 0.371315\n",
      "[9,    99] loss: 0.409870\n",
      "[9,   199] loss: 0.318429\n",
      "[9,   299] loss: 0.388092\n",
      "[10,    99] loss: 0.368630\n",
      "[10,   199] loss: 0.311175\n",
      "[10,   299] loss: 0.390701\n",
      "[11,    99] loss: 0.350988\n",
      "[11,   199] loss: 0.348259\n",
      "[11,   299] loss: 0.339741\n",
      "[12,    99] loss: 0.293837\n",
      "[12,   199] loss: 0.403309\n",
      "[12,   299] loss: 0.346550\n",
      "[13,    99] loss: 0.313011\n",
      "[13,   199] loss: 0.213385\n",
      "[13,   299] loss: 0.258835\n",
      "[14,    99] loss: 0.240328\n",
      "[14,   199] loss: 0.199610\n",
      "[14,   299] loss: 0.264620\n",
      "[15,    99] loss: 0.253852\n",
      "[15,   199] loss: 0.192836\n",
      "[15,   299] loss: 0.281528\n",
      "[16,    99] loss: 0.287288\n",
      "[16,   199] loss: 0.295718\n",
      "[16,   299] loss: 0.233218\n",
      "[17,    99] loss: 0.260717\n",
      "[17,   199] loss: 0.219340\n",
      "[17,   299] loss: 0.279344\n",
      "[18,    99] loss: 0.192993\n",
      "[18,   199] loss: 0.198095\n",
      "[18,   299] loss: 0.171430\n",
      "[19,    99] loss: 0.244143\n",
      "[19,   199] loss: 0.294140\n",
      "[19,   299] loss: 0.273665\n",
      "[20,    99] loss: 0.250208\n",
      "[20,   199] loss: 0.259291\n",
      "[20,   299] loss: 0.226605\n",
      "[21,    99] loss: 0.191993\n",
      "[21,   199] loss: 0.208817\n",
      "[21,   299] loss: 0.176282\n",
      "[22,    99] loss: 0.219316\n",
      "[22,   199] loss: 0.186748\n",
      "[22,   299] loss: 0.143235\n",
      "[23,    99] loss: 0.151768\n",
      "[23,   199] loss: 0.155667\n",
      "[23,   299] loss: 0.146328\n",
      "[24,    99] loss: 0.278926\n",
      "[24,   199] loss: 0.229045\n",
      "[24,   299] loss: 0.225491\n",
      "[25,    99] loss: 0.240028\n",
      "[25,   199] loss: 0.157098\n",
      "[25,   299] loss: 0.156588\n",
      "[26,    99] loss: 0.186737\n",
      "[26,   199] loss: 0.176660\n",
      "[26,   299] loss: 0.147758\n",
      "[27,    99] loss: 0.221298\n",
      "[27,   199] loss: 0.200140\n",
      "[27,   299] loss: 0.207354\n",
      "[28,    99] loss: 0.174947\n",
      "[28,   199] loss: 0.224928\n",
      "[28,   299] loss: 0.243316\n",
      "[29,    99] loss: 0.268052\n",
      "[29,   199] loss: 0.199683\n",
      "[29,   299] loss: 0.109393\n",
      "[30,    99] loss: 0.129665\n",
      "[30,   199] loss: 0.114706\n",
      "[30,   299] loss: 0.109671\n",
      "[31,    99] loss: 0.144038\n",
      "[31,   199] loss: 0.138386\n",
      "[31,   299] loss: 0.138931\n",
      "[32,    99] loss: 0.103231\n",
      "[32,   199] loss: 0.133857\n",
      "[32,   299] loss: 0.258133\n",
      "[33,    99] loss: 0.339940\n",
      "[33,   199] loss: 0.199563\n",
      "[33,   299] loss: 0.121632\n",
      "[34,    99] loss: 0.121960\n",
      "[34,   199] loss: 0.141018\n",
      "[34,   299] loss: 0.076145\n",
      "[35,    99] loss: 0.086592\n",
      "[35,   199] loss: 0.154099\n",
      "[35,   299] loss: 0.063348\n",
      "[36,    99] loss: 0.183411\n",
      "[36,   199] loss: 0.100482\n",
      "[36,   299] loss: 0.115233\n",
      "[37,    99] loss: 0.172354\n",
      "[37,   199] loss: 0.091944\n",
      "[37,   299] loss: 0.161007\n",
      "[38,    99] loss: 0.102302\n",
      "[38,   199] loss: 0.054986\n",
      "[38,   299] loss: 0.097212\n",
      "[39,    99] loss: 0.118684\n",
      "[39,   199] loss: 0.130079\n",
      "[39,   299] loss: 0.114321\n",
      "[40,    99] loss: 0.215560\n",
      "[40,   199] loss: 0.134035\n",
      "[40,   299] loss: 0.116461\n",
      "[41,    99] loss: 0.079237\n",
      "[41,   199] loss: 0.184432\n",
      "[41,   299] loss: 0.123788\n",
      "[42,    99] loss: 0.149370\n",
      "[42,   199] loss: 0.109895\n",
      "[42,   299] loss: 0.063045\n",
      "[43,    99] loss: 0.114963\n",
      "[43,   199] loss: 0.127326\n",
      "[43,   299] loss: 0.315513\n",
      "[44,    99] loss: 0.186384\n",
      "[44,   199] loss: 0.100790\n",
      "[44,   299] loss: 0.062429\n",
      "[45,    99] loss: 0.066500\n",
      "[45,   199] loss: 0.138812\n",
      "[45,   299] loss: 0.164585\n",
      "[46,    99] loss: 0.200292\n",
      "[46,   199] loss: 0.153073\n",
      "[46,   299] loss: 0.113885\n",
      "[47,    99] loss: 0.106345\n",
      "[47,   199] loss: 0.240108\n",
      "[47,   299] loss: 0.067333\n",
      "[48,    99] loss: 0.165891\n",
      "[48,   199] loss: 0.076991\n",
      "[48,   299] loss: 0.034851\n",
      "[49,    99] loss: 0.072693\n",
      "[49,   199] loss: 0.080683\n",
      "[49,   299] loss: 0.033217\n",
      "[50,    99] loss: 0.113920\n",
      "[50,   199] loss: 0.221915\n",
      "[50,   299] loss: 0.059781\n",
      "[51,    99] loss: 0.137175\n",
      "[51,   199] loss: 0.113486\n",
      "[51,   299] loss: 0.068324\n",
      "[52,    99] loss: 0.199245\n",
      "[52,   199] loss: 0.175076\n",
      "[52,   299] loss: 0.100761\n",
      "[53,    99] loss: 0.207205\n",
      "[53,   199] loss: 0.083146\n",
      "[53,   299] loss: 0.455545\n",
      "[54,    99] loss: 0.208673\n",
      "[54,   199] loss: 0.091885\n",
      "[54,   299] loss: 0.157878\n",
      "[55,    99] loss: 0.084843\n",
      "[55,   199] loss: 0.117077\n",
      "[55,   299] loss: 0.044477\n",
      "[56,    99] loss: 0.136630\n",
      "[56,   199] loss: 0.193411\n",
      "[56,   299] loss: 0.046639\n",
      "[57,    99] loss: 0.096221\n",
      "[57,   199] loss: 0.063035\n",
      "[57,   299] loss: 0.025803\n",
      "[58,    99] loss: 0.073261\n",
      "[58,   199] loss: 0.068709\n",
      "[58,   299] loss: 0.059471\n",
      "[59,    99] loss: 0.147402\n",
      "[59,   199] loss: 0.187825\n",
      "[59,   299] loss: 0.119346\n",
      "[60,    99] loss: 0.041664\n",
      "[60,   199] loss: 0.070934\n",
      "[60,   299] loss: 0.028449\n",
      "[61,    99] loss: 0.028962\n",
      "[61,   199] loss: 0.027697\n",
      "[61,   299] loss: 0.015552\n",
      "[62,    99] loss: 0.023500\n",
      "[62,   199] loss: 0.020463\n",
      "[62,   299] loss: 0.026271\n",
      "[63,    99] loss: 0.051558\n",
      "[63,   199] loss: 0.036024\n",
      "[63,   299] loss: 0.020448\n",
      "[64,    99] loss: 0.084123\n",
      "[64,   199] loss: 0.037272\n",
      "[64,   299] loss: 0.020292\n",
      "[65,    99] loss: 0.041445\n",
      "[65,   199] loss: 0.018530\n",
      "[65,   299] loss: 0.420426\n",
      "[66,    99] loss: 0.197699\n",
      "[66,   199] loss: 0.188823\n",
      "[66,   299] loss: 0.175779\n",
      "[67,    99] loss: 0.121808\n",
      "[67,   199] loss: 0.116487\n",
      "[67,   299] loss: 0.070881\n",
      "[68,    99] loss: 0.131877\n",
      "[68,   199] loss: 0.112439\n",
      "[68,   299] loss: 0.015897\n",
      "[69,    99] loss: 0.056416\n",
      "[69,   199] loss: 0.024776\n",
      "[69,   299] loss: 0.016495\n",
      "[70,    99] loss: 0.053177\n",
      "[70,   199] loss: 0.046764\n",
      "[70,   299] loss: 0.010582\n",
      "[71,    99] loss: 0.039284\n",
      "[71,   199] loss: 0.066954\n",
      "[71,   299] loss: 0.078832\n",
      "[72,    99] loss: 0.168712\n",
      "[72,   199] loss: 0.059285\n",
      "[72,   299] loss: 0.024971\n",
      "[73,    99] loss: 0.181471\n",
      "[73,   199] loss: 0.198817\n",
      "[73,   299] loss: 0.129173\n",
      "[74,    99] loss: 0.090377\n",
      "[74,   199] loss: 0.074122\n",
      "[74,   299] loss: 0.190139\n",
      "[75,    99] loss: 0.041797\n",
      "[75,   199] loss: 0.040818\n",
      "[75,   299] loss: 0.041235\n",
      "[76,    99] loss: 0.028784\n",
      "[76,   199] loss: 0.014571\n",
      "[76,   299] loss: 0.012084\n",
      "[77,    99] loss: 0.014956\n",
      "[77,   199] loss: 0.027553\n",
      "[77,   299] loss: 0.066075\n",
      "[78,    99] loss: 0.261069\n",
      "[78,   199] loss: 0.068200\n",
      "[78,   299] loss: 0.119543\n",
      "[79,    99] loss: 0.080569\n",
      "[79,   199] loss: 0.271448\n",
      "[79,   299] loss: 0.159836\n",
      "[80,    99] loss: 0.119500\n",
      "[80,   199] loss: 0.048159\n",
      "[80,   299] loss: 0.038727\n",
      "[81,    99] loss: 0.097737\n",
      "[81,   199] loss: 0.095895\n",
      "[81,   299] loss: 0.067381\n",
      "[82,    99] loss: 0.054814\n",
      "[82,   199] loss: 0.037368\n",
      "[82,   299] loss: 0.028326\n",
      "[83,    99] loss: 0.147506\n",
      "[83,   199] loss: 0.029963\n",
      "[83,   299] loss: 0.078300\n",
      "[84,    99] loss: 0.033776\n",
      "[84,   199] loss: 0.080181\n",
      "[84,   299] loss: 0.009330\n",
      "[85,    99] loss: 0.011144\n",
      "[85,   199] loss: 0.009215\n",
      "[85,   299] loss: 0.033089\n",
      "[86,    99] loss: 0.070439\n",
      "[86,   199] loss: 0.005500\n",
      "[86,   299] loss: 0.005633\n",
      "[87,    99] loss: 0.051635\n",
      "[87,   199] loss: 0.147868\n",
      "[87,   299] loss: 0.068084\n",
      "[88,    99] loss: 0.070483\n",
      "[88,   199] loss: 0.007879\n",
      "[88,   299] loss: 0.005212\n",
      "[89,    99] loss: 0.059241\n",
      "[89,   199] loss: 0.007336\n",
      "[89,   299] loss: 0.004375\n",
      "[90,    99] loss: 0.077755\n",
      "[90,   199] loss: 0.009285\n",
      "[90,   299] loss: 0.004638\n",
      "[91,    99] loss: 0.006399\n",
      "[91,   199] loss: 0.140771\n",
      "[91,   299] loss: 0.149456\n",
      "[92,    99] loss: 0.319431\n",
      "[92,   199] loss: 0.247489\n",
      "[92,   299] loss: 0.114456\n",
      "[93,    99] loss: 0.266430\n",
      "[93,   199] loss: 0.033848\n",
      "[93,   299] loss: 0.080195\n",
      "[94,    99] loss: 0.144452\n",
      "[94,   199] loss: 0.139488\n",
      "[94,   299] loss: 0.104468\n",
      "[95,    99] loss: 0.066952\n",
      "[95,   199] loss: 0.065335\n",
      "[95,   299] loss: 0.015238\n",
      "[96,    99] loss: 0.024267\n",
      "[96,   199] loss: 0.010691\n",
      "[96,   299] loss: 0.040676\n",
      "[97,    99] loss: 0.017712\n",
      "[97,   199] loss: 0.007750\n",
      "[97,   299] loss: 0.011826\n",
      "[98,    99] loss: 0.116181\n",
      "[98,   199] loss: 0.076647\n",
      "[98,   299] loss: 0.100878\n",
      "[99,    99] loss: 0.022673\n",
      "[99,   199] loss: 0.114608\n",
      "[99,   299] loss: 0.305257\n",
      "[100,    99] loss: 0.158316\n",
      "[100,   199] loss: 0.260172\n",
      "[100,   299] loss: 0.098698\n",
      "Finished Training\n",
      "[1,    99] loss: 0.672157\n",
      "[1,   199] loss: 0.659642\n",
      "[1,   299] loss: 0.644656\n",
      "[2,    99] loss: 0.581949\n",
      "[2,   199] loss: 0.581422\n",
      "[2,   299] loss: 0.572742\n",
      "[3,    99] loss: 0.493958\n",
      "[3,   199] loss: 0.515403\n",
      "[3,   299] loss: 0.506672\n",
      "[4,    99] loss: 0.410618\n",
      "[4,   199] loss: 0.451672\n",
      "[4,   299] loss: 0.452462\n",
      "[5,    99] loss: 0.341957\n",
      "[5,   199] loss: 0.406879\n",
      "[5,   299] loss: 0.398776\n",
      "[6,    99] loss: 0.280275\n",
      "[6,   199] loss: 0.374790\n",
      "[6,   299] loss: 0.351972\n",
      "[7,    99] loss: 0.237462\n",
      "[7,   199] loss: 0.338181\n",
      "[7,   299] loss: 0.309070\n",
      "[8,    99] loss: 0.200115\n",
      "[8,   199] loss: 0.308252\n",
      "[8,   299] loss: 0.267451\n",
      "[9,    99] loss: 0.167756\n",
      "[9,   199] loss: 0.278822\n",
      "[9,   299] loss: 0.235270\n",
      "[10,    99] loss: 0.146259\n",
      "[10,   199] loss: 0.253925\n",
      "[10,   299] loss: 0.198009\n",
      "[11,    99] loss: 0.122432\n",
      "[11,   199] loss: 0.239549\n",
      "[11,   299] loss: 0.168922\n",
      "[12,    99] loss: 0.101063\n",
      "[12,   199] loss: 0.216731\n",
      "[12,   299] loss: 0.146978\n",
      "[13,    99] loss: 0.083136\n",
      "[13,   199] loss: 0.197677\n",
      "[13,   299] loss: 0.134878\n",
      "[14,    99] loss: 0.078022\n",
      "[14,   199] loss: 0.182695\n",
      "[14,   299] loss: 0.113727\n",
      "[15,    99] loss: 0.066381\n",
      "[15,   199] loss: 0.176935\n",
      "[15,   299] loss: 0.109592\n",
      "[16,    99] loss: 0.060906\n",
      "[16,   199] loss: 0.152475\n",
      "[16,   299] loss: 0.101512\n",
      "[17,    99] loss: 0.058071\n",
      "[17,   199] loss: 0.142958\n",
      "[17,   299] loss: 0.096200\n",
      "[18,    99] loss: 0.046968\n",
      "[18,   199] loss: 0.142535\n",
      "[18,   299] loss: 0.091195\n",
      "[19,    99] loss: 0.040669\n",
      "[19,   199] loss: 0.134405\n",
      "[19,   299] loss: 0.076706\n",
      "[20,    99] loss: 0.033847\n",
      "[20,   199] loss: 0.110436\n",
      "[20,   299] loss: 0.054761\n",
      "[21,    99] loss: 0.040702\n",
      "[21,   199] loss: 0.095349\n",
      "[21,   299] loss: 0.056097\n",
      "[22,    99] loss: 0.038400\n",
      "[22,   199] loss: 0.104769\n",
      "[22,   299] loss: 0.051051\n",
      "[23,    99] loss: 0.039688\n",
      "[23,   199] loss: 0.081480\n",
      "[23,   299] loss: 0.078030\n",
      "[24,    99] loss: 0.079634\n",
      "[24,   199] loss: 0.099544\n",
      "[24,   299] loss: 0.084593\n",
      "[25,    99] loss: 0.024075\n",
      "[25,   199] loss: 0.096920\n",
      "[25,   299] loss: 0.045398\n",
      "[26,    99] loss: 0.025974\n",
      "[26,   199] loss: 0.063063\n",
      "[26,   299] loss: 0.051417\n",
      "[27,    99] loss: 0.041693\n",
      "[27,   199] loss: 0.072254\n",
      "[27,   299] loss: 0.035756\n",
      "[28,    99] loss: 0.023797\n",
      "[28,   199] loss: 0.055165\n",
      "[28,   299] loss: 0.018824\n",
      "[29,    99] loss: 0.034838\n",
      "[29,   199] loss: 0.058356\n",
      "[29,   299] loss: 0.043278\n",
      "[30,    99] loss: 0.046076\n",
      "[30,   199] loss: 0.039077\n",
      "[30,   299] loss: 0.081930\n",
      "[31,    99] loss: 0.016816\n",
      "[31,   199] loss: 0.044203\n",
      "[31,   299] loss: 0.051394\n",
      "[32,    99] loss: 0.015843\n",
      "[32,   199] loss: 0.040076\n",
      "[32,   299] loss: 0.039015\n",
      "[33,    99] loss: 0.038617\n",
      "[33,   199] loss: 0.039155\n",
      "[33,   299] loss: 0.012691\n",
      "[34,    99] loss: 0.014632\n",
      "[34,   199] loss: 0.024109\n",
      "[34,   299] loss: 0.009320\n",
      "[35,    99] loss: 0.048092\n",
      "[35,   199] loss: 0.034076\n",
      "[35,   299] loss: 0.015971\n",
      "[36,    99] loss: 0.171876\n",
      "[36,   199] loss: 0.117530\n",
      "[36,   299] loss: 0.115471\n",
      "[37,    99] loss: 0.155091\n",
      "[37,   199] loss: 0.050366\n",
      "[37,   299] loss: 0.056238\n",
      "[38,    99] loss: 0.015910\n",
      "[38,   199] loss: 0.021537\n",
      "[38,   299] loss: 0.015488\n",
      "[39,    99] loss: 0.007850\n",
      "[39,   199] loss: 0.012027\n",
      "[39,   299] loss: 0.009068\n",
      "[40,    99] loss: 0.005360\n",
      "[40,   199] loss: 0.009034\n",
      "[40,   299] loss: 0.007232\n",
      "[41,    99] loss: 0.005755\n",
      "[41,   199] loss: 0.008594\n",
      "[41,   299] loss: 0.006145\n",
      "[42,    99] loss: 0.007900\n",
      "[42,   199] loss: 0.013743\n",
      "[42,   299] loss: 0.006208\n",
      "[43,    99] loss: 0.125015\n",
      "[43,   199] loss: 0.170327\n",
      "[43,   299] loss: 0.143694\n",
      "[44,    99] loss: 0.025179\n",
      "[44,   199] loss: 0.074616\n",
      "[44,   299] loss: 0.018274\n",
      "[45,    99] loss: 0.009042\n",
      "[45,   199] loss: 0.008495\n",
      "[45,   299] loss: 0.007498\n",
      "[46,    99] loss: 0.005277\n",
      "[46,   199] loss: 0.006777\n",
      "[46,   299] loss: 0.005550\n",
      "[47,    99] loss: 0.003694\n",
      "[47,   199] loss: 0.006379\n",
      "[47,   299] loss: 0.004447\n",
      "[48,    99] loss: 0.003857\n",
      "[48,   199] loss: 0.005852\n",
      "[48,   299] loss: 0.003839\n",
      "[49,    99] loss: 0.003986\n",
      "[49,   199] loss: 0.006234\n",
      "[49,   299] loss: 0.003282\n",
      "[50,    99] loss: 0.006488\n",
      "[50,   199] loss: 0.045462\n",
      "[50,   299] loss: 0.323502\n",
      "[51,    99] loss: 0.106327\n",
      "[51,   199] loss: 0.088344\n",
      "[51,   299] loss: 0.059689\n",
      "[52,    99] loss: 0.016215\n",
      "[52,   199] loss: 0.042317\n",
      "[52,   299] loss: 0.014969\n",
      "[53,    99] loss: 0.007425\n",
      "[53,   199] loss: 0.009080\n",
      "[53,   299] loss: 0.007309\n",
      "[54,    99] loss: 0.002740\n",
      "[54,   199] loss: 0.006109\n",
      "[54,   299] loss: 0.003996\n",
      "[55,    99] loss: 0.001929\n",
      "[55,   199] loss: 0.004691\n",
      "[55,   299] loss: 0.003327\n",
      "[56,    99] loss: 0.001849\n",
      "[56,   199] loss: 0.004035\n",
      "[56,   299] loss: 0.002562\n",
      "[57,    99] loss: 0.001603\n",
      "[57,   199] loss: 0.003363\n",
      "[57,   299] loss: 0.002147\n",
      "[58,    99] loss: 0.001632\n",
      "[58,   199] loss: 0.003141\n",
      "[58,   299] loss: 0.001762\n",
      "[59,    99] loss: 0.001935\n",
      "[59,   199] loss: 0.004026\n",
      "[59,   299] loss: 0.001559\n",
      "[60,    99] loss: 0.011582\n",
      "[60,   199] loss: 0.191227\n",
      "[60,   299] loss: 0.209038\n",
      "[61,    99] loss: 0.018771\n",
      "[61,   199] loss: 0.121097\n",
      "[61,   299] loss: 0.031812\n",
      "[62,    99] loss: 0.013410\n",
      "[62,   199] loss: 0.052749\n",
      "[62,   299] loss: 0.014901\n",
      "[63,    99] loss: 0.011425\n",
      "[63,   199] loss: 0.008569\n",
      "[63,   299] loss: 0.003246\n",
      "[64,    99] loss: 0.001959\n",
      "[64,   199] loss: 0.012585\n",
      "[64,   299] loss: 0.009667\n",
      "[65,    99] loss: 0.003643\n",
      "[65,   199] loss: 0.004782\n",
      "[65,   299] loss: 0.002605\n",
      "[66,    99] loss: 0.001288\n",
      "[66,   199] loss: 0.004588\n",
      "[66,   299] loss: 0.002486\n",
      "[67,    99] loss: 0.001176\n",
      "[67,   199] loss: 0.002723\n",
      "[67,   299] loss: 0.001602\n",
      "[68,    99] loss: 0.000944\n",
      "[68,   199] loss: 0.002441\n",
      "[68,   299] loss: 0.001573\n",
      "[69,    99] loss: 0.000837\n",
      "[69,   199] loss: 0.002057\n",
      "[69,   299] loss: 0.001260\n",
      "[70,    99] loss: 0.000798\n",
      "[70,   199] loss: 0.001788\n",
      "[70,   299] loss: 0.001005\n",
      "[71,    99] loss: 0.000802\n",
      "[71,   199] loss: 0.028031\n",
      "[71,   299] loss: 0.471329\n",
      "[72,    99] loss: 0.100371\n",
      "[72,   199] loss: 0.081608\n",
      "[72,   299] loss: 0.045868\n",
      "[73,    99] loss: 0.026691\n",
      "[73,   199] loss: 0.024879\n",
      "[73,   299] loss: 0.025610\n",
      "[74,    99] loss: 0.006006\n",
      "[74,   199] loss: 0.037870\n",
      "[74,   299] loss: 0.007668\n",
      "[75,    99] loss: 0.005657\n",
      "[75,   199] loss: 0.014746\n",
      "[75,   299] loss: 0.003709\n",
      "[76,    99] loss: 0.001438\n",
      "[76,   199] loss: 0.004062\n",
      "[76,   299] loss: 0.002244\n",
      "[77,    99] loss: 0.001026\n",
      "[77,   199] loss: 0.002646\n",
      "[77,   299] loss: 0.001642\n",
      "[78,    99] loss: 0.000844\n",
      "[78,   199] loss: 0.002213\n",
      "[78,   299] loss: 0.001260\n",
      "[79,    99] loss: 0.000706\n",
      "[79,   199] loss: 0.001908\n",
      "[79,   299] loss: 0.001045\n",
      "[80,    99] loss: 0.000615\n",
      "[80,   199] loss: 0.001600\n",
      "[80,   299] loss: 0.000881\n",
      "[81,    99] loss: 0.000546\n",
      "[81,   199] loss: 0.001386\n",
      "[81,   299] loss: 0.000754\n",
      "[82,    99] loss: 0.000496\n",
      "[82,   199] loss: 0.001230\n",
      "[82,   299] loss: 0.000696\n",
      "[83,    99] loss: 0.000456\n",
      "[83,   199] loss: 0.001094\n",
      "[83,   299] loss: 0.000651\n",
      "[84,    99] loss: 0.000432\n",
      "[84,   199] loss: 0.000980\n",
      "[84,   299] loss: 0.000528\n",
      "[85,    99] loss: 0.000426\n",
      "[85,   199] loss: 0.000997\n",
      "[85,   299] loss: 0.000442\n",
      "[86,    99] loss: 0.190275\n",
      "[86,   199] loss: 0.409560\n",
      "[86,   299] loss: 0.030034\n",
      "[87,    99] loss: 0.021976\n",
      "[87,   199] loss: 0.045404\n",
      "[87,   299] loss: 0.028300\n",
      "[88,    99] loss: 0.006218\n",
      "[88,   199] loss: 0.030850\n",
      "[88,   299] loss: 0.004406\n",
      "[89,    99] loss: 0.002146\n",
      "[89,   199] loss: 0.007453\n",
      "[89,   299] loss: 0.012530\n",
      "[90,    99] loss: 0.001683\n",
      "[90,   199] loss: 0.012050\n",
      "[90,   299] loss: 0.034775\n",
      "[91,    99] loss: 0.001569\n",
      "[91,   199] loss: 0.002296\n",
      "[91,   299] loss: 0.001744\n",
      "[92,    99] loss: 0.000961\n",
      "[92,   199] loss: 0.001549\n",
      "[92,   299] loss: 0.001248\n",
      "[93,    99] loss: 0.000790\n",
      "[93,   199] loss: 0.001286\n",
      "[93,   299] loss: 0.001027\n",
      "[94,    99] loss: 0.000683\n",
      "[94,   199] loss: 0.001094\n",
      "[94,   299] loss: 0.000851\n",
      "[95,    99] loss: 0.000606\n",
      "[95,   199] loss: 0.000971\n",
      "[95,   299] loss: 0.000736\n",
      "[96,    99] loss: 0.000539\n",
      "[96,   199] loss: 0.000859\n",
      "[96,   299] loss: 0.000636\n",
      "[97,    99] loss: 0.000487\n",
      "[97,   199] loss: 0.000779\n",
      "[97,   299] loss: 0.000544\n",
      "[98,    99] loss: 0.000440\n",
      "[98,   199] loss: 0.000728\n",
      "[98,   299] loss: 0.000463\n",
      "[99,    99] loss: 0.000435\n",
      "[99,   199] loss: 0.000714\n",
      "[99,   299] loss: 0.000411\n",
      "[100,    99] loss: 0.000450\n",
      "[100,   199] loss: 0.000841\n",
      "[100,   299] loss: 0.000366\n",
      "Finished Training\n",
      "[1,    99] loss: 0.682970\n",
      "[1,   199] loss: 0.655535\n",
      "[1,   299] loss: 0.655474\n",
      "[2,    99] loss: 0.611572\n",
      "[2,   199] loss: 0.578129\n",
      "[2,   299] loss: 0.593353\n",
      "[3,    99] loss: 0.531635\n",
      "[3,   199] loss: 0.499782\n",
      "[3,   299] loss: 0.519376\n",
      "[4,    99] loss: 0.461726\n",
      "[4,   199] loss: 0.420769\n",
      "[4,   299] loss: 0.450569\n",
      "[5,    99] loss: 0.403161\n",
      "[5,   199] loss: 0.354194\n",
      "[5,   299] loss: 0.395039\n",
      "[6,    99] loss: 0.339477\n",
      "[6,   199] loss: 0.290799\n",
      "[6,   299] loss: 0.347433\n",
      "[7,    99] loss: 0.289469\n",
      "[7,   199] loss: 0.250436\n",
      "[7,   299] loss: 0.306556\n",
      "[8,    99] loss: 0.252053\n",
      "[8,   199] loss: 0.220096\n",
      "[8,   299] loss: 0.267458\n",
      "[9,    99] loss: 0.222917\n",
      "[9,   199] loss: 0.199677\n",
      "[9,   299] loss: 0.238908\n",
      "[10,    99] loss: 0.194145\n",
      "[10,   199] loss: 0.179861\n",
      "[10,   299] loss: 0.217152\n",
      "[11,    99] loss: 0.200744\n",
      "[11,   199] loss: 0.163182\n",
      "[11,   299] loss: 0.184741\n",
      "[12,    99] loss: 0.158157\n",
      "[12,   199] loss: 0.153084\n",
      "[12,   299] loss: 0.179164\n",
      "[13,    99] loss: 0.150397\n",
      "[13,   199] loss: 0.139879\n",
      "[13,   299] loss: 0.168639\n",
      "[14,    99] loss: 0.129184\n",
      "[14,   199] loss: 0.127198\n",
      "[14,   299] loss: 0.149750\n",
      "[15,    99] loss: 0.127634\n",
      "[15,   199] loss: 0.110592\n",
      "[15,   299] loss: 0.121528\n",
      "[16,    99] loss: 0.108577\n",
      "[16,   199] loss: 0.112590\n",
      "[16,   299] loss: 0.141659\n",
      "[17,    99] loss: 0.116122\n",
      "[17,   199] loss: 0.103778\n",
      "[17,   299] loss: 0.135578\n",
      "[18,    99] loss: 0.105268\n",
      "[18,   199] loss: 0.093011\n",
      "[18,   299] loss: 0.135626\n",
      "[19,    99] loss: 0.083938\n",
      "[19,   199] loss: 0.096336\n",
      "[19,   299] loss: 0.089374\n",
      "[20,    99] loss: 0.066197\n",
      "[20,   199] loss: 0.080109\n",
      "[20,   299] loss: 0.115322\n",
      "[21,    99] loss: 0.078104\n",
      "[21,   199] loss: 0.068956\n",
      "[21,   299] loss: 0.110302\n",
      "[22,    99] loss: 0.071565\n",
      "[22,   199] loss: 0.059191\n",
      "[22,   299] loss: 0.108109\n",
      "[23,    99] loss: 0.057925\n",
      "[23,   199] loss: 0.065211\n",
      "[23,   299] loss: 0.163225\n",
      "[24,    99] loss: 0.062506\n",
      "[24,   199] loss: 0.088318\n",
      "[24,   299] loss: 0.087059\n",
      "[25,    99] loss: 0.066700\n",
      "[25,   199] loss: 0.052700\n",
      "[25,   299] loss: 0.066011\n",
      "[26,    99] loss: 0.035234\n",
      "[26,   199] loss: 0.067122\n",
      "[26,   299] loss: 0.052225\n",
      "[27,    99] loss: 0.071038\n",
      "[27,   199] loss: 0.058034\n",
      "[27,   299] loss: 0.131603\n",
      "[28,    99] loss: 0.105900\n",
      "[28,   199] loss: 0.120990\n",
      "[28,   299] loss: 0.061729\n",
      "[29,    99] loss: 0.043340\n",
      "[29,   199] loss: 0.043395\n",
      "[29,   299] loss: 0.098864\n",
      "[30,    99] loss: 0.052148\n",
      "[30,   199] loss: 0.053552\n",
      "[30,   299] loss: 0.074809\n",
      "[31,    99] loss: 0.045533\n",
      "[31,   199] loss: 0.049642\n",
      "[31,   299] loss: 0.129576\n",
      "[32,    99] loss: 0.067145\n",
      "[32,   199] loss: 0.036537\n",
      "[32,   299] loss: 0.089078\n",
      "[33,    99] loss: 0.044560\n",
      "[33,   199] loss: 0.049313\n",
      "[33,   299] loss: 0.148885\n",
      "[34,    99] loss: 0.036405\n",
      "[34,   199] loss: 0.030241\n",
      "[34,   299] loss: 0.049553\n",
      "[35,    99] loss: 0.018620\n",
      "[35,   199] loss: 0.040319\n",
      "[35,   299] loss: 0.040462\n",
      "[36,    99] loss: 0.013133\n",
      "[36,   199] loss: 0.030953\n",
      "[36,   299] loss: 0.030160\n",
      "[37,    99] loss: 0.049635\n",
      "[37,   199] loss: 0.044777\n",
      "[37,   299] loss: 0.114211\n",
      "[38,    99] loss: 0.033474\n",
      "[38,   199] loss: 0.028721\n",
      "[38,   299] loss: 0.050719\n",
      "[39,    99] loss: 0.045846\n",
      "[39,   199] loss: 0.051079\n",
      "[39,   299] loss: 0.146440\n",
      "[40,    99] loss: 0.052820\n",
      "[40,   199] loss: 0.062551\n",
      "[40,   299] loss: 0.050252\n",
      "[41,    99] loss: 0.043147\n",
      "[41,   199] loss: 0.034629\n",
      "[41,   299] loss: 0.035177\n",
      "[42,    99] loss: 0.012282\n",
      "[42,   199] loss: 0.032733\n",
      "[42,   299] loss: 0.025942\n",
      "[43,    99] loss: 0.010584\n",
      "[43,   199] loss: 0.022207\n",
      "[43,   299] loss: 0.024021\n",
      "[44,    99] loss: 0.010072\n",
      "[44,   199] loss: 0.026438\n",
      "[44,   299] loss: 0.184035\n",
      "[45,    99] loss: 0.144306\n",
      "[45,   199] loss: 0.061581\n",
      "[45,   299] loss: 0.045629\n",
      "[46,    99] loss: 0.016490\n",
      "[46,   199] loss: 0.040740\n",
      "[46,   299] loss: 0.054790\n",
      "[47,    99] loss: 0.053465\n",
      "[47,   199] loss: 0.038209\n",
      "[47,   299] loss: 0.160406\n",
      "[48,    99] loss: 0.022489\n",
      "[48,   199] loss: 0.029155\n",
      "[48,   299] loss: 0.066002\n",
      "[49,    99] loss: 0.040106\n",
      "[49,   199] loss: 0.035826\n",
      "[49,   299] loss: 0.061017\n",
      "[50,    99] loss: 0.036024\n",
      "[50,   199] loss: 0.018382\n",
      "[50,   299] loss: 0.019801\n",
      "[51,    99] loss: 0.004659\n",
      "[51,   199] loss: 0.014067\n",
      "[51,   299] loss: 0.012522\n",
      "[52,    99] loss: 0.006913\n",
      "[52,   199] loss: 0.016248\n",
      "[52,   299] loss: 0.006839\n",
      "[53,    99] loss: 0.003363\n",
      "[53,   199] loss: 0.014385\n",
      "[53,   299] loss: 0.005625\n",
      "[54,    99] loss: 0.003368\n",
      "[54,   199] loss: 0.016395\n",
      "[54,   299] loss: 0.004888\n",
      "[55,    99] loss: 0.011574\n",
      "[55,   199] loss: 0.072206\n",
      "[55,   299] loss: 0.051947\n",
      "[56,    99] loss: 0.123278\n",
      "[56,   199] loss: 0.109663\n",
      "[56,   299] loss: 0.270292\n",
      "[57,    99] loss: 0.042174\n",
      "[57,   199] loss: 0.029271\n",
      "[57,   299] loss: 0.041437\n",
      "[58,    99] loss: 0.012284\n",
      "[58,   199] loss: 0.018149\n",
      "[58,   299] loss: 0.018098\n",
      "[59,    99] loss: 0.006977\n",
      "[59,   199] loss: 0.014534\n",
      "[59,   299] loss: 0.080281\n",
      "[60,    99] loss: 0.011314\n",
      "[60,   199] loss: 0.012356\n",
      "[60,   299] loss: 0.019683\n",
      "[61,    99] loss: 0.005458\n",
      "[61,   199] loss: 0.031679\n",
      "[61,   299] loss: 0.049114\n",
      "[62,    99] loss: 0.144334\n",
      "[62,   199] loss: 0.137509\n",
      "[62,   299] loss: 0.086945\n",
      "[63,    99] loss: 0.035557\n",
      "[63,   199] loss: 0.029240\n",
      "[63,   299] loss: 0.024917\n",
      "[64,    99] loss: 0.007950\n",
      "[64,   199] loss: 0.009715\n",
      "[64,   299] loss: 0.006508\n",
      "[65,    99] loss: 0.004942\n",
      "[65,   199] loss: 0.017233\n",
      "[65,   299] loss: 0.022095\n",
      "[66,    99] loss: 0.006937\n",
      "[66,   199] loss: 0.016655\n",
      "[66,   299] loss: 0.093715\n",
      "[67,    99] loss: 0.013201\n",
      "[67,   199] loss: 0.035982\n",
      "[67,   299] loss: 0.019890\n",
      "[68,    99] loss: 0.034091\n",
      "[68,   199] loss: 0.058407\n",
      "[68,   299] loss: 0.061713\n",
      "[69,    99] loss: 0.072606\n",
      "[69,   199] loss: 0.055756\n",
      "[69,   299] loss: 0.094079\n",
      "[70,    99] loss: 0.010052\n",
      "[70,   199] loss: 0.058608\n",
      "[70,   299] loss: 0.017229\n",
      "[71,    99] loss: 0.021427\n",
      "[71,   199] loss: 0.053301\n",
      "[71,   299] loss: 0.005337\n",
      "[72,    99] loss: 0.013612\n",
      "[72,   199] loss: 0.032685\n",
      "[72,   299] loss: 0.004547\n",
      "[73,    99] loss: 0.005300\n",
      "[73,   199] loss: 0.011278\n",
      "[73,   299] loss: 0.004804\n",
      "[74,    99] loss: 0.007668\n",
      "[74,   199] loss: 0.018931\n",
      "[74,   299] loss: 0.007272\n",
      "[75,    99] loss: 0.003903\n",
      "[75,   199] loss: 0.018484\n",
      "[75,   299] loss: 0.003354\n",
      "[76,    99] loss: 0.001317\n",
      "[76,   199] loss: 0.010903\n",
      "[76,   299] loss: 0.002451\n",
      "[77,    99] loss: 0.002434\n",
      "[77,   199] loss: 0.014488\n",
      "[77,   299] loss: 0.002283\n",
      "[78,    99] loss: 0.019502\n",
      "[78,   199] loss: 0.173593\n",
      "[78,   299] loss: 0.268823\n",
      "[79,    99] loss: 0.111979\n",
      "[79,   199] loss: 0.045400\n",
      "[79,   299] loss: 0.053664\n",
      "[80,    99] loss: 0.019225\n",
      "[80,   199] loss: 0.013776\n",
      "[80,   299] loss: 0.038146\n",
      "[81,    99] loss: 0.008144\n",
      "[81,   199] loss: 0.029705\n",
      "[81,   299] loss: 0.005331\n",
      "[82,    99] loss: 0.015068\n",
      "[82,   199] loss: 0.025092\n",
      "[82,   299] loss: 0.004435\n",
      "[83,    99] loss: 0.008808\n",
      "[83,   199] loss: 0.015438\n",
      "[83,   299] loss: 0.003611\n",
      "[84,    99] loss: 0.010022\n",
      "[84,   199] loss: 0.020547\n",
      "[84,   299] loss: 0.003635\n",
      "[85,    99] loss: 0.009653\n",
      "[85,   199] loss: 0.017198\n",
      "[85,   299] loss: 0.012407\n",
      "[86,    99] loss: 0.032012\n",
      "[86,   199] loss: 0.012447\n",
      "[86,   299] loss: 0.033437\n",
      "[87,    99] loss: 0.049425\n",
      "[87,   199] loss: 0.223002\n",
      "[87,   299] loss: 0.066132\n",
      "[88,    99] loss: 0.010234\n",
      "[88,   199] loss: 0.051636\n",
      "[88,   299] loss: 0.007592\n",
      "[89,    99] loss: 0.003608\n",
      "[89,   199] loss: 0.009061\n",
      "[89,   299] loss: 0.065101\n",
      "[90,    99] loss: 0.017292\n",
      "[90,   199] loss: 0.026657\n",
      "[90,   299] loss: 0.017517\n",
      "[91,    99] loss: 0.002827\n",
      "[91,   199] loss: 0.009884\n",
      "[91,   299] loss: 0.036420\n",
      "[92,    99] loss: 0.002588\n",
      "[92,   199] loss: 0.016172\n",
      "[92,   299] loss: 0.004106\n",
      "[93,    99] loss: 0.002281\n",
      "[93,   199] loss: 0.015188\n",
      "[93,   299] loss: 0.002623\n",
      "[94,    99] loss: 0.000906\n",
      "[94,   199] loss: 0.003962\n",
      "[94,   299] loss: 0.001588\n",
      "[95,    99] loss: 0.000827\n",
      "[95,   199] loss: 0.006068\n",
      "[95,   299] loss: 0.001488\n",
      "[96,    99] loss: 0.002243\n",
      "[96,   199] loss: 0.016255\n",
      "[96,   299] loss: 0.001632\n",
      "[97,    99] loss: 0.000950\n",
      "[97,   199] loss: 0.010253\n",
      "[97,   299] loss: 0.004108\n",
      "[98,    99] loss: 0.140431\n",
      "[98,   199] loss: 0.045137\n",
      "[98,   299] loss: 0.085691\n",
      "[99,    99] loss: 0.003988\n",
      "[99,   199] loss: 0.003196\n",
      "[99,   299] loss: 0.010350\n",
      "[100,    99] loss: 0.008035\n",
      "[100,   199] loss: 0.059784\n",
      "[100,   299] loss: 0.188848\n",
      "Finished Training\n",
      "[1,    99] loss: 0.689758\n",
      "[1,   199] loss: 0.661598\n",
      "[1,   299] loss: 0.646792\n",
      "[2,    99] loss: 0.616898\n",
      "[2,   199] loss: 0.577766\n",
      "[2,   299] loss: 0.572460\n",
      "[3,    99] loss: 0.551099\n",
      "[3,   199] loss: 0.484514\n",
      "[3,   299] loss: 0.490016\n",
      "[4,    99] loss: 0.481192\n",
      "[4,   199] loss: 0.392893\n",
      "[4,   299] loss: 0.419333\n",
      "[5,    99] loss: 0.420662\n",
      "[5,   199] loss: 0.323408\n",
      "[5,   299] loss: 0.359231\n",
      "[6,    99] loss: 0.361925\n",
      "[6,   199] loss: 0.274768\n",
      "[6,   299] loss: 0.307731\n",
      "[7,    99] loss: 0.321722\n",
      "[7,   199] loss: 0.238338\n",
      "[7,   299] loss: 0.263385\n",
      "[8,    99] loss: 0.283502\n",
      "[8,   199] loss: 0.210750\n",
      "[8,   299] loss: 0.239980\n",
      "[9,    99] loss: 0.255815\n",
      "[9,   199] loss: 0.195580\n",
      "[9,   299] loss: 0.220991\n",
      "[10,    99] loss: 0.230779\n",
      "[10,   199] loss: 0.171220\n",
      "[10,   299] loss: 0.198232\n",
      "[11,    99] loss: 0.208248\n",
      "[11,   199] loss: 0.154726\n",
      "[11,   299] loss: 0.182551\n",
      "[12,    99] loss: 0.201478\n",
      "[12,   199] loss: 0.143345\n",
      "[12,   299] loss: 0.164601\n",
      "[13,    99] loss: 0.186848\n",
      "[13,   199] loss: 0.130588\n",
      "[13,   299] loss: 0.149366\n",
      "[14,    99] loss: 0.157164\n",
      "[14,   199] loss: 0.120723\n",
      "[14,   299] loss: 0.134910\n",
      "[15,    99] loss: 0.150747\n",
      "[15,   199] loss: 0.102920\n",
      "[15,   299] loss: 0.127376\n",
      "[16,    99] loss: 0.137206\n",
      "[16,   199] loss: 0.090310\n",
      "[16,   299] loss: 0.115490\n",
      "[17,    99] loss: 0.144260\n",
      "[17,   199] loss: 0.101928\n",
      "[17,   299] loss: 0.131640\n",
      "[18,    99] loss: 0.107565\n",
      "[18,   199] loss: 0.127947\n",
      "[18,   299] loss: 0.118920\n",
      "[19,    99] loss: 0.117137\n",
      "[19,   199] loss: 0.080033\n",
      "[19,   299] loss: 0.117765\n",
      "[20,    99] loss: 0.088959\n",
      "[20,   199] loss: 0.078044\n",
      "[20,   299] loss: 0.099087\n",
      "[21,    99] loss: 0.110665\n",
      "[21,   199] loss: 0.079656\n",
      "[21,   299] loss: 0.111916\n",
      "[22,    99] loss: 0.076693\n",
      "[22,   199] loss: 0.075037\n",
      "[22,   299] loss: 0.094338\n",
      "[23,    99] loss: 0.079528\n",
      "[23,   199] loss: 0.075489\n",
      "[23,   299] loss: 0.085348\n",
      "[24,    99] loss: 0.084391\n",
      "[24,   199] loss: 0.059973\n",
      "[24,   299] loss: 0.086543\n",
      "[25,    99] loss: 0.093439\n",
      "[25,   199] loss: 0.054299\n",
      "[25,   299] loss: 0.116522\n",
      "[26,    99] loss: 0.071649\n",
      "[26,   199] loss: 0.067649\n",
      "[26,   299] loss: 0.089314\n",
      "[27,    99] loss: 0.074978\n",
      "[27,   199] loss: 0.053528\n",
      "[27,   299] loss: 0.112066\n",
      "[28,    99] loss: 0.055083\n",
      "[28,   199] loss: 0.064118\n",
      "[28,   299] loss: 0.113575\n",
      "[29,    99] loss: 0.044974\n",
      "[29,   199] loss: 0.090064\n",
      "[29,   299] loss: 0.111466\n",
      "[30,    99] loss: 0.072961\n",
      "[30,   199] loss: 0.066285\n",
      "[30,   299] loss: 0.089606\n",
      "[31,    99] loss: 0.051031\n",
      "[31,   199] loss: 0.036018\n",
      "[31,   299] loss: 0.083333\n",
      "[32,    99] loss: 0.044248\n",
      "[32,   199] loss: 0.031798\n",
      "[32,   299] loss: 0.107535\n",
      "[33,    99] loss: 0.043418\n",
      "[33,   199] loss: 0.031275\n",
      "[33,   299] loss: 0.083208\n",
      "[34,    99] loss: 0.038376\n",
      "[34,   199] loss: 0.028187\n",
      "[34,   299] loss: 0.079688\n",
      "[35,    99] loss: 0.058543\n",
      "[35,   199] loss: 0.041969\n",
      "[35,   299] loss: 0.073360\n",
      "[36,    99] loss: 0.125489\n",
      "[36,   199] loss: 0.055129\n",
      "[36,   299] loss: 0.061469\n",
      "[37,    99] loss: 0.051495\n",
      "[37,   199] loss: 0.035688\n",
      "[37,   299] loss: 0.065407\n",
      "[38,    99] loss: 0.036580\n",
      "[38,   199] loss: 0.038486\n",
      "[38,   299] loss: 0.080307\n",
      "[39,    99] loss: 0.036349\n",
      "[39,   199] loss: 0.032631\n",
      "[39,   299] loss: 0.087462\n",
      "[40,    99] loss: 0.022519\n",
      "[40,   199] loss: 0.023931\n",
      "[40,   299] loss: 0.035344\n",
      "[41,    99] loss: 0.023298\n",
      "[41,   199] loss: 0.025502\n",
      "[41,   299] loss: 0.037256\n",
      "[42,    99] loss: 0.029454\n",
      "[42,   199] loss: 0.028863\n",
      "[42,   299] loss: 0.069794\n",
      "[43,    99] loss: 0.084733\n",
      "[43,   199] loss: 0.159502\n",
      "[43,   299] loss: 0.103302\n",
      "[44,    99] loss: 0.045648\n",
      "[44,   199] loss: 0.035901\n",
      "[44,   299] loss: 0.061182\n",
      "[45,    99] loss: 0.048961\n",
      "[45,   199] loss: 0.015372\n",
      "[45,   299] loss: 0.087307\n",
      "[46,    99] loss: 0.029981\n",
      "[46,   199] loss: 0.039470\n",
      "[46,   299] loss: 0.125006\n",
      "[47,    99] loss: 0.028551\n",
      "[47,   199] loss: 0.053452\n",
      "[47,   299] loss: 0.038108\n",
      "[48,    99] loss: 0.036344\n",
      "[48,   199] loss: 0.050792\n",
      "[48,   299] loss: 0.111872\n",
      "[49,    99] loss: 0.024799\n",
      "[49,   199] loss: 0.016948\n",
      "[49,   299] loss: 0.033674\n",
      "[50,    99] loss: 0.020006\n",
      "[50,   199] loss: 0.009122\n",
      "[50,   299] loss: 0.015211\n",
      "[51,    99] loss: 0.019361\n",
      "[51,   199] loss: 0.012648\n",
      "[51,   299] loss: 0.019102\n",
      "[52,    99] loss: 0.022332\n",
      "[52,   199] loss: 0.023546\n",
      "[52,   299] loss: 0.072296\n",
      "[53,    99] loss: 0.149208\n",
      "[53,   199] loss: 0.052926\n",
      "[53,   299] loss: 0.038971\n",
      "[54,    99] loss: 0.023068\n",
      "[54,   199] loss: 0.011690\n",
      "[54,   299] loss: 0.014977\n",
      "[55,    99] loss: 0.014737\n",
      "[55,   199] loss: 0.024406\n",
      "[55,   299] loss: 0.062370\n",
      "[56,    99] loss: 0.058600\n",
      "[56,   199] loss: 0.082517\n",
      "[56,   299] loss: 0.051255\n",
      "[57,    99] loss: 0.023143\n",
      "[57,   199] loss: 0.027418\n",
      "[57,   299] loss: 0.019932\n",
      "[58,    99] loss: 0.014388\n",
      "[58,   199] loss: 0.023726\n",
      "[58,   299] loss: 0.017911\n",
      "[59,    99] loss: 0.029261\n",
      "[59,   199] loss: 0.037106\n",
      "[59,   299] loss: 0.040042\n",
      "[60,    99] loss: 0.074860\n",
      "[60,   199] loss: 0.134626\n",
      "[60,   299] loss: 0.083571\n",
      "[61,    99] loss: 0.041725\n",
      "[61,   199] loss: 0.016493\n",
      "[61,   299] loss: 0.010826\n",
      "[62,    99] loss: 0.009186\n",
      "[62,   199] loss: 0.007472\n",
      "[62,   299] loss: 0.007106\n",
      "[63,    99] loss: 0.007430\n",
      "[63,   199] loss: 0.004101\n",
      "[63,   299] loss: 0.004310\n",
      "[64,    99] loss: 0.005942\n",
      "[64,   199] loss: 0.003000\n",
      "[64,   299] loss: 0.004805\n",
      "[65,    99] loss: 0.008830\n",
      "[65,   199] loss: 0.002485\n",
      "[65,   299] loss: 0.020413\n",
      "[66,    99] loss: 0.016593\n",
      "[66,   199] loss: 0.017241\n",
      "[66,   299] loss: 0.137169\n",
      "[67,    99] loss: 0.100249\n",
      "[67,   199] loss: 0.040987\n",
      "[67,   299] loss: 0.109551\n",
      "[68,    99] loss: 0.014302\n",
      "[68,   199] loss: 0.028159\n",
      "[68,   299] loss: 0.025338\n",
      "[69,    99] loss: 0.009473\n",
      "[69,   199] loss: 0.004608\n",
      "[69,   299] loss: 0.010420\n",
      "[70,    99] loss: 0.006893\n",
      "[70,   199] loss: 0.006058\n",
      "[70,   299] loss: 0.006667\n",
      "[71,    99] loss: 0.013764\n",
      "[71,   199] loss: 0.016307\n",
      "[71,   299] loss: 0.030718\n",
      "[72,    99] loss: 0.096300\n",
      "[72,   199] loss: 0.055927\n",
      "[72,   299] loss: 0.195401\n",
      "[73,    99] loss: 0.030327\n",
      "[73,   199] loss: 0.009325\n",
      "[73,   299] loss: 0.016708\n",
      "[74,    99] loss: 0.005827\n",
      "[74,   199] loss: 0.004722\n",
      "[74,   299] loss: 0.003028\n",
      "[75,    99] loss: 0.003603\n",
      "[75,   199] loss: 0.002754\n",
      "[75,   299] loss: 0.002420\n",
      "[76,    99] loss: 0.002818\n",
      "[76,   199] loss: 0.002182\n",
      "[76,   299] loss: 0.002064\n",
      "[77,    99] loss: 0.002392\n",
      "[77,   199] loss: 0.001784\n",
      "[77,   299] loss: 0.001723\n",
      "[78,    99] loss: 0.002140\n",
      "[78,   199] loss: 0.001451\n",
      "[78,   299] loss: 0.001516\n",
      "[79,    99] loss: 0.001844\n",
      "[79,   199] loss: 0.001223\n",
      "[79,   299] loss: 0.001314\n",
      "[80,    99] loss: 0.001751\n",
      "[80,   199] loss: 0.001107\n",
      "[80,   299] loss: 0.001301\n",
      "[81,    99] loss: 0.001645\n",
      "[81,   199] loss: 0.001063\n",
      "[81,   299] loss: 0.001643\n",
      "[82,    99] loss: 0.010653\n",
      "[82,   199] loss: 0.484274\n",
      "[82,   299] loss: 0.122413\n",
      "[83,    99] loss: 0.065331\n",
      "[83,   199] loss: 0.052494\n",
      "[83,   299] loss: 0.033299\n",
      "[84,    99] loss: 0.013146\n",
      "[84,   199] loss: 0.017581\n",
      "[84,   299] loss: 0.016490\n",
      "[85,    99] loss: 0.010307\n",
      "[85,   199] loss: 0.011382\n",
      "[85,   299] loss: 0.015526\n",
      "[86,    99] loss: 0.005859\n",
      "[86,   199] loss: 0.021883\n",
      "[86,   299] loss: 0.011193\n",
      "[87,    99] loss: 0.004387\n",
      "[87,   199] loss: 0.009708\n",
      "[87,   299] loss: 0.008778\n",
      "[88,    99] loss: 0.002922\n",
      "[88,   199] loss: 0.009010\n",
      "[88,   299] loss: 0.008555\n",
      "[89,    99] loss: 0.002293\n",
      "[89,   199] loss: 0.007194\n",
      "[89,   299] loss: 0.006773\n",
      "[90,    99] loss: 0.001939\n",
      "[90,   199] loss: 0.010706\n",
      "[90,   299] loss: 0.018958\n",
      "[91,    99] loss: 0.002606\n",
      "[91,   199] loss: 0.019986\n",
      "[91,   299] loss: 0.034184\n",
      "[92,    99] loss: 0.083122\n",
      "[92,   199] loss: 0.171124\n",
      "[92,   299] loss: 0.050095\n",
      "[93,    99] loss: 0.033435\n",
      "[93,   199] loss: 0.052894\n",
      "[93,   299] loss: 0.038705\n",
      "[94,    99] loss: 0.016534\n",
      "[94,   199] loss: 0.003699\n",
      "[94,   299] loss: 0.005497\n",
      "[95,    99] loss: 0.005387\n",
      "[95,   199] loss: 0.003145\n",
      "[95,   299] loss: 0.002996\n",
      "[96,    99] loss: 0.003643\n",
      "[96,   199] loss: 0.002636\n",
      "[96,   299] loss: 0.002152\n",
      "[97,    99] loss: 0.002676\n",
      "[97,   199] loss: 0.001510\n",
      "[97,   299] loss: 0.001584\n",
      "[98,    99] loss: 0.001812\n",
      "[98,   199] loss: 0.001533\n",
      "[98,   299] loss: 0.001284\n",
      "[99,    99] loss: 0.001688\n",
      "[99,   199] loss: 0.001084\n",
      "[99,   299] loss: 0.001151\n",
      "[100,    99] loss: 0.001689\n",
      "[100,   199] loss: 0.000892\n",
      "[100,   299] loss: 0.001063\n",
      "Finished Training\n",
      "[1,    99] loss: 0.688381\n",
      "[1,   199] loss: 0.669097\n",
      "[1,   299] loss: 0.640310\n",
      "[2,    99] loss: 0.590142\n",
      "[2,   199] loss: 0.604036\n",
      "[2,   299] loss: 0.555524\n",
      "[3,    99] loss: 0.490307\n",
      "[3,   199] loss: 0.515485\n",
      "[3,   299] loss: 0.469965\n",
      "[4,    99] loss: 0.386862\n",
      "[4,   199] loss: 0.428171\n",
      "[4,   299] loss: 0.395601\n",
      "[5,    99] loss: 0.312047\n",
      "[5,   199] loss: 0.351675\n",
      "[5,   299] loss: 0.330423\n",
      "[6,    99] loss: 0.256532\n",
      "[6,   199] loss: 0.300554\n",
      "[6,   299] loss: 0.280010\n",
      "[7,    99] loss: 0.216193\n",
      "[7,   199] loss: 0.250882\n",
      "[7,   299] loss: 0.243185\n",
      "[8,    99] loss: 0.183017\n",
      "[8,   199] loss: 0.212241\n",
      "[8,   299] loss: 0.215752\n",
      "[9,    99] loss: 0.163335\n",
      "[9,   199] loss: 0.173631\n",
      "[9,   299] loss: 0.186439\n",
      "[10,    99] loss: 0.148583\n",
      "[10,   199] loss: 0.148860\n",
      "[10,   299] loss: 0.170568\n",
      "[11,    99] loss: 0.126217\n",
      "[11,   199] loss: 0.131300\n",
      "[11,   299] loss: 0.168364\n",
      "[12,    99] loss: 0.119508\n",
      "[12,   199] loss: 0.112815\n",
      "[12,   299] loss: 0.186558\n",
      "[13,    99] loss: 0.106519\n",
      "[13,   199] loss: 0.099411\n",
      "[13,   299] loss: 0.127484\n",
      "[14,    99] loss: 0.098769\n",
      "[14,   199] loss: 0.089112\n",
      "[14,   299] loss: 0.115308\n",
      "[15,    99] loss: 0.099948\n",
      "[15,   199] loss: 0.086264\n",
      "[15,   299] loss: 0.163049\n",
      "[16,    99] loss: 0.135220\n",
      "[16,   199] loss: 0.080594\n",
      "[16,   299] loss: 0.093456\n",
      "[17,    99] loss: 0.078033\n",
      "[17,   199] loss: 0.079800\n",
      "[17,   299] loss: 0.091233\n",
      "[18,    99] loss: 0.079645\n",
      "[18,   199] loss: 0.089590\n",
      "[18,   299] loss: 0.088390\n",
      "[19,    99] loss: 0.064405\n",
      "[19,   199] loss: 0.079612\n",
      "[19,   299] loss: 0.077589\n",
      "[20,    99] loss: 0.057142\n",
      "[20,   199] loss: 0.071052\n",
      "[20,   299] loss: 0.080656\n",
      "[21,    99] loss: 0.052731\n",
      "[21,   199] loss: 0.065545\n",
      "[21,   299] loss: 0.103012\n",
      "[22,    99] loss: 0.062880\n",
      "[22,   199] loss: 0.056760\n",
      "[22,   299] loss: 0.060856\n",
      "[23,    99] loss: 0.047468\n",
      "[23,   199] loss: 0.042197\n",
      "[23,   299] loss: 0.054752\n",
      "[24,    99] loss: 0.068031\n",
      "[24,   199] loss: 0.068588\n",
      "[24,   299] loss: 0.070013\n",
      "[25,    99] loss: 0.042420\n",
      "[25,   199] loss: 0.041766\n",
      "[25,   299] loss: 0.051578\n",
      "[26,    99] loss: 0.035271\n",
      "[26,   199] loss: 0.034178\n",
      "[26,   299] loss: 0.042609\n",
      "[27,    99] loss: 0.043380\n",
      "[27,   199] loss: 0.158629\n",
      "[27,   299] loss: 0.196509\n",
      "[28,    99] loss: 0.044206\n",
      "[28,   199] loss: 0.082580\n",
      "[28,   299] loss: 0.077473\n",
      "[29,    99] loss: 0.131312\n",
      "[29,   199] loss: 0.055449\n",
      "[29,   299] loss: 0.076873\n",
      "[30,    99] loss: 0.026471\n",
      "[30,   199] loss: 0.023082\n",
      "[30,   299] loss: 0.035300\n",
      "[31,    99] loss: 0.025701\n",
      "[31,   199] loss: 0.019234\n",
      "[31,   299] loss: 0.030679\n",
      "[32,    99] loss: 0.026725\n",
      "[32,   199] loss: 0.031422\n",
      "[32,   299] loss: 0.044162\n",
      "[33,    99] loss: 0.025417\n",
      "[33,   199] loss: 0.028592\n",
      "[33,   299] loss: 0.045603\n",
      "[34,    99] loss: 0.105029\n",
      "[34,   199] loss: 0.127401\n",
      "[34,   299] loss: 0.117936\n",
      "[35,    99] loss: 0.039988\n",
      "[35,   199] loss: 0.022467\n",
      "[35,   299] loss: 0.040669\n",
      "[36,    99] loss: 0.025114\n",
      "[36,   199] loss: 0.024182\n",
      "[36,   299] loss: 0.026573\n",
      "[37,    99] loss: 0.020810\n",
      "[37,   199] loss: 0.050901\n",
      "[37,   299] loss: 0.026397\n",
      "[38,    99] loss: 0.025628\n",
      "[38,   199] loss: 0.018728\n",
      "[38,   299] loss: 0.019714\n",
      "[39,    99] loss: 0.018293\n",
      "[39,   199] loss: 0.013565\n",
      "[39,   299] loss: 0.021690\n",
      "[40,    99] loss: 0.019845\n",
      "[40,   199] loss: 0.011739\n",
      "[40,   299] loss: 0.019973\n",
      "[41,    99] loss: 0.019200\n",
      "[41,   199] loss: 0.024217\n",
      "[41,   299] loss: 0.038645\n",
      "[42,    99] loss: 0.030991\n",
      "[42,   199] loss: 0.305521\n",
      "[42,   299] loss: 0.137841\n",
      "[43,    99] loss: 0.081039\n",
      "[43,   199] loss: 0.074878\n",
      "[43,   299] loss: 0.045828\n",
      "[44,    99] loss: 0.038755\n",
      "[44,   199] loss: 0.050827\n",
      "[44,   299] loss: 0.023559\n",
      "[45,    99] loss: 0.018377\n",
      "[45,   199] loss: 0.046650\n",
      "[45,   299] loss: 0.021273\n",
      "[46,    99] loss: 0.025540\n",
      "[46,   199] loss: 0.060918\n",
      "[46,   299] loss: 0.020982\n",
      "[47,    99] loss: 0.024323\n",
      "[47,   199] loss: 0.039702\n",
      "[47,   299] loss: 0.096287\n",
      "[48,    99] loss: 0.063050\n",
      "[48,   199] loss: 0.042535\n",
      "[48,   299] loss: 0.018997\n",
      "[49,    99] loss: 0.018536\n",
      "[49,   199] loss: 0.029692\n",
      "[49,   299] loss: 0.018242\n",
      "[50,    99] loss: 0.017889\n",
      "[50,   199] loss: 0.064324\n",
      "[50,   299] loss: 0.023713\n",
      "[51,    99] loss: 0.038007\n",
      "[51,   199] loss: 0.023134\n",
      "[51,   299] loss: 0.010003\n",
      "[52,    99] loss: 0.022003\n",
      "[52,   199] loss: 0.030585\n",
      "[52,   299] loss: 0.041416\n",
      "[53,    99] loss: 0.010872\n",
      "[53,   199] loss: 0.020869\n",
      "[53,   299] loss: 0.009210\n",
      "[54,    99] loss: 0.010863\n",
      "[54,   199] loss: 0.026669\n",
      "[54,   299] loss: 0.018753\n",
      "[55,    99] loss: 0.018770\n",
      "[55,   199] loss: 0.030347\n",
      "[55,   299] loss: 0.035516\n",
      "[56,    99] loss: 0.018462\n",
      "[56,   199] loss: 0.042896\n",
      "[56,   299] loss: 0.120989\n",
      "[57,    99] loss: 0.041120\n",
      "[57,   199] loss: 0.024393\n",
      "[57,   299] loss: 0.013097\n",
      "[58,    99] loss: 0.019761\n",
      "[58,   199] loss: 0.029294\n",
      "[58,   299] loss: 0.010344\n",
      "[59,    99] loss: 0.014961\n",
      "[59,   199] loss: 0.033375\n",
      "[59,   299] loss: 0.011464\n",
      "[60,    99] loss: 0.012833\n",
      "[60,   199] loss: 0.018993\n",
      "[60,   299] loss: 0.006305\n",
      "[61,    99] loss: 0.012585\n",
      "[61,   199] loss: 0.017407\n",
      "[61,   299] loss: 0.026581\n",
      "[62,    99] loss: 0.308883\n",
      "[62,   199] loss: 0.106536\n",
      "[62,   299] loss: 0.101566\n",
      "[63,    99] loss: 0.063354\n",
      "[63,   199] loss: 0.015070\n",
      "[63,   299] loss: 0.010296\n",
      "[64,    99] loss: 0.007424\n",
      "[64,   199] loss: 0.008283\n",
      "[64,   299] loss: 0.005888\n",
      "[65,    99] loss: 0.005758\n",
      "[65,   199] loss: 0.006509\n",
      "[65,   299] loss: 0.004096\n",
      "[66,    99] loss: 0.006672\n",
      "[66,   199] loss: 0.014141\n",
      "[66,   299] loss: 0.006664\n",
      "[67,    99] loss: 0.019591\n",
      "[67,   199] loss: 0.034235\n",
      "[67,   299] loss: 0.029960\n",
      "[68,    99] loss: 0.026511\n",
      "[68,   199] loss: 0.026086\n",
      "[68,   299] loss: 0.015817\n",
      "[69,    99] loss: 0.038301\n",
      "[69,   199] loss: 0.079917\n",
      "[69,   299] loss: 0.038953\n",
      "[70,    99] loss: 0.288318\n",
      "[70,   199] loss: 0.038609\n",
      "[70,   299] loss: 0.072120\n",
      "[71,    99] loss: 0.009480\n",
      "[71,   199] loss: 0.004477\n",
      "[71,   299] loss: 0.004446\n",
      "[72,    99] loss: 0.003418\n",
      "[72,   199] loss: 0.003480\n",
      "[72,   299] loss: 0.003448\n",
      "[73,    99] loss: 0.002555\n",
      "[73,   199] loss: 0.002426\n",
      "[73,   299] loss: 0.002946\n",
      "[74,    99] loss: 0.002325\n",
      "[74,   199] loss: 0.002183\n",
      "[74,   299] loss: 0.002731\n",
      "[75,    99] loss: 0.002179\n",
      "[75,   199] loss: 0.001970\n",
      "[75,   299] loss: 0.002793\n",
      "[76,    99] loss: 0.002586\n",
      "[76,   199] loss: 0.001792\n",
      "[76,   299] loss: 0.002694\n",
      "[77,    99] loss: 0.003519\n",
      "[77,   199] loss: 0.001764\n",
      "[77,   299] loss: 0.002499\n",
      "[78,    99] loss: 0.004592\n",
      "[78,   199] loss: 0.022811\n",
      "[78,   299] loss: 0.097207\n",
      "[79,    99] loss: 0.235054\n",
      "[79,   199] loss: 0.148023\n",
      "[79,   299] loss: 0.053348\n",
      "[80,    99] loss: 0.044343\n",
      "[80,   199] loss: 0.078952\n",
      "[80,   299] loss: 0.011994\n",
      "[81,    99] loss: 0.009874\n",
      "[81,   199] loss: 0.005076\n",
      "[81,   299] loss: 0.003544\n",
      "[82,    99] loss: 0.003104\n",
      "[82,   199] loss: 0.002544\n",
      "[82,   299] loss: 0.002995\n",
      "[83,    99] loss: 0.002214\n",
      "[83,   199] loss: 0.001967\n",
      "[83,   299] loss: 0.002438\n",
      "[84,    99] loss: 0.001804\n",
      "[84,   199] loss: 0.001679\n",
      "[84,   299] loss: 0.002092\n",
      "[85,    99] loss: 0.001552\n",
      "[85,   199] loss: 0.001478\n",
      "[85,   299] loss: 0.001879\n",
      "[86,    99] loss: 0.001387\n",
      "[86,   199] loss: 0.001335\n",
      "[86,   299] loss: 0.001802\n",
      "[87,    99] loss: 0.001502\n",
      "[87,   199] loss: 0.001378\n",
      "[87,   299] loss: 0.001934\n",
      "[88,    99] loss: 0.001996\n",
      "[88,   199] loss: 0.001681\n",
      "[88,   299] loss: 0.007251\n",
      "[89,    99] loss: 0.152787\n",
      "[89,   199] loss: 0.041104\n",
      "[89,   299] loss: 0.112330\n",
      "[90,    99] loss: 0.013092\n",
      "[90,   199] loss: 0.044343\n",
      "[90,   299] loss: 0.018755\n",
      "[91,    99] loss: 0.013054\n",
      "[91,   199] loss: 0.028727\n",
      "[91,   299] loss: 0.005917\n",
      "[92,    99] loss: 0.022705\n",
      "[92,   199] loss: 0.072541\n",
      "[92,   299] loss: 0.008291\n",
      "[93,    99] loss: 0.005195\n",
      "[93,   199] loss: 0.004513\n",
      "[93,   299] loss: 0.001866\n",
      "[94,    99] loss: 0.003070\n",
      "[94,   199] loss: 0.003779\n",
      "[94,   299] loss: 0.001582\n",
      "[95,    99] loss: 0.004068\n",
      "[95,   199] loss: 0.012107\n",
      "[95,   299] loss: 0.002005\n",
      "[96,    99] loss: 0.016454\n",
      "[96,   199] loss: 0.032287\n",
      "[96,   299] loss: 0.012029\n",
      "[97,    99] loss: 0.022493\n",
      "[97,   199] loss: 0.186750\n",
      "[97,   299] loss: 0.018815\n",
      "[98,    99] loss: 0.018248\n",
      "[98,   199] loss: 0.007412\n",
      "[98,   299] loss: 0.005529\n",
      "[99,    99] loss: 0.005183\n",
      "[99,   199] loss: 0.007497\n",
      "[99,   299] loss: 0.001417\n",
      "[100,    99] loss: 0.006430\n",
      "[100,   199] loss: 0.014873\n",
      "[100,   299] loss: 0.001360\n",
      "Finished Training\n",
      "[1,    99] loss: 0.660664\n",
      "[1,   199] loss: 0.680902\n",
      "[1,   299] loss: 0.638667\n",
      "[2,    99] loss: 0.597217\n",
      "[2,   199] loss: 0.621360\n",
      "[2,   299] loss: 0.570147\n",
      "[3,    99] loss: 0.528504\n",
      "[3,   199] loss: 0.555656\n",
      "[3,   299] loss: 0.491584\n",
      "[4,    99] loss: 0.452782\n",
      "[4,   199] loss: 0.480562\n",
      "[4,   299] loss: 0.408060\n",
      "[5,    99] loss: 0.385213\n",
      "[5,   199] loss: 0.418876\n",
      "[5,   299] loss: 0.345577\n",
      "[6,    99] loss: 0.331072\n",
      "[6,   199] loss: 0.368306\n",
      "[6,   299] loss: 0.284838\n",
      "[7,    99] loss: 0.291501\n",
      "[7,   199] loss: 0.335049\n",
      "[7,   299] loss: 0.241052\n",
      "[8,    99] loss: 0.259889\n",
      "[8,   199] loss: 0.301322\n",
      "[8,   299] loss: 0.210702\n",
      "[9,    99] loss: 0.234723\n",
      "[9,   199] loss: 0.273597\n",
      "[9,   299] loss: 0.182986\n",
      "[10,    99] loss: 0.225102\n",
      "[10,   199] loss: 0.250505\n",
      "[10,   299] loss: 0.160508\n",
      "[11,    99] loss: 0.206213\n",
      "[11,   199] loss: 0.229544\n",
      "[11,   299] loss: 0.141235\n",
      "[12,    99] loss: 0.194289\n",
      "[12,   199] loss: 0.215434\n",
      "[12,   299] loss: 0.128657\n",
      "[13,    99] loss: 0.181748\n",
      "[13,   199] loss: 0.202593\n",
      "[13,   299] loss: 0.114037\n",
      "[14,    99] loss: 0.170462\n",
      "[14,   199] loss: 0.193258\n",
      "[14,   299] loss: 0.108972\n",
      "[15,    99] loss: 0.167786\n",
      "[15,   199] loss: 0.163121\n",
      "[15,   299] loss: 0.096070\n",
      "[16,    99] loss: 0.151400\n",
      "[16,   199] loss: 0.138575\n",
      "[16,   299] loss: 0.085373\n",
      "[17,    99] loss: 0.140069\n",
      "[17,   199] loss: 0.127129\n",
      "[17,   299] loss: 0.074287\n",
      "[18,    99] loss: 0.132650\n",
      "[18,   199] loss: 0.108206\n",
      "[18,   299] loss: 0.065728\n",
      "[19,    99] loss: 0.132050\n",
      "[19,   199] loss: 0.097505\n",
      "[19,   299] loss: 0.060025\n",
      "[20,    99] loss: 0.124226\n",
      "[20,   199] loss: 0.083712\n",
      "[20,   299] loss: 0.055843\n",
      "[21,    99] loss: 0.124615\n",
      "[21,   199] loss: 0.077063\n",
      "[21,   299] loss: 0.046563\n",
      "[22,    99] loss: 0.126840\n",
      "[22,   199] loss: 0.090964\n",
      "[22,   299] loss: 0.040906\n",
      "[23,    99] loss: 0.116782\n",
      "[23,   199] loss: 0.065333\n",
      "[23,   299] loss: 0.055087\n",
      "[24,    99] loss: 0.117581\n",
      "[24,   199] loss: 0.068533\n",
      "[24,   299] loss: 0.047495\n",
      "[25,    99] loss: 0.110181\n",
      "[25,   199] loss: 0.046190\n",
      "[25,   299] loss: 0.035544\n",
      "[26,    99] loss: 0.097236\n",
      "[26,   199] loss: 0.039223\n",
      "[26,   299] loss: 0.058937\n",
      "[27,    99] loss: 0.080246\n",
      "[27,   199] loss: 0.037702\n",
      "[27,   299] loss: 0.044294\n",
      "[28,    99] loss: 0.083649\n",
      "[28,   199] loss: 0.045735\n",
      "[28,   299] loss: 0.044407\n",
      "[29,    99] loss: 0.080296\n",
      "[29,   199] loss: 0.029578\n",
      "[29,   299] loss: 0.043355\n",
      "[30,    99] loss: 0.081261\n",
      "[30,   199] loss: 0.030519\n",
      "[30,   299] loss: 0.042801\n",
      "[31,    99] loss: 0.045648\n",
      "[31,   199] loss: 0.027412\n",
      "[31,   299] loss: 0.034302\n",
      "[32,    99] loss: 0.096301\n",
      "[32,   199] loss: 0.032020\n",
      "[32,   299] loss: 0.024916\n",
      "[33,    99] loss: 0.078349\n",
      "[33,   199] loss: 0.045562\n",
      "[33,   299] loss: 0.096348\n",
      "[34,    99] loss: 0.090521\n",
      "[34,   199] loss: 0.041016\n",
      "[34,   299] loss: 0.066013\n",
      "[35,    99] loss: 0.077099\n",
      "[35,   199] loss: 0.026191\n",
      "[35,   299] loss: 0.024292\n",
      "[36,    99] loss: 0.052015\n",
      "[36,   199] loss: 0.015410\n",
      "[36,   299] loss: 0.019847\n",
      "[37,    99] loss: 0.034598\n",
      "[37,   199] loss: 0.012423\n",
      "[37,   299] loss: 0.014252\n",
      "[38,    99] loss: 0.041366\n",
      "[38,   199] loss: 0.027765\n",
      "[38,   299] loss: 0.035402\n",
      "[39,    99] loss: 0.043220\n",
      "[39,   199] loss: 0.019886\n",
      "[39,   299] loss: 0.017795\n",
      "[40,    99] loss: 0.062472\n",
      "[40,   199] loss: 0.026848\n",
      "[40,   299] loss: 0.033979\n",
      "[41,    99] loss: 0.045264\n",
      "[41,   199] loss: 0.029902\n",
      "[41,   299] loss: 0.059941\n",
      "[42,    99] loss: 0.060651\n",
      "[42,   199] loss: 0.026821\n",
      "[42,   299] loss: 0.030161\n",
      "[43,    99] loss: 0.062008\n",
      "[43,   199] loss: 0.014726\n",
      "[43,   299] loss: 0.040365\n",
      "[44,    99] loss: 0.044220\n",
      "[44,   199] loss: 0.010209\n",
      "[44,   299] loss: 0.006945\n",
      "[45,    99] loss: 0.044645\n",
      "[45,   199] loss: 0.012036\n",
      "[45,   299] loss: 0.023276\n",
      "[46,    99] loss: 0.026493\n",
      "[46,   199] loss: 0.009815\n",
      "[46,   299] loss: 0.011933\n",
      "[47,    99] loss: 0.026385\n",
      "[47,   199] loss: 0.009700\n",
      "[47,   299] loss: 0.008595\n",
      "[48,    99] loss: 0.036476\n",
      "[48,   199] loss: 0.025133\n",
      "[48,   299] loss: 0.049962\n",
      "[49,    99] loss: 0.122367\n",
      "[49,   199] loss: 0.059792\n",
      "[49,   299] loss: 0.025473\n",
      "[50,    99] loss: 0.086112\n",
      "[50,   199] loss: 0.061529\n",
      "[50,   299] loss: 0.209532\n",
      "[51,    99] loss: 0.079456\n",
      "[51,   199] loss: 0.027204\n",
      "[51,   299] loss: 0.028399\n",
      "[52,    99] loss: 0.031152\n",
      "[52,   199] loss: 0.009498\n",
      "[52,   299] loss: 0.006826\n",
      "[53,    99] loss: 0.009088\n",
      "[53,   199] loss: 0.006531\n",
      "[53,   299] loss: 0.003205\n",
      "[54,    99] loss: 0.010384\n",
      "[54,   199] loss: 0.004125\n",
      "[54,   299] loss: 0.001753\n",
      "[55,    99] loss: 0.009666\n",
      "[55,   199] loss: 0.003387\n",
      "[55,   299] loss: 0.001477\n",
      "[56,    99] loss: 0.014290\n",
      "[56,   199] loss: 0.003437\n",
      "[56,   299] loss: 0.002001\n",
      "[57,    99] loss: 0.028520\n",
      "[57,   199] loss: 0.037273\n",
      "[57,   299] loss: 0.070798\n",
      "[58,    99] loss: 0.161662\n",
      "[58,   199] loss: 0.101078\n",
      "[58,   299] loss: 0.030462\n",
      "[59,    99] loss: 0.131094\n",
      "[59,   199] loss: 0.036997\n",
      "[59,   299] loss: 0.031347\n",
      "[60,    99] loss: 0.041621\n",
      "[60,   199] loss: 0.007121\n",
      "[60,   299] loss: 0.019316\n",
      "[61,    99] loss: 0.013937\n",
      "[61,   199] loss: 0.006271\n",
      "[61,   299] loss: 0.006883\n",
      "[62,    99] loss: 0.008600\n",
      "[62,   199] loss: 0.007948\n",
      "[62,   299] loss: 0.027998\n",
      "[63,    99] loss: 0.007637\n",
      "[63,   199] loss: 0.005869\n",
      "[63,   299] loss: 0.006618\n",
      "[64,    99] loss: 0.006889\n",
      "[64,   199] loss: 0.011516\n",
      "[64,   299] loss: 0.038739\n",
      "[65,    99] loss: 0.031449\n",
      "[65,   199] loss: 0.006640\n",
      "[65,   299] loss: 0.018220\n",
      "[66,    99] loss: 0.088357\n",
      "[66,   199] loss: 0.008806\n",
      "[66,   299] loss: 0.002687\n",
      "[67,    99] loss: 0.036043\n",
      "[67,   199] loss: 0.003709\n",
      "[67,   299] loss: 0.001673\n",
      "[68,    99] loss: 0.026331\n",
      "[68,   199] loss: 0.003440\n",
      "[68,   299] loss: 0.001039\n",
      "[69,    99] loss: 0.018805\n",
      "[69,   199] loss: 0.003133\n",
      "[69,   299] loss: 0.001972\n",
      "[70,    99] loss: 0.013591\n",
      "[70,   199] loss: 0.003296\n",
      "[70,   299] loss: 0.045813\n",
      "[71,    99] loss: 0.367968\n",
      "[71,   199] loss: 0.051589\n",
      "[71,   299] loss: 0.008960\n",
      "[72,    99] loss: 0.049216\n",
      "[72,   199] loss: 0.009204\n",
      "[72,   299] loss: 0.005993\n",
      "[73,    99] loss: 0.020056\n",
      "[73,   199] loss: 0.007693\n",
      "[73,   299] loss: 0.006167\n",
      "[74,    99] loss: 0.007771\n",
      "[74,   199] loss: 0.004215\n",
      "[74,   299] loss: 0.001723\n",
      "[75,    99] loss: 0.005229\n",
      "[75,   199] loss: 0.004364\n",
      "[75,   299] loss: 0.003880\n",
      "[76,    99] loss: 0.003709\n",
      "[76,   199] loss: 0.002835\n",
      "[76,   299] loss: 0.001023\n",
      "[77,    99] loss: 0.020558\n",
      "[77,   199] loss: 0.003173\n",
      "[77,   299] loss: 0.001873\n",
      "[78,    99] loss: 0.039824\n",
      "[78,   199] loss: 0.010326\n",
      "[78,   299] loss: 0.004556\n",
      "[79,    99] loss: 0.025216\n",
      "[79,   199] loss: 0.031595\n",
      "[79,   299] loss: 0.061894\n",
      "[80,    99] loss: 0.244152\n",
      "[80,   199] loss: 0.096477\n",
      "[80,   299] loss: 0.027864\n",
      "[81,    99] loss: 0.096571\n",
      "[81,   199] loss: 0.032754\n",
      "[81,   299] loss: 0.013915\n",
      "[82,    99] loss: 0.011701\n",
      "[82,   199] loss: 0.005963\n",
      "[82,   299] loss: 0.001349\n",
      "[83,    99] loss: 0.003176\n",
      "[83,   199] loss: 0.003157\n",
      "[83,   299] loss: 0.000849\n",
      "[84,    99] loss: 0.002300\n",
      "[84,   199] loss: 0.002646\n",
      "[84,   299] loss: 0.000717\n",
      "[85,    99] loss: 0.002080\n",
      "[85,   199] loss: 0.003008\n",
      "[85,   299] loss: 0.000887\n",
      "[86,    99] loss: 0.005987\n",
      "[86,   199] loss: 0.001570\n",
      "[86,   299] loss: 0.000620\n",
      "[87,    99] loss: 0.013303\n",
      "[87,   199] loss: 0.003188\n",
      "[87,   299] loss: 0.007099\n",
      "[88,    99] loss: 0.002007\n",
      "[88,   199] loss: 0.002311\n",
      "[88,   299] loss: 0.012857\n",
      "[89,    99] loss: 0.003549\n",
      "[89,   199] loss: 0.002867\n",
      "[89,   299] loss: 0.005020\n",
      "[90,    99] loss: 0.004361\n",
      "[90,   199] loss: 0.001912\n",
      "[90,   299] loss: 0.000543\n",
      "[91,    99] loss: 0.050661\n",
      "[91,   199] loss: 0.001759\n",
      "[91,   299] loss: 0.000893\n",
      "[92,    99] loss: 0.051641\n",
      "[92,   199] loss: 0.002454\n",
      "[92,   299] loss: 0.003128\n",
      "[93,    99] loss: 0.036554\n",
      "[93,   199] loss: 0.169063\n",
      "[93,   299] loss: 0.094620\n",
      "[94,    99] loss: 0.080325\n",
      "[94,   199] loss: 0.012157\n",
      "[94,   299] loss: 0.032893\n",
      "[95,    99] loss: 0.002653\n",
      "[95,   199] loss: 0.011044\n",
      "[95,   299] loss: 0.003997\n",
      "[96,    99] loss: 0.002858\n",
      "[96,   199] loss: 0.002597\n",
      "[96,   299] loss: 0.000833\n",
      "[97,    99] loss: 0.001315\n",
      "[97,   199] loss: 0.001678\n",
      "[97,   299] loss: 0.000611\n",
      "[98,    99] loss: 0.001119\n",
      "[98,   199] loss: 0.001475\n",
      "[98,   299] loss: 0.000478\n",
      "[99,    99] loss: 0.001010\n",
      "[99,   199] loss: 0.001421\n",
      "[99,   299] loss: 0.000446\n",
      "[100,    99] loss: 0.001093\n",
      "[100,   199] loss: 0.002309\n",
      "[100,   299] loss: 0.022039\n",
      "Finished Training\n",
      "[1,    99] loss: 0.693471\n",
      "[1,   199] loss: 0.691355\n",
      "[1,   299] loss: 0.688587\n",
      "[2,    99] loss: 0.676793\n",
      "[2,   199] loss: 0.680894\n",
      "[2,   299] loss: 0.675817\n",
      "[3,    99] loss: 0.661764\n",
      "[3,   199] loss: 0.672273\n",
      "[3,   299] loss: 0.663336\n",
      "[4,    99] loss: 0.645801\n",
      "[4,   199] loss: 0.664090\n",
      "[4,   299] loss: 0.649701\n",
      "[5,    99] loss: 0.628799\n",
      "[5,   199] loss: 0.655518\n",
      "[5,   299] loss: 0.635346\n",
      "[6,    99] loss: 0.611294\n",
      "[6,   199] loss: 0.646785\n",
      "[6,   299] loss: 0.620466\n",
      "[7,    99] loss: 0.594309\n",
      "[7,   199] loss: 0.638248\n",
      "[7,   299] loss: 0.605290\n",
      "[8,    99] loss: 0.578239\n",
      "[8,   199] loss: 0.629874\n",
      "[8,   299] loss: 0.591168\n",
      "[9,    99] loss: 0.563452\n",
      "[9,   199] loss: 0.621274\n",
      "[9,   299] loss: 0.577087\n",
      "[10,    99] loss: 0.549171\n",
      "[10,   199] loss: 0.611539\n",
      "[10,   299] loss: 0.562694\n",
      "[11,    99] loss: 0.535688\n",
      "[11,   199] loss: 0.601299\n",
      "[11,   299] loss: 0.548886\n",
      "[12,    99] loss: 0.523162\n",
      "[12,   199] loss: 0.590632\n",
      "[12,   299] loss: 0.535363\n",
      "[13,    99] loss: 0.510914\n",
      "[13,   199] loss: 0.579616\n",
      "[13,   299] loss: 0.521755\n",
      "[14,    99] loss: 0.498697\n",
      "[14,   199] loss: 0.568116\n",
      "[14,   299] loss: 0.508178\n",
      "[15,    99] loss: 0.486993\n",
      "[15,   199] loss: 0.556705\n",
      "[15,   299] loss: 0.494891\n",
      "[16,    99] loss: 0.475631\n",
      "[16,   199] loss: 0.545085\n",
      "[16,   299] loss: 0.481991\n",
      "[17,    99] loss: 0.464231\n",
      "[17,   199] loss: 0.533284\n",
      "[17,   299] loss: 0.469435\n",
      "[18,    99] loss: 0.453156\n",
      "[18,   199] loss: 0.521359\n",
      "[18,   299] loss: 0.457155\n",
      "[19,    99] loss: 0.442154\n",
      "[19,   199] loss: 0.509567\n",
      "[19,   299] loss: 0.445392\n",
      "[20,    99] loss: 0.431545\n",
      "[20,   199] loss: 0.497997\n",
      "[20,   299] loss: 0.433997\n",
      "[21,    99] loss: 0.421140\n",
      "[21,   199] loss: 0.486501\n",
      "[21,   299] loss: 0.423037\n",
      "[22,    99] loss: 0.410676\n",
      "[22,   199] loss: 0.474970\n",
      "[22,   299] loss: 0.412715\n",
      "[23,    99] loss: 0.400570\n",
      "[23,   199] loss: 0.463548\n",
      "[23,   299] loss: 0.402605\n",
      "[24,    99] loss: 0.390557\n",
      "[24,   199] loss: 0.452222\n",
      "[24,   299] loss: 0.392792\n",
      "[25,    99] loss: 0.380762\n",
      "[25,   199] loss: 0.441092\n",
      "[25,   299] loss: 0.383230\n",
      "[26,    99] loss: 0.371284\n",
      "[26,   199] loss: 0.430229\n",
      "[26,   299] loss: 0.373951\n",
      "[27,    99] loss: 0.361709\n",
      "[27,   199] loss: 0.419343\n",
      "[27,   299] loss: 0.365029\n",
      "[28,    99] loss: 0.351927\n",
      "[28,   199] loss: 0.408783\n",
      "[28,   299] loss: 0.356623\n",
      "[29,    99] loss: 0.342522\n",
      "[29,   199] loss: 0.398388\n",
      "[29,   299] loss: 0.348342\n",
      "[30,    99] loss: 0.333429\n",
      "[30,   199] loss: 0.388399\n",
      "[30,   299] loss: 0.340221\n",
      "[31,    99] loss: 0.324440\n",
      "[31,   199] loss: 0.378243\n",
      "[31,   299] loss: 0.332369\n",
      "[32,    99] loss: 0.315659\n",
      "[32,   199] loss: 0.368288\n",
      "[32,   299] loss: 0.324748\n",
      "[33,    99] loss: 0.307033\n",
      "[33,   199] loss: 0.358469\n",
      "[33,   299] loss: 0.317383\n",
      "[34,    99] loss: 0.298334\n",
      "[34,   199] loss: 0.349130\n",
      "[34,   299] loss: 0.309565\n",
      "[35,    99] loss: 0.290141\n",
      "[35,   199] loss: 0.339938\n",
      "[35,   299] loss: 0.302196\n",
      "[36,    99] loss: 0.281708\n",
      "[36,   199] loss: 0.330981\n",
      "[36,   299] loss: 0.295157\n",
      "[37,    99] loss: 0.273581\n",
      "[37,   199] loss: 0.321972\n",
      "[37,   299] loss: 0.288110\n",
      "[38,    99] loss: 0.265644\n",
      "[38,   199] loss: 0.313732\n",
      "[38,   299] loss: 0.281453\n",
      "[39,    99] loss: 0.258058\n",
      "[39,   199] loss: 0.305301\n",
      "[39,   299] loss: 0.275122\n",
      "[40,    99] loss: 0.250705\n",
      "[40,   199] loss: 0.297073\n",
      "[40,   299] loss: 0.268748\n",
      "[41,    99] loss: 0.243584\n",
      "[41,   199] loss: 0.289336\n",
      "[41,   299] loss: 0.262628\n",
      "[42,    99] loss: 0.236585\n",
      "[42,   199] loss: 0.281544\n",
      "[42,   299] loss: 0.256598\n",
      "[43,    99] loss: 0.229829\n",
      "[43,   199] loss: 0.274091\n",
      "[43,   299] loss: 0.250729\n",
      "[44,    99] loss: 0.223296\n",
      "[44,   199] loss: 0.266710\n",
      "[44,   299] loss: 0.244876\n",
      "[45,    99] loss: 0.217069\n",
      "[45,   199] loss: 0.259379\n",
      "[45,   299] loss: 0.239434\n",
      "[46,    99] loss: 0.210997\n",
      "[46,   199] loss: 0.252406\n",
      "[46,   299] loss: 0.234111\n",
      "[47,    99] loss: 0.205202\n",
      "[47,   199] loss: 0.245355\n",
      "[47,   299] loss: 0.228907\n",
      "[48,    99] loss: 0.199648\n",
      "[48,   199] loss: 0.238614\n",
      "[48,   299] loss: 0.223721\n",
      "[49,    99] loss: 0.194035\n",
      "[49,   199] loss: 0.231990\n",
      "[49,   299] loss: 0.218878\n",
      "[50,    99] loss: 0.188779\n",
      "[50,   199] loss: 0.225593\n",
      "[50,   299] loss: 0.213684\n",
      "[51,    99] loss: 0.183836\n",
      "[51,   199] loss: 0.219504\n",
      "[51,   299] loss: 0.209034\n",
      "[52,    99] loss: 0.178914\n",
      "[52,   199] loss: 0.213463\n",
      "[52,   299] loss: 0.204354\n",
      "[53,    99] loss: 0.174117\n",
      "[53,   199] loss: 0.208137\n",
      "[53,   299] loss: 0.199469\n",
      "[54,    99] loss: 0.169457\n",
      "[54,   199] loss: 0.202499\n",
      "[54,   299] loss: 0.195368\n",
      "[55,    99] loss: 0.164952\n",
      "[55,   199] loss: 0.197093\n",
      "[55,   299] loss: 0.190815\n",
      "[56,    99] loss: 0.160790\n",
      "[56,   199] loss: 0.191863\n",
      "[56,   299] loss: 0.186691\n",
      "[57,    99] loss: 0.156940\n",
      "[57,   199] loss: 0.187032\n",
      "[57,   299] loss: 0.182005\n",
      "[58,    99] loss: 0.152672\n",
      "[58,   199] loss: 0.182316\n",
      "[58,   299] loss: 0.178154\n",
      "[59,    99] loss: 0.148789\n",
      "[59,   199] loss: 0.177529\n",
      "[59,   299] loss: 0.173599\n",
      "[60,    99] loss: 0.144733\n",
      "[60,   199] loss: 0.173356\n",
      "[60,   299] loss: 0.170492\n",
      "[61,    99] loss: 0.141584\n",
      "[61,   199] loss: 0.168747\n",
      "[61,   299] loss: 0.166265\n",
      "[62,    99] loss: 0.137666\n",
      "[62,   199] loss: 0.164676\n",
      "[62,   299] loss: 0.163212\n",
      "[63,    99] loss: 0.134245\n",
      "[63,   199] loss: 0.160317\n",
      "[63,   299] loss: 0.159188\n",
      "[64,    99] loss: 0.130799\n",
      "[64,   199] loss: 0.156390\n",
      "[64,   299] loss: 0.156212\n",
      "[65,    99] loss: 0.127667\n",
      "[65,   199] loss: 0.152347\n",
      "[65,   299] loss: 0.152489\n",
      "[66,    99] loss: 0.124459\n",
      "[66,   199] loss: 0.148648\n",
      "[66,   299] loss: 0.149437\n",
      "[67,    99] loss: 0.121550\n",
      "[67,   199] loss: 0.144925\n",
      "[67,   299] loss: 0.146331\n",
      "[68,    99] loss: 0.118360\n",
      "[68,   199] loss: 0.141444\n",
      "[68,   299] loss: 0.143042\n",
      "[69,    99] loss: 0.115658\n",
      "[69,   199] loss: 0.138086\n",
      "[69,   299] loss: 0.140495\n",
      "[70,    99] loss: 0.113081\n",
      "[70,   199] loss: 0.134328\n",
      "[70,   299] loss: 0.137394\n",
      "[71,    99] loss: 0.110227\n",
      "[71,   199] loss: 0.131116\n",
      "[71,   299] loss: 0.134649\n",
      "[72,    99] loss: 0.107638\n",
      "[72,   199] loss: 0.128096\n",
      "[72,   299] loss: 0.131400\n",
      "[73,    99] loss: 0.105440\n",
      "[73,   199] loss: 0.124927\n",
      "[73,   299] loss: 0.129099\n",
      "[74,    99] loss: 0.102388\n",
      "[74,   199] loss: 0.122217\n",
      "[74,   299] loss: 0.125916\n",
      "[75,    99] loss: 0.100209\n",
      "[75,   199] loss: 0.119157\n",
      "[75,   299] loss: 0.123440\n",
      "[76,    99] loss: 0.097941\n",
      "[76,   199] loss: 0.116640\n",
      "[76,   299] loss: 0.120672\n",
      "[77,    99] loss: 0.095508\n",
      "[77,   199] loss: 0.113936\n",
      "[77,   299] loss: 0.117957\n",
      "[78,    99] loss: 0.093152\n",
      "[78,   199] loss: 0.111283\n",
      "[78,   299] loss: 0.115609\n",
      "[79,    99] loss: 0.090772\n",
      "[79,   199] loss: 0.108848\n",
      "[79,   299] loss: 0.113133\n",
      "[80,    99] loss: 0.089082\n",
      "[80,   199] loss: 0.106096\n",
      "[80,   299] loss: 0.109918\n",
      "[81,    99] loss: 0.086688\n",
      "[81,   199] loss: 0.103720\n",
      "[81,   299] loss: 0.107429\n",
      "[82,    99] loss: 0.084734\n",
      "[82,   199] loss: 0.101403\n",
      "[82,   299] loss: 0.105356\n",
      "[83,    99] loss: 0.082775\n",
      "[83,   199] loss: 0.098942\n",
      "[83,   299] loss: 0.102888\n",
      "[84,    99] loss: 0.080711\n",
      "[84,   199] loss: 0.096684\n",
      "[84,   299] loss: 0.100569\n",
      "[85,    99] loss: 0.078849\n",
      "[85,   199] loss: 0.094658\n",
      "[85,   299] loss: 0.098187\n",
      "[86,    99] loss: 0.076642\n",
      "[86,   199] loss: 0.092404\n",
      "[86,   299] loss: 0.096145\n",
      "[87,    99] loss: 0.075129\n",
      "[87,   199] loss: 0.090376\n",
      "[87,   299] loss: 0.093392\n",
      "[88,    99] loss: 0.072917\n",
      "[88,   199] loss: 0.088520\n",
      "[88,   299] loss: 0.091509\n",
      "[89,    99] loss: 0.071618\n",
      "[89,   199] loss: 0.086218\n",
      "[89,   299] loss: 0.089460\n",
      "[90,    99] loss: 0.069422\n",
      "[90,   199] loss: 0.084478\n",
      "[90,   299] loss: 0.086967\n",
      "[91,    99] loss: 0.068198\n",
      "[91,   199] loss: 0.082477\n",
      "[91,   299] loss: 0.085171\n",
      "[92,    99] loss: 0.065590\n",
      "[92,   199] loss: 0.080837\n",
      "[92,   299] loss: 0.083054\n",
      "[93,    99] loss: 0.064517\n",
      "[93,   199] loss: 0.078810\n",
      "[93,   299] loss: 0.081071\n",
      "[94,    99] loss: 0.062947\n",
      "[94,   199] loss: 0.077396\n",
      "[94,   299] loss: 0.079270\n",
      "[95,    99] loss: 0.061149\n",
      "[95,   199] loss: 0.075657\n",
      "[95,   299] loss: 0.077129\n",
      "[96,    99] loss: 0.059835\n",
      "[96,   199] loss: 0.073880\n",
      "[96,   299] loss: 0.075333\n",
      "[97,    99] loss: 0.058046\n",
      "[97,   199] loss: 0.072294\n",
      "[97,   299] loss: 0.073995\n",
      "[98,    99] loss: 0.056495\n",
      "[98,   199] loss: 0.070994\n",
      "[98,   299] loss: 0.071624\n",
      "[99,    99] loss: 0.055222\n",
      "[99,   199] loss: 0.069110\n",
      "[99,   299] loss: 0.070067\n",
      "[100,    99] loss: 0.053811\n",
      "[100,   199] loss: 0.067783\n",
      "[100,   299] loss: 0.068358\n",
      "Finished Training\n",
      "[1,    99] loss: 0.691600\n",
      "[1,   199] loss: 0.687606\n",
      "[1,   299] loss: 0.682934\n",
      "[2,    99] loss: 0.672269\n",
      "[2,   199] loss: 0.667272\n",
      "[2,   299] loss: 0.667130\n",
      "[3,    99] loss: 0.657434\n",
      "[3,   199] loss: 0.651334\n",
      "[3,   299] loss: 0.653137\n",
      "[4,    99] loss: 0.643649\n",
      "[4,   199] loss: 0.638489\n",
      "[4,   299] loss: 0.639418\n",
      "[5,    99] loss: 0.630045\n",
      "[5,   199] loss: 0.626448\n",
      "[5,   299] loss: 0.625478\n",
      "[6,    99] loss: 0.615908\n",
      "[6,   199] loss: 0.614717\n",
      "[6,   299] loss: 0.611507\n",
      "[7,    99] loss: 0.601914\n",
      "[7,   199] loss: 0.603762\n",
      "[7,   299] loss: 0.597789\n",
      "[8,    99] loss: 0.588222\n",
      "[8,   199] loss: 0.592749\n",
      "[8,   299] loss: 0.584174\n",
      "[9,    99] loss: 0.574780\n",
      "[9,   199] loss: 0.581709\n",
      "[9,   299] loss: 0.570936\n",
      "[10,    99] loss: 0.562113\n",
      "[10,   199] loss: 0.571100\n",
      "[10,   299] loss: 0.558832\n",
      "[11,    99] loss: 0.549855\n",
      "[11,   199] loss: 0.560708\n",
      "[11,   299] loss: 0.546696\n",
      "[12,    99] loss: 0.537880\n",
      "[12,   199] loss: 0.550434\n",
      "[12,   299] loss: 0.535056\n",
      "[13,    99] loss: 0.526150\n",
      "[13,   199] loss: 0.540215\n",
      "[13,   299] loss: 0.524022\n",
      "[14,    99] loss: 0.514796\n",
      "[14,   199] loss: 0.530219\n",
      "[14,   299] loss: 0.513316\n",
      "[15,    99] loss: 0.503589\n",
      "[15,   199] loss: 0.520452\n",
      "[15,   299] loss: 0.502791\n",
      "[16,    99] loss: 0.492845\n",
      "[16,   199] loss: 0.511022\n",
      "[16,   299] loss: 0.492629\n",
      "[17,    99] loss: 0.482347\n",
      "[17,   199] loss: 0.501538\n",
      "[17,   299] loss: 0.482734\n",
      "[18,    99] loss: 0.472095\n",
      "[18,   199] loss: 0.492148\n",
      "[18,   299] loss: 0.473162\n",
      "[19,    99] loss: 0.462037\n",
      "[19,   199] loss: 0.482939\n",
      "[19,   299] loss: 0.463752\n",
      "[20,    99] loss: 0.452055\n",
      "[20,   199] loss: 0.473528\n",
      "[20,   299] loss: 0.454818\n",
      "[21,    99] loss: 0.442099\n",
      "[21,   199] loss: 0.464254\n",
      "[21,   299] loss: 0.446118\n",
      "[22,    99] loss: 0.432258\n",
      "[22,   199] loss: 0.455126\n",
      "[22,   299] loss: 0.437282\n",
      "[23,    99] loss: 0.422530\n",
      "[23,   199] loss: 0.445819\n",
      "[23,   299] loss: 0.428753\n",
      "[24,    99] loss: 0.412989\n",
      "[24,   199] loss: 0.436650\n",
      "[24,   299] loss: 0.419970\n",
      "[25,    99] loss: 0.403868\n",
      "[25,   199] loss: 0.427554\n",
      "[25,   299] loss: 0.411505\n",
      "[26,    99] loss: 0.395181\n",
      "[26,   199] loss: 0.418342\n",
      "[26,   299] loss: 0.403294\n",
      "[27,    99] loss: 0.386583\n",
      "[27,   199] loss: 0.409563\n",
      "[27,   299] loss: 0.395048\n",
      "[28,    99] loss: 0.378116\n",
      "[28,   199] loss: 0.400923\n",
      "[28,   299] loss: 0.387411\n",
      "[29,    99] loss: 0.369803\n",
      "[29,   199] loss: 0.392453\n",
      "[29,   299] loss: 0.379473\n",
      "[30,    99] loss: 0.361971\n",
      "[30,   199] loss: 0.384177\n",
      "[30,   299] loss: 0.371885\n",
      "[31,    99] loss: 0.353987\n",
      "[31,   199] loss: 0.376092\n",
      "[31,   299] loss: 0.364440\n",
      "[32,    99] loss: 0.346367\n",
      "[32,   199] loss: 0.368037\n",
      "[32,   299] loss: 0.356879\n",
      "[33,    99] loss: 0.338699\n",
      "[33,   199] loss: 0.360416\n",
      "[33,   299] loss: 0.350111\n",
      "[34,    99] loss: 0.331218\n",
      "[34,   199] loss: 0.352496\n",
      "[34,   299] loss: 0.342939\n",
      "[35,    99] loss: 0.323854\n",
      "[35,   199] loss: 0.344966\n",
      "[35,   299] loss: 0.336080\n",
      "[36,    99] loss: 0.316767\n",
      "[36,   199] loss: 0.337758\n",
      "[36,   299] loss: 0.329643\n",
      "[37,    99] loss: 0.309378\n",
      "[37,   199] loss: 0.330406\n",
      "[37,   299] loss: 0.323079\n",
      "[38,    99] loss: 0.302561\n",
      "[38,   199] loss: 0.323518\n",
      "[38,   299] loss: 0.316569\n",
      "[39,    99] loss: 0.295512\n",
      "[39,   199] loss: 0.316592\n",
      "[39,   299] loss: 0.310641\n",
      "[40,    99] loss: 0.288723\n",
      "[40,   199] loss: 0.309567\n",
      "[40,   299] loss: 0.304454\n",
      "[41,    99] loss: 0.282057\n",
      "[41,   199] loss: 0.302754\n",
      "[41,   299] loss: 0.298346\n",
      "[42,    99] loss: 0.275335\n",
      "[42,   199] loss: 0.296025\n",
      "[42,   299] loss: 0.292148\n",
      "[43,    99] loss: 0.268903\n",
      "[43,   199] loss: 0.289192\n",
      "[43,   299] loss: 0.285802\n",
      "[44,    99] loss: 0.262255\n",
      "[44,   199] loss: 0.282868\n",
      "[44,   299] loss: 0.280150\n",
      "[45,    99] loss: 0.255908\n",
      "[45,   199] loss: 0.276059\n",
      "[45,   299] loss: 0.273892\n",
      "[46,    99] loss: 0.249725\n",
      "[46,   199] loss: 0.269217\n",
      "[46,   299] loss: 0.268233\n",
      "[47,    99] loss: 0.243463\n",
      "[47,   199] loss: 0.262630\n",
      "[47,   299] loss: 0.262286\n",
      "[48,    99] loss: 0.237597\n",
      "[48,   199] loss: 0.256681\n",
      "[48,   299] loss: 0.256856\n",
      "[49,    99] loss: 0.231474\n",
      "[49,   199] loss: 0.250196\n",
      "[49,   299] loss: 0.251408\n",
      "[50,    99] loss: 0.226091\n",
      "[50,   199] loss: 0.244496\n",
      "[50,   299] loss: 0.246477\n",
      "[51,    99] loss: 0.220365\n",
      "[51,   199] loss: 0.238561\n",
      "[51,   299] loss: 0.241234\n",
      "[52,    99] loss: 0.214888\n",
      "[52,   199] loss: 0.232693\n",
      "[52,   299] loss: 0.236281\n",
      "[53,    99] loss: 0.209955\n",
      "[53,   199] loss: 0.226929\n",
      "[53,   299] loss: 0.231321\n",
      "[54,    99] loss: 0.204109\n",
      "[54,   199] loss: 0.221477\n",
      "[54,   299] loss: 0.226508\n",
      "[55,    99] loss: 0.199285\n",
      "[55,   199] loss: 0.216491\n",
      "[55,   299] loss: 0.221732\n",
      "[56,    99] loss: 0.194255\n",
      "[56,   199] loss: 0.211095\n",
      "[56,   299] loss: 0.217117\n",
      "[57,    99] loss: 0.189483\n",
      "[57,   199] loss: 0.206444\n",
      "[57,   299] loss: 0.212352\n",
      "[58,    99] loss: 0.184678\n",
      "[58,   199] loss: 0.201241\n",
      "[58,   299] loss: 0.207916\n",
      "[59,    99] loss: 0.180240\n",
      "[59,   199] loss: 0.196418\n",
      "[59,   299] loss: 0.203484\n",
      "[60,    99] loss: 0.175386\n",
      "[60,   199] loss: 0.192096\n",
      "[60,   299] loss: 0.199183\n",
      "[61,    99] loss: 0.170797\n",
      "[61,   199] loss: 0.186966\n",
      "[61,   299] loss: 0.195284\n",
      "[62,    99] loss: 0.166603\n",
      "[62,   199] loss: 0.182960\n",
      "[62,   299] loss: 0.190949\n",
      "[63,    99] loss: 0.162034\n",
      "[63,   199] loss: 0.178363\n",
      "[63,   299] loss: 0.186891\n",
      "[64,    99] loss: 0.157809\n",
      "[64,   199] loss: 0.174465\n",
      "[64,   299] loss: 0.182759\n",
      "[65,    99] loss: 0.153665\n",
      "[65,   199] loss: 0.170419\n",
      "[65,   299] loss: 0.178730\n",
      "[66,    99] loss: 0.149646\n",
      "[66,   199] loss: 0.166478\n",
      "[66,   299] loss: 0.174686\n",
      "[67,    99] loss: 0.145711\n",
      "[67,   199] loss: 0.162599\n",
      "[67,   299] loss: 0.170855\n",
      "[68,    99] loss: 0.141687\n",
      "[68,   199] loss: 0.158977\n",
      "[68,   299] loss: 0.166912\n",
      "[69,    99] loss: 0.137883\n",
      "[69,   199] loss: 0.155187\n",
      "[69,   299] loss: 0.163333\n",
      "[70,    99] loss: 0.134470\n",
      "[70,   199] loss: 0.151624\n",
      "[70,   299] loss: 0.159233\n",
      "[71,    99] loss: 0.130570\n",
      "[71,   199] loss: 0.147999\n",
      "[71,   299] loss: 0.155578\n",
      "[72,    99] loss: 0.127141\n",
      "[72,   199] loss: 0.144492\n",
      "[72,   299] loss: 0.152034\n",
      "[73,    99] loss: 0.123454\n",
      "[73,   199] loss: 0.141288\n",
      "[73,   299] loss: 0.148214\n",
      "[74,    99] loss: 0.120347\n",
      "[74,   199] loss: 0.137777\n",
      "[74,   299] loss: 0.144703\n",
      "[75,    99] loss: 0.117000\n",
      "[75,   199] loss: 0.134622\n",
      "[75,   299] loss: 0.141281\n",
      "[76,    99] loss: 0.113835\n",
      "[76,   199] loss: 0.131469\n",
      "[76,   299] loss: 0.137812\n",
      "[77,    99] loss: 0.110593\n",
      "[77,   199] loss: 0.128192\n",
      "[77,   299] loss: 0.134487\n",
      "[78,    99] loss: 0.107558\n",
      "[78,   199] loss: 0.125372\n",
      "[78,   299] loss: 0.131270\n",
      "[79,    99] loss: 0.104798\n",
      "[79,   199] loss: 0.122767\n",
      "[79,   299] loss: 0.128095\n",
      "[80,    99] loss: 0.102031\n",
      "[80,   199] loss: 0.119700\n",
      "[80,   299] loss: 0.124968\n",
      "[81,    99] loss: 0.099114\n",
      "[81,   199] loss: 0.116870\n",
      "[81,   299] loss: 0.121993\n",
      "[82,    99] loss: 0.096259\n",
      "[82,   199] loss: 0.114159\n",
      "[82,   299] loss: 0.119093\n",
      "[83,    99] loss: 0.093627\n",
      "[83,   199] loss: 0.111436\n",
      "[83,   299] loss: 0.116176\n",
      "[84,    99] loss: 0.090937\n",
      "[84,   199] loss: 0.108602\n",
      "[84,   299] loss: 0.113053\n",
      "[85,    99] loss: 0.088342\n",
      "[85,   199] loss: 0.106408\n",
      "[85,   299] loss: 0.110225\n",
      "[86,    99] loss: 0.085817\n",
      "[86,   199] loss: 0.103322\n",
      "[86,   299] loss: 0.107502\n",
      "[87,    99] loss: 0.083364\n",
      "[87,   199] loss: 0.101096\n",
      "[87,   299] loss: 0.104566\n",
      "[88,    99] loss: 0.080980\n",
      "[88,   199] loss: 0.098410\n",
      "[88,   299] loss: 0.101929\n",
      "[89,    99] loss: 0.078470\n",
      "[89,   199] loss: 0.096199\n",
      "[89,   299] loss: 0.099384\n",
      "[90,    99] loss: 0.076402\n",
      "[90,   199] loss: 0.094049\n",
      "[90,   299] loss: 0.096930\n",
      "[91,    99] loss: 0.074178\n",
      "[91,   199] loss: 0.091742\n",
      "[91,   299] loss: 0.094495\n",
      "[92,    99] loss: 0.071892\n",
      "[92,   199] loss: 0.089581\n",
      "[92,   299] loss: 0.092101\n",
      "[93,    99] loss: 0.069662\n",
      "[93,   199] loss: 0.087528\n",
      "[93,   299] loss: 0.089656\n",
      "[94,    99] loss: 0.067827\n",
      "[94,   199] loss: 0.085541\n",
      "[94,   299] loss: 0.087413\n",
      "[95,    99] loss: 0.065818\n",
      "[95,   199] loss: 0.083696\n",
      "[95,   299] loss: 0.085109\n",
      "[96,    99] loss: 0.063873\n",
      "[96,   199] loss: 0.081378\n",
      "[96,   299] loss: 0.083146\n",
      "[97,    99] loss: 0.062125\n",
      "[97,   199] loss: 0.079713\n",
      "[97,   299] loss: 0.080898\n",
      "[98,    99] loss: 0.060428\n",
      "[98,   199] loss: 0.077679\n",
      "[98,   299] loss: 0.078925\n",
      "[99,    99] loss: 0.058685\n",
      "[99,   199] loss: 0.076118\n",
      "[99,   299] loss: 0.077133\n",
      "[100,    99] loss: 0.057026\n",
      "[100,   199] loss: 0.074280\n",
      "[100,   299] loss: 0.075149\n",
      "Finished Training\n",
      "[1,    99] loss: 0.694332\n",
      "[1,   199] loss: 0.693792\n",
      "[1,   299] loss: 0.682845\n",
      "[2,    99] loss: 0.686796\n",
      "[2,   199] loss: 0.682702\n",
      "[2,   299] loss: 0.671224\n",
      "[3,    99] loss: 0.678775\n",
      "[3,   199] loss: 0.671005\n",
      "[3,   299] loss: 0.658869\n",
      "[4,    99] loss: 0.669582\n",
      "[4,   199] loss: 0.659207\n",
      "[4,   299] loss: 0.646201\n",
      "[5,    99] loss: 0.660756\n",
      "[5,   199] loss: 0.646893\n",
      "[5,   299] loss: 0.633291\n",
      "[6,    99] loss: 0.651577\n",
      "[6,   199] loss: 0.633498\n",
      "[6,   299] loss: 0.620568\n",
      "[7,    99] loss: 0.642512\n",
      "[7,   199] loss: 0.619948\n",
      "[7,   299] loss: 0.608256\n",
      "[8,    99] loss: 0.633625\n",
      "[8,   199] loss: 0.606516\n",
      "[8,   299] loss: 0.596467\n",
      "[9,    99] loss: 0.624470\n",
      "[9,   199] loss: 0.593471\n",
      "[9,   299] loss: 0.585829\n",
      "[10,    99] loss: 0.614988\n",
      "[10,   199] loss: 0.580985\n",
      "[10,   299] loss: 0.575928\n",
      "[11,    99] loss: 0.605817\n",
      "[11,   199] loss: 0.568952\n",
      "[11,   299] loss: 0.566585\n",
      "[12,    99] loss: 0.596835\n",
      "[12,   199] loss: 0.556829\n",
      "[12,   299] loss: 0.557555\n",
      "[13,    99] loss: 0.587339\n",
      "[13,   199] loss: 0.545039\n",
      "[13,   299] loss: 0.548474\n",
      "[14,    99] loss: 0.577435\n",
      "[14,   199] loss: 0.533127\n",
      "[14,   299] loss: 0.539899\n",
      "[15,    99] loss: 0.567249\n",
      "[15,   199] loss: 0.520915\n",
      "[15,   299] loss: 0.531044\n",
      "[16,    99] loss: 0.556446\n",
      "[16,   199] loss: 0.508689\n",
      "[16,   299] loss: 0.521981\n",
      "[17,    99] loss: 0.545521\n",
      "[17,   199] loss: 0.496120\n",
      "[17,   299] loss: 0.512691\n",
      "[18,    99] loss: 0.534139\n",
      "[18,   199] loss: 0.483162\n",
      "[18,   299] loss: 0.502829\n",
      "[19,    99] loss: 0.522747\n",
      "[19,   199] loss: 0.470128\n",
      "[19,   299] loss: 0.492822\n",
      "[20,    99] loss: 0.511186\n",
      "[20,   199] loss: 0.457262\n",
      "[20,   299] loss: 0.482587\n",
      "[21,    99] loss: 0.499239\n",
      "[21,   199] loss: 0.444619\n",
      "[21,   299] loss: 0.471729\n",
      "[22,    99] loss: 0.487137\n",
      "[22,   199] loss: 0.431986\n",
      "[22,   299] loss: 0.460943\n",
      "[23,    99] loss: 0.474891\n",
      "[23,   199] loss: 0.419266\n",
      "[23,   299] loss: 0.450292\n",
      "[24,    99] loss: 0.462919\n",
      "[24,   199] loss: 0.406647\n",
      "[24,   299] loss: 0.439649\n",
      "[25,    99] loss: 0.451454\n",
      "[25,   199] loss: 0.394182\n",
      "[25,   299] loss: 0.428912\n",
      "[26,    99] loss: 0.440205\n",
      "[26,   199] loss: 0.381888\n",
      "[26,   299] loss: 0.418239\n",
      "[27,    99] loss: 0.429139\n",
      "[27,   199] loss: 0.370163\n",
      "[27,   299] loss: 0.407692\n",
      "[28,    99] loss: 0.418227\n",
      "[28,   199] loss: 0.359132\n",
      "[28,   299] loss: 0.397321\n",
      "[29,    99] loss: 0.407639\n",
      "[29,   199] loss: 0.348328\n",
      "[29,   299] loss: 0.387287\n",
      "[30,    99] loss: 0.396954\n",
      "[30,   199] loss: 0.337975\n",
      "[30,   299] loss: 0.377448\n",
      "[31,    99] loss: 0.387006\n",
      "[31,   199] loss: 0.327981\n",
      "[31,   299] loss: 0.367410\n",
      "[32,    99] loss: 0.377025\n",
      "[32,   199] loss: 0.318329\n",
      "[32,   299] loss: 0.357764\n",
      "[33,    99] loss: 0.367602\n",
      "[33,   199] loss: 0.309128\n",
      "[33,   299] loss: 0.348078\n",
      "[34,    99] loss: 0.358471\n",
      "[34,   199] loss: 0.300239\n",
      "[34,   299] loss: 0.338774\n",
      "[35,    99] loss: 0.349360\n",
      "[35,   199] loss: 0.291829\n",
      "[35,   299] loss: 0.329831\n",
      "[36,    99] loss: 0.340786\n",
      "[36,   199] loss: 0.283739\n",
      "[36,   299] loss: 0.320742\n",
      "[37,    99] loss: 0.332305\n",
      "[37,   199] loss: 0.275865\n",
      "[37,   299] loss: 0.312155\n",
      "[38,    99] loss: 0.324350\n",
      "[38,   199] loss: 0.268127\n",
      "[38,   299] loss: 0.303627\n",
      "[39,    99] loss: 0.316551\n",
      "[39,   199] loss: 0.260567\n",
      "[39,   299] loss: 0.295387\n",
      "[40,    99] loss: 0.308935\n",
      "[40,   199] loss: 0.253319\n",
      "[40,   299] loss: 0.287393\n",
      "[41,    99] loss: 0.301355\n",
      "[41,   199] loss: 0.246512\n",
      "[41,   299] loss: 0.279746\n",
      "[42,    99] loss: 0.293870\n",
      "[42,   199] loss: 0.239856\n",
      "[42,   299] loss: 0.272215\n",
      "[43,    99] loss: 0.286835\n",
      "[43,   199] loss: 0.233639\n",
      "[43,   299] loss: 0.264936\n",
      "[44,    99] loss: 0.280382\n",
      "[44,   199] loss: 0.227493\n",
      "[44,   299] loss: 0.258055\n",
      "[45,    99] loss: 0.273546\n",
      "[45,   199] loss: 0.221777\n",
      "[45,   299] loss: 0.251226\n",
      "[46,    99] loss: 0.267539\n",
      "[46,   199] loss: 0.215856\n",
      "[46,   299] loss: 0.244536\n",
      "[47,    99] loss: 0.261508\n",
      "[47,   199] loss: 0.210097\n",
      "[47,   299] loss: 0.238236\n",
      "[48,    99] loss: 0.255566\n",
      "[48,   199] loss: 0.204471\n",
      "[48,   299] loss: 0.232287\n",
      "[49,    99] loss: 0.249942\n",
      "[49,   199] loss: 0.199175\n",
      "[49,   299] loss: 0.226354\n",
      "[50,    99] loss: 0.244328\n",
      "[50,   199] loss: 0.194004\n",
      "[50,   299] loss: 0.220738\n",
      "[51,    99] loss: 0.239088\n",
      "[51,   199] loss: 0.188965\n",
      "[51,   299] loss: 0.215053\n",
      "[52,    99] loss: 0.233913\n",
      "[52,   199] loss: 0.183975\n",
      "[52,   299] loss: 0.209548\n",
      "[53,    99] loss: 0.228894\n",
      "[53,   199] loss: 0.179371\n",
      "[53,   299] loss: 0.204224\n",
      "[54,    99] loss: 0.224041\n",
      "[54,   199] loss: 0.174857\n",
      "[54,   299] loss: 0.198971\n",
      "[55,    99] loss: 0.219335\n",
      "[55,   199] loss: 0.170463\n",
      "[55,   299] loss: 0.193898\n",
      "[56,    99] loss: 0.214821\n",
      "[56,   199] loss: 0.166193\n",
      "[56,   299] loss: 0.188803\n",
      "[57,    99] loss: 0.210506\n",
      "[57,   199] loss: 0.161956\n",
      "[57,   299] loss: 0.184103\n",
      "[58,    99] loss: 0.206096\n",
      "[58,   199] loss: 0.158083\n",
      "[58,   299] loss: 0.179419\n",
      "[59,    99] loss: 0.201834\n",
      "[59,   199] loss: 0.154074\n",
      "[59,   299] loss: 0.175112\n",
      "[60,    99] loss: 0.197610\n",
      "[60,   199] loss: 0.150327\n",
      "[60,   299] loss: 0.170780\n",
      "[61,    99] loss: 0.193650\n",
      "[61,   199] loss: 0.146476\n",
      "[61,   299] loss: 0.166477\n",
      "[62,    99] loss: 0.189596\n",
      "[62,   199] loss: 0.143009\n",
      "[62,   299] loss: 0.162335\n",
      "[63,    99] loss: 0.185838\n",
      "[63,   199] loss: 0.139495\n",
      "[63,   299] loss: 0.158266\n",
      "[64,    99] loss: 0.181975\n",
      "[64,   199] loss: 0.136023\n",
      "[64,   299] loss: 0.154552\n",
      "[65,    99] loss: 0.178299\n",
      "[65,   199] loss: 0.132654\n",
      "[65,   299] loss: 0.150716\n",
      "[66,    99] loss: 0.174785\n",
      "[66,   199] loss: 0.129512\n",
      "[66,   299] loss: 0.146819\n",
      "[67,    99] loss: 0.171300\n",
      "[67,   199] loss: 0.126373\n",
      "[67,   299] loss: 0.143406\n",
      "[68,    99] loss: 0.167780\n",
      "[68,   199] loss: 0.123181\n",
      "[68,   299] loss: 0.139879\n",
      "[69,    99] loss: 0.164151\n",
      "[69,   199] loss: 0.120477\n",
      "[69,   299] loss: 0.136497\n",
      "[70,    99] loss: 0.160657\n",
      "[70,   199] loss: 0.117553\n",
      "[70,   299] loss: 0.133108\n",
      "[71,    99] loss: 0.157294\n",
      "[71,   199] loss: 0.114812\n",
      "[71,   299] loss: 0.129833\n",
      "[72,    99] loss: 0.153928\n",
      "[72,   199] loss: 0.111922\n",
      "[72,   299] loss: 0.126635\n",
      "[73,    99] loss: 0.150448\n",
      "[73,   199] loss: 0.109072\n",
      "[73,   299] loss: 0.123547\n",
      "[74,    99] loss: 0.147221\n",
      "[74,   199] loss: 0.106391\n",
      "[74,   299] loss: 0.120495\n",
      "[75,    99] loss: 0.143908\n",
      "[75,   199] loss: 0.103683\n",
      "[75,   299] loss: 0.117512\n",
      "[76,    99] loss: 0.140873\n",
      "[76,   199] loss: 0.101034\n",
      "[76,   299] loss: 0.114562\n",
      "[77,    99] loss: 0.137866\n",
      "[77,   199] loss: 0.098582\n",
      "[77,   299] loss: 0.111999\n",
      "[78,    99] loss: 0.134709\n",
      "[78,   199] loss: 0.096155\n",
      "[78,   299] loss: 0.109603\n",
      "[79,    99] loss: 0.131735\n",
      "[79,   199] loss: 0.093659\n",
      "[79,   299] loss: 0.106732\n",
      "[80,    99] loss: 0.128708\n",
      "[80,   199] loss: 0.091386\n",
      "[80,   299] loss: 0.104245\n",
      "[81,    99] loss: 0.125738\n",
      "[81,   199] loss: 0.089158\n",
      "[81,   299] loss: 0.101445\n",
      "[82,    99] loss: 0.122903\n",
      "[82,   199] loss: 0.087026\n",
      "[82,   299] loss: 0.099296\n",
      "[83,    99] loss: 0.120166\n",
      "[83,   199] loss: 0.084910\n",
      "[83,   299] loss: 0.096691\n",
      "[84,    99] loss: 0.117235\n",
      "[84,   199] loss: 0.083000\n",
      "[84,   299] loss: 0.094374\n",
      "[85,    99] loss: 0.115011\n",
      "[85,   199] loss: 0.081048\n",
      "[85,   299] loss: 0.092153\n",
      "[86,    99] loss: 0.112284\n",
      "[86,   199] loss: 0.079243\n",
      "[86,   299] loss: 0.089700\n",
      "[87,    99] loss: 0.109705\n",
      "[87,   199] loss: 0.077275\n",
      "[87,   299] loss: 0.087674\n",
      "[88,    99] loss: 0.107072\n",
      "[88,   199] loss: 0.075303\n",
      "[88,   299] loss: 0.085344\n",
      "[89,    99] loss: 0.104289\n",
      "[89,   199] loss: 0.073584\n",
      "[89,   299] loss: 0.083396\n",
      "[90,    99] loss: 0.101757\n",
      "[90,   199] loss: 0.071843\n",
      "[90,   299] loss: 0.081290\n",
      "[91,    99] loss: 0.099315\n",
      "[91,   199] loss: 0.070213\n",
      "[91,   299] loss: 0.079229\n",
      "[92,    99] loss: 0.097013\n",
      "[92,   199] loss: 0.068572\n",
      "[92,   299] loss: 0.077406\n",
      "[93,    99] loss: 0.094713\n",
      "[93,   199] loss: 0.066783\n",
      "[93,   299] loss: 0.075597\n",
      "[94,    99] loss: 0.092449\n",
      "[94,   199] loss: 0.065501\n",
      "[94,   299] loss: 0.073724\n",
      "[95,    99] loss: 0.090332\n",
      "[95,   199] loss: 0.064111\n",
      "[95,   299] loss: 0.071876\n",
      "[96,    99] loss: 0.088118\n",
      "[96,   199] loss: 0.062551\n",
      "[96,   299] loss: 0.070298\n",
      "[97,    99] loss: 0.086018\n",
      "[97,   199] loss: 0.061199\n",
      "[97,   299] loss: 0.068504\n",
      "[98,    99] loss: 0.084054\n",
      "[98,   199] loss: 0.059962\n",
      "[98,   299] loss: 0.067000\n",
      "[99,    99] loss: 0.081698\n",
      "[99,   199] loss: 0.058548\n",
      "[99,   299] loss: 0.065291\n",
      "[100,    99] loss: 0.079973\n",
      "[100,   199] loss: 0.056999\n",
      "[100,   299] loss: 0.063921\n",
      "Finished Training\n",
      "[1,    99] loss: 0.692474\n",
      "[1,   199] loss: 0.695668\n",
      "[1,   299] loss: 0.685908\n",
      "[2,    99] loss: 0.677663\n",
      "[2,   199] loss: 0.685894\n",
      "[2,   299] loss: 0.676663\n",
      "[3,    99] loss: 0.664790\n",
      "[3,   199] loss: 0.675914\n",
      "[3,   299] loss: 0.668511\n",
      "[4,    99] loss: 0.652294\n",
      "[4,   199] loss: 0.665206\n",
      "[4,   299] loss: 0.659306\n",
      "[5,    99] loss: 0.638608\n",
      "[5,   199] loss: 0.653475\n",
      "[5,   299] loss: 0.649780\n",
      "[6,    99] loss: 0.624979\n",
      "[6,   199] loss: 0.641014\n",
      "[6,   299] loss: 0.639106\n",
      "[7,    99] loss: 0.611000\n",
      "[7,   199] loss: 0.627786\n",
      "[7,   299] loss: 0.627721\n",
      "[8,    99] loss: 0.596760\n",
      "[8,   199] loss: 0.614555\n",
      "[8,   299] loss: 0.615855\n",
      "[9,    99] loss: 0.582697\n",
      "[9,   199] loss: 0.601007\n",
      "[9,   299] loss: 0.603586\n",
      "[10,    99] loss: 0.568585\n",
      "[10,   199] loss: 0.587178\n",
      "[10,   299] loss: 0.590922\n",
      "[11,    99] loss: 0.554288\n",
      "[11,   199] loss: 0.572938\n",
      "[11,   299] loss: 0.578057\n",
      "[12,    99] loss: 0.540121\n",
      "[12,   199] loss: 0.558685\n",
      "[12,   299] loss: 0.565006\n",
      "[13,    99] loss: 0.526586\n",
      "[13,   199] loss: 0.544543\n",
      "[13,   299] loss: 0.552192\n",
      "[14,    99] loss: 0.513249\n",
      "[14,   199] loss: 0.530321\n",
      "[14,   299] loss: 0.539497\n",
      "[15,    99] loss: 0.500276\n",
      "[15,   199] loss: 0.515749\n",
      "[15,   299] loss: 0.526597\n",
      "[16,    99] loss: 0.487757\n",
      "[16,   199] loss: 0.501246\n",
      "[16,   299] loss: 0.513603\n",
      "[17,    99] loss: 0.475183\n",
      "[17,   199] loss: 0.486700\n",
      "[17,   299] loss: 0.500606\n",
      "[18,    99] loss: 0.462946\n",
      "[18,   199] loss: 0.472375\n",
      "[18,   299] loss: 0.487606\n",
      "[19,    99] loss: 0.451027\n",
      "[19,   199] loss: 0.458064\n",
      "[19,   299] loss: 0.474605\n",
      "[20,    99] loss: 0.439301\n",
      "[20,   199] loss: 0.443909\n",
      "[20,   299] loss: 0.461141\n",
      "[21,    99] loss: 0.427578\n",
      "[21,   199] loss: 0.429913\n",
      "[21,   299] loss: 0.447566\n",
      "[22,    99] loss: 0.415904\n",
      "[22,   199] loss: 0.415961\n",
      "[22,   299] loss: 0.434113\n",
      "[23,    99] loss: 0.404631\n",
      "[23,   199] loss: 0.402154\n",
      "[23,   299] loss: 0.421079\n",
      "[24,    99] loss: 0.393558\n",
      "[24,   199] loss: 0.388560\n",
      "[24,   299] loss: 0.408506\n",
      "[25,    99] loss: 0.382800\n",
      "[25,   199] loss: 0.375466\n",
      "[25,   299] loss: 0.396161\n",
      "[26,    99] loss: 0.372312\n",
      "[26,   199] loss: 0.362635\n",
      "[26,   299] loss: 0.384158\n",
      "[27,    99] loss: 0.362202\n",
      "[27,   199] loss: 0.350546\n",
      "[27,   299] loss: 0.372435\n",
      "[28,    99] loss: 0.352337\n",
      "[28,   199] loss: 0.338834\n",
      "[28,   299] loss: 0.361066\n",
      "[29,    99] loss: 0.342768\n",
      "[29,   199] loss: 0.327635\n",
      "[29,   299] loss: 0.350205\n",
      "[30,    99] loss: 0.333387\n",
      "[30,   199] loss: 0.316740\n",
      "[30,   299] loss: 0.339620\n",
      "[31,    99] loss: 0.324151\n",
      "[31,   199] loss: 0.306299\n",
      "[31,   299] loss: 0.329208\n",
      "[32,    99] loss: 0.315110\n",
      "[32,   199] loss: 0.295953\n",
      "[32,   299] loss: 0.319178\n",
      "[33,    99] loss: 0.306083\n",
      "[33,   199] loss: 0.285851\n",
      "[33,   299] loss: 0.309540\n",
      "[34,    99] loss: 0.297586\n",
      "[34,   199] loss: 0.276142\n",
      "[34,   299] loss: 0.299634\n",
      "[35,    99] loss: 0.289128\n",
      "[35,   199] loss: 0.266738\n",
      "[35,   299] loss: 0.290236\n",
      "[36,    99] loss: 0.280874\n",
      "[36,   199] loss: 0.257633\n",
      "[36,   299] loss: 0.281226\n",
      "[37,    99] loss: 0.272866\n",
      "[37,   199] loss: 0.248645\n",
      "[37,   299] loss: 0.272208\n",
      "[38,    99] loss: 0.264874\n",
      "[38,   199] loss: 0.240303\n",
      "[38,   299] loss: 0.263456\n",
      "[39,    99] loss: 0.257741\n",
      "[39,   199] loss: 0.231988\n",
      "[39,   299] loss: 0.255267\n",
      "[40,    99] loss: 0.250441\n",
      "[40,   199] loss: 0.224480\n",
      "[40,   299] loss: 0.247283\n",
      "[41,    99] loss: 0.243492\n",
      "[41,   199] loss: 0.217134\n",
      "[41,   299] loss: 0.239682\n",
      "[42,    99] loss: 0.236840\n",
      "[42,   199] loss: 0.210320\n",
      "[42,   299] loss: 0.232590\n",
      "[43,    99] loss: 0.230393\n",
      "[43,   199] loss: 0.203667\n",
      "[43,   299] loss: 0.225863\n",
      "[44,    99] loss: 0.223902\n",
      "[44,   199] loss: 0.197545\n",
      "[44,   299] loss: 0.219462\n",
      "[45,    99] loss: 0.217874\n",
      "[45,   199] loss: 0.191581\n",
      "[45,   299] loss: 0.213262\n",
      "[46,    99] loss: 0.211969\n",
      "[46,   199] loss: 0.185509\n",
      "[46,   299] loss: 0.207646\n",
      "[47,    99] loss: 0.206390\n",
      "[47,   199] loss: 0.180063\n",
      "[47,   299] loss: 0.201860\n",
      "[48,    99] loss: 0.200748\n",
      "[48,   199] loss: 0.174611\n",
      "[48,   299] loss: 0.196405\n",
      "[49,    99] loss: 0.195604\n",
      "[49,   199] loss: 0.169157\n",
      "[49,   299] loss: 0.191054\n",
      "[50,    99] loss: 0.190482\n",
      "[50,   199] loss: 0.164139\n",
      "[50,   299] loss: 0.185909\n",
      "[51,    99] loss: 0.185604\n",
      "[51,   199] loss: 0.158926\n",
      "[51,   299] loss: 0.181133\n",
      "[52,    99] loss: 0.180833\n",
      "[52,   199] loss: 0.154000\n",
      "[52,   299] loss: 0.176326\n",
      "[53,    99] loss: 0.176171\n",
      "[53,   199] loss: 0.149319\n",
      "[53,   299] loss: 0.171814\n",
      "[54,    99] loss: 0.171713\n",
      "[54,   199] loss: 0.144729\n",
      "[54,   299] loss: 0.167381\n",
      "[55,    99] loss: 0.167484\n",
      "[55,   199] loss: 0.140065\n",
      "[55,   299] loss: 0.163327\n",
      "[56,    99] loss: 0.163216\n",
      "[56,   199] loss: 0.135881\n",
      "[56,   299] loss: 0.159295\n",
      "[57,    99] loss: 0.159164\n",
      "[57,   199] loss: 0.131529\n",
      "[57,   299] loss: 0.155458\n",
      "[58,    99] loss: 0.155332\n",
      "[58,   199] loss: 0.127335\n",
      "[58,   299] loss: 0.151835\n",
      "[59,    99] loss: 0.151287\n",
      "[59,   199] loss: 0.123507\n",
      "[59,   299] loss: 0.148203\n",
      "[60,    99] loss: 0.147358\n",
      "[60,   199] loss: 0.119598\n",
      "[60,   299] loss: 0.144552\n",
      "[61,    99] loss: 0.143812\n",
      "[61,   199] loss: 0.115778\n",
      "[61,   299] loss: 0.141198\n",
      "[62,    99] loss: 0.139941\n",
      "[62,   199] loss: 0.112177\n",
      "[62,   299] loss: 0.137589\n",
      "[63,    99] loss: 0.136522\n",
      "[63,   199] loss: 0.108614\n",
      "[63,   299] loss: 0.134421\n",
      "[64,    99] loss: 0.132667\n",
      "[64,   199] loss: 0.105296\n",
      "[64,   299] loss: 0.131097\n",
      "[65,    99] loss: 0.129259\n",
      "[65,   199] loss: 0.102011\n",
      "[65,   299] loss: 0.128065\n",
      "[66,    99] loss: 0.125722\n",
      "[66,   199] loss: 0.098858\n",
      "[66,   299] loss: 0.124927\n",
      "[67,    99] loss: 0.122426\n",
      "[67,   199] loss: 0.095737\n",
      "[67,   299] loss: 0.122073\n",
      "[68,    99] loss: 0.118864\n",
      "[68,   199] loss: 0.092846\n",
      "[68,   299] loss: 0.119259\n",
      "[69,    99] loss: 0.115802\n",
      "[69,   199] loss: 0.089954\n",
      "[69,   299] loss: 0.116655\n",
      "[70,    99] loss: 0.112401\n",
      "[70,   199] loss: 0.087222\n",
      "[70,   299] loss: 0.113999\n",
      "[71,    99] loss: 0.109496\n",
      "[71,   199] loss: 0.084453\n",
      "[71,   299] loss: 0.111459\n",
      "[72,    99] loss: 0.106176\n",
      "[72,   199] loss: 0.081851\n",
      "[72,   299] loss: 0.108804\n",
      "[73,    99] loss: 0.103243\n",
      "[73,   199] loss: 0.079385\n",
      "[73,   299] loss: 0.106413\n",
      "[74,    99] loss: 0.099730\n",
      "[74,   199] loss: 0.077134\n",
      "[74,   299] loss: 0.103848\n",
      "[75,    99] loss: 0.096865\n",
      "[75,   199] loss: 0.074810\n",
      "[75,   299] loss: 0.101367\n",
      "[76,    99] loss: 0.094420\n",
      "[76,   199] loss: 0.072526\n",
      "[76,   299] loss: 0.099057\n",
      "[77,    99] loss: 0.091124\n",
      "[77,   199] loss: 0.070483\n",
      "[77,   299] loss: 0.096713\n",
      "[78,    99] loss: 0.088558\n",
      "[78,   199] loss: 0.068451\n",
      "[78,   299] loss: 0.094351\n",
      "[79,    99] loss: 0.086142\n",
      "[79,   199] loss: 0.066388\n",
      "[79,   299] loss: 0.092423\n",
      "[80,    99] loss: 0.083479\n",
      "[80,   199] loss: 0.064613\n",
      "[80,   299] loss: 0.090232\n",
      "[81,    99] loss: 0.080636\n",
      "[81,   199] loss: 0.062801\n",
      "[81,   299] loss: 0.088231\n",
      "[82,    99] loss: 0.078560\n",
      "[82,   199] loss: 0.061037\n",
      "[82,   299] loss: 0.086359\n",
      "[83,    99] loss: 0.075863\n",
      "[83,   199] loss: 0.059237\n",
      "[83,   299] loss: 0.084512\n",
      "[84,    99] loss: 0.073515\n",
      "[84,   199] loss: 0.057703\n",
      "[84,   299] loss: 0.082736\n",
      "[85,    99] loss: 0.071248\n",
      "[85,   199] loss: 0.056005\n",
      "[85,   299] loss: 0.080779\n",
      "[86,    99] loss: 0.069274\n",
      "[86,   199] loss: 0.054553\n",
      "[86,   299] loss: 0.078919\n",
      "[87,    99] loss: 0.067256\n",
      "[87,   199] loss: 0.053080\n",
      "[87,   299] loss: 0.077382\n",
      "[88,    99] loss: 0.064650\n",
      "[88,   199] loss: 0.051584\n",
      "[88,   299] loss: 0.075612\n",
      "[89,    99] loss: 0.063120\n",
      "[89,   199] loss: 0.050291\n",
      "[89,   299] loss: 0.073906\n",
      "[90,    99] loss: 0.061225\n",
      "[90,   199] loss: 0.048851\n",
      "[90,   299] loss: 0.072334\n",
      "[91,    99] loss: 0.059303\n",
      "[91,   199] loss: 0.047785\n",
      "[91,   299] loss: 0.070731\n",
      "[92,    99] loss: 0.057614\n",
      "[92,   199] loss: 0.046448\n",
      "[92,   299] loss: 0.069320\n",
      "[93,    99] loss: 0.055524\n",
      "[93,   199] loss: 0.045383\n",
      "[93,   299] loss: 0.067584\n",
      "[94,    99] loss: 0.054253\n",
      "[94,   199] loss: 0.044081\n",
      "[94,   299] loss: 0.066285\n",
      "[95,    99] loss: 0.052311\n",
      "[95,   199] loss: 0.043031\n",
      "[95,   299] loss: 0.064786\n",
      "[96,    99] loss: 0.050845\n",
      "[96,   199] loss: 0.042071\n",
      "[96,   299] loss: 0.063105\n",
      "[97,    99] loss: 0.049388\n",
      "[97,   199] loss: 0.040940\n",
      "[97,   299] loss: 0.061932\n",
      "[98,    99] loss: 0.048026\n",
      "[98,   199] loss: 0.040019\n",
      "[98,   299] loss: 0.060580\n",
      "[99,    99] loss: 0.046188\n",
      "[99,   199] loss: 0.039047\n",
      "[99,   299] loss: 0.059049\n",
      "[100,    99] loss: 0.045301\n",
      "[100,   199] loss: 0.038186\n",
      "[100,   299] loss: 0.057684\n",
      "Finished Training\n",
      "[1,    99] loss: 0.700400\n",
      "[1,   199] loss: 0.693916\n",
      "[1,   299] loss: 0.692253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    99] loss: 0.685658\n",
      "[2,   199] loss: 0.682793\n",
      "[2,   299] loss: 0.681241\n",
      "[3,    99] loss: 0.674108\n",
      "[3,   199] loss: 0.672607\n",
      "[3,   299] loss: 0.669850\n",
      "[4,    99] loss: 0.660882\n",
      "[4,   199] loss: 0.660756\n",
      "[4,   299] loss: 0.655233\n",
      "[5,    99] loss: 0.646529\n",
      "[5,   199] loss: 0.646764\n",
      "[5,   299] loss: 0.637564\n",
      "[6,    99] loss: 0.632698\n",
      "[6,   199] loss: 0.633347\n",
      "[6,   299] loss: 0.620409\n",
      "[7,    99] loss: 0.620645\n",
      "[7,   199] loss: 0.621766\n",
      "[7,   299] loss: 0.604666\n",
      "[8,    99] loss: 0.610244\n",
      "[8,   199] loss: 0.611465\n",
      "[8,   299] loss: 0.590493\n",
      "[9,    99] loss: 0.600985\n",
      "[9,   199] loss: 0.602215\n",
      "[9,   299] loss: 0.577291\n",
      "[10,    99] loss: 0.592059\n",
      "[10,   199] loss: 0.593452\n",
      "[10,   299] loss: 0.565029\n",
      "[11,    99] loss: 0.583269\n",
      "[11,   199] loss: 0.585153\n",
      "[11,   299] loss: 0.553319\n",
      "[12,    99] loss: 0.574367\n",
      "[12,   199] loss: 0.577161\n",
      "[12,   299] loss: 0.541799\n",
      "[13,    99] loss: 0.565520\n",
      "[13,   199] loss: 0.568916\n",
      "[13,   299] loss: 0.530578\n",
      "[14,    99] loss: 0.556138\n",
      "[14,   199] loss: 0.560599\n",
      "[14,   299] loss: 0.519397\n",
      "[15,    99] loss: 0.546364\n",
      "[15,   199] loss: 0.552478\n",
      "[15,   299] loss: 0.508203\n",
      "[16,    99] loss: 0.536607\n",
      "[16,   199] loss: 0.544170\n",
      "[16,   299] loss: 0.497443\n",
      "[17,    99] loss: 0.526772\n",
      "[17,   199] loss: 0.535956\n",
      "[17,   299] loss: 0.486927\n",
      "[18,    99] loss: 0.516813\n",
      "[18,   199] loss: 0.527775\n",
      "[18,   299] loss: 0.476296\n",
      "[19,    99] loss: 0.506743\n",
      "[19,   199] loss: 0.519579\n",
      "[19,   299] loss: 0.465746\n",
      "[20,    99] loss: 0.496475\n",
      "[20,   199] loss: 0.511269\n",
      "[20,   299] loss: 0.455013\n",
      "[21,    99] loss: 0.486070\n",
      "[21,   199] loss: 0.502929\n",
      "[21,   299] loss: 0.444310\n",
      "[22,    99] loss: 0.475641\n",
      "[22,   199] loss: 0.494510\n",
      "[22,   299] loss: 0.433931\n",
      "[23,    99] loss: 0.465185\n",
      "[23,   199] loss: 0.486134\n",
      "[23,   299] loss: 0.423526\n",
      "[24,    99] loss: 0.454665\n",
      "[24,   199] loss: 0.477859\n",
      "[24,   299] loss: 0.413204\n",
      "[25,    99] loss: 0.444465\n",
      "[25,   199] loss: 0.469691\n",
      "[25,   299] loss: 0.403122\n",
      "[26,    99] loss: 0.433893\n",
      "[26,   199] loss: 0.461489\n",
      "[26,   299] loss: 0.393267\n",
      "[27,    99] loss: 0.423607\n",
      "[27,   199] loss: 0.453245\n",
      "[27,   299] loss: 0.383574\n",
      "[28,    99] loss: 0.413424\n",
      "[28,   199] loss: 0.445315\n",
      "[28,   299] loss: 0.374063\n",
      "[29,    99] loss: 0.403339\n",
      "[29,   199] loss: 0.437478\n",
      "[29,   299] loss: 0.364682\n",
      "[30,    99] loss: 0.393163\n",
      "[30,   199] loss: 0.429739\n",
      "[30,   299] loss: 0.355663\n",
      "[31,    99] loss: 0.383320\n",
      "[31,   199] loss: 0.421864\n",
      "[31,   299] loss: 0.346795\n",
      "[32,    99] loss: 0.373675\n",
      "[32,   199] loss: 0.413993\n",
      "[32,   299] loss: 0.338246\n",
      "[33,    99] loss: 0.364191\n",
      "[33,   199] loss: 0.406172\n",
      "[33,   299] loss: 0.329724\n",
      "[34,    99] loss: 0.355082\n",
      "[34,   199] loss: 0.398720\n",
      "[34,   299] loss: 0.321385\n",
      "[35,    99] loss: 0.345945\n",
      "[35,   199] loss: 0.390997\n",
      "[35,   299] loss: 0.313563\n",
      "[36,    99] loss: 0.336986\n",
      "[36,   199] loss: 0.383690\n",
      "[36,   299] loss: 0.305923\n",
      "[37,    99] loss: 0.328175\n",
      "[37,   199] loss: 0.376556\n",
      "[37,   299] loss: 0.298608\n",
      "[38,    99] loss: 0.319640\n",
      "[38,   199] loss: 0.369206\n",
      "[38,   299] loss: 0.291263\n",
      "[39,    99] loss: 0.311536\n",
      "[39,   199] loss: 0.362357\n",
      "[39,   299] loss: 0.284102\n",
      "[40,    99] loss: 0.303596\n",
      "[40,   199] loss: 0.355570\n",
      "[40,   299] loss: 0.277024\n",
      "[41,    99] loss: 0.295969\n",
      "[41,   199] loss: 0.349159\n",
      "[41,   299] loss: 0.270435\n",
      "[42,    99] loss: 0.288296\n",
      "[42,   199] loss: 0.342374\n",
      "[42,   299] loss: 0.263920\n",
      "[43,    99] loss: 0.280866\n",
      "[43,   199] loss: 0.336163\n",
      "[43,   299] loss: 0.257676\n",
      "[44,    99] loss: 0.273692\n",
      "[44,   199] loss: 0.330052\n",
      "[44,   299] loss: 0.251665\n",
      "[45,    99] loss: 0.266377\n",
      "[45,   199] loss: 0.323840\n",
      "[45,   299] loss: 0.245916\n",
      "[46,    99] loss: 0.259756\n",
      "[46,   199] loss: 0.317398\n",
      "[46,   299] loss: 0.240553\n",
      "[47,    99] loss: 0.252925\n",
      "[47,   199] loss: 0.311651\n",
      "[47,   299] loss: 0.235079\n",
      "[48,    99] loss: 0.246527\n",
      "[48,   199] loss: 0.306062\n",
      "[48,   299] loss: 0.229596\n",
      "[49,    99] loss: 0.240306\n",
      "[49,   199] loss: 0.300335\n",
      "[49,   299] loss: 0.224484\n",
      "[50,    99] loss: 0.234453\n",
      "[50,   199] loss: 0.294889\n",
      "[50,   299] loss: 0.219454\n",
      "[51,    99] loss: 0.228528\n",
      "[51,   199] loss: 0.289602\n",
      "[51,   299] loss: 0.214596\n",
      "[52,    99] loss: 0.222919\n",
      "[52,   199] loss: 0.284359\n",
      "[52,   299] loss: 0.209799\n",
      "[53,    99] loss: 0.217304\n",
      "[53,   199] loss: 0.279397\n",
      "[53,   299] loss: 0.205084\n",
      "[54,    99] loss: 0.211994\n",
      "[54,   199] loss: 0.274349\n",
      "[54,   299] loss: 0.200703\n",
      "[55,    99] loss: 0.206874\n",
      "[55,   199] loss: 0.269392\n",
      "[55,   299] loss: 0.196278\n",
      "[56,    99] loss: 0.201986\n",
      "[56,   199] loss: 0.264397\n",
      "[56,   299] loss: 0.192166\n",
      "[57,    99] loss: 0.196976\n",
      "[57,   199] loss: 0.259477\n",
      "[57,   299] loss: 0.188321\n",
      "[58,    99] loss: 0.192147\n",
      "[58,   199] loss: 0.254352\n",
      "[58,   299] loss: 0.184290\n",
      "[59,    99] loss: 0.187665\n",
      "[59,   199] loss: 0.249600\n",
      "[59,   299] loss: 0.180535\n",
      "[60,    99] loss: 0.183194\n",
      "[60,   199] loss: 0.245118\n",
      "[60,   299] loss: 0.176968\n",
      "[61,    99] loss: 0.178795\n",
      "[61,   199] loss: 0.240492\n",
      "[61,   299] loss: 0.173256\n",
      "[62,    99] loss: 0.174470\n",
      "[62,   199] loss: 0.236264\n",
      "[62,   299] loss: 0.169814\n",
      "[63,    99] loss: 0.170477\n",
      "[63,   199] loss: 0.232122\n",
      "[63,   299] loss: 0.166132\n",
      "[64,    99] loss: 0.166498\n",
      "[64,   199] loss: 0.228631\n",
      "[64,   299] loss: 0.162967\n",
      "[65,    99] loss: 0.162787\n",
      "[65,   199] loss: 0.224488\n",
      "[65,   299] loss: 0.159506\n",
      "[66,    99] loss: 0.158931\n",
      "[66,   199] loss: 0.220682\n",
      "[66,   299] loss: 0.156616\n",
      "[67,    99] loss: 0.155191\n",
      "[67,   199] loss: 0.216856\n",
      "[67,   299] loss: 0.153147\n",
      "[68,    99] loss: 0.151724\n",
      "[68,   199] loss: 0.213278\n",
      "[68,   299] loss: 0.150457\n",
      "[69,    99] loss: 0.148299\n",
      "[69,   199] loss: 0.209070\n",
      "[69,   299] loss: 0.146877\n",
      "[70,    99] loss: 0.144871\n",
      "[70,   199] loss: 0.205957\n",
      "[70,   299] loss: 0.144352\n",
      "[71,    99] loss: 0.141667\n",
      "[71,   199] loss: 0.202077\n",
      "[71,   299] loss: 0.141274\n",
      "[72,    99] loss: 0.138213\n",
      "[72,   199] loss: 0.198512\n",
      "[72,   299] loss: 0.139067\n",
      "[73,    99] loss: 0.134932\n",
      "[73,   199] loss: 0.194632\n",
      "[73,   299] loss: 0.135898\n",
      "[74,    99] loss: 0.131841\n",
      "[74,   199] loss: 0.191074\n",
      "[74,   299] loss: 0.133243\n",
      "[75,    99] loss: 0.128335\n",
      "[75,   199] loss: 0.187334\n",
      "[75,   299] loss: 0.130241\n",
      "[76,    99] loss: 0.125277\n",
      "[76,   199] loss: 0.184551\n",
      "[76,   299] loss: 0.127205\n",
      "[77,    99] loss: 0.122185\n",
      "[77,   199] loss: 0.180627\n",
      "[77,   299] loss: 0.125093\n",
      "[78,    99] loss: 0.119048\n",
      "[78,   199] loss: 0.177463\n",
      "[78,   299] loss: 0.122198\n",
      "[79,    99] loss: 0.116024\n",
      "[79,   199] loss: 0.174337\n",
      "[79,   299] loss: 0.120317\n",
      "[80,    99] loss: 0.113308\n",
      "[80,   199] loss: 0.170585\n",
      "[80,   299] loss: 0.117366\n",
      "[81,    99] loss: 0.110531\n",
      "[81,   199] loss: 0.167350\n",
      "[81,   299] loss: 0.115381\n",
      "[82,    99] loss: 0.108143\n",
      "[82,   199] loss: 0.164388\n",
      "[82,   299] loss: 0.112892\n",
      "[83,    99] loss: 0.105644\n",
      "[83,   199] loss: 0.161665\n",
      "[83,   299] loss: 0.110868\n",
      "[84,    99] loss: 0.103417\n",
      "[84,   199] loss: 0.157896\n",
      "[84,   299] loss: 0.108906\n",
      "[85,    99] loss: 0.101083\n",
      "[85,   199] loss: 0.155181\n",
      "[85,   299] loss: 0.106844\n",
      "[86,    99] loss: 0.099408\n",
      "[86,   199] loss: 0.151789\n",
      "[86,   299] loss: 0.104457\n",
      "[87,    99] loss: 0.096877\n",
      "[87,   199] loss: 0.149223\n",
      "[87,   299] loss: 0.102841\n",
      "[88,    99] loss: 0.094965\n",
      "[88,   199] loss: 0.146203\n",
      "[88,   299] loss: 0.100598\n",
      "[89,    99] loss: 0.093038\n",
      "[89,   199] loss: 0.143467\n",
      "[89,   299] loss: 0.099151\n",
      "[90,    99] loss: 0.091106\n",
      "[90,   199] loss: 0.141292\n",
      "[90,   299] loss: 0.096446\n",
      "[91,    99] loss: 0.089077\n",
      "[91,   199] loss: 0.138508\n",
      "[91,   299] loss: 0.094654\n",
      "[92,    99] loss: 0.087503\n",
      "[92,   199] loss: 0.135430\n",
      "[92,   299] loss: 0.092797\n",
      "[93,    99] loss: 0.085502\n",
      "[93,   199] loss: 0.132822\n",
      "[93,   299] loss: 0.091137\n",
      "[94,    99] loss: 0.083854\n",
      "[94,   199] loss: 0.131255\n",
      "[94,   299] loss: 0.088906\n",
      "[95,    99] loss: 0.082341\n",
      "[95,   199] loss: 0.127790\n",
      "[95,   299] loss: 0.087103\n",
      "[96,    99] loss: 0.080649\n",
      "[96,   199] loss: 0.125543\n",
      "[96,   299] loss: 0.084921\n",
      "[97,    99] loss: 0.079303\n",
      "[97,   199] loss: 0.124010\n",
      "[97,   299] loss: 0.083469\n",
      "[98,    99] loss: 0.078013\n",
      "[98,   199] loss: 0.121252\n",
      "[98,   299] loss: 0.081677\n",
      "[99,    99] loss: 0.076122\n",
      "[99,   199] loss: 0.118844\n",
      "[99,   299] loss: 0.080661\n",
      "[100,    99] loss: 0.075107\n",
      "[100,   199] loss: 0.116693\n",
      "[100,   299] loss: 0.078279\n",
      "Finished Training\n",
      "[1,    99] loss: 1.038625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    99] loss: 0.717914\n",
      "[3,    99] loss: 0.703195\n",
      "[4,    99] loss: 0.703225\n",
      "[5,    99] loss: 0.703269\n",
      "[6,    99] loss: 0.703296\n",
      "[7,    99] loss: 0.703313\n",
      "[8,    99] loss: 0.703325\n",
      "[9,    99] loss: 0.703334\n",
      "[10,    99] loss: 0.703341\n",
      "[11,    99] loss: 0.703346\n",
      "[12,    99] loss: 0.703350\n",
      "[13,    99] loss: 0.703353\n",
      "[14,    99] loss: 0.703355\n",
      "[15,    99] loss: 0.703357\n",
      "[16,    99] loss: 0.703358\n",
      "[17,    99] loss: 0.703360\n",
      "[18,    99] loss: 0.703361\n",
      "[19,    99] loss: 0.703362\n",
      "[20,    99] loss: 0.703362\n",
      "[21,    99] loss: 0.703363\n",
      "[22,    99] loss: 0.703363\n",
      "[23,    99] loss: 0.703364\n",
      "[24,    99] loss: 0.703364\n",
      "[25,    99] loss: 0.703364\n",
      "[26,    99] loss: 0.703364\n",
      "[27,    99] loss: 0.703365\n",
      "[28,    99] loss: 0.703365\n",
      "[29,    99] loss: 0.703365\n",
      "[30,    99] loss: 0.703365\n",
      "[31,    99] loss: 0.703365\n",
      "[32,    99] loss: 0.703365\n",
      "[33,    99] loss: 0.703365\n",
      "[34,    99] loss: 0.703365\n",
      "[35,    99] loss: 0.703365\n",
      "[36,    99] loss: 0.703365\n",
      "[37,    99] loss: 0.703365\n",
      "[38,    99] loss: 0.703365\n",
      "[39,    99] loss: 0.703365\n",
      "[40,    99] loss: 0.703365\n",
      "[41,    99] loss: 0.703365\n",
      "[42,    99] loss: 0.703365\n",
      "[43,    99] loss: 0.703365\n",
      "[44,    99] loss: 0.703365\n",
      "[45,    99] loss: 0.703365\n",
      "[46,    99] loss: 0.703365\n",
      "[47,    99] loss: 0.703365\n",
      "[48,    99] loss: 0.703365\n",
      "[49,    99] loss: 0.703365\n",
      "[50,    99] loss: 0.703365\n",
      "[51,    99] loss: 0.703365\n",
      "[52,    99] loss: 0.703365\n",
      "[53,    99] loss: 0.703365\n",
      "[54,    99] loss: 0.703365\n",
      "[55,    99] loss: 0.703365\n",
      "[56,    99] loss: 0.703365\n",
      "[57,    99] loss: 0.703365\n",
      "[58,    99] loss: 0.703365\n",
      "[59,    99] loss: 0.703365\n",
      "[60,    99] loss: 0.703365\n",
      "[61,    99] loss: 0.703365\n",
      "[62,    99] loss: 0.703365\n",
      "[63,    99] loss: 0.703365\n",
      "[64,    99] loss: 0.703365\n",
      "[65,    99] loss: 0.703365\n",
      "[66,    99] loss: 0.703365\n",
      "[67,    99] loss: 0.703365\n",
      "[68,    99] loss: 0.703365\n",
      "[69,    99] loss: 0.703365\n",
      "[70,    99] loss: 0.703365\n",
      "[71,    99] loss: 0.703365\n",
      "[72,    99] loss: 0.703365\n",
      "[73,    99] loss: 0.703365\n",
      "[74,    99] loss: 0.703365\n",
      "[75,    99] loss: 0.703365\n",
      "[76,    99] loss: 0.703365\n",
      "[77,    99] loss: 0.703365\n",
      "[78,    99] loss: 0.703365\n",
      "[79,    99] loss: 0.703365\n",
      "[80,    99] loss: 0.703365\n",
      "[81,    99] loss: 0.703365\n",
      "[82,    99] loss: 0.703365\n",
      "[83,    99] loss: 0.703365\n",
      "[84,    99] loss: 0.703365\n",
      "[85,    99] loss: 0.703365\n",
      "[86,    99] loss: 0.703365\n",
      "[87,    99] loss: 0.703365\n",
      "[88,    99] loss: 0.703365\n",
      "[89,    99] loss: 0.703365\n",
      "[90,    99] loss: 0.703365\n",
      "[91,    99] loss: 0.703365\n",
      "[92,    99] loss: 0.703365\n",
      "[93,    99] loss: 0.703365\n",
      "[94,    99] loss: 0.703365\n",
      "[95,    99] loss: 0.703365\n",
      "[96,    99] loss: 0.703365\n",
      "[97,    99] loss: 0.703365\n",
      "[98,    99] loss: 0.703365\n",
      "[99,    99] loss: 0.703365\n",
      "[100,    99] loss: 0.703365\n",
      "Finished Training\n",
      "[1,    99] loss: 0.908225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    99] loss: 0.690400\n",
      "[3,    99] loss: 0.688104\n",
      "[4,    99] loss: 0.688143\n",
      "[5,    99] loss: 0.688164\n",
      "[6,    99] loss: 0.688177\n",
      "[7,    99] loss: 0.688186\n",
      "[8,    99] loss: 0.688192\n",
      "[9,    99] loss: 0.688197\n",
      "[10,    99] loss: 0.688200\n",
      "[11,    99] loss: 0.688203\n",
      "[12,    99] loss: 0.688205\n",
      "[13,    99] loss: 0.688206\n",
      "[14,    99] loss: 0.688208\n",
      "[15,    99] loss: 0.688209\n",
      "[16,    99] loss: 0.688209\n",
      "[17,    99] loss: 0.688210\n",
      "[18,    99] loss: 0.688211\n",
      "[19,    99] loss: 0.688211\n",
      "[20,    99] loss: 0.688211\n",
      "[21,    99] loss: 0.688212\n",
      "[22,    99] loss: 0.688212\n",
      "[23,    99] loss: 0.688212\n",
      "[24,    99] loss: 0.688212\n",
      "[25,    99] loss: 0.688212\n",
      "[26,    99] loss: 0.688213\n",
      "[27,    99] loss: 0.688213\n",
      "[28,    99] loss: 0.688213\n",
      "[29,    99] loss: 0.688213\n",
      "[30,    99] loss: 0.688213\n",
      "[31,    99] loss: 0.688213\n",
      "[32,    99] loss: 0.688213\n",
      "[33,    99] loss: 0.688213\n",
      "[34,    99] loss: 0.688213\n",
      "[35,    99] loss: 0.688213\n",
      "[36,    99] loss: 0.688213\n",
      "[37,    99] loss: 0.688213\n",
      "[38,    99] loss: 0.688213\n",
      "[39,    99] loss: 0.688213\n",
      "[40,    99] loss: 0.688213\n",
      "[41,    99] loss: 0.688213\n",
      "[42,    99] loss: 0.688213\n",
      "[43,    99] loss: 0.688213\n",
      "[44,    99] loss: 0.688213\n",
      "[45,    99] loss: 0.688213\n",
      "[46,    99] loss: 0.688213\n",
      "[47,    99] loss: 0.688213\n",
      "[48,    99] loss: 0.688213\n",
      "[49,    99] loss: 0.688213\n",
      "[50,    99] loss: 0.688213\n",
      "[51,    99] loss: 0.688213\n",
      "[52,    99] loss: 0.688213\n",
      "[53,    99] loss: 0.688213\n",
      "[54,    99] loss: 0.688213\n",
      "[55,    99] loss: 0.688213\n",
      "[56,    99] loss: 0.688213\n",
      "[57,    99] loss: 0.688213\n",
      "[58,    99] loss: 0.688213\n",
      "[59,    99] loss: 0.688213\n",
      "[60,    99] loss: 0.688213\n",
      "[61,    99] loss: 0.688213\n",
      "[62,    99] loss: 0.688213\n",
      "[63,    99] loss: 0.688213\n",
      "[64,    99] loss: 0.688213\n",
      "[65,    99] loss: 0.688213\n",
      "[66,    99] loss: 0.688213\n",
      "[67,    99] loss: 0.688213\n",
      "[68,    99] loss: 0.688213\n",
      "[69,    99] loss: 0.688213\n",
      "[70,    99] loss: 0.688213\n",
      "[71,    99] loss: 0.688213\n",
      "[72,    99] loss: 0.688213\n",
      "[73,    99] loss: 0.688213\n",
      "[74,    99] loss: 0.688213\n",
      "[75,    99] loss: 0.688213\n",
      "[76,    99] loss: 0.688213\n",
      "[77,    99] loss: 0.688213\n",
      "[78,    99] loss: 0.688213\n",
      "[79,    99] loss: 0.688213\n",
      "[80,    99] loss: 0.688213\n",
      "[81,    99] loss: 0.688213\n",
      "[82,    99] loss: 0.688213\n",
      "[83,    99] loss: 0.688213\n",
      "[84,    99] loss: 0.688213\n",
      "[85,    99] loss: 0.688213\n",
      "[86,    99] loss: 0.688213\n",
      "[87,    99] loss: 0.688213\n",
      "[88,    99] loss: 0.688213\n",
      "[89,    99] loss: 0.688213\n",
      "[90,    99] loss: 0.688213\n",
      "[91,    99] loss: 0.688213\n",
      "[92,    99] loss: 0.688213\n",
      "[93,    99] loss: 0.688213\n",
      "[94,    99] loss: 0.688213\n",
      "[95,    99] loss: 0.688213\n",
      "[96,    99] loss: 0.688213\n",
      "[97,    99] loss: 0.688213\n",
      "[98,    99] loss: 0.688213\n",
      "[99,    99] loss: 0.688213\n",
      "[100,    99] loss: 0.688213\n",
      "Finished Training\n",
      "[1,    99] loss: 1.303269\n",
      "[2,    99] loss: 0.745201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,    99] loss: 0.698345\n",
      "[4,    99] loss: 0.698455\n",
      "[5,    99] loss: 0.698512\n",
      "[6,    99] loss: 0.698546\n",
      "[7,    99] loss: 0.698568\n",
      "[8,    99] loss: 0.698584\n",
      "[9,    99] loss: 0.698595\n",
      "[10,    99] loss: 0.698603\n",
      "[11,    99] loss: 0.698609\n",
      "[12,    99] loss: 0.698614\n",
      "[13,    99] loss: 0.698618\n",
      "[14,    99] loss: 0.698621\n",
      "[15,    99] loss: 0.698623\n",
      "[16,    99] loss: 0.698625\n",
      "[17,    99] loss: 0.698627\n",
      "[18,    99] loss: 0.698628\n",
      "[19,    99] loss: 0.698629\n",
      "[20,    99] loss: 0.698630\n",
      "[21,    99] loss: 0.698630\n",
      "[22,    99] loss: 0.698631\n",
      "[23,    99] loss: 0.698631\n",
      "[24,    99] loss: 0.698632\n",
      "[25,    99] loss: 0.698632\n",
      "[26,    99] loss: 0.698632\n",
      "[27,    99] loss: 0.698632\n",
      "[28,    99] loss: 0.698632\n",
      "[29,    99] loss: 0.698633\n",
      "[30,    99] loss: 0.698633\n",
      "[31,    99] loss: 0.698633\n",
      "[32,    99] loss: 0.698633\n",
      "[33,    99] loss: 0.698633\n",
      "[34,    99] loss: 0.698633\n",
      "[35,    99] loss: 0.698633\n",
      "[36,    99] loss: 0.698633\n",
      "[37,    99] loss: 0.698633\n",
      "[38,    99] loss: 0.698633\n",
      "[39,    99] loss: 0.698633\n",
      "[40,    99] loss: 0.698633\n",
      "[41,    99] loss: 0.698633\n",
      "[42,    99] loss: 0.698633\n",
      "[43,    99] loss: 0.698633\n",
      "[44,    99] loss: 0.698633\n",
      "[45,    99] loss: 0.698633\n",
      "[46,    99] loss: 0.698633\n",
      "[47,    99] loss: 0.698633\n",
      "[48,    99] loss: 0.698633\n",
      "[49,    99] loss: 0.698633\n",
      "[50,    99] loss: 0.698633\n",
      "[51,    99] loss: 0.698633\n",
      "[52,    99] loss: 0.698633\n",
      "[53,    99] loss: 0.698633\n",
      "[54,    99] loss: 0.698633\n",
      "[55,    99] loss: 0.698633\n",
      "[56,    99] loss: 0.698633\n",
      "[57,    99] loss: 0.698633\n",
      "[58,    99] loss: 0.698633\n",
      "[59,    99] loss: 0.698633\n",
      "[60,    99] loss: 0.698633\n",
      "[61,    99] loss: 0.698633\n",
      "[62,    99] loss: 0.698633\n",
      "[63,    99] loss: 0.698633\n",
      "[64,    99] loss: 0.698633\n",
      "[65,    99] loss: 0.698633\n",
      "[66,    99] loss: 0.698633\n",
      "[67,    99] loss: 0.698633\n",
      "[68,    99] loss: 0.698633\n",
      "[69,    99] loss: 0.698633\n",
      "[70,    99] loss: 0.698633\n",
      "[71,    99] loss: 0.698633\n",
      "[72,    99] loss: 0.698633\n",
      "[73,    99] loss: 0.698633\n",
      "[74,    99] loss: 0.698633\n",
      "[75,    99] loss: 0.698633\n",
      "[76,    99] loss: 0.698633\n",
      "[77,    99] loss: 0.698633\n",
      "[78,    99] loss: 0.698633\n",
      "[79,    99] loss: 0.698633\n",
      "[80,    99] loss: 0.698633\n",
      "[81,    99] loss: 0.698633\n",
      "[82,    99] loss: 0.698633\n",
      "[83,    99] loss: 0.698633\n",
      "[84,    99] loss: 0.698633\n",
      "[85,    99] loss: 0.698633\n",
      "[86,    99] loss: 0.698633\n",
      "[87,    99] loss: 0.698633\n",
      "[88,    99] loss: 0.698633\n",
      "[89,    99] loss: 0.698633\n",
      "[90,    99] loss: 0.698633\n",
      "[91,    99] loss: 0.698633\n",
      "[92,    99] loss: 0.698633\n",
      "[93,    99] loss: 0.698633\n",
      "[94,    99] loss: 0.698633\n",
      "[95,    99] loss: 0.698633\n",
      "[96,    99] loss: 0.698633\n",
      "[97,    99] loss: 0.698633\n",
      "[98,    99] loss: 0.698633\n",
      "[99,    99] loss: 0.698633\n",
      "[100,    99] loss: 0.698633\n",
      "Finished Training\n",
      "[1,    99] loss: 1.246966\n",
      "[2,    99] loss: 0.703664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,    99] loss: 0.699371\n",
      "[4,    99] loss: 0.699467\n",
      "[5,    99] loss: 0.699518\n",
      "[6,    99] loss: 0.699549\n",
      "[7,    99] loss: 0.699570\n",
      "[8,    99] loss: 0.699585\n",
      "[9,    99] loss: 0.699595\n",
      "[10,    99] loss: 0.699603\n",
      "[11,    99] loss: 0.699609\n",
      "[12,    99] loss: 0.699614\n",
      "[13,    99] loss: 0.699617\n",
      "[14,    99] loss: 0.699620\n",
      "[15,    99] loss: 0.699622\n",
      "[16,    99] loss: 0.699624\n",
      "[17,    99] loss: 0.699626\n",
      "[18,    99] loss: 0.699627\n",
      "[19,    99] loss: 0.699628\n",
      "[20,    99] loss: 0.699629\n",
      "[21,    99] loss: 0.699629\n",
      "[22,    99] loss: 0.699630\n",
      "[23,    99] loss: 0.699630\n",
      "[24,    99] loss: 0.699631\n",
      "[25,    99] loss: 0.699631\n",
      "[26,    99] loss: 0.699631\n",
      "[27,    99] loss: 0.699631\n",
      "[28,    99] loss: 0.699632\n",
      "[29,    99] loss: 0.699632\n",
      "[30,    99] loss: 0.699632\n",
      "[31,    99] loss: 0.699632\n",
      "[32,    99] loss: 0.699632\n",
      "[33,    99] loss: 0.699632\n",
      "[34,    99] loss: 0.699632\n",
      "[35,    99] loss: 0.699632\n",
      "[36,    99] loss: 0.699632\n",
      "[37,    99] loss: 0.699632\n",
      "[38,    99] loss: 0.699632\n",
      "[39,    99] loss: 0.699632\n",
      "[40,    99] loss: 0.699632\n",
      "[41,    99] loss: 0.699632\n",
      "[42,    99] loss: 0.699632\n",
      "[43,    99] loss: 0.699632\n",
      "[44,    99] loss: 0.699632\n",
      "[45,    99] loss: 0.699632\n",
      "[46,    99] loss: 0.699632\n",
      "[47,    99] loss: 0.699632\n",
      "[48,    99] loss: 0.699632\n",
      "[49,    99] loss: 0.699632\n",
      "[50,    99] loss: 0.699632\n",
      "[51,    99] loss: 0.699632\n",
      "[52,    99] loss: 0.699632\n",
      "[53,    99] loss: 0.699632\n",
      "[54,    99] loss: 0.699632\n",
      "[55,    99] loss: 0.699632\n",
      "[56,    99] loss: 0.699632\n",
      "[57,    99] loss: 0.699632\n",
      "[58,    99] loss: 0.699632\n",
      "[59,    99] loss: 0.699632\n",
      "[60,    99] loss: 0.699632\n",
      "[61,    99] loss: 0.699632\n",
      "[62,    99] loss: 0.699632\n",
      "[63,    99] loss: 0.699632\n",
      "[64,    99] loss: 0.699632\n",
      "[65,    99] loss: 0.699632\n",
      "[66,    99] loss: 0.699632\n",
      "[67,    99] loss: 0.699632\n",
      "[68,    99] loss: 0.699632\n",
      "[69,    99] loss: 0.699632\n",
      "[70,    99] loss: 0.699632\n",
      "[71,    99] loss: 0.699632\n",
      "[72,    99] loss: 0.699632\n",
      "[73,    99] loss: 0.699632\n",
      "[74,    99] loss: 0.699632\n",
      "[75,    99] loss: 0.699632\n",
      "[76,    99] loss: 0.699632\n",
      "[77,    99] loss: 0.699632\n",
      "[78,    99] loss: 0.699632\n",
      "[79,    99] loss: 0.699632\n",
      "[80,    99] loss: 0.699632\n",
      "[81,    99] loss: 0.699632\n",
      "[82,    99] loss: 0.699632\n",
      "[83,    99] loss: 0.699632\n",
      "[84,    99] loss: 0.699632\n",
      "[85,    99] loss: 0.699632\n",
      "[86,    99] loss: 0.699632\n",
      "[87,    99] loss: 0.699632\n",
      "[88,    99] loss: 0.699632\n",
      "[89,    99] loss: 0.699632\n",
      "[90,    99] loss: 0.699632\n",
      "[91,    99] loss: 0.699632\n",
      "[92,    99] loss: 0.699632\n",
      "[93,    99] loss: 0.699632\n",
      "[94,    99] loss: 0.699632\n",
      "[95,    99] loss: 0.699632\n",
      "[96,    99] loss: 0.699632\n",
      "[97,    99] loss: 0.699632\n",
      "[98,    99] loss: 0.699632\n",
      "[99,    99] loss: 0.699632\n",
      "[100,    99] loss: 0.699632\n",
      "Finished Training\n",
      "[1,    99] loss: 1.268655\n",
      "[2,    99] loss: 0.998305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,    99] loss: 0.706384\n",
      "[4,    99] loss: 0.706392\n",
      "[5,    99] loss: 0.706418\n",
      "[6,    99] loss: 0.706433\n",
      "[7,    99] loss: 0.706444\n",
      "[8,    99] loss: 0.706450\n",
      "[9,    99] loss: 0.706455\n",
      "[10,    99] loss: 0.706459\n",
      "[11,    99] loss: 0.706462\n",
      "[12,    99] loss: 0.706464\n",
      "[13,    99] loss: 0.706466\n",
      "[14,    99] loss: 0.706467\n",
      "[15,    99] loss: 0.706468\n",
      "[16,    99] loss: 0.706469\n",
      "[17,    99] loss: 0.706470\n",
      "[18,    99] loss: 0.706470\n",
      "[19,    99] loss: 0.706471\n",
      "[20,    99] loss: 0.706471\n",
      "[21,    99] loss: 0.706472\n",
      "[22,    99] loss: 0.706472\n",
      "[23,    99] loss: 0.706472\n",
      "[24,    99] loss: 0.706472\n",
      "[25,    99] loss: 0.706472\n",
      "[26,    99] loss: 0.706473\n",
      "[27,    99] loss: 0.706473\n",
      "[28,    99] loss: 0.706473\n",
      "[29,    99] loss: 0.706473\n",
      "[30,    99] loss: 0.706473\n",
      "[31,    99] loss: 0.706473\n",
      "[32,    99] loss: 0.706473\n",
      "[33,    99] loss: 0.706473\n",
      "[34,    99] loss: 0.706473\n",
      "[35,    99] loss: 0.706473\n",
      "[36,    99] loss: 0.706473\n",
      "[37,    99] loss: 0.706473\n",
      "[38,    99] loss: 0.706473\n",
      "[39,    99] loss: 0.706473\n",
      "[40,    99] loss: 0.706473\n",
      "[41,    99] loss: 0.706473\n",
      "[42,    99] loss: 0.706473\n",
      "[43,    99] loss: 0.706473\n",
      "[44,    99] loss: 0.706473\n",
      "[45,    99] loss: 0.706473\n",
      "[46,    99] loss: 0.706473\n",
      "[47,    99] loss: 0.706473\n",
      "[48,    99] loss: 0.706473\n",
      "[49,    99] loss: 0.706473\n",
      "[50,    99] loss: 0.706473\n",
      "[51,    99] loss: 0.706473\n",
      "[52,    99] loss: 0.706473\n",
      "[53,    99] loss: 0.706473\n",
      "[54,    99] loss: 0.706473\n",
      "[55,    99] loss: 0.706473\n",
      "[56,    99] loss: 0.706473\n",
      "[57,    99] loss: 0.706473\n",
      "[58,    99] loss: 0.706473\n",
      "[59,    99] loss: 0.706473\n",
      "[60,    99] loss: 0.706473\n",
      "[61,    99] loss: 0.706473\n",
      "[62,    99] loss: 0.706473\n",
      "[63,    99] loss: 0.706473\n",
      "[64,    99] loss: 0.706473\n",
      "[65,    99] loss: 0.706473\n",
      "[66,    99] loss: 0.706473\n",
      "[67,    99] loss: 0.706473\n",
      "[68,    99] loss: 0.706473\n",
      "[69,    99] loss: 0.706473\n",
      "[70,    99] loss: 0.706473\n",
      "[71,    99] loss: 0.706473\n",
      "[72,    99] loss: 0.706473\n",
      "[73,    99] loss: 0.706473\n",
      "[74,    99] loss: 0.706473\n",
      "[75,    99] loss: 0.706473\n",
      "[76,    99] loss: 0.706473\n",
      "[77,    99] loss: 0.706473\n",
      "[78,    99] loss: 0.706473\n",
      "[79,    99] loss: 0.706473\n",
      "[80,    99] loss: 0.706473\n",
      "[81,    99] loss: 0.706473\n",
      "[82,    99] loss: 0.706473\n",
      "[83,    99] loss: 0.706473\n",
      "[84,    99] loss: 0.706473\n",
      "[85,    99] loss: 0.706473\n",
      "[86,    99] loss: 0.706473\n",
      "[87,    99] loss: 0.706473\n",
      "[88,    99] loss: 0.706473\n",
      "[89,    99] loss: 0.706473\n",
      "[90,    99] loss: 0.706473\n",
      "[91,    99] loss: 0.706473\n",
      "[92,    99] loss: 0.706473\n",
      "[93,    99] loss: 0.706473\n",
      "[94,    99] loss: 0.706473\n",
      "[95,    99] loss: 0.706473\n",
      "[96,    99] loss: 0.706473\n",
      "[97,    99] loss: 0.706473\n",
      "[98,    99] loss: 0.706473\n",
      "[99,    99] loss: 0.706473\n",
      "[100,    99] loss: 0.706473\n",
      "Finished Training\n",
      "[1,    99] loss: 0.683920\n",
      "[2,    99] loss: 0.589168\n",
      "[3,    99] loss: 0.545509\n",
      "[4,    99] loss: 0.506838\n",
      "[5,    99] loss: 0.444740\n",
      "[6,    99] loss: 0.454992\n",
      "[7,    99] loss: 0.400817\n",
      "[8,    99] loss: 0.380003\n",
      "[9,    99] loss: 0.358277\n",
      "[10,    99] loss: 0.301488\n",
      "[11,    99] loss: 0.276210\n",
      "[12,    99] loss: 0.344733\n",
      "[13,    99] loss: 0.282345\n",
      "[14,    99] loss: 0.300806\n",
      "[15,    99] loss: 0.244116\n",
      "[16,    99] loss: 0.228543\n",
      "[17,    99] loss: 0.259859\n",
      "[18,    99] loss: 0.211072\n",
      "[19,    99] loss: 0.270847\n",
      "[20,    99] loss: 0.242780\n",
      "[21,    99] loss: 0.190553\n",
      "[22,    99] loss: 0.225213\n",
      "[23,    99] loss: 0.154771\n",
      "[24,    99] loss: 0.149947\n",
      "[25,    99] loss: 0.147241\n",
      "[26,    99] loss: 0.165658\n",
      "[27,    99] loss: 0.154627\n",
      "[28,    99] loss: 0.165232\n",
      "[29,    99] loss: 0.178792\n",
      "[30,    99] loss: 0.128630\n",
      "[31,    99] loss: 0.177843\n",
      "[32,    99] loss: 0.230921\n",
      "[33,    99] loss: 0.138934\n",
      "[34,    99] loss: 0.122678\n",
      "[35,    99] loss: 0.109196\n",
      "[36,    99] loss: 0.119086\n",
      "[37,    99] loss: 0.143125\n",
      "[38,    99] loss: 0.063789\n",
      "[39,    99] loss: 0.066752\n",
      "[40,    99] loss: 0.097636\n",
      "[41,    99] loss: 0.187488\n",
      "[42,    99] loss: 0.110873\n",
      "[43,    99] loss: 0.103998\n",
      "[44,    99] loss: 0.091347\n",
      "[45,    99] loss: 0.078713\n",
      "[46,    99] loss: 0.049265\n",
      "[47,    99] loss: 0.039942\n",
      "[48,    99] loss: 0.042704\n",
      "[49,    99] loss: 0.119951\n",
      "[50,    99] loss: 0.108374\n",
      "[51,    99] loss: 0.101733\n",
      "[52,    99] loss: 0.117105\n",
      "[53,    99] loss: 0.095385\n",
      "[54,    99] loss: 0.135629\n",
      "[55,    99] loss: 0.057592\n",
      "[56,    99] loss: 0.036590\n",
      "[57,    99] loss: 0.027115\n",
      "[58,    99] loss: 0.032760\n",
      "[59,    99] loss: 0.197578\n",
      "[60,    99] loss: 0.077769\n",
      "[61,    99] loss: 0.037184\n",
      "[62,    99] loss: 0.390973\n",
      "[63,    99] loss: 0.174588\n",
      "[64,    99] loss: 0.077107\n",
      "[65,    99] loss: 0.044874\n",
      "[66,    99] loss: 0.050778\n",
      "[67,    99] loss: 0.036920\n",
      "[68,    99] loss: 0.023307\n",
      "[69,    99] loss: 0.019928\n",
      "[70,    99] loss: 0.062391\n",
      "[71,    99] loss: 0.043683\n",
      "[72,    99] loss: 0.073671\n",
      "[73,    99] loss: 0.158071\n",
      "[74,    99] loss: 0.117804\n",
      "[75,    99] loss: 0.029260\n",
      "[76,    99] loss: 0.046011\n",
      "[77,    99] loss: 0.032773\n",
      "[78,    99] loss: 0.012662\n",
      "[79,    99] loss: 0.006239\n",
      "[80,    99] loss: 0.003494\n",
      "[81,    99] loss: 0.002375\n",
      "[82,    99] loss: 0.001968\n",
      "[83,    99] loss: 0.001593\n",
      "[84,    99] loss: 0.001245\n",
      "[85,    99] loss: 0.001042\n",
      "[86,    99] loss: 0.000858\n",
      "[87,    99] loss: 0.000734\n",
      "[88,    99] loss: 0.000612\n",
      "[89,    99] loss: 0.000429\n",
      "[90,    99] loss: 0.000281\n",
      "[91,    99] loss: 0.000249\n",
      "[92,    99] loss: 0.000217\n",
      "[93,    99] loss: 0.000181\n",
      "[94,    99] loss: 0.000165\n",
      "[95,    99] loss: 0.000143\n",
      "[96,    99] loss: 0.000127\n",
      "[97,    99] loss: 0.249290\n",
      "[98,    99] loss: 0.387072\n",
      "[99,    99] loss: 0.119167\n",
      "[100,    99] loss: 0.056993\n",
      "Finished Training\n",
      "[1,    99] loss: 0.684321\n",
      "[2,    99] loss: 0.622557\n",
      "[3,    99] loss: 0.568513\n",
      "[4,    99] loss: 0.524900\n",
      "[5,    99] loss: 0.479497\n",
      "[6,    99] loss: 0.414677\n",
      "[7,    99] loss: 0.403849\n",
      "[8,    99] loss: 0.388726\n",
      "[9,    99] loss: 0.367879\n",
      "[10,    99] loss: 0.389815\n",
      "[11,    99] loss: 0.332594\n",
      "[12,    99] loss: 0.279861\n",
      "[13,    99] loss: 0.326402\n",
      "[14,    99] loss: 0.248675\n",
      "[15,    99] loss: 0.286173\n",
      "[16,    99] loss: 0.281681\n",
      "[17,    99] loss: 0.228178\n",
      "[18,    99] loss: 0.249696\n",
      "[19,    99] loss: 0.223421\n",
      "[20,    99] loss: 0.187229\n",
      "[21,    99] loss: 0.180163\n",
      "[22,    99] loss: 0.170402\n",
      "[23,    99] loss: 0.181887\n",
      "[24,    99] loss: 0.163280\n",
      "[25,    99] loss: 0.165293\n",
      "[26,    99] loss: 0.181115\n",
      "[27,    99] loss: 0.138469\n",
      "[28,    99] loss: 0.129603\n",
      "[29,    99] loss: 0.150399\n",
      "[30,    99] loss: 0.188173\n",
      "[31,    99] loss: 0.095627\n",
      "[32,    99] loss: 0.079092\n",
      "[33,    99] loss: 0.091080\n",
      "[34,    99] loss: 0.111670\n",
      "[35,    99] loss: 0.113067\n",
      "[36,    99] loss: 0.141914\n",
      "[37,    99] loss: 0.259686\n",
      "[38,    99] loss: 0.103814\n",
      "[39,    99] loss: 0.101182\n",
      "[40,    99] loss: 0.122431\n",
      "[41,    99] loss: 0.137122\n",
      "[42,    99] loss: 0.084638\n",
      "[43,    99] loss: 0.072763\n",
      "[44,    99] loss: 0.075295\n",
      "[45,    99] loss: 0.067443\n",
      "[46,    99] loss: 0.063591\n",
      "[47,    99] loss: 0.091803\n",
      "[48,    99] loss: 0.057023\n",
      "[49,    99] loss: 0.105752\n",
      "[50,    99] loss: 0.051476\n",
      "[51,    99] loss: 0.089214\n",
      "[52,    99] loss: 0.058354\n",
      "[53,    99] loss: 0.099887\n",
      "[54,    99] loss: 0.236674\n",
      "[55,    99] loss: 0.114991\n",
      "[56,    99] loss: 0.104741\n",
      "[57,    99] loss: 0.110380\n",
      "[58,    99] loss: 0.080310\n",
      "[59,    99] loss: 0.065404\n",
      "[60,    99] loss: 0.051554\n",
      "[61,    99] loss: 0.077665\n",
      "[62,    99] loss: 0.119291\n",
      "[63,    99] loss: 0.113858\n",
      "[64,    99] loss: 0.024901\n",
      "[65,    99] loss: 0.018536\n",
      "[66,    99] loss: 0.015745\n",
      "[67,    99] loss: 0.089062\n",
      "[68,    99] loss: 0.154985\n",
      "[69,    99] loss: 0.086726\n",
      "[70,    99] loss: 0.049945\n",
      "[71,    99] loss: 0.032364\n",
      "[72,    99] loss: 0.019831\n",
      "[73,    99] loss: 0.074934\n",
      "[74,    99] loss: 0.051456\n",
      "[75,    99] loss: 0.042855\n",
      "[76,    99] loss: 0.081896\n",
      "[77,    99] loss: 0.044986\n",
      "[78,    99] loss: 0.062807\n",
      "[79,    99] loss: 0.111493\n",
      "[80,    99] loss: 0.108013\n",
      "[81,    99] loss: 0.043686\n",
      "[82,    99] loss: 0.057290\n",
      "[83,    99] loss: 0.100769\n",
      "[84,    99] loss: 0.166708\n",
      "[85,    99] loss: 0.036705\n",
      "[86,    99] loss: 0.030682\n",
      "[87,    99] loss: 0.028841\n",
      "[88,    99] loss: 0.028972\n",
      "[89,    99] loss: 0.082862\n",
      "[90,    99] loss: 0.084848\n",
      "[91,    99] loss: 0.137987\n",
      "[92,    99] loss: 0.109453\n",
      "[93,    99] loss: 0.023889\n",
      "[94,    99] loss: 0.015373\n",
      "[95,    99] loss: 0.024565\n",
      "[96,    99] loss: 0.025170\n",
      "[97,    99] loss: 0.047810\n",
      "[98,    99] loss: 0.121166\n",
      "[99,    99] loss: 0.146363\n",
      "[100,    99] loss: 0.151679\n",
      "Finished Training\n",
      "[1,    99] loss: 0.683934\n",
      "[2,    99] loss: 0.613751\n",
      "[3,    99] loss: 0.562167\n",
      "[4,    99] loss: 0.479259\n",
      "[5,    99] loss: 0.466372\n",
      "[6,    99] loss: 0.406333\n",
      "[7,    99] loss: 0.399964\n",
      "[8,    99] loss: 0.364992\n",
      "[9,    99] loss: 0.352047\n",
      "[10,    99] loss: 0.365614\n",
      "[11,    99] loss: 0.325980\n",
      "[12,    99] loss: 0.297525\n",
      "[13,    99] loss: 0.329311\n",
      "[14,    99] loss: 0.304419\n",
      "[15,    99] loss: 0.245417\n",
      "[16,    99] loss: 0.297991\n",
      "[17,    99] loss: 0.283672\n",
      "[18,    99] loss: 0.239482\n",
      "[19,    99] loss: 0.227034\n",
      "[20,    99] loss: 0.171766\n",
      "[21,    99] loss: 0.184451\n",
      "[22,    99] loss: 0.158924\n",
      "[23,    99] loss: 0.192050\n",
      "[24,    99] loss: 0.128553\n",
      "[25,    99] loss: 0.213623\n",
      "[26,    99] loss: 0.136042\n",
      "[27,    99] loss: 0.188021\n",
      "[28,    99] loss: 0.118428\n",
      "[29,    99] loss: 0.110253\n",
      "[30,    99] loss: 0.176224\n",
      "[31,    99] loss: 0.165589\n",
      "[32,    99] loss: 0.074743\n",
      "[33,    99] loss: 0.050057\n",
      "[34,    99] loss: 0.074009\n",
      "[35,    99] loss: 0.063320\n",
      "[36,    99] loss: 0.110983\n",
      "[37,    99] loss: 0.107743\n",
      "[38,    99] loss: 0.058052\n",
      "[39,    99] loss: 0.051169\n",
      "[40,    99] loss: 0.096736\n",
      "[41,    99] loss: 0.122215\n",
      "[42,    99] loss: 0.123488\n",
      "[43,    99] loss: 0.056515\n",
      "[44,    99] loss: 0.044689\n",
      "[45,    99] loss: 0.051113\n",
      "[46,    99] loss: 0.027368\n",
      "[47,    99] loss: 0.209397\n",
      "[48,    99] loss: 0.048932\n",
      "[49,    99] loss: 0.027908\n",
      "[50,    99] loss: 0.075905\n",
      "[51,    99] loss: 0.105084\n",
      "[52,    99] loss: 0.132824\n",
      "[53,    99] loss: 0.047493\n",
      "[54,    99] loss: 0.113181\n",
      "[55,    99] loss: 0.134656\n",
      "[56,    99] loss: 0.060954\n",
      "[57,    99] loss: 0.052650\n",
      "[58,    99] loss: 0.072550\n",
      "[59,    99] loss: 0.066383\n",
      "[60,    99] loss: 0.104030\n",
      "[61,    99] loss: 0.060975\n",
      "[62,    99] loss: 0.024731\n",
      "[63,    99] loss: 0.032321\n",
      "[64,    99] loss: 0.035386\n",
      "[65,    99] loss: 0.098401\n",
      "[66,    99] loss: 0.074490\n",
      "[67,    99] loss: 0.066834\n",
      "[68,    99] loss: 0.029618\n",
      "[69,    99] loss: 0.033369\n",
      "[70,    99] loss: 0.015615\n",
      "[71,    99] loss: 0.071437\n",
      "[72,    99] loss: 0.033426\n",
      "[73,    99] loss: 0.071067\n",
      "[74,    99] loss: 0.137505\n",
      "[75,    99] loss: 0.107862\n",
      "[76,    99] loss: 0.096260\n",
      "[77,    99] loss: 0.144830\n",
      "[78,    99] loss: 0.061366\n",
      "[79,    99] loss: 0.041449\n",
      "[80,    99] loss: 0.046359\n",
      "[81,    99] loss: 0.018481\n",
      "[82,    99] loss: 0.052775\n",
      "[83,    99] loss: 0.033624\n",
      "[84,    99] loss: 0.015237\n",
      "[85,    99] loss: 0.018777\n",
      "[86,    99] loss: 0.034701\n",
      "[87,    99] loss: 0.028971\n",
      "[88,    99] loss: 0.109868\n",
      "[89,    99] loss: 0.103028\n",
      "[90,    99] loss: 0.057348\n",
      "[91,    99] loss: 0.044078\n",
      "[92,    99] loss: 0.026387\n",
      "[93,    99] loss: 0.012833\n",
      "[94,    99] loss: 0.022073\n",
      "[95,    99] loss: 0.029859\n",
      "[96,    99] loss: 0.023279\n",
      "[97,    99] loss: 0.020769\n",
      "[98,    99] loss: 0.019389\n",
      "[99,    99] loss: 0.019604\n",
      "[100,    99] loss: 0.016714\n",
      "Finished Training\n",
      "[1,    99] loss: 0.699750\n",
      "[2,    99] loss: 0.586538\n",
      "[3,    99] loss: 0.472140\n",
      "[4,    99] loss: 0.391663\n",
      "[5,    99] loss: 0.360972\n",
      "[6,    99] loss: 0.287089\n",
      "[7,    99] loss: 0.297789\n",
      "[8,    99] loss: 0.252208\n",
      "[9,    99] loss: 0.225055\n",
      "[10,    99] loss: 0.194889\n",
      "[11,    99] loss: 0.186128\n",
      "[12,    99] loss: 0.177136\n",
      "[13,    99] loss: 0.201102\n",
      "[14,    99] loss: 0.191096\n",
      "[15,    99] loss: 0.197621\n",
      "[16,    99] loss: 0.194105\n",
      "[17,    99] loss: 0.172219\n",
      "[18,    99] loss: 0.115688\n",
      "[19,    99] loss: 0.110118\n",
      "[20,    99] loss: 0.176429\n",
      "[21,    99] loss: 0.125362\n",
      "[22,    99] loss: 0.138407\n",
      "[23,    99] loss: 0.109348\n",
      "[24,    99] loss: 0.088354\n",
      "[25,    99] loss: 0.168210\n",
      "[26,    99] loss: 0.105779\n",
      "[27,    99] loss: 0.071178\n",
      "[28,    99] loss: 0.114760\n",
      "[29,    99] loss: 0.069758\n",
      "[30,    99] loss: 0.079597\n",
      "[31,    99] loss: 0.107363\n",
      "[32,    99] loss: 0.126574\n",
      "[33,    99] loss: 0.130009\n",
      "[34,    99] loss: 0.096560\n",
      "[35,    99] loss: 0.083012\n",
      "[36,    99] loss: 0.113490\n",
      "[37,    99] loss: 0.065995\n",
      "[38,    99] loss: 0.053916\n",
      "[39,    99] loss: 0.060931\n",
      "[40,    99] loss: 0.082294\n",
      "[41,    99] loss: 0.131255\n",
      "[42,    99] loss: 0.074595\n",
      "[43,    99] loss: 0.085041\n",
      "[44,    99] loss: 0.053166\n",
      "[45,    99] loss: 0.088697\n",
      "[46,    99] loss: 0.084930\n",
      "[47,    99] loss: 0.041520\n",
      "[48,    99] loss: 0.055607\n",
      "[49,    99] loss: 0.031703\n",
      "[50,    99] loss: 0.106027\n",
      "[51,    99] loss: 0.080696\n",
      "[52,    99] loss: 0.095988\n",
      "[53,    99] loss: 0.050954\n",
      "[54,    99] loss: 0.052381\n",
      "[55,    99] loss: 0.046363\n",
      "[56,    99] loss: 0.085849\n",
      "[57,    99] loss: 0.071614\n",
      "[58,    99] loss: 0.063337\n",
      "[59,    99] loss: 0.037721\n",
      "[60,    99] loss: 0.142007\n",
      "[61,    99] loss: 0.044642\n",
      "[62,    99] loss: 0.035956\n",
      "[63,    99] loss: 0.018137\n",
      "[64,    99] loss: 0.043882\n",
      "[65,    99] loss: 0.049607\n",
      "[66,    99] loss: 0.104469\n",
      "[67,    99] loss: 0.181127\n",
      "[68,    99] loss: 0.057344\n",
      "[69,    99] loss: 0.052478\n",
      "[70,    99] loss: 0.012962\n",
      "[71,    99] loss: 0.006804\n",
      "[72,    99] loss: 0.004463\n",
      "[73,    99] loss: 0.045303\n",
      "[74,    99] loss: 0.060496\n",
      "[75,    99] loss: 0.116651\n",
      "[76,    99] loss: 0.048536\n",
      "[77,    99] loss: 0.027015\n",
      "[78,    99] loss: 0.016630\n",
      "[79,    99] loss: 0.005602\n",
      "[80,    99] loss: 0.005621\n",
      "[81,    99] loss: 0.032204\n",
      "[82,    99] loss: 0.047773\n",
      "[83,    99] loss: 0.306362\n",
      "[84,    99] loss: 0.188989\n",
      "[85,    99] loss: 0.085095\n",
      "[86,    99] loss: 0.027064\n",
      "[87,    99] loss: 0.018229\n",
      "[88,    99] loss: 0.010153\n",
      "[89,    99] loss: 0.005985\n",
      "[90,    99] loss: 0.010043\n",
      "[91,    99] loss: 0.019375\n",
      "[92,    99] loss: 0.002950\n",
      "[93,    99] loss: 0.002567\n",
      "[94,    99] loss: 0.002827\n",
      "[95,    99] loss: 0.083599\n",
      "[96,    99] loss: 0.155280\n",
      "[97,    99] loss: 0.315134\n",
      "[98,    99] loss: 0.071773\n",
      "[99,    99] loss: 0.017523\n",
      "[100,    99] loss: 0.012236\n",
      "Finished Training\n",
      "[1,    99] loss: 0.685000\n",
      "[2,    99] loss: 0.610373\n",
      "[3,    99] loss: 0.574889\n",
      "[4,    99] loss: 0.551885\n",
      "[5,    99] loss: 0.521119\n",
      "[6,    99] loss: 0.465719\n",
      "[7,    99] loss: 0.411252\n",
      "[8,    99] loss: 0.470528\n",
      "[9,    99] loss: 0.367036\n",
      "[10,    99] loss: 0.355766\n",
      "[11,    99] loss: 0.330810\n",
      "[12,    99] loss: 0.262825\n",
      "[13,    99] loss: 0.257009\n",
      "[14,    99] loss: 0.312208\n",
      "[15,    99] loss: 0.314128\n",
      "[16,    99] loss: 0.238260\n",
      "[17,    99] loss: 0.231377\n",
      "[18,    99] loss: 0.183715\n",
      "[19,    99] loss: 0.210413\n",
      "[20,    99] loss: 0.270972\n",
      "[21,    99] loss: 0.131413\n",
      "[22,    99] loss: 0.119362\n",
      "[23,    99] loss: 0.162449\n",
      "[24,    99] loss: 0.185671\n",
      "[25,    99] loss: 0.106038\n",
      "[26,    99] loss: 0.122200\n",
      "[27,    99] loss: 0.169247\n",
      "[28,    99] loss: 0.210222\n",
      "[29,    99] loss: 0.097696\n",
      "[30,    99] loss: 0.104417\n",
      "[31,    99] loss: 0.151051\n",
      "[32,    99] loss: 0.120681\n",
      "[33,    99] loss: 0.137247\n",
      "[34,    99] loss: 0.145571\n",
      "[35,    99] loss: 0.090319\n",
      "[36,    99] loss: 0.112973\n",
      "[37,    99] loss: 0.138414\n",
      "[38,    99] loss: 0.086799\n",
      "[39,    99] loss: 0.140303\n",
      "[40,    99] loss: 0.049685\n",
      "[41,    99] loss: 0.115966\n",
      "[42,    99] loss: 0.092755\n",
      "[43,    99] loss: 0.062241\n",
      "[44,    99] loss: 0.161951\n",
      "[45,    99] loss: 0.098508\n",
      "[46,    99] loss: 0.089717\n",
      "[47,    99] loss: 0.070185\n",
      "[48,    99] loss: 0.096907\n",
      "[49,    99] loss: 0.120302\n",
      "[50,    99] loss: 0.064026\n",
      "[51,    99] loss: 0.045792\n",
      "[52,    99] loss: 0.034392\n",
      "[53,    99] loss: 0.023431\n",
      "[54,    99] loss: 0.050164\n",
      "[55,    99] loss: 0.087507\n",
      "[56,    99] loss: 0.089844\n",
      "[57,    99] loss: 0.085850\n",
      "[58,    99] loss: 0.065799\n",
      "[59,    99] loss: 0.113707\n",
      "[60,    99] loss: 0.084375\n",
      "[61,    99] loss: 0.157030\n",
      "[62,    99] loss: 0.040697\n",
      "[63,    99] loss: 0.047932\n",
      "[64,    99] loss: 0.055806\n",
      "[65,    99] loss: 0.281311\n",
      "[66,    99] loss: 0.143142\n",
      "[67,    99] loss: 0.101926\n",
      "[68,    99] loss: 0.073703\n",
      "[69,    99] loss: 0.088866\n",
      "[70,    99] loss: 0.088655\n",
      "[71,    99] loss: 0.057864\n",
      "[72,    99] loss: 0.128486\n",
      "[73,    99] loss: 0.066498\n",
      "[74,    99] loss: 0.101977\n",
      "[75,    99] loss: 0.048699\n",
      "[76,    99] loss: 0.039703\n",
      "[77,    99] loss: 0.037428\n",
      "[78,    99] loss: 0.113843\n",
      "[79,    99] loss: 0.068871\n",
      "[80,    99] loss: 0.163395\n",
      "[81,    99] loss: 0.085440\n",
      "[82,    99] loss: 0.065882\n",
      "[83,    99] loss: 0.217713\n",
      "[84,    99] loss: 0.057529\n",
      "[85,    99] loss: 0.040639\n",
      "[86,    99] loss: 0.073644\n",
      "[87,    99] loss: 0.080111\n",
      "[88,    99] loss: 0.055553\n",
      "[89,    99] loss: 0.025058\n",
      "[90,    99] loss: 0.018572\n",
      "[91,    99] loss: 0.023939\n",
      "[92,    99] loss: 0.019940\n",
      "[93,    99] loss: 0.023620\n",
      "[94,    99] loss: 0.016763\n",
      "[95,    99] loss: 0.024958\n",
      "[96,    99] loss: 0.473418\n",
      "[97,    99] loss: 0.116107\n",
      "[98,    99] loss: 0.096773\n",
      "[99,    99] loss: 0.084340\n",
      "[100,    99] loss: 0.127170\n",
      "Finished Training\n",
      "[1,    99] loss: 0.676831\n",
      "[2,    99] loss: 0.612256\n",
      "[3,    99] loss: 0.542101\n",
      "[4,    99] loss: 0.464629\n",
      "[5,    99] loss: 0.390459\n",
      "[6,    99] loss: 0.323832\n",
      "[7,    99] loss: 0.273388\n",
      "[8,    99] loss: 0.236139\n",
      "[9,    99] loss: 0.206804\n",
      "[10,    99] loss: 0.183459\n",
      "[11,    99] loss: 0.169784\n",
      "[12,    99] loss: 0.153967\n",
      "[13,    99] loss: 0.141876\n",
      "[14,    99] loss: 0.129819\n",
      "[15,    99] loss: 0.123137\n",
      "[16,    99] loss: 0.112647\n",
      "[17,    99] loss: 0.103956\n",
      "[18,    99] loss: 0.095570\n",
      "[19,    99] loss: 0.087998\n",
      "[20,    99] loss: 0.087759\n",
      "[21,    99] loss: 0.079842\n",
      "[22,    99] loss: 0.076348\n",
      "[23,    99] loss: 0.074692\n",
      "[24,    99] loss: 0.072668\n",
      "[25,    99] loss: 0.070173\n",
      "[26,    99] loss: 0.058438\n",
      "[27,    99] loss: 0.058514\n",
      "[28,    99] loss: 0.053052\n",
      "[29,    99] loss: 0.050969\n",
      "[30,    99] loss: 0.039525\n",
      "[31,    99] loss: 0.047922\n",
      "[32,    99] loss: 0.045097\n",
      "[33,    99] loss: 0.068832\n",
      "[34,    99] loss: 0.030198\n",
      "[35,    99] loss: 0.056423\n",
      "[36,    99] loss: 0.025805\n",
      "[37,    99] loss: 0.016678\n",
      "[38,    99] loss: 0.016255\n",
      "[39,    99] loss: 0.060350\n",
      "[40,    99] loss: 0.035470\n",
      "[41,    99] loss: 0.044159\n",
      "[42,    99] loss: 0.023415\n",
      "[43,    99] loss: 0.019197\n",
      "[44,    99] loss: 0.026439\n",
      "[45,    99] loss: 0.011111\n",
      "[46,    99] loss: 0.017344\n",
      "[47,    99] loss: 0.007373\n",
      "[48,    99] loss: 0.007298\n",
      "[49,    99] loss: 0.073722\n",
      "[50,    99] loss: 0.058539\n",
      "[51,    99] loss: 0.016742\n",
      "[52,    99] loss: 0.012054\n",
      "[53,    99] loss: 0.019903\n",
      "[54,    99] loss: 0.014447\n",
      "[55,    99] loss: 0.020342\n",
      "[56,    99] loss: 0.018489\n",
      "[57,    99] loss: 0.023836\n",
      "[58,    99] loss: 0.018632\n",
      "[59,    99] loss: 0.006581\n",
      "[60,    99] loss: 0.004940\n",
      "[61,    99] loss: 0.003223\n",
      "[62,    99] loss: 0.003262\n",
      "[63,    99] loss: 0.001773\n",
      "[64,    99] loss: 0.002169\n",
      "[65,    99] loss: 0.001634\n",
      "[66,    99] loss: 0.001272\n",
      "[67,    99] loss: 0.001189\n",
      "[68,    99] loss: 0.001084\n",
      "[69,    99] loss: 0.001036\n",
      "[70,    99] loss: 0.000969\n",
      "[71,    99] loss: 0.000931\n",
      "[72,    99] loss: 0.000835\n",
      "[73,    99] loss: 0.000821\n",
      "[74,    99] loss: 0.000763\n",
      "[75,    99] loss: 0.000775\n",
      "[76,    99] loss: 0.572622\n",
      "[77,    99] loss: 0.031824\n",
      "[78,    99] loss: 0.011784\n",
      "[79,    99] loss: 0.005458\n",
      "[80,    99] loss: 0.003218\n",
      "[81,    99] loss: 0.002767\n",
      "[82,    99] loss: 0.002366\n",
      "[83,    99] loss: 0.002034\n",
      "[84,    99] loss: 0.001802\n",
      "[85,    99] loss: 0.001605\n",
      "[86,    99] loss: 0.001456\n",
      "[87,    99] loss: 0.001319\n",
      "[88,    99] loss: 0.001196\n",
      "[89,    99] loss: 0.001087\n",
      "[90,    99] loss: 0.000986\n",
      "[91,    99] loss: 0.000912\n",
      "[92,    99] loss: 0.000828\n",
      "[93,    99] loss: 0.000765\n",
      "[94,    99] loss: 0.000711\n",
      "[95,    99] loss: 0.000653\n",
      "[96,    99] loss: 0.000610\n",
      "[97,    99] loss: 0.000560\n",
      "[98,    99] loss: 0.000523\n",
      "[99,    99] loss: 0.000506\n",
      "[100,    99] loss: 0.000553\n",
      "Finished Training\n",
      "[1,    99] loss: 0.684049\n",
      "[2,    99] loss: 0.617312\n",
      "[3,    99] loss: 0.550763\n",
      "[4,    99] loss: 0.482614\n",
      "[5,    99] loss: 0.419803\n",
      "[6,    99] loss: 0.367184\n",
      "[7,    99] loss: 0.321103\n",
      "[8,    99] loss: 0.285613\n",
      "[9,    99] loss: 0.257055\n",
      "[10,    99] loss: 0.234543\n",
      "[11,    99] loss: 0.219732\n",
      "[12,    99] loss: 0.201811\n",
      "[13,    99] loss: 0.184025\n",
      "[14,    99] loss: 0.171559\n",
      "[15,    99] loss: 0.161578\n",
      "[16,    99] loss: 0.151456\n",
      "[17,    99] loss: 0.141278\n",
      "[18,    99] loss: 0.126726\n",
      "[19,    99] loss: 0.119728\n",
      "[20,    99] loss: 0.109966\n",
      "[21,    99] loss: 0.105795\n",
      "[22,    99] loss: 0.101658\n",
      "[23,    99] loss: 0.095327\n",
      "[24,    99] loss: 0.085339\n",
      "[25,    99] loss: 0.083117\n",
      "[26,    99] loss: 0.075177\n",
      "[27,    99] loss: 0.070543\n",
      "[28,    99] loss: 0.069605\n",
      "[29,    99] loss: 0.064988\n",
      "[30,    99] loss: 0.059003\n",
      "[31,    99] loss: 0.060006\n",
      "[32,    99] loss: 0.057093\n",
      "[33,    99] loss: 0.049962\n",
      "[34,    99] loss: 0.046383\n",
      "[35,    99] loss: 0.043177\n",
      "[36,    99] loss: 0.040714\n",
      "[37,    99] loss: 0.036206\n",
      "[38,    99] loss: 0.040790\n",
      "[39,    99] loss: 0.034173\n",
      "[40,    99] loss: 0.040055\n",
      "[41,    99] loss: 0.042173\n",
      "[42,    99] loss: 0.042699\n",
      "[43,    99] loss: 0.041085\n",
      "[44,    99] loss: 0.032933\n",
      "[45,    99] loss: 0.028980\n",
      "[46,    99] loss: 0.026787\n",
      "[47,    99] loss: 0.038778\n",
      "[48,    99] loss: 0.033322\n",
      "[49,    99] loss: 0.028428\n",
      "[50,    99] loss: 0.034043\n",
      "[51,    99] loss: 0.026380\n",
      "[52,    99] loss: 0.038997\n",
      "[53,    99] loss: 0.052346\n",
      "[54,    99] loss: 0.060859\n",
      "[55,    99] loss: 0.051713\n",
      "[56,    99] loss: 0.035337\n",
      "[57,    99] loss: 0.021847\n",
      "[58,    99] loss: 0.018971\n",
      "[59,    99] loss: 0.015278\n",
      "[60,    99] loss: 0.012848\n",
      "[61,    99] loss: 0.013309\n",
      "[62,    99] loss: 0.007977\n",
      "[63,    99] loss: 0.008367\n",
      "[64,    99] loss: 0.013958\n",
      "[65,    99] loss: 0.066866\n",
      "[66,    99] loss: 0.045033\n",
      "[67,    99] loss: 0.042241\n",
      "[68,    99] loss: 0.014733\n",
      "[69,    99] loss: 0.016333\n",
      "[70,    99] loss: 0.014051\n",
      "[71,    99] loss: 0.017307\n",
      "[72,    99] loss: 0.013610\n",
      "[73,    99] loss: 0.013467\n",
      "[74,    99] loss: 0.044426\n",
      "[75,    99] loss: 0.026927\n",
      "[76,    99] loss: 0.053512\n",
      "[77,    99] loss: 0.024833\n",
      "[78,    99] loss: 0.018662\n",
      "[79,    99] loss: 0.014956\n",
      "[80,    99] loss: 0.017472\n",
      "[81,    99] loss: 0.014708\n",
      "[82,    99] loss: 0.025163\n",
      "[83,    99] loss: 0.012662\n",
      "[84,    99] loss: 0.065142\n",
      "[85,    99] loss: 0.041472\n",
      "[86,    99] loss: 0.009560\n",
      "[87,    99] loss: 0.005091\n",
      "[88,    99] loss: 0.003190\n",
      "[89,    99] loss: 0.002571\n",
      "[90,    99] loss: 0.002277\n",
      "[91,    99] loss: 0.002044\n",
      "[92,    99] loss: 0.001848\n",
      "[93,    99] loss: 0.001693\n",
      "[94,    99] loss: 0.001559\n",
      "[95,    99] loss: 0.001449\n",
      "[96,    99] loss: 0.001357\n",
      "[97,    99] loss: 0.001310\n",
      "[98,    99] loss: 0.001341\n",
      "[99,    99] loss: 0.003167\n",
      "[100,    99] loss: 0.179141\n",
      "Finished Training\n",
      "[1,    99] loss: 0.676955\n",
      "[2,    99] loss: 0.599612\n",
      "[3,    99] loss: 0.519959\n",
      "[4,    99] loss: 0.450880\n",
      "[5,    99] loss: 0.391290\n",
      "[6,    99] loss: 0.342508\n",
      "[7,    99] loss: 0.299008\n",
      "[8,    99] loss: 0.265796\n",
      "[9,    99] loss: 0.236393\n",
      "[10,    99] loss: 0.209794\n",
      "[11,    99] loss: 0.186853\n",
      "[12,    99] loss: 0.164808\n",
      "[13,    99] loss: 0.147479\n",
      "[14,    99] loss: 0.137149\n",
      "[15,    99] loss: 0.125203\n",
      "[16,    99] loss: 0.118160\n",
      "[17,    99] loss: 0.110857\n",
      "[18,    99] loss: 0.098354\n",
      "[19,    99] loss: 0.075760\n",
      "[20,    99] loss: 0.070364\n",
      "[21,    99] loss: 0.062898\n",
      "[22,    99] loss: 0.054795\n",
      "[23,    99] loss: 0.062920\n",
      "[24,    99] loss: 0.044548\n",
      "[25,    99] loss: 0.041555\n",
      "[26,    99] loss: 0.044491\n",
      "[27,    99] loss: 0.037513\n",
      "[28,    99] loss: 0.040614\n",
      "[29,    99] loss: 0.082854\n",
      "[30,    99] loss: 0.042985\n",
      "[31,    99] loss: 0.029849\n",
      "[32,    99] loss: 0.025828\n",
      "[33,    99] loss: 0.037234\n",
      "[34,    99] loss: 0.037178\n",
      "[35,    99] loss: 0.045953\n",
      "[36,    99] loss: 0.019675\n",
      "[37,    99] loss: 0.065970\n",
      "[38,    99] loss: 0.020822\n",
      "[39,    99] loss: 0.018389\n",
      "[40,    99] loss: 0.032580\n",
      "[41,    99] loss: 0.038444\n",
      "[42,    99] loss: 0.038331\n",
      "[43,    99] loss: 0.017817\n",
      "[44,    99] loss: 0.012152\n",
      "[45,    99] loss: 0.016289\n",
      "[46,    99] loss: 0.010894\n",
      "[47,    99] loss: 0.012784\n",
      "[48,    99] loss: 0.016392\n",
      "[49,    99] loss: 0.034771\n",
      "[50,    99] loss: 0.060344\n",
      "[51,    99] loss: 0.033786\n",
      "[52,    99] loss: 0.018076\n",
      "[53,    99] loss: 0.010485\n",
      "[54,    99] loss: 0.092977\n",
      "[55,    99] loss: 0.070971\n",
      "[56,    99] loss: 0.010241\n",
      "[57,    99] loss: 0.005428\n",
      "[58,    99] loss: 0.004500\n",
      "[59,    99] loss: 0.004033\n",
      "[60,    99] loss: 0.003785\n",
      "[61,    99] loss: 0.003611\n",
      "[62,    99] loss: 0.003301\n",
      "[63,    99] loss: 0.003022\n",
      "[64,    99] loss: 0.002860\n",
      "[65,    99] loss: 0.003066\n",
      "[66,    99] loss: 0.035143\n",
      "[67,    99] loss: 0.166262\n",
      "[68,    99] loss: 0.027831\n",
      "[69,    99] loss: 0.011907\n",
      "[70,    99] loss: 0.010954\n",
      "[71,    99] loss: 0.011746\n",
      "[72,    99] loss: 0.010187\n",
      "[73,    99] loss: 0.009642\n",
      "[74,    99] loss: 0.011727\n",
      "[75,    99] loss: 0.009565\n",
      "[76,    99] loss: 0.012756\n",
      "[77,    99] loss: 0.009007\n",
      "[78,    99] loss: 0.017010\n",
      "[79,    99] loss: 0.034449\n",
      "[80,    99] loss: 0.084497\n",
      "[81,    99] loss: 0.022779\n",
      "[82,    99] loss: 0.010811\n",
      "[83,    99] loss: 0.003805\n",
      "[84,    99] loss: 0.002818\n",
      "[85,    99] loss: 0.002446\n",
      "[86,    99] loss: 0.002189\n",
      "[87,    99] loss: 0.002014\n",
      "[88,    99] loss: 0.001893\n",
      "[89,    99] loss: 0.001771\n",
      "[90,    99] loss: 0.001646\n",
      "[91,    99] loss: 0.001548\n",
      "[92,    99] loss: 0.001483\n",
      "[93,    99] loss: 0.001371\n",
      "[94,    99] loss: 0.001275\n",
      "[95,    99] loss: 0.001189\n",
      "[96,    99] loss: 0.001121\n",
      "[97,    99] loss: 0.001113\n",
      "[98,    99] loss: 0.040981\n",
      "[99,    99] loss: 0.145558\n",
      "[100,    99] loss: 0.017822\n",
      "Finished Training\n",
      "[1,    99] loss: 0.678425\n",
      "[2,    99] loss: 0.603061\n",
      "[3,    99] loss: 0.508736\n",
      "[4,    99] loss: 0.424346\n",
      "[5,    99] loss: 0.357840\n",
      "[6,    99] loss: 0.304237\n",
      "[7,    99] loss: 0.257756\n",
      "[8,    99] loss: 0.224285\n",
      "[9,    99] loss: 0.192102\n",
      "[10,    99] loss: 0.169630\n",
      "[11,    99] loss: 0.161650\n",
      "[12,    99] loss: 0.145759\n",
      "[13,    99] loss: 0.119716\n",
      "[14,    99] loss: 0.107939\n",
      "[15,    99] loss: 0.098096\n",
      "[16,    99] loss: 0.096317\n",
      "[17,    99] loss: 0.158481\n",
      "[18,    99] loss: 0.082450\n",
      "[19,    99] loss: 0.124639\n",
      "[20,    99] loss: 0.074805\n",
      "[21,    99] loss: 0.079706\n",
      "[22,    99] loss: 0.071264\n",
      "[23,    99] loss: 0.080072\n",
      "[24,    99] loss: 0.081368\n",
      "[25,    99] loss: 0.066202\n",
      "[26,    99] loss: 0.099643\n",
      "[27,    99] loss: 0.061563\n",
      "[28,    99] loss: 0.050369\n",
      "[29,    99] loss: 0.039712\n",
      "[30,    99] loss: 0.034590\n",
      "[31,    99] loss: 0.026712\n",
      "[32,    99] loss: 0.026001\n",
      "[33,    99] loss: 0.026066\n",
      "[34,    99] loss: 0.025575\n",
      "[35,    99] loss: 0.040732\n",
      "[36,    99] loss: 0.031033\n",
      "[37,    99] loss: 0.032814\n",
      "[38,    99] loss: 0.018792\n",
      "[39,    99] loss: 0.023618\n",
      "[40,    99] loss: 0.163841\n",
      "[41,    99] loss: 0.058373\n",
      "[42,    99] loss: 0.059850\n",
      "[43,    99] loss: 0.012373\n",
      "[44,    99] loss: 0.013911\n",
      "[45,    99] loss: 0.014640\n",
      "[46,    99] loss: 0.010615\n",
      "[47,    99] loss: 0.014034\n",
      "[48,    99] loss: 0.011625\n",
      "[49,    99] loss: 0.012884\n",
      "[50,    99] loss: 0.011865\n",
      "[51,    99] loss: 0.014363\n",
      "[52,    99] loss: 0.004312\n",
      "[53,    99] loss: 0.002676\n",
      "[54,    99] loss: 0.002272\n",
      "[55,    99] loss: 0.002106\n",
      "[56,    99] loss: 0.002112\n",
      "[57,    99] loss: 0.005446\n",
      "[58,    99] loss: 0.295409\n",
      "[59,    99] loss: 0.033437\n",
      "[60,    99] loss: 0.040680\n",
      "[61,    99] loss: 0.007255\n",
      "[62,    99] loss: 0.003825\n",
      "[63,    99] loss: 0.003001\n",
      "[64,    99] loss: 0.002710\n",
      "[65,    99] loss: 0.002454\n",
      "[66,    99] loss: 0.002233\n",
      "[67,    99] loss: 0.001996\n",
      "[68,    99] loss: 0.001832\n",
      "[69,    99] loss: 0.001671\n",
      "[70,    99] loss: 0.001546\n",
      "[71,    99] loss: 0.001437\n",
      "[72,    99] loss: 0.001336\n",
      "[73,    99] loss: 0.001258\n",
      "[74,    99] loss: 0.001166\n",
      "[75,    99] loss: 0.001077\n",
      "[76,    99] loss: 0.001039\n",
      "[77,    99] loss: 0.001102\n",
      "[78,    99] loss: 0.147679\n",
      "[79,    99] loss: 0.261518\n",
      "[80,    99] loss: 0.016517\n",
      "[81,    99] loss: 0.010427\n",
      "[82,    99] loss: 0.006578\n",
      "[83,    99] loss: 0.004135\n",
      "[84,    99] loss: 0.003555\n",
      "[85,    99] loss: 0.002859\n",
      "[86,    99] loss: 0.002421\n",
      "[87,    99] loss: 0.002097\n",
      "[88,    99] loss: 0.001865\n",
      "[89,    99] loss: 0.001636\n",
      "[90,    99] loss: 0.001471\n",
      "[91,    99] loss: 0.001324\n",
      "[92,    99] loss: 0.001174\n",
      "[93,    99] loss: 0.001064\n",
      "[94,    99] loss: 0.000969\n",
      "[95,    99] loss: 0.000894\n",
      "[96,    99] loss: 0.000819\n",
      "[97,    99] loss: 0.000728\n",
      "[98,    99] loss: 0.000729\n",
      "[99,    99] loss: 0.000567\n",
      "[100,    99] loss: 0.000674\n",
      "Finished Training\n",
      "[1,    99] loss: 0.678465\n",
      "[2,    99] loss: 0.611849\n",
      "[3,    99] loss: 0.558089\n",
      "[4,    99] loss: 0.497192\n",
      "[5,    99] loss: 0.431276\n",
      "[6,    99] loss: 0.370863\n",
      "[7,    99] loss: 0.323539\n",
      "[8,    99] loss: 0.285539\n",
      "[9,    99] loss: 0.251781\n",
      "[10,    99] loss: 0.224463\n",
      "[11,    99] loss: 0.201777\n",
      "[12,    99] loss: 0.178448\n",
      "[13,    99] loss: 0.166188\n",
      "[14,    99] loss: 0.148026\n",
      "[15,    99] loss: 0.136198\n",
      "[16,    99] loss: 0.125112\n",
      "[17,    99] loss: 0.111806\n",
      "[18,    99] loss: 0.102093\n",
      "[19,    99] loss: 0.090874\n",
      "[20,    99] loss: 0.097644\n",
      "[21,    99] loss: 0.076031\n",
      "[22,    99] loss: 0.073967\n",
      "[23,    99] loss: 0.067067\n",
      "[24,    99] loss: 0.057394\n",
      "[25,    99] loss: 0.051120\n",
      "[26,    99] loss: 0.053115\n",
      "[27,    99] loss: 0.056962\n",
      "[28,    99] loss: 0.047172\n",
      "[29,    99] loss: 0.044205\n",
      "[30,    99] loss: 0.047601\n",
      "[31,    99] loss: 0.048669\n",
      "[32,    99] loss: 0.037329\n",
      "[33,    99] loss: 0.041371\n",
      "[34,    99] loss: 0.032639\n",
      "[35,    99] loss: 0.035825\n",
      "[36,    99] loss: 0.040173\n",
      "[37,    99] loss: 0.061622\n",
      "[38,    99] loss: 0.049757\n",
      "[39,    99] loss: 0.032803\n",
      "[40,    99] loss: 0.024725\n",
      "[41,    99] loss: 0.025705\n",
      "[42,    99] loss: 0.029997\n",
      "[43,    99] loss: 0.027705\n",
      "[44,    99] loss: 0.031500\n",
      "[45,    99] loss: 0.036225\n",
      "[46,    99] loss: 0.061213\n",
      "[47,    99] loss: 0.024931\n",
      "[48,    99] loss: 0.023710\n",
      "[49,    99] loss: 0.025055\n",
      "[50,    99] loss: 0.024666\n",
      "[51,    99] loss: 0.025443\n",
      "[52,    99] loss: 0.025217\n",
      "[53,    99] loss: 0.052590\n",
      "[54,    99] loss: 0.058068\n",
      "[55,    99] loss: 0.041323\n",
      "[56,    99] loss: 0.031979\n",
      "[57,    99] loss: 0.017057\n",
      "[58,    99] loss: 0.017983\n",
      "[59,    99] loss: 0.022514\n",
      "[60,    99] loss: 0.022519\n",
      "[61,    99] loss: 0.043080\n",
      "[62,    99] loss: 0.025389\n",
      "[63,    99] loss: 0.011896\n",
      "[64,    99] loss: 0.014732\n",
      "[65,    99] loss: 0.008778\n",
      "[66,    99] loss: 0.014984\n",
      "[67,    99] loss: 0.031834\n",
      "[68,    99] loss: 0.026304\n",
      "[69,    99] loss: 0.026554\n",
      "[70,    99] loss: 0.093588\n",
      "[71,    99] loss: 0.013272\n",
      "[72,    99] loss: 0.051076\n",
      "[73,    99] loss: 0.018964\n",
      "[74,    99] loss: 0.009726\n",
      "[75,    99] loss: 0.008984\n",
      "[76,    99] loss: 0.008271\n",
      "[77,    99] loss: 0.029731\n",
      "[78,    99] loss: 0.010794\n",
      "[79,    99] loss: 0.071302\n",
      "[80,    99] loss: 0.014134\n",
      "[81,    99] loss: 0.004767\n",
      "[82,    99] loss: 0.006184\n",
      "[83,    99] loss: 0.079598\n",
      "[84,    99] loss: 0.022080\n",
      "[85,    99] loss: 0.014064\n",
      "[86,    99] loss: 0.007157\n",
      "[87,    99] loss: 0.005927\n",
      "[88,    99] loss: 0.005338\n",
      "[89,    99] loss: 0.006886\n",
      "[90,    99] loss: 0.005771\n",
      "[91,    99] loss: 0.004636\n",
      "[92,    99] loss: 0.003392\n",
      "[93,    99] loss: 0.001692\n",
      "[94,    99] loss: 0.001619\n",
      "[95,    99] loss: 0.001604\n",
      "[96,    99] loss: 0.001670\n",
      "[97,    99] loss: 0.002725\n",
      "[98,    99] loss: 0.045152\n",
      "[99,    99] loss: 0.095875\n",
      "[100,    99] loss: 0.017089\n",
      "Finished Training\n",
      "[1,    99] loss: 0.706643\n",
      "[2,    99] loss: 0.688757\n",
      "[3,    99] loss: 0.675433\n",
      "[4,    99] loss: 0.663699\n",
      "[5,    99] loss: 0.652984\n",
      "[6,    99] loss: 0.642908\n",
      "[7,    99] loss: 0.633255\n",
      "[8,    99] loss: 0.623934\n",
      "[9,    99] loss: 0.614853\n",
      "[10,    99] loss: 0.605958\n",
      "[11,    99] loss: 0.597308\n",
      "[12,    99] loss: 0.588848\n",
      "[13,    99] loss: 0.580207\n",
      "[14,    99] loss: 0.571462\n",
      "[15,    99] loss: 0.562829\n",
      "[16,    99] loss: 0.554089\n",
      "[17,    99] loss: 0.545276\n",
      "[18,    99] loss: 0.536387\n",
      "[19,    99] loss: 0.527519\n",
      "[20,    99] loss: 0.518475\n",
      "[21,    99] loss: 0.509451\n",
      "[22,    99] loss: 0.500263\n",
      "[23,    99] loss: 0.491211\n",
      "[24,    99] loss: 0.482156\n",
      "[25,    99] loss: 0.473082\n",
      "[26,    99] loss: 0.463687\n",
      "[27,    99] loss: 0.454501\n",
      "[28,    99] loss: 0.445669\n",
      "[29,    99] loss: 0.436815\n",
      "[30,    99] loss: 0.428137\n",
      "[31,    99] loss: 0.419484\n",
      "[32,    99] loss: 0.411079\n",
      "[33,    99] loss: 0.402642\n",
      "[34,    99] loss: 0.394560\n",
      "[35,    99] loss: 0.386778\n",
      "[36,    99] loss: 0.379182\n",
      "[37,    99] loss: 0.371608\n",
      "[38,    99] loss: 0.364339\n",
      "[39,    99] loss: 0.357162\n",
      "[40,    99] loss: 0.350143\n",
      "[41,    99] loss: 0.343141\n",
      "[42,    99] loss: 0.336157\n",
      "[43,    99] loss: 0.329401\n",
      "[44,    99] loss: 0.322830\n",
      "[45,    99] loss: 0.316430\n",
      "[46,    99] loss: 0.310058\n",
      "[47,    99] loss: 0.303896\n",
      "[48,    99] loss: 0.297850\n",
      "[49,    99] loss: 0.291859\n",
      "[50,    99] loss: 0.286051\n",
      "[51,    99] loss: 0.280462\n",
      "[52,    99] loss: 0.274900\n",
      "[53,    99] loss: 0.269440\n",
      "[54,    99] loss: 0.264094\n",
      "[55,    99] loss: 0.258767\n",
      "[56,    99] loss: 0.253634\n",
      "[57,    99] loss: 0.248572\n",
      "[58,    99] loss: 0.243765\n",
      "[59,    99] loss: 0.238923\n",
      "[60,    99] loss: 0.234220\n",
      "[61,    99] loss: 0.229638\n",
      "[62,    99] loss: 0.225080\n",
      "[63,    99] loss: 0.220717\n",
      "[64,    99] loss: 0.216332\n",
      "[65,    99] loss: 0.212035\n",
      "[66,    99] loss: 0.207757\n",
      "[67,    99] loss: 0.203700\n",
      "[68,    99] loss: 0.199636\n",
      "[69,    99] loss: 0.195679\n",
      "[70,    99] loss: 0.191795\n",
      "[71,    99] loss: 0.188083\n",
      "[72,    99] loss: 0.184300\n",
      "[73,    99] loss: 0.180659\n",
      "[74,    99] loss: 0.177006\n",
      "[75,    99] loss: 0.173438\n",
      "[76,    99] loss: 0.169977\n",
      "[77,    99] loss: 0.166561\n",
      "[78,    99] loss: 0.163249\n",
      "[79,    99] loss: 0.159895\n",
      "[80,    99] loss: 0.156691\n",
      "[81,    99] loss: 0.153524\n",
      "[82,    99] loss: 0.150346\n",
      "[83,    99] loss: 0.147423\n",
      "[84,    99] loss: 0.144425\n",
      "[85,    99] loss: 0.141553\n",
      "[86,    99] loss: 0.138752\n",
      "[87,    99] loss: 0.135996\n",
      "[88,    99] loss: 0.133190\n",
      "[89,    99] loss: 0.130565\n",
      "[90,    99] loss: 0.128005\n",
      "[91,    99] loss: 0.125434\n",
      "[92,    99] loss: 0.123007\n",
      "[93,    99] loss: 0.120488\n",
      "[94,    99] loss: 0.118159\n",
      "[95,    99] loss: 0.115840\n",
      "[96,    99] loss: 0.113608\n",
      "[97,    99] loss: 0.111370\n",
      "[98,    99] loss: 0.109157\n",
      "[99,    99] loss: 0.106982\n",
      "[100,    99] loss: 0.104810\n",
      "Finished Training\n",
      "[1,    99] loss: 0.696046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    99] loss: 0.686479\n",
      "[3,    99] loss: 0.677825\n",
      "[4,    99] loss: 0.669204\n",
      "[5,    99] loss: 0.660642\n",
      "[6,    99] loss: 0.651695\n",
      "[7,    99] loss: 0.642085\n",
      "[8,    99] loss: 0.631917\n",
      "[9,    99] loss: 0.621414\n",
      "[10,    99] loss: 0.611452\n",
      "[11,    99] loss: 0.601605\n",
      "[12,    99] loss: 0.592220\n",
      "[13,    99] loss: 0.583100\n",
      "[14,    99] loss: 0.574278\n",
      "[15,    99] loss: 0.565682\n",
      "[16,    99] loss: 0.557270\n",
      "[17,    99] loss: 0.549256\n",
      "[18,    99] loss: 0.541360\n",
      "[19,    99] loss: 0.533704\n",
      "[20,    99] loss: 0.526204\n",
      "[21,    99] loss: 0.518796\n",
      "[22,    99] loss: 0.511545\n",
      "[23,    99] loss: 0.504199\n",
      "[24,    99] loss: 0.497155\n",
      "[25,    99] loss: 0.490168\n",
      "[26,    99] loss: 0.483224\n",
      "[27,    99] loss: 0.476577\n",
      "[28,    99] loss: 0.469878\n",
      "[29,    99] loss: 0.463502\n",
      "[30,    99] loss: 0.457024\n",
      "[31,    99] loss: 0.450851\n",
      "[32,    99] loss: 0.444577\n",
      "[33,    99] loss: 0.438230\n",
      "[34,    99] loss: 0.432560\n",
      "[35,    99] loss: 0.426548\n",
      "[36,    99] loss: 0.420712\n",
      "[37,    99] loss: 0.415092\n",
      "[38,    99] loss: 0.409285\n",
      "[39,    99] loss: 0.403725\n",
      "[40,    99] loss: 0.398068\n",
      "[41,    99] loss: 0.392617\n",
      "[42,    99] loss: 0.386975\n",
      "[43,    99] loss: 0.381374\n",
      "[44,    99] loss: 0.375864\n",
      "[45,    99] loss: 0.370214\n",
      "[46,    99] loss: 0.364911\n",
      "[47,    99] loss: 0.359644\n",
      "[48,    99] loss: 0.354360\n",
      "[49,    99] loss: 0.349310\n",
      "[50,    99] loss: 0.344271\n",
      "[51,    99] loss: 0.339191\n",
      "[52,    99] loss: 0.333992\n",
      "[53,    99] loss: 0.329241\n",
      "[54,    99] loss: 0.324372\n",
      "[55,    99] loss: 0.319484\n",
      "[56,    99] loss: 0.314432\n",
      "[57,    99] loss: 0.309856\n",
      "[58,    99] loss: 0.304909\n",
      "[59,    99] loss: 0.300317\n",
      "[60,    99] loss: 0.295799\n",
      "[61,    99] loss: 0.291125\n",
      "[62,    99] loss: 0.286931\n",
      "[63,    99] loss: 0.282244\n",
      "[64,    99] loss: 0.277949\n",
      "[65,    99] loss: 0.273785\n",
      "[66,    99] loss: 0.269510\n",
      "[67,    99] loss: 0.265164\n",
      "[68,    99] loss: 0.260992\n",
      "[69,    99] loss: 0.257195\n",
      "[70,    99] loss: 0.253342\n",
      "[71,    99] loss: 0.249452\n",
      "[72,    99] loss: 0.245380\n",
      "[73,    99] loss: 0.241637\n",
      "[74,    99] loss: 0.238065\n",
      "[75,    99] loss: 0.234463\n",
      "[76,    99] loss: 0.230768\n",
      "[77,    99] loss: 0.227378\n",
      "[78,    99] loss: 0.224044\n",
      "[79,    99] loss: 0.220525\n",
      "[80,    99] loss: 0.217437\n",
      "[81,    99] loss: 0.214111\n",
      "[82,    99] loss: 0.210992\n",
      "[83,    99] loss: 0.207753\n",
      "[84,    99] loss: 0.204862\n",
      "[85,    99] loss: 0.201794\n",
      "[86,    99] loss: 0.198884\n",
      "[87,    99] loss: 0.196043\n",
      "[88,    99] loss: 0.193133\n",
      "[89,    99] loss: 0.190233\n",
      "[90,    99] loss: 0.187381\n",
      "[91,    99] loss: 0.184608\n",
      "[92,    99] loss: 0.181859\n",
      "[93,    99] loss: 0.179177\n",
      "[94,    99] loss: 0.176309\n",
      "[95,    99] loss: 0.173369\n",
      "[96,    99] loss: 0.170787\n",
      "[97,    99] loss: 0.168111\n",
      "[98,    99] loss: 0.165522\n",
      "[99,    99] loss: 0.162912\n",
      "[100,    99] loss: 0.160490\n",
      "Finished Training\n",
      "[1,    99] loss: 0.687301\n",
      "[2,    99] loss: 0.678813\n",
      "[3,    99] loss: 0.670911\n",
      "[4,    99] loss: 0.662881\n",
      "[5,    99] loss: 0.654436\n",
      "[6,    99] loss: 0.645786\n",
      "[7,    99] loss: 0.637018\n",
      "[8,    99] loss: 0.628320\n",
      "[9,    99] loss: 0.619558\n",
      "[10,    99] loss: 0.610799\n",
      "[11,    99] loss: 0.601957\n",
      "[12,    99] loss: 0.593111\n",
      "[13,    99] loss: 0.584338\n",
      "[14,    99] loss: 0.575544\n",
      "[15,    99] loss: 0.566967\n",
      "[16,    99] loss: 0.558299\n",
      "[17,    99] loss: 0.549606\n",
      "[18,    99] loss: 0.540952\n",
      "[19,    99] loss: 0.532316\n",
      "[20,    99] loss: 0.523670\n",
      "[21,    99] loss: 0.515026\n",
      "[22,    99] loss: 0.506367\n",
      "[23,    99] loss: 0.497784\n",
      "[24,    99] loss: 0.489179\n",
      "[25,    99] loss: 0.480678\n",
      "[26,    99] loss: 0.472278\n",
      "[27,    99] loss: 0.463959\n",
      "[28,    99] loss: 0.455748\n",
      "[29,    99] loss: 0.447537\n",
      "[30,    99] loss: 0.439428\n",
      "[31,    99] loss: 0.431603\n",
      "[32,    99] loss: 0.424010\n",
      "[33,    99] loss: 0.416427\n",
      "[34,    99] loss: 0.408998\n",
      "[35,    99] loss: 0.401607\n",
      "[36,    99] loss: 0.394335\n",
      "[37,    99] loss: 0.387233\n",
      "[38,    99] loss: 0.380179\n",
      "[39,    99] loss: 0.373421\n",
      "[40,    99] loss: 0.366660\n",
      "[41,    99] loss: 0.360179\n",
      "[42,    99] loss: 0.353674\n",
      "[43,    99] loss: 0.347426\n",
      "[44,    99] loss: 0.341246\n",
      "[45,    99] loss: 0.335174\n",
      "[46,    99] loss: 0.329157\n",
      "[47,    99] loss: 0.323314\n",
      "[48,    99] loss: 0.317560\n",
      "[49,    99] loss: 0.311913\n",
      "[50,    99] loss: 0.306422\n",
      "[51,    99] loss: 0.300937\n",
      "[52,    99] loss: 0.295697\n",
      "[53,    99] loss: 0.290453\n",
      "[54,    99] loss: 0.285382\n",
      "[55,    99] loss: 0.280511\n",
      "[56,    99] loss: 0.275729\n",
      "[57,    99] loss: 0.271087\n",
      "[58,    99] loss: 0.266548\n",
      "[59,    99] loss: 0.262087\n",
      "[60,    99] loss: 0.257723\n",
      "[61,    99] loss: 0.253365\n",
      "[62,    99] loss: 0.249159\n",
      "[63,    99] loss: 0.245021\n",
      "[64,    99] loss: 0.241037\n",
      "[65,    99] loss: 0.237067\n",
      "[66,    99] loss: 0.233193\n",
      "[67,    99] loss: 0.229426\n",
      "[68,    99] loss: 0.225705\n",
      "[69,    99] loss: 0.222081\n",
      "[70,    99] loss: 0.218484\n",
      "[71,    99] loss: 0.214915\n",
      "[72,    99] loss: 0.211508\n",
      "[73,    99] loss: 0.208082\n",
      "[74,    99] loss: 0.204763\n",
      "[75,    99] loss: 0.201483\n",
      "[76,    99] loss: 0.198247\n",
      "[77,    99] loss: 0.195064\n",
      "[78,    99] loss: 0.191880\n",
      "[79,    99] loss: 0.188893\n",
      "[80,    99] loss: 0.185840\n",
      "[81,    99] loss: 0.182736\n",
      "[82,    99] loss: 0.179820\n",
      "[83,    99] loss: 0.176710\n",
      "[84,    99] loss: 0.173699\n",
      "[85,    99] loss: 0.170871\n",
      "[86,    99] loss: 0.167989\n",
      "[87,    99] loss: 0.165339\n",
      "[88,    99] loss: 0.162606\n",
      "[89,    99] loss: 0.159887\n",
      "[90,    99] loss: 0.157372\n",
      "[91,    99] loss: 0.154815\n",
      "[92,    99] loss: 0.152293\n",
      "[93,    99] loss: 0.149871\n",
      "[94,    99] loss: 0.147474\n",
      "[95,    99] loss: 0.145120\n",
      "[96,    99] loss: 0.142796\n",
      "[97,    99] loss: 0.140530\n",
      "[98,    99] loss: 0.138253\n",
      "[99,    99] loss: 0.136101\n",
      "[100,    99] loss: 0.133865\n",
      "Finished Training\n",
      "[1,    99] loss: 0.689759\n",
      "[2,    99] loss: 0.679464\n",
      "[3,    99] loss: 0.671602\n",
      "[4,    99] loss: 0.664347\n",
      "[5,    99] loss: 0.656908\n",
      "[6,    99] loss: 0.649436\n",
      "[7,    99] loss: 0.641701\n",
      "[8,    99] loss: 0.633704\n",
      "[9,    99] loss: 0.625364\n",
      "[10,    99] loss: 0.616785\n",
      "[11,    99] loss: 0.608029\n",
      "[12,    99] loss: 0.599224\n",
      "[13,    99] loss: 0.590233\n",
      "[14,    99] loss: 0.581164\n",
      "[15,    99] loss: 0.572002\n",
      "[16,    99] loss: 0.562762\n",
      "[17,    99] loss: 0.553489\n",
      "[18,    99] loss: 0.544182\n",
      "[19,    99] loss: 0.534773\n",
      "[20,    99] loss: 0.525490\n",
      "[21,    99] loss: 0.516158\n",
      "[22,    99] loss: 0.506792\n",
      "[23,    99] loss: 0.497536\n",
      "[24,    99] loss: 0.488398\n",
      "[25,    99] loss: 0.479225\n",
      "[26,    99] loss: 0.470040\n",
      "[27,    99] loss: 0.460942\n",
      "[28,    99] loss: 0.452147\n",
      "[29,    99] loss: 0.443310\n",
      "[30,    99] loss: 0.434663\n",
      "[31,    99] loss: 0.426220\n",
      "[32,    99] loss: 0.417842\n",
      "[33,    99] loss: 0.409578\n",
      "[34,    99] loss: 0.401393\n",
      "[35,    99] loss: 0.393412\n",
      "[36,    99] loss: 0.385573\n",
      "[37,    99] loss: 0.377723\n",
      "[38,    99] loss: 0.370116\n",
      "[39,    99] loss: 0.362584\n",
      "[40,    99] loss: 0.355005\n",
      "[41,    99] loss: 0.347724\n",
      "[42,    99] loss: 0.340362\n",
      "[43,    99] loss: 0.333119\n",
      "[44,    99] loss: 0.326081\n",
      "[45,    99] loss: 0.319193\n",
      "[46,    99] loss: 0.312275\n",
      "[47,    99] loss: 0.305648\n",
      "[48,    99] loss: 0.299154\n",
      "[49,    99] loss: 0.292857\n",
      "[50,    99] loss: 0.286659\n",
      "[51,    99] loss: 0.280753\n",
      "[52,    99] loss: 0.274713\n",
      "[53,    99] loss: 0.269096\n",
      "[54,    99] loss: 0.263239\n",
      "[55,    99] loss: 0.257603\n",
      "[56,    99] loss: 0.252313\n",
      "[57,    99] loss: 0.246969\n",
      "[58,    99] loss: 0.241549\n",
      "[59,    99] loss: 0.236420\n",
      "[60,    99] loss: 0.231246\n",
      "[61,    99] loss: 0.226390\n",
      "[62,    99] loss: 0.221368\n",
      "[63,    99] loss: 0.216604\n",
      "[64,    99] loss: 0.211925\n",
      "[65,    99] loss: 0.207341\n",
      "[66,    99] loss: 0.202749\n",
      "[67,    99] loss: 0.198454\n",
      "[68,    99] loss: 0.194207\n",
      "[69,    99] loss: 0.190187\n",
      "[70,    99] loss: 0.186085\n",
      "[71,    99] loss: 0.182114\n",
      "[72,    99] loss: 0.178209\n",
      "[73,    99] loss: 0.174573\n",
      "[74,    99] loss: 0.170783\n",
      "[75,    99] loss: 0.167217\n",
      "[76,    99] loss: 0.163628\n",
      "[77,    99] loss: 0.160096\n",
      "[78,    99] loss: 0.156968\n",
      "[79,    99] loss: 0.153636\n",
      "[80,    99] loss: 0.150526\n",
      "[81,    99] loss: 0.147329\n",
      "[82,    99] loss: 0.144122\n",
      "[83,    99] loss: 0.141228\n",
      "[84,    99] loss: 0.138174\n",
      "[85,    99] loss: 0.135107\n",
      "[86,    99] loss: 0.132482\n",
      "[87,    99] loss: 0.129807\n",
      "[88,    99] loss: 0.127047\n",
      "[89,    99] loss: 0.124527\n",
      "[90,    99] loss: 0.121868\n",
      "[91,    99] loss: 0.119385\n",
      "[92,    99] loss: 0.116976\n",
      "[93,    99] loss: 0.114624\n",
      "[94,    99] loss: 0.112389\n",
      "[95,    99] loss: 0.109994\n",
      "[96,    99] loss: 0.107958\n",
      "[97,    99] loss: 0.105658\n",
      "[98,    99] loss: 0.103443\n",
      "[99,    99] loss: 0.101379\n",
      "[100,    99] loss: 0.099332\n",
      "Finished Training\n",
      "[1,    99] loss: 0.694213\n",
      "[2,    99] loss: 0.681814\n",
      "[3,    99] loss: 0.675137\n",
      "[4,    99] loss: 0.669813\n",
      "[5,    99] loss: 0.664077\n",
      "[6,    99] loss: 0.657147\n",
      "[7,    99] loss: 0.649548\n",
      "[8,    99] loss: 0.641105\n",
      "[9,    99] loss: 0.631726\n",
      "[10,    99] loss: 0.621744\n",
      "[11,    99] loss: 0.611786\n",
      "[12,    99] loss: 0.602264\n",
      "[13,    99] loss: 0.593196\n",
      "[14,    99] loss: 0.584277\n",
      "[15,    99] loss: 0.575545\n",
      "[16,    99] loss: 0.567157\n",
      "[17,    99] loss: 0.559034\n",
      "[18,    99] loss: 0.551094\n",
      "[19,    99] loss: 0.543252\n",
      "[20,    99] loss: 0.535477\n",
      "[21,    99] loss: 0.527673\n",
      "[22,    99] loss: 0.520024\n",
      "[23,    99] loss: 0.512428\n",
      "[24,    99] loss: 0.504874\n",
      "[25,    99] loss: 0.497222\n",
      "[26,    99] loss: 0.489668\n",
      "[27,    99] loss: 0.482156\n",
      "[28,    99] loss: 0.474598\n",
      "[29,    99] loss: 0.467066\n",
      "[30,    99] loss: 0.459010\n",
      "[31,    99] loss: 0.451105\n",
      "[32,    99] loss: 0.443773\n",
      "[33,    99] loss: 0.436494\n",
      "[34,    99] loss: 0.429437\n",
      "[35,    99] loss: 0.422513\n",
      "[36,    99] loss: 0.415647\n",
      "[37,    99] loss: 0.408967\n",
      "[38,    99] loss: 0.402327\n",
      "[39,    99] loss: 0.395718\n",
      "[40,    99] loss: 0.389366\n",
      "[41,    99] loss: 0.383038\n",
      "[42,    99] loss: 0.376875\n",
      "[43,    99] loss: 0.370582\n",
      "[44,    99] loss: 0.364553\n",
      "[45,    99] loss: 0.358714\n",
      "[46,    99] loss: 0.352968\n",
      "[47,    99] loss: 0.347326\n",
      "[48,    99] loss: 0.341835\n",
      "[49,    99] loss: 0.336276\n",
      "[50,    99] loss: 0.330896\n",
      "[51,    99] loss: 0.325554\n",
      "[52,    99] loss: 0.320282\n",
      "[53,    99] loss: 0.315151\n",
      "[54,    99] loss: 0.310115\n",
      "[55,    99] loss: 0.305171\n",
      "[56,    99] loss: 0.300318\n",
      "[57,    99] loss: 0.295461\n",
      "[58,    99] loss: 0.290764\n",
      "[59,    99] loss: 0.286086\n",
      "[60,    99] loss: 0.281501\n",
      "[61,    99] loss: 0.277018\n",
      "[62,    99] loss: 0.272547\n",
      "[63,    99] loss: 0.268216\n",
      "[64,    99] loss: 0.263938\n",
      "[65,    99] loss: 0.259816\n",
      "[66,    99] loss: 0.255641\n",
      "[67,    99] loss: 0.251620\n",
      "[68,    99] loss: 0.247595\n",
      "[69,    99] loss: 0.243628\n",
      "[70,    99] loss: 0.239811\n",
      "[71,    99] loss: 0.235943\n",
      "[72,    99] loss: 0.232194\n",
      "[73,    99] loss: 0.228398\n",
      "[74,    99] loss: 0.224589\n",
      "[75,    99] loss: 0.220991\n",
      "[76,    99] loss: 0.217347\n",
      "[77,    99] loss: 0.213569\n",
      "[78,    99] loss: 0.210012\n",
      "[79,    99] loss: 0.206534\n",
      "[80,    99] loss: 0.203026\n",
      "[81,    99] loss: 0.199571\n",
      "[82,    99] loss: 0.196178\n",
      "[83,    99] loss: 0.192947\n",
      "[84,    99] loss: 0.189798\n",
      "[85,    99] loss: 0.186620\n",
      "[86,    99] loss: 0.183504\n",
      "[87,    99] loss: 0.180519\n",
      "[88,    99] loss: 0.177499\n",
      "[89,    99] loss: 0.174607\n",
      "[90,    99] loss: 0.171646\n",
      "[91,    99] loss: 0.168831\n",
      "[92,    99] loss: 0.165959\n",
      "[93,    99] loss: 0.163391\n",
      "[94,    99] loss: 0.160653\n",
      "[95,    99] loss: 0.158016\n",
      "[96,    99] loss: 0.155310\n",
      "[97,    99] loss: 0.152781\n",
      "[98,    99] loss: 0.150173\n",
      "[99,    99] loss: 0.147667\n",
      "[100,    99] loss: 0.145280\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#Here we use only 12 features(Temporal rest and claim are omitted)\n",
    "#Due to concatanation it comes out as 24 features per sample\n",
    "final_stat_s=[]\n",
    "epoch_stat_s=[]\n",
    "ms_arr_s=[]\n",
    "for batch_size,lr in product([1,2,4,8,16], [0.1,0.01,0.001,0.0001]):\n",
    "    final_stat,epoch_stat, ms_arr = cross_validation(24,labels, features_s, 5, NO_EPOCH, batch_size,lr,cuda_is_available,True,None)\n",
    "    final_stat_s.append(final_stat)\n",
    "    epoch_stat_s.append(epoch_stat)\n",
    "    ms_arr_s.append(ms_arr)\n",
    "np.save('qB_final_stat_s.npy', np.array(final_stat_s))\n",
    "np.save('qB_epoch_stat_s.npy', np.array(epoch_stat_s))\n",
    "np.save('qB_ms_arr_s.npy', np.array(ms_arr_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    99] loss: 1.494938\n",
      "[1,   199] loss: 2.440083\n",
      "[1,   299] loss: 1.194763\n",
      "[1,   399] loss: 0.809247\n",
      "[1,   499] loss: 0.704329\n",
      "[1,   599] loss: 0.716361\n",
      "[1,   699] loss: 0.734060\n",
      "[2,    99] loss: 0.725674"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2,   199] loss: 0.716831\n",
      "[2,   299] loss: 7.899501\n",
      "[2,   399] loss: 0.765316\n",
      "[2,   499] loss: 0.724793\n",
      "[2,   599] loss: 0.716877\n",
      "[2,   699] loss: 0.734374\n",
      "[3,    99] loss: 0.725877\n",
      "[3,   199] loss: 0.717032\n",
      "[3,   299] loss: 0.695728\n",
      "[3,   399] loss: 0.732263\n",
      "[3,   499] loss: 0.704684\n",
      "[3,   599] loss: 0.716945\n",
      "[3,   699] loss: 0.734508\n",
      "[4,    99] loss: 0.725971\n",
      "[4,   199] loss: 0.717129\n",
      "[4,   299] loss: 0.695785\n",
      "[4,   399] loss: 0.732367\n",
      "[4,   499] loss: 0.704713\n",
      "[4,   599] loss: 0.717003\n",
      "[4,   699] loss: 0.734560\n",
      "[5,    99] loss: 0.726009\n",
      "[5,   199] loss: 0.717168\n",
      "[5,   299] loss: 0.695808\n",
      "[5,   399] loss: 0.732410\n",
      "[5,   499] loss: 0.704726\n",
      "[5,   599] loss: 0.717027\n",
      "[5,   699] loss: 0.734582\n",
      "[6,    99] loss: 0.726025\n",
      "[6,   199] loss: 0.717186\n",
      "[6,   299] loss: 0.695818\n",
      "[6,   399] loss: 0.732429\n",
      "[6,   499] loss: 0.704732\n",
      "[6,   599] loss: 0.717038\n",
      "[6,   699] loss: 0.734592\n",
      "[7,    99] loss: 0.726033\n",
      "[7,   199] loss: 0.717194\n",
      "[7,   299] loss: 0.695823\n",
      "[7,   399] loss: 0.732438\n",
      "[7,   499] loss: 0.704734\n",
      "[7,   599] loss: 0.717043\n",
      "[7,   699] loss: 0.734597\n",
      "[8,    99] loss: 0.726036\n",
      "[8,   199] loss: 0.717197\n",
      "[8,   299] loss: 0.695825\n",
      "[8,   399] loss: 0.732442\n",
      "[8,   499] loss: 0.704736\n",
      "[8,   599] loss: 0.717046\n",
      "[8,   699] loss: 0.734599\n",
      "[9,    99] loss: 0.726038\n",
      "[9,   199] loss: 0.717199\n",
      "[9,   299] loss: 0.695826\n",
      "[9,   399] loss: 0.732444\n",
      "[9,   499] loss: 0.704736\n",
      "[9,   599] loss: 0.717047\n",
      "[9,   699] loss: 0.734600\n",
      "[10,    99] loss: 0.726039\n",
      "[10,   199] loss: 0.717200\n",
      "[10,   299] loss: 0.695827\n",
      "[10,   399] loss: 0.732445\n",
      "[10,   499] loss: 0.704737\n",
      "[10,   599] loss: 0.717048\n",
      "[10,   699] loss: 0.734601\n",
      "[11,    99] loss: 0.726039\n",
      "[11,   199] loss: 0.717200\n",
      "[11,   299] loss: 0.695827\n",
      "[11,   399] loss: 0.732446\n",
      "[11,   499] loss: 0.704737\n",
      "[11,   599] loss: 0.717048\n",
      "[11,   699] loss: 0.734601\n",
      "[12,    99] loss: 0.726039\n",
      "[12,   199] loss: 0.717201\n",
      "[12,   299] loss: 0.695827\n",
      "[12,   399] loss: 0.732446\n",
      "[12,   499] loss: 0.704737\n",
      "[12,   599] loss: 0.717048\n",
      "[12,   699] loss: 0.734601\n",
      "[13,    99] loss: 0.726039\n",
      "[13,   199] loss: 0.717201\n",
      "[13,   299] loss: 0.695827\n",
      "[13,   399] loss: 0.732446\n",
      "[13,   499] loss: 0.704737\n",
      "[13,   599] loss: 0.717048\n",
      "[13,   699] loss: 0.734601\n",
      "[14,    99] loss: 0.726039\n",
      "[14,   199] loss: 0.717201\n",
      "[14,   299] loss: 0.695827\n",
      "[14,   399] loss: 0.732446\n",
      "[14,   499] loss: 0.704737\n",
      "[14,   599] loss: 0.717048\n",
      "[14,   699] loss: 0.734601\n",
      "[15,    99] loss: 0.726039\n",
      "[15,   199] loss: 0.717201\n",
      "[15,   299] loss: 0.695827\n",
      "[15,   399] loss: 0.732446\n",
      "[15,   499] loss: 0.704737\n",
      "[15,   599] loss: 0.717048\n",
      "[15,   699] loss: 0.734601\n",
      "[16,    99] loss: 0.726039\n",
      "[16,   199] loss: 0.717201\n",
      "[16,   299] loss: 0.695827\n",
      "[16,   399] loss: 0.732446\n",
      "[16,   499] loss: 0.704737\n",
      "[16,   599] loss: 0.717048\n",
      "[16,   699] loss: 0.734601\n",
      "[17,    99] loss: 0.726039\n",
      "[17,   199] loss: 0.717201\n",
      "[17,   299] loss: 0.695827\n",
      "[17,   399] loss: 0.732446\n",
      "[17,   499] loss: 0.704737\n",
      "[17,   599] loss: 0.717048\n",
      "[17,   699] loss: 0.734601\n",
      "[18,    99] loss: 0.726040\n",
      "[18,   199] loss: 0.717201\n",
      "[18,   299] loss: 0.695827\n",
      "[18,   399] loss: 0.732446\n",
      "[18,   499] loss: 0.704737\n",
      "[18,   599] loss: 0.717048\n",
      "[18,   699] loss: 0.734601\n",
      "[19,    99] loss: 0.726040\n",
      "[19,   199] loss: 0.717201\n",
      "[19,   299] loss: 0.695827\n",
      "[19,   399] loss: 0.732446\n",
      "[19,   499] loss: 0.704737\n",
      "[19,   599] loss: 0.717048\n",
      "[19,   699] loss: 0.734601\n",
      "[20,    99] loss: 0.726039\n",
      "[20,   199] loss: 0.717201\n",
      "[20,   299] loss: 0.695827\n",
      "[20,   399] loss: 0.732446\n",
      "[20,   499] loss: 0.704737\n",
      "[20,   599] loss: 0.717048\n",
      "[20,   699] loss: 0.734601\n",
      "[21,    99] loss: 0.726039\n",
      "[21,   199] loss: 0.717201\n",
      "[21,   299] loss: 0.695827\n",
      "[21,   399] loss: 0.732446\n",
      "[21,   499] loss: 0.704737\n",
      "[21,   599] loss: 0.717048\n",
      "[21,   699] loss: 0.734601\n",
      "[22,    99] loss: 0.726039\n",
      "[22,   199] loss: 0.717201\n",
      "[22,   299] loss: 0.695827\n",
      "[22,   399] loss: 0.732446\n",
      "[22,   499] loss: 0.704737\n",
      "[22,   599] loss: 0.717048\n",
      "[22,   699] loss: 0.734601\n",
      "[23,    99] loss: 0.726039\n",
      "[23,   199] loss: 0.717201\n",
      "[23,   299] loss: 0.695827\n",
      "[23,   399] loss: 0.732446\n",
      "[23,   499] loss: 0.704737\n",
      "[23,   599] loss: 0.717048\n",
      "[23,   699] loss: 0.734601\n",
      "[24,    99] loss: 0.726039\n",
      "[24,   199] loss: 0.717201\n",
      "[24,   299] loss: 0.695827\n",
      "[24,   399] loss: 0.732446\n",
      "[24,   499] loss: 0.704737\n",
      "[24,   599] loss: 0.717048\n",
      "[24,   699] loss: 0.734601\n",
      "[25,    99] loss: 0.726039\n",
      "[25,   199] loss: 0.717201\n",
      "[25,   299] loss: 0.695827\n",
      "[25,   399] loss: 0.732446\n",
      "[25,   499] loss: 0.704737\n",
      "[25,   599] loss: 0.717048\n",
      "[25,   699] loss: 0.734601\n",
      "[26,    99] loss: 0.726039\n",
      "[26,   199] loss: 0.717201\n",
      "[26,   299] loss: 0.695827\n",
      "[26,   399] loss: 0.732446\n",
      "[26,   499] loss: 0.704737\n",
      "[26,   599] loss: 0.717048\n",
      "[26,   699] loss: 0.734601\n",
      "[27,    99] loss: 0.726039\n",
      "[27,   199] loss: 0.717201\n",
      "[27,   299] loss: 0.695827\n",
      "[27,   399] loss: 0.732446\n",
      "[27,   499] loss: 0.704737\n",
      "[27,   599] loss: 0.717048\n",
      "[27,   699] loss: 0.734601\n",
      "[28,    99] loss: 0.726039\n",
      "[28,   199] loss: 0.717201\n",
      "[28,   299] loss: 0.695827\n",
      "[28,   399] loss: 0.732446\n",
      "[28,   499] loss: 0.704737\n",
      "[28,   599] loss: 0.717048\n",
      "[28,   699] loss: 0.734601\n",
      "[29,    99] loss: 0.726039\n",
      "[29,   199] loss: 0.717201\n",
      "[29,   299] loss: 0.695827\n",
      "[29,   399] loss: 0.732446\n",
      "[29,   499] loss: 0.704737\n",
      "[29,   599] loss: 0.717048\n",
      "[29,   699] loss: 0.734601\n",
      "[30,    99] loss: 0.726039\n",
      "[30,   199] loss: 0.717201\n",
      "[30,   299] loss: 0.695827\n",
      "[30,   399] loss: 0.732446\n",
      "[30,   499] loss: 0.704737\n",
      "[30,   599] loss: 0.717048\n",
      "[30,   699] loss: 0.734601\n",
      "[31,    99] loss: 0.726039\n",
      "[31,   199] loss: 0.717201\n",
      "[31,   299] loss: 0.695827\n",
      "[31,   399] loss: 0.732446\n",
      "[31,   499] loss: 0.704737\n",
      "[31,   599] loss: 0.717048\n",
      "[31,   699] loss: 0.734601\n",
      "[32,    99] loss: 0.726039\n",
      "[32,   199] loss: 0.717201\n",
      "[32,   299] loss: 0.695827\n",
      "[32,   399] loss: 0.732446\n",
      "[32,   499] loss: 0.704737\n",
      "[32,   599] loss: 0.717048\n",
      "[32,   699] loss: 0.734601\n",
      "[33,    99] loss: 0.726039\n",
      "[33,   199] loss: 0.717201\n",
      "[33,   299] loss: 0.695827\n",
      "[33,   399] loss: 0.732446\n",
      "[33,   499] loss: 0.704737\n",
      "[33,   599] loss: 0.717048\n",
      "[33,   699] loss: 0.734601\n",
      "[34,    99] loss: 0.726039\n",
      "[34,   199] loss: 0.717201\n",
      "[34,   299] loss: 0.695827\n",
      "[34,   399] loss: 0.732446\n",
      "[34,   499] loss: 0.704737\n",
      "[34,   599] loss: 0.717048\n",
      "[34,   699] loss: 0.734601\n",
      "[35,    99] loss: 0.726039\n",
      "[35,   199] loss: 0.717201\n",
      "[35,   299] loss: 0.695827\n",
      "[35,   399] loss: 0.732446\n",
      "[35,   499] loss: 0.704737\n",
      "[35,   599] loss: 0.717048\n",
      "[35,   699] loss: 0.734601\n",
      "[36,    99] loss: 0.726039\n",
      "[36,   199] loss: 0.717201\n",
      "[36,   299] loss: 0.695827\n",
      "[36,   399] loss: 0.732446\n",
      "[36,   499] loss: 0.704737\n",
      "[36,   599] loss: 0.717048\n",
      "[36,   699] loss: 0.734601\n",
      "[37,    99] loss: 0.726039\n",
      "[37,   199] loss: 0.717201\n",
      "[37,   299] loss: 0.695827\n",
      "[37,   399] loss: 0.732446\n",
      "[37,   499] loss: 0.704737\n",
      "[37,   599] loss: 0.717048\n",
      "[37,   699] loss: 0.734601\n",
      "[38,    99] loss: 0.726039\n",
      "[38,   199] loss: 0.717201\n",
      "[38,   299] loss: 0.695827\n",
      "[38,   399] loss: 0.732446\n",
      "[38,   499] loss: 0.704737\n",
      "[38,   599] loss: 0.717048\n",
      "[38,   699] loss: 0.734601\n",
      "[39,    99] loss: 0.726039\n",
      "[39,   199] loss: 0.717201\n",
      "[39,   299] loss: 0.695827\n",
      "[39,   399] loss: 0.732446\n",
      "[39,   499] loss: 0.704737\n",
      "[39,   599] loss: 0.717048\n",
      "[39,   699] loss: 0.734601\n",
      "[40,    99] loss: 0.726039\n",
      "[40,   199] loss: 0.717201\n",
      "[40,   299] loss: 0.695827\n",
      "[40,   399] loss: 0.732446\n",
      "[40,   499] loss: 0.704737\n",
      "[40,   599] loss: 0.717048\n",
      "[40,   699] loss: 0.734601\n",
      "[41,    99] loss: 0.726039\n",
      "[41,   199] loss: 0.717201\n",
      "[41,   299] loss: 0.695827\n",
      "[41,   399] loss: 0.732446\n",
      "[41,   499] loss: 0.704737\n",
      "[41,   599] loss: 0.717048\n",
      "[41,   699] loss: 0.734601\n",
      "[42,    99] loss: 0.726039\n",
      "[42,   199] loss: 0.717201\n",
      "[42,   299] loss: 0.695827\n",
      "[42,   399] loss: 0.732446\n",
      "[42,   499] loss: 0.704737\n",
      "[42,   599] loss: 0.717048\n",
      "[42,   699] loss: 0.734601\n",
      "[43,    99] loss: 0.726039\n",
      "[43,   199] loss: 0.717201\n",
      "[43,   299] loss: 0.695827\n",
      "[43,   399] loss: 0.732446\n",
      "[43,   499] loss: 0.704737\n",
      "[43,   599] loss: 0.717048\n",
      "[43,   699] loss: 0.734601\n",
      "[44,    99] loss: 0.726039\n",
      "[44,   199] loss: 0.717201\n",
      "[44,   299] loss: 0.695827\n",
      "[44,   399] loss: 0.732446\n",
      "[44,   499] loss: 0.704737\n",
      "[44,   599] loss: 0.717048\n",
      "[44,   699] loss: 0.734601\n",
      "[45,    99] loss: 0.726039\n",
      "[45,   199] loss: 0.717201\n",
      "[45,   299] loss: 0.695827\n",
      "[45,   399] loss: 0.732446\n",
      "[45,   499] loss: 0.704737\n",
      "[45,   599] loss: 0.717048\n",
      "[45,   699] loss: 0.734601\n",
      "[46,    99] loss: 0.726039\n",
      "[46,   199] loss: 0.717201\n",
      "[46,   299] loss: 0.695827\n",
      "[46,   399] loss: 0.732446\n",
      "[46,   499] loss: 0.704737\n",
      "[46,   599] loss: 0.717048\n",
      "[46,   699] loss: 0.734601\n",
      "[47,    99] loss: 0.726039\n",
      "[47,   199] loss: 0.717201\n",
      "[47,   299] loss: 0.695827\n",
      "[47,   399] loss: 0.732446\n",
      "[47,   499] loss: 0.704737\n",
      "[47,   599] loss: 0.717048\n",
      "[47,   699] loss: 0.734601\n",
      "[48,    99] loss: 0.726039\n",
      "[48,   199] loss: 0.717201\n",
      "[48,   299] loss: 0.695827\n",
      "[48,   399] loss: 0.732446\n",
      "[48,   499] loss: 0.704737\n",
      "[48,   599] loss: 0.717048\n",
      "[48,   699] loss: 0.734601\n",
      "[49,    99] loss: 0.726039\n",
      "[49,   199] loss: 0.717201\n",
      "[49,   299] loss: 0.695827\n",
      "[49,   399] loss: 0.732446\n",
      "[49,   499] loss: 0.704737\n",
      "[49,   599] loss: 0.717048\n",
      "[49,   699] loss: 0.734601\n",
      "[50,    99] loss: 0.726039\n",
      "[50,   199] loss: 0.717201\n",
      "[50,   299] loss: 0.695827\n",
      "[50,   399] loss: 0.732446\n",
      "[50,   499] loss: 0.704737\n",
      "[50,   599] loss: 0.717048\n",
      "[50,   699] loss: 0.734601\n",
      "[51,    99] loss: 0.726039\n",
      "[51,   199] loss: 0.717201\n",
      "[51,   299] loss: 0.695827\n",
      "[51,   399] loss: 0.732446\n",
      "[51,   499] loss: 0.704737\n",
      "[51,   599] loss: 0.717048\n",
      "[51,   699] loss: 0.734601\n",
      "[52,    99] loss: 0.726039\n",
      "[52,   199] loss: 0.717201\n",
      "[52,   299] loss: 0.695827\n",
      "[52,   399] loss: 0.732446\n",
      "[52,   499] loss: 0.704737\n",
      "[52,   599] loss: 0.717048\n",
      "[52,   699] loss: 0.734601\n",
      "[53,    99] loss: 0.726039\n",
      "[53,   199] loss: 0.717201\n",
      "[53,   299] loss: 0.695827\n",
      "[53,   399] loss: 0.732446\n",
      "[53,   499] loss: 0.704737\n",
      "[53,   599] loss: 0.717048\n",
      "[53,   699] loss: 0.734601\n",
      "[54,    99] loss: 0.726039\n",
      "[54,   199] loss: 0.717201\n",
      "[54,   299] loss: 0.695827\n",
      "[54,   399] loss: 0.732446\n",
      "[54,   499] loss: 0.704737\n",
      "[54,   599] loss: 0.717048\n",
      "[54,   699] loss: 0.734601\n",
      "[55,    99] loss: 0.726039\n",
      "[55,   199] loss: 0.717201\n",
      "[55,   299] loss: 0.695827\n",
      "[55,   399] loss: 0.732446\n",
      "[55,   499] loss: 0.704737\n",
      "[55,   599] loss: 0.717048\n",
      "[55,   699] loss: 0.734601\n",
      "[56,    99] loss: 0.726039\n",
      "[56,   199] loss: 0.717201\n",
      "[56,   299] loss: 0.695827\n",
      "[56,   399] loss: 0.732446\n",
      "[56,   499] loss: 0.704737\n",
      "[56,   599] loss: 0.717048\n",
      "[56,   699] loss: 0.734601\n",
      "[57,    99] loss: 0.726039\n",
      "[57,   199] loss: 0.717201\n",
      "[57,   299] loss: 0.695827\n",
      "[57,   399] loss: 0.732446\n",
      "[57,   499] loss: 0.704737\n",
      "[57,   599] loss: 0.717048\n",
      "[57,   699] loss: 0.734601\n",
      "[58,    99] loss: 0.726039\n",
      "[58,   199] loss: 0.717201\n",
      "[58,   299] loss: 0.695827\n",
      "[58,   399] loss: 0.732446\n",
      "[58,   499] loss: 0.704737\n",
      "[58,   599] loss: 0.717048\n",
      "[58,   699] loss: 0.734601\n",
      "[59,    99] loss: 0.726039\n",
      "[59,   199] loss: 0.717201\n",
      "[59,   299] loss: 0.695827\n",
      "[59,   399] loss: 0.732446\n",
      "[59,   499] loss: 0.704737\n",
      "[59,   599] loss: 0.717048\n",
      "[59,   699] loss: 0.734601\n",
      "[60,    99] loss: 0.726039\n",
      "[60,   199] loss: 0.717201\n",
      "[60,   299] loss: 0.695827\n",
      "[60,   399] loss: 0.732446\n",
      "[60,   499] loss: 0.704737\n",
      "[60,   599] loss: 0.717048\n",
      "[60,   699] loss: 0.734601\n",
      "[61,    99] loss: 0.726039\n",
      "[61,   199] loss: 0.717201\n",
      "[61,   299] loss: 0.695827\n",
      "[61,   399] loss: 0.732446\n",
      "[61,   499] loss: 0.704737\n",
      "[61,   599] loss: 0.717048\n",
      "[61,   699] loss: 0.734601\n",
      "[62,    99] loss: 0.726039\n",
      "[62,   199] loss: 0.717201\n",
      "[62,   299] loss: 0.695827\n",
      "[62,   399] loss: 0.732446\n",
      "[62,   499] loss: 0.704737\n",
      "[62,   599] loss: 0.717048\n",
      "[62,   699] loss: 0.734601\n",
      "[63,    99] loss: 0.726039\n",
      "[63,   199] loss: 0.717201\n",
      "[63,   299] loss: 0.695827\n",
      "[63,   399] loss: 0.732446\n",
      "[63,   499] loss: 0.704737\n",
      "[63,   599] loss: 0.717048\n",
      "[63,   699] loss: 0.734601\n",
      "[64,    99] loss: 0.726039\n",
      "[64,   199] loss: 0.717201\n",
      "[64,   299] loss: 0.695827\n",
      "[64,   399] loss: 0.732446\n",
      "[64,   499] loss: 0.704737\n",
      "[64,   599] loss: 0.717048\n",
      "[64,   699] loss: 0.734601\n",
      "[65,    99] loss: 0.726039\n",
      "[65,   199] loss: 0.717201\n",
      "[65,   299] loss: 0.695827\n",
      "[65,   399] loss: 0.732446\n",
      "[65,   499] loss: 0.704737\n",
      "[65,   599] loss: 0.717048\n",
      "[65,   699] loss: 0.734601\n",
      "[66,    99] loss: 0.726039\n",
      "[66,   199] loss: 0.717201\n",
      "[66,   299] loss: 0.695827\n",
      "[66,   399] loss: 0.732446\n",
      "[66,   499] loss: 0.704737\n",
      "[66,   599] loss: 0.717048\n",
      "[66,   699] loss: 0.734601\n",
      "[67,    99] loss: 0.726039\n",
      "[67,   199] loss: 0.717201\n",
      "[67,   299] loss: 0.695827\n",
      "[67,   399] loss: 0.732446\n",
      "[67,   499] loss: 0.704737\n",
      "[67,   599] loss: 0.717048\n",
      "[67,   699] loss: 0.734601\n",
      "[68,    99] loss: 0.726039\n",
      "[68,   199] loss: 0.717201\n",
      "[68,   299] loss: 0.695827\n",
      "[68,   399] loss: 0.732446\n",
      "[68,   499] loss: 0.704737\n",
      "[68,   599] loss: 0.717048\n",
      "[68,   699] loss: 0.734601\n",
      "[69,    99] loss: 0.726039\n",
      "[69,   199] loss: 0.717201\n",
      "[69,   299] loss: 0.695827\n",
      "[69,   399] loss: 0.732446\n",
      "[69,   499] loss: 0.704737\n",
      "[69,   599] loss: 0.717048\n",
      "[69,   699] loss: 0.734601\n",
      "[70,    99] loss: 0.726039\n",
      "[70,   199] loss: 0.717201\n",
      "[70,   299] loss: 0.695827\n",
      "[70,   399] loss: 0.732446\n",
      "[70,   499] loss: 0.704737\n",
      "[70,   599] loss: 0.717048\n",
      "[70,   699] loss: 0.734601\n",
      "[71,    99] loss: 0.726039\n",
      "[71,   199] loss: 0.717201\n",
      "[71,   299] loss: 0.695827\n",
      "[71,   399] loss: 0.732446\n",
      "[71,   499] loss: 0.704737\n",
      "[71,   599] loss: 0.717048\n",
      "[71,   699] loss: 0.734601\n",
      "[72,    99] loss: 0.726039\n",
      "[72,   199] loss: 0.717201\n",
      "[72,   299] loss: 0.695827\n",
      "[72,   399] loss: 0.732446\n",
      "[72,   499] loss: 0.704737\n",
      "[72,   599] loss: 0.717048\n",
      "[72,   699] loss: 0.734601\n",
      "[73,    99] loss: 0.726039\n",
      "[73,   199] loss: 0.717201\n",
      "[73,   299] loss: 0.695827\n",
      "[73,   399] loss: 0.732446\n",
      "[73,   499] loss: 0.704737\n",
      "[73,   599] loss: 0.717048\n",
      "[73,   699] loss: 0.734601\n",
      "[74,    99] loss: 0.726039\n",
      "[74,   199] loss: 0.717201\n",
      "[74,   299] loss: 0.695827\n",
      "[74,   399] loss: 0.732446\n",
      "[74,   499] loss: 0.704737\n",
      "[74,   599] loss: 0.717048\n",
      "[74,   699] loss: 0.734601\n",
      "[75,    99] loss: 0.726039\n",
      "[75,   199] loss: 0.717201\n",
      "[75,   299] loss: 0.695827\n",
      "[75,   399] loss: 0.732446\n",
      "[75,   499] loss: 0.704737\n",
      "[75,   599] loss: 0.717048\n",
      "[75,   699] loss: 0.734601\n",
      "[76,    99] loss: 0.726039\n",
      "[76,   199] loss: 0.717201\n",
      "[76,   299] loss: 0.695827\n",
      "[76,   399] loss: 0.732446\n",
      "[76,   499] loss: 0.704737\n",
      "[76,   599] loss: 0.717048\n",
      "[76,   699] loss: 0.734601\n",
      "[77,    99] loss: 0.726039\n",
      "[77,   199] loss: 0.717201\n",
      "[77,   299] loss: 0.695827\n",
      "[77,   399] loss: 0.732446\n",
      "[77,   499] loss: 0.704737\n",
      "[77,   599] loss: 0.717048\n",
      "[77,   699] loss: 0.734601\n",
      "[78,    99] loss: 0.726039\n",
      "[78,   199] loss: 0.717201\n",
      "[78,   299] loss: 0.695827\n",
      "[78,   399] loss: 0.732446\n",
      "[78,   499] loss: 0.704737\n",
      "[78,   599] loss: 0.717048\n",
      "[78,   699] loss: 0.734601\n",
      "[79,    99] loss: 0.726039\n",
      "[79,   199] loss: 0.717201\n",
      "[79,   299] loss: 0.695827\n",
      "[79,   399] loss: 0.732446\n",
      "[79,   499] loss: 0.704737\n",
      "[79,   599] loss: 0.717048\n",
      "[79,   699] loss: 0.734601\n",
      "[80,    99] loss: 0.726039\n",
      "[80,   199] loss: 0.717201\n",
      "[80,   299] loss: 0.695827\n",
      "[80,   399] loss: 0.732446\n",
      "[80,   499] loss: 0.704737\n",
      "[80,   599] loss: 0.717048\n",
      "[80,   699] loss: 0.734601\n",
      "[81,    99] loss: 0.726039\n",
      "[81,   199] loss: 0.717201\n",
      "[81,   299] loss: 0.695827\n",
      "[81,   399] loss: 0.732446\n",
      "[81,   499] loss: 0.704737\n",
      "[81,   599] loss: 0.717048\n",
      "[81,   699] loss: 0.734601\n",
      "[82,    99] loss: 0.726039\n",
      "[82,   199] loss: 0.717201\n",
      "[82,   299] loss: 0.695827\n",
      "[82,   399] loss: 0.732446\n",
      "[82,   499] loss: 0.704737\n",
      "[82,   599] loss: 0.717048\n",
      "[82,   699] loss: 0.734601\n",
      "[83,    99] loss: 0.726039\n",
      "[83,   199] loss: 0.717201\n",
      "[83,   299] loss: 0.695827\n",
      "[83,   399] loss: 0.732446\n",
      "[83,   499] loss: 0.704737\n",
      "[83,   599] loss: 0.717048\n",
      "[83,   699] loss: 0.734601\n",
      "[84,    99] loss: 0.726039\n",
      "[84,   199] loss: 0.717201\n",
      "[84,   299] loss: 0.695827\n",
      "[84,   399] loss: 0.732446\n",
      "[84,   499] loss: 0.704737\n",
      "[84,   599] loss: 0.717048\n",
      "[84,   699] loss: 0.734601\n",
      "[85,    99] loss: 0.726039\n",
      "[85,   199] loss: 0.717201\n",
      "[85,   299] loss: 0.695827\n",
      "[85,   399] loss: 0.732446\n",
      "[85,   499] loss: 0.704737\n",
      "[85,   599] loss: 0.717048\n",
      "[85,   699] loss: 0.734601\n",
      "[86,    99] loss: 0.726039\n",
      "[86,   199] loss: 0.717201\n",
      "[86,   299] loss: 0.695827\n",
      "[86,   399] loss: 0.732446\n",
      "[86,   499] loss: 0.704737\n",
      "[86,   599] loss: 0.717048\n",
      "[86,   699] loss: 0.734601\n",
      "[87,    99] loss: 0.726039\n",
      "[87,   199] loss: 0.717201\n",
      "[87,   299] loss: 0.695827\n",
      "[87,   399] loss: 0.732446\n",
      "[87,   499] loss: 0.704737\n",
      "[87,   599] loss: 0.717048\n",
      "[87,   699] loss: 0.734601\n",
      "[88,    99] loss: 0.726039\n",
      "[88,   199] loss: 0.717201\n",
      "[88,   299] loss: 0.695827\n",
      "[88,   399] loss: 0.732446\n",
      "[88,   499] loss: 0.704737\n",
      "[88,   599] loss: 0.717048\n",
      "[88,   699] loss: 0.734601\n",
      "[89,    99] loss: 0.726039\n",
      "[89,   199] loss: 0.717201\n",
      "[89,   299] loss: 0.695827\n",
      "[89,   399] loss: 0.732446\n",
      "[89,   499] loss: 0.704737\n",
      "[89,   599] loss: 0.717048\n",
      "[89,   699] loss: 0.734601\n",
      "[90,    99] loss: 0.726039\n",
      "[90,   199] loss: 0.717201\n",
      "[90,   299] loss: 0.695827\n",
      "[90,   399] loss: 0.732446\n",
      "[90,   499] loss: 0.704737\n",
      "[90,   599] loss: 0.717048\n",
      "[90,   699] loss: 0.734601\n",
      "[91,    99] loss: 0.726039\n",
      "[91,   199] loss: 0.717201\n",
      "[91,   299] loss: 0.695827\n",
      "[91,   399] loss: 0.732446\n",
      "[91,   499] loss: 0.704737\n",
      "[91,   599] loss: 0.717048\n",
      "[91,   699] loss: 0.734601\n",
      "[92,    99] loss: 0.726039\n",
      "[92,   199] loss: 0.717201\n",
      "[92,   299] loss: 0.695827\n",
      "[92,   399] loss: 0.732446\n",
      "[92,   499] loss: 0.704737\n",
      "[92,   599] loss: 0.717048\n",
      "[92,   699] loss: 0.734601\n",
      "[93,    99] loss: 0.726039\n",
      "[93,   199] loss: 0.717201\n",
      "[93,   299] loss: 0.695827\n",
      "[93,   399] loss: 0.732446\n",
      "[93,   499] loss: 0.704737\n",
      "[93,   599] loss: 0.717048\n",
      "[93,   699] loss: 0.734601\n",
      "[94,    99] loss: 0.726039\n",
      "[94,   199] loss: 0.717201\n",
      "[94,   299] loss: 0.695827\n",
      "[94,   399] loss: 0.732446\n",
      "[94,   499] loss: 0.704737\n",
      "[94,   599] loss: 0.717048\n",
      "[94,   699] loss: 0.734601\n",
      "[95,    99] loss: 0.726039\n",
      "[95,   199] loss: 0.717201\n",
      "[95,   299] loss: 0.695827\n",
      "[95,   399] loss: 0.732446\n",
      "[95,   499] loss: 0.704737\n",
      "[95,   599] loss: 0.717048\n",
      "[95,   699] loss: 0.734601\n",
      "[96,    99] loss: 0.726039\n",
      "[96,   199] loss: 0.717201\n",
      "[96,   299] loss: 0.695827\n",
      "[96,   399] loss: 0.732446\n",
      "[96,   499] loss: 0.704737\n",
      "[96,   599] loss: 0.717048\n",
      "[96,   699] loss: 0.734601\n",
      "[97,    99] loss: 0.726039\n",
      "[97,   199] loss: 0.717201\n",
      "[97,   299] loss: 0.695827\n",
      "[97,   399] loss: 0.732446\n",
      "[97,   499] loss: 0.704737\n",
      "[97,   599] loss: 0.717048\n",
      "[97,   699] loss: 0.734601\n",
      "[98,    99] loss: 0.726039\n",
      "[98,   199] loss: 0.717201\n",
      "[98,   299] loss: 0.695827\n",
      "[98,   399] loss: 0.732446\n",
      "[98,   499] loss: 0.704737\n",
      "[98,   599] loss: 0.717048\n",
      "[98,   699] loss: 0.734601\n",
      "[99,    99] loss: 0.726039\n",
      "[99,   199] loss: 0.717201\n",
      "[99,   299] loss: 0.695827\n",
      "[99,   399] loss: 0.732446\n",
      "[99,   499] loss: 0.704737\n",
      "[99,   599] loss: 0.717048\n",
      "[99,   699] loss: 0.734601\n",
      "[100,    99] loss: 0.726039\n",
      "[100,   199] loss: 0.717201\n",
      "[100,   299] loss: 0.695827\n",
      "[100,   399] loss: 0.732446\n",
      "[100,   499] loss: 0.704737\n",
      "[100,   599] loss: 0.717048\n",
      "[100,   699] loss: 0.734601\n",
      "Finished Training\n",
      "[1,    99] loss: 2.295280\n",
      "[1,   199] loss: 1.409356\n",
      "[1,   299] loss: 0.793503\n",
      "[1,   399] loss: 1.148677\n",
      "[1,   499] loss: 0.693334\n",
      "[1,   599] loss: 0.724452\n",
      "[1,   699] loss: 0.718262\n",
      "[2,    99] loss: 0.710416"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2,   199] loss: 0.693954\n",
      "[2,   299] loss: 0.689483\n",
      "[2,   399] loss: 0.735857\n",
      "[2,   499] loss: 0.694806\n",
      "[2,   599] loss: 0.724875\n",
      "[2,   699] loss: 0.718557\n",
      "[3,    99] loss: 0.710589\n",
      "[3,   199] loss: 0.694107\n",
      "[3,   299] loss: 0.689512\n",
      "[3,   399] loss: 0.735962\n",
      "[3,   499] loss: 0.694829\n",
      "[3,   599] loss: 0.724976\n",
      "[3,   699] loss: 0.718637\n",
      "[4,    99] loss: 0.710639\n",
      "[4,   199] loss: 0.694155\n",
      "[4,   299] loss: 0.689521\n",
      "[4,   399] loss: 0.735998\n",
      "[4,   499] loss: 0.694838\n",
      "[4,   599] loss: 0.725013\n",
      "[4,   699] loss: 0.718667\n",
      "[5,    99] loss: 0.710659\n",
      "[5,   199] loss: 0.694174\n",
      "[5,   299] loss: 0.689525\n",
      "[5,   399] loss: 0.736013\n",
      "[5,   499] loss: 0.694841\n",
      "[5,   599] loss: 0.725029\n",
      "[5,   699] loss: 0.718680\n",
      "[6,    99] loss: 0.710667\n",
      "[6,   199] loss: 0.694182\n",
      "[6,   299] loss: 0.689527\n",
      "[6,   399] loss: 0.736020\n",
      "[6,   499] loss: 0.694843\n",
      "[6,   599] loss: 0.725037\n",
      "[6,   699] loss: 0.718687\n",
      "[7,    99] loss: 0.710671\n",
      "[7,   199] loss: 0.694186\n",
      "[7,   299] loss: 0.689528\n",
      "[7,   399] loss: 0.736023\n",
      "[7,   499] loss: 0.694844\n",
      "[7,   599] loss: 0.725040\n",
      "[7,   699] loss: 0.718689\n",
      "[8,    99] loss: 0.710673\n",
      "[8,   199] loss: 0.694188\n",
      "[8,   299] loss: 0.689528\n",
      "[8,   399] loss: 0.736024\n",
      "[8,   499] loss: 0.694844\n",
      "[8,   599] loss: 0.725042\n",
      "[8,   699] loss: 0.718691\n",
      "[9,    99] loss: 0.710674\n",
      "[9,   199] loss: 0.694189\n",
      "[9,   299] loss: 0.689528\n",
      "[9,   399] loss: 0.736025\n",
      "[9,   499] loss: 0.694844\n",
      "[9,   599] loss: 0.725043\n",
      "[9,   699] loss: 0.718692\n",
      "[10,    99] loss: 0.710674\n",
      "[10,   199] loss: 0.694189\n",
      "[10,   299] loss: 0.689528\n",
      "[10,   399] loss: 0.736025\n",
      "[10,   499] loss: 0.694844\n",
      "[10,   599] loss: 0.725043\n",
      "[10,   699] loss: 0.718692\n",
      "[11,    99] loss: 0.710675\n",
      "[11,   199] loss: 0.694189\n",
      "[11,   299] loss: 0.689528\n",
      "[11,   399] loss: 0.736025\n",
      "[11,   499] loss: 0.694845\n",
      "[11,   599] loss: 0.725043\n",
      "[11,   699] loss: 0.718692\n",
      "[12,    99] loss: 0.710675\n",
      "[12,   199] loss: 0.694189\n",
      "[12,   299] loss: 0.689529\n",
      "[12,   399] loss: 0.736025\n",
      "[12,   499] loss: 0.694845\n",
      "[12,   599] loss: 0.725043\n",
      "[12,   699] loss: 0.718692\n",
      "[13,    99] loss: 0.710675\n",
      "[13,   199] loss: 0.694190\n",
      "[13,   299] loss: 0.689529\n",
      "[13,   399] loss: 0.736025\n",
      "[13,   499] loss: 0.694845\n",
      "[13,   599] loss: 0.725043\n",
      "[13,   699] loss: 0.718692\n",
      "[14,    99] loss: 0.710675\n",
      "[14,   199] loss: 0.694190\n",
      "[14,   299] loss: 0.689529\n",
      "[14,   399] loss: 0.736025\n",
      "[14,   499] loss: 0.694845\n",
      "[14,   599] loss: 0.725043\n",
      "[14,   699] loss: 0.718692\n",
      "[15,    99] loss: 0.710675\n",
      "[15,   199] loss: 0.694190\n",
      "[15,   299] loss: 0.689529\n",
      "[15,   399] loss: 0.736025\n",
      "[15,   499] loss: 0.694845\n",
      "[15,   599] loss: 0.725043\n",
      "[15,   699] loss: 0.718692\n",
      "[16,    99] loss: 0.710675\n",
      "[16,   199] loss: 0.694190\n",
      "[16,   299] loss: 0.689529\n",
      "[16,   399] loss: 0.736025\n",
      "[16,   499] loss: 0.694845\n",
      "[16,   599] loss: 0.725043\n",
      "[16,   699] loss: 0.718692\n",
      "[17,    99] loss: 0.710675\n",
      "[17,   199] loss: 0.694190\n",
      "[17,   299] loss: 0.689529\n",
      "[17,   399] loss: 0.736025\n",
      "[17,   499] loss: 0.694845\n",
      "[17,   599] loss: 0.725043\n",
      "[17,   699] loss: 0.718692\n",
      "[18,    99] loss: 0.710675\n",
      "[18,   199] loss: 0.694190\n",
      "[18,   299] loss: 0.689529\n",
      "[18,   399] loss: 0.736025\n",
      "[18,   499] loss: 0.694845\n",
      "[18,   599] loss: 0.725043\n",
      "[18,   699] loss: 0.718692\n",
      "[19,    99] loss: 0.710675\n",
      "[19,   199] loss: 0.694190\n",
      "[19,   299] loss: 0.689529\n",
      "[19,   399] loss: 0.736025\n",
      "[19,   499] loss: 0.694845\n",
      "[19,   599] loss: 0.725043\n",
      "[19,   699] loss: 0.718692\n",
      "[20,    99] loss: 0.710675\n",
      "[20,   199] loss: 0.694190\n",
      "[20,   299] loss: 0.689529\n",
      "[20,   399] loss: 0.736025\n",
      "[20,   499] loss: 0.694845\n",
      "[20,   599] loss: 0.725043\n",
      "[20,   699] loss: 0.718692\n",
      "[21,    99] loss: 0.710675\n",
      "[21,   199] loss: 0.694190\n",
      "[21,   299] loss: 0.689529\n",
      "[21,   399] loss: 0.736025\n",
      "[21,   499] loss: 0.694845\n",
      "[21,   599] loss: 0.725043\n",
      "[21,   699] loss: 0.718692\n",
      "[22,    99] loss: 0.710675\n",
      "[22,   199] loss: 0.694190\n",
      "[22,   299] loss: 0.689529\n",
      "[22,   399] loss: 0.736025\n",
      "[22,   499] loss: 0.694845\n",
      "[22,   599] loss: 0.725043\n",
      "[22,   699] loss: 0.718692\n",
      "[23,    99] loss: 0.710675\n",
      "[23,   199] loss: 0.694190\n",
      "[23,   299] loss: 0.689529\n",
      "[23,   399] loss: 0.736025\n",
      "[23,   499] loss: 0.694845\n",
      "[23,   599] loss: 0.725043\n",
      "[23,   699] loss: 0.718692\n",
      "[24,    99] loss: 0.710675\n",
      "[24,   199] loss: 0.694190\n",
      "[24,   299] loss: 0.689529\n",
      "[24,   399] loss: 0.736025\n",
      "[24,   499] loss: 0.694845\n",
      "[24,   599] loss: 0.725043\n",
      "[24,   699] loss: 0.718692\n",
      "[25,    99] loss: 0.710675\n",
      "[25,   199] loss: 0.694190\n",
      "[25,   299] loss: 0.689529\n",
      "[25,   399] loss: 0.736025\n",
      "[25,   499] loss: 0.694845\n",
      "[25,   599] loss: 0.725043\n",
      "[25,   699] loss: 0.718692\n",
      "[26,    99] loss: 0.710675\n",
      "[26,   199] loss: 0.694190\n",
      "[26,   299] loss: 0.689529\n",
      "[26,   399] loss: 0.736025\n",
      "[26,   499] loss: 0.694845\n",
      "[26,   599] loss: 0.725043\n",
      "[26,   699] loss: 0.718692\n",
      "[27,    99] loss: 0.710675\n",
      "[27,   199] loss: 0.694190\n",
      "[27,   299] loss: 0.689529\n",
      "[27,   399] loss: 0.736025\n",
      "[27,   499] loss: 0.694845\n",
      "[27,   599] loss: 0.725043\n",
      "[27,   699] loss: 0.718692\n",
      "[28,    99] loss: 0.710675\n",
      "[28,   199] loss: 0.694190\n",
      "[28,   299] loss: 0.689529\n",
      "[28,   399] loss: 0.736025\n",
      "[28,   499] loss: 0.694845\n",
      "[28,   599] loss: 0.725043\n",
      "[28,   699] loss: 0.718692\n",
      "[29,    99] loss: 0.710675\n",
      "[29,   199] loss: 0.694190\n",
      "[29,   299] loss: 0.689529\n",
      "[29,   399] loss: 0.736025\n",
      "[29,   499] loss: 0.694845\n",
      "[29,   599] loss: 0.725043\n",
      "[29,   699] loss: 0.718692\n",
      "[30,    99] loss: 0.710675\n",
      "[30,   199] loss: 0.694190\n",
      "[30,   299] loss: 0.689529\n",
      "[30,   399] loss: 0.736025\n",
      "[30,   499] loss: 0.694845\n",
      "[30,   599] loss: 0.725043\n",
      "[30,   699] loss: 0.718692\n",
      "[31,    99] loss: 0.710675\n",
      "[31,   199] loss: 0.694190\n",
      "[31,   299] loss: 0.689529\n",
      "[31,   399] loss: 0.736025\n",
      "[31,   499] loss: 0.694845\n",
      "[31,   599] loss: 0.725043\n",
      "[31,   699] loss: 0.718692\n",
      "[32,    99] loss: 0.710675\n",
      "[32,   199] loss: 0.694190\n",
      "[32,   299] loss: 0.689529\n",
      "[32,   399] loss: 0.736025\n",
      "[32,   499] loss: 0.694845\n",
      "[32,   599] loss: 0.725043\n",
      "[32,   699] loss: 0.718692\n",
      "[33,    99] loss: 0.710675\n",
      "[33,   199] loss: 0.694190\n",
      "[33,   299] loss: 0.689529\n",
      "[33,   399] loss: 0.736025\n",
      "[33,   499] loss: 0.694845\n",
      "[33,   599] loss: 0.725043\n",
      "[33,   699] loss: 0.718692\n",
      "[34,    99] loss: 0.710675\n",
      "[34,   199] loss: 0.694190\n",
      "[34,   299] loss: 0.689529\n",
      "[34,   399] loss: 0.736025\n",
      "[34,   499] loss: 0.694845\n",
      "[34,   599] loss: 0.725043\n",
      "[34,   699] loss: 0.718692\n",
      "[35,    99] loss: 0.710675\n",
      "[35,   199] loss: 0.694190\n",
      "[35,   299] loss: 0.689529\n",
      "[35,   399] loss: 0.736025\n",
      "[35,   499] loss: 0.694845\n",
      "[35,   599] loss: 0.725043\n",
      "[35,   699] loss: 0.718692\n",
      "[36,    99] loss: 0.710675\n",
      "[36,   199] loss: 0.694190\n",
      "[36,   299] loss: 0.689529\n",
      "[36,   399] loss: 0.736025\n",
      "[36,   499] loss: 0.694845\n",
      "[36,   599] loss: 0.725043\n",
      "[36,   699] loss: 0.718692\n",
      "[37,    99] loss: 0.710675\n",
      "[37,   199] loss: 0.694190\n",
      "[37,   299] loss: 0.689529\n",
      "[37,   399] loss: 0.736025\n",
      "[37,   499] loss: 0.694845\n",
      "[37,   599] loss: 0.725043\n",
      "[37,   699] loss: 0.718692\n",
      "[38,    99] loss: 0.710675\n",
      "[38,   199] loss: 0.694190\n",
      "[38,   299] loss: 0.689529\n",
      "[38,   399] loss: 0.736025\n",
      "[38,   499] loss: 0.694845\n",
      "[38,   599] loss: 0.725043\n",
      "[38,   699] loss: 0.718692\n",
      "[39,    99] loss: 0.710675\n",
      "[39,   199] loss: 0.694190\n",
      "[39,   299] loss: 0.689529\n",
      "[39,   399] loss: 0.736025\n",
      "[39,   499] loss: 0.694845\n",
      "[39,   599] loss: 0.725043\n",
      "[39,   699] loss: 0.718692\n",
      "[40,    99] loss: 0.710675\n",
      "[40,   199] loss: 0.694190\n",
      "[40,   299] loss: 0.689529\n",
      "[40,   399] loss: 0.736025\n",
      "[40,   499] loss: 0.694845\n",
      "[40,   599] loss: 0.725043\n",
      "[40,   699] loss: 0.718692\n",
      "[41,    99] loss: 0.710675\n",
      "[41,   199] loss: 0.694190\n",
      "[41,   299] loss: 0.689529\n",
      "[41,   399] loss: 0.736025\n",
      "[41,   499] loss: 0.694845\n",
      "[41,   599] loss: 0.725043\n",
      "[41,   699] loss: 0.718692\n",
      "[42,    99] loss: 0.710675\n",
      "[42,   199] loss: 0.694190\n",
      "[42,   299] loss: 0.689529\n",
      "[42,   399] loss: 0.736025\n",
      "[42,   499] loss: 0.694845\n",
      "[42,   599] loss: 0.725043\n",
      "[42,   699] loss: 0.718692\n",
      "[43,    99] loss: 0.710675\n",
      "[43,   199] loss: 0.694190\n",
      "[43,   299] loss: 0.689529\n",
      "[43,   399] loss: 0.736025\n",
      "[43,   499] loss: 0.694845\n",
      "[43,   599] loss: 0.725043\n",
      "[43,   699] loss: 0.718692\n",
      "[44,    99] loss: 0.710675\n",
      "[44,   199] loss: 0.694190\n",
      "[44,   299] loss: 0.689529\n",
      "[44,   399] loss: 0.736025\n",
      "[44,   499] loss: 0.694845\n",
      "[44,   599] loss: 0.725043\n",
      "[44,   699] loss: 0.718692\n",
      "[45,    99] loss: 0.710675\n",
      "[45,   199] loss: 0.694190\n",
      "[45,   299] loss: 0.689529\n",
      "[45,   399] loss: 0.736025\n",
      "[45,   499] loss: 0.694845\n",
      "[45,   599] loss: 0.725043\n",
      "[45,   699] loss: 0.718692\n",
      "[46,    99] loss: 0.710675\n",
      "[46,   199] loss: 0.694190\n",
      "[46,   299] loss: 0.689529\n",
      "[46,   399] loss: 0.736025\n",
      "[46,   499] loss: 0.694845\n",
      "[46,   599] loss: 0.725043\n",
      "[46,   699] loss: 0.718692\n",
      "[47,    99] loss: 0.710675\n",
      "[47,   199] loss: 0.694190\n",
      "[47,   299] loss: 0.689529\n",
      "[47,   399] loss: 0.736025\n",
      "[47,   499] loss: 0.694845\n",
      "[47,   599] loss: 0.725043\n",
      "[47,   699] loss: 0.718692\n",
      "[48,    99] loss: 0.710675\n",
      "[48,   199] loss: 0.694190\n",
      "[48,   299] loss: 0.689529\n",
      "[48,   399] loss: 0.736025\n",
      "[48,   499] loss: 0.694845\n",
      "[48,   599] loss: 0.725043\n",
      "[48,   699] loss: 0.718692\n",
      "[49,    99] loss: 0.710675\n",
      "[49,   199] loss: 0.694190\n",
      "[49,   299] loss: 0.689529\n",
      "[49,   399] loss: 0.736025\n",
      "[49,   499] loss: 0.694845\n",
      "[49,   599] loss: 0.725043\n",
      "[49,   699] loss: 0.718692\n",
      "[50,    99] loss: 0.710675\n",
      "[50,   199] loss: 0.694190\n",
      "[50,   299] loss: 0.689529\n",
      "[50,   399] loss: 0.736025\n",
      "[50,   499] loss: 0.694845\n",
      "[50,   599] loss: 0.725043\n",
      "[50,   699] loss: 0.718692\n",
      "[51,    99] loss: 0.710675\n",
      "[51,   199] loss: 0.694190\n",
      "[51,   299] loss: 0.689529\n",
      "[51,   399] loss: 0.736025\n",
      "[51,   499] loss: 0.694845\n",
      "[51,   599] loss: 0.725043\n",
      "[51,   699] loss: 0.718692\n",
      "[52,    99] loss: 0.710675\n",
      "[52,   199] loss: 0.694190\n",
      "[52,   299] loss: 0.689529\n",
      "[52,   399] loss: 0.736025\n",
      "[52,   499] loss: 0.694845\n",
      "[52,   599] loss: 0.725043\n",
      "[52,   699] loss: 0.718692\n",
      "[53,    99] loss: 0.710675\n",
      "[53,   199] loss: 0.694190\n",
      "[53,   299] loss: 0.689529\n",
      "[53,   399] loss: 0.736025\n",
      "[53,   499] loss: 0.694845\n",
      "[53,   599] loss: 0.725043\n",
      "[53,   699] loss: 0.718692\n",
      "[54,    99] loss: 0.710675\n",
      "[54,   199] loss: 0.694190\n",
      "[54,   299] loss: 0.689529\n",
      "[54,   399] loss: 0.736025\n",
      "[54,   499] loss: 0.694845\n",
      "[54,   599] loss: 0.725043\n",
      "[54,   699] loss: 0.718692\n",
      "[55,    99] loss: 0.710675\n",
      "[55,   199] loss: 0.694190\n",
      "[55,   299] loss: 0.689529\n",
      "[55,   399] loss: 0.736025\n",
      "[55,   499] loss: 0.694845\n",
      "[55,   599] loss: 0.725043\n",
      "[55,   699] loss: 0.718692\n",
      "[56,    99] loss: 0.710675\n",
      "[56,   199] loss: 0.694190\n",
      "[56,   299] loss: 0.689529\n",
      "[56,   399] loss: 0.736025\n",
      "[56,   499] loss: 0.694845\n",
      "[56,   599] loss: 0.725043\n",
      "[56,   699] loss: 0.718692\n",
      "[57,    99] loss: 0.710675\n",
      "[57,   199] loss: 0.694190\n",
      "[57,   299] loss: 0.689529\n",
      "[57,   399] loss: 0.736025\n",
      "[57,   499] loss: 0.694845\n",
      "[57,   599] loss: 0.725043\n",
      "[57,   699] loss: 0.718692\n",
      "[58,    99] loss: 0.710675\n",
      "[58,   199] loss: 0.694190\n",
      "[58,   299] loss: 0.689529\n",
      "[58,   399] loss: 0.736025\n",
      "[58,   499] loss: 0.694845\n",
      "[58,   599] loss: 0.725043\n",
      "[58,   699] loss: 0.718692\n",
      "[59,    99] loss: 0.710675\n",
      "[59,   199] loss: 0.694190\n",
      "[59,   299] loss: 0.689529\n",
      "[59,   399] loss: 0.736025\n",
      "[59,   499] loss: 0.694845\n",
      "[59,   599] loss: 0.725043\n",
      "[59,   699] loss: 0.718692\n",
      "[60,    99] loss: 0.710675\n",
      "[60,   199] loss: 0.694190\n",
      "[60,   299] loss: 0.689529\n",
      "[60,   399] loss: 0.736025\n",
      "[60,   499] loss: 0.694845\n",
      "[60,   599] loss: 0.725043\n",
      "[60,   699] loss: 0.718692\n",
      "[61,    99] loss: 0.710675\n",
      "[61,   199] loss: 0.694190\n",
      "[61,   299] loss: 0.689529\n",
      "[61,   399] loss: 0.736025\n",
      "[61,   499] loss: 0.694845\n",
      "[61,   599] loss: 0.725043\n",
      "[61,   699] loss: 0.718692\n",
      "[62,    99] loss: 0.710675\n",
      "[62,   199] loss: 0.694190\n",
      "[62,   299] loss: 0.689529\n",
      "[62,   399] loss: 0.736025\n",
      "[62,   499] loss: 0.694845\n",
      "[62,   599] loss: 0.725043\n",
      "[62,   699] loss: 0.718692\n",
      "[63,    99] loss: 0.710675\n",
      "[63,   199] loss: 0.694190\n",
      "[63,   299] loss: 0.689529\n",
      "[63,   399] loss: 0.736025\n",
      "[63,   499] loss: 0.694845\n",
      "[63,   599] loss: 0.725043\n",
      "[63,   699] loss: 0.718692\n",
      "[64,    99] loss: 0.710675\n",
      "[64,   199] loss: 0.694190\n",
      "[64,   299] loss: 0.689529\n",
      "[64,   399] loss: 0.736025\n",
      "[64,   499] loss: 0.694845\n",
      "[64,   599] loss: 0.725043\n",
      "[64,   699] loss: 0.718692\n",
      "[65,    99] loss: 0.710675\n",
      "[65,   199] loss: 0.694190\n",
      "[65,   299] loss: 0.689529\n",
      "[65,   399] loss: 0.736025\n",
      "[65,   499] loss: 0.694845\n",
      "[65,   599] loss: 0.725043\n",
      "[65,   699] loss: 0.718692\n",
      "[66,    99] loss: 0.710675\n",
      "[66,   199] loss: 0.694190\n",
      "[66,   299] loss: 0.689529\n",
      "[66,   399] loss: 0.736025\n",
      "[66,   499] loss: 0.694845\n",
      "[66,   599] loss: 0.725043\n",
      "[66,   699] loss: 0.718692\n",
      "[67,    99] loss: 0.710675\n",
      "[67,   199] loss: 0.694190\n",
      "[67,   299] loss: 0.689529\n",
      "[67,   399] loss: 0.736025\n",
      "[67,   499] loss: 0.694845\n",
      "[67,   599] loss: 0.725043\n",
      "[67,   699] loss: 0.718692\n",
      "[68,    99] loss: 0.710675\n",
      "[68,   199] loss: 0.694190\n",
      "[68,   299] loss: 0.689529\n",
      "[68,   399] loss: 0.736025\n",
      "[68,   499] loss: 0.694845\n",
      "[68,   599] loss: 0.725043\n",
      "[68,   699] loss: 0.718692\n",
      "[69,    99] loss: 0.710675\n",
      "[69,   199] loss: 0.694190\n",
      "[69,   299] loss: 0.689529\n",
      "[69,   399] loss: 0.736025\n",
      "[69,   499] loss: 0.694845\n",
      "[69,   599] loss: 0.725043\n",
      "[69,   699] loss: 0.718692\n",
      "[70,    99] loss: 0.710675\n",
      "[70,   199] loss: 0.694190\n",
      "[70,   299] loss: 0.689529\n",
      "[70,   399] loss: 0.736025\n",
      "[70,   499] loss: 0.694845\n",
      "[70,   599] loss: 0.725043\n",
      "[70,   699] loss: 0.718692\n",
      "[71,    99] loss: 0.710675\n",
      "[71,   199] loss: 0.694190\n",
      "[71,   299] loss: 0.689529\n",
      "[71,   399] loss: 0.736025\n",
      "[71,   499] loss: 0.694845\n",
      "[71,   599] loss: 0.725043\n",
      "[71,   699] loss: 0.718692\n",
      "[72,    99] loss: 0.710675\n",
      "[72,   199] loss: 0.694190\n",
      "[72,   299] loss: 0.689529\n",
      "[72,   399] loss: 0.736025\n",
      "[72,   499] loss: 0.694845\n",
      "[72,   599] loss: 0.725043\n",
      "[72,   699] loss: 0.718692\n",
      "[73,    99] loss: 0.710675\n",
      "[73,   199] loss: 0.694190\n",
      "[73,   299] loss: 0.689529\n",
      "[73,   399] loss: 0.736025\n",
      "[73,   499] loss: 0.694845\n",
      "[73,   599] loss: 0.725043\n",
      "[73,   699] loss: 0.718692\n",
      "[74,    99] loss: 0.710675\n",
      "[74,   199] loss: 0.694190\n",
      "[74,   299] loss: 0.689529\n",
      "[74,   399] loss: 0.736025\n",
      "[74,   499] loss: 0.694845\n",
      "[74,   599] loss: 0.725043\n",
      "[74,   699] loss: 0.718692\n",
      "[75,    99] loss: 0.710675\n",
      "[75,   199] loss: 0.694190\n",
      "[75,   299] loss: 0.689529\n",
      "[75,   399] loss: 0.736025\n",
      "[75,   499] loss: 0.694845\n",
      "[75,   599] loss: 0.725043\n",
      "[75,   699] loss: 0.718692\n",
      "[76,    99] loss: 0.710675\n",
      "[76,   199] loss: 0.694190\n",
      "[76,   299] loss: 0.689529\n",
      "[76,   399] loss: 0.736025\n",
      "[76,   499] loss: 0.694845\n",
      "[76,   599] loss: 0.725043\n",
      "[76,   699] loss: 0.718692\n",
      "[77,    99] loss: 0.710675\n",
      "[77,   199] loss: 0.694190\n",
      "[77,   299] loss: 0.689529\n",
      "[77,   399] loss: 0.736025\n",
      "[77,   499] loss: 0.694845\n",
      "[77,   599] loss: 0.725043\n",
      "[77,   699] loss: 0.718692\n",
      "[78,    99] loss: 0.710675\n",
      "[78,   199] loss: 0.694190\n",
      "[78,   299] loss: 0.689529\n",
      "[78,   399] loss: 0.736025\n",
      "[78,   499] loss: 0.694845\n",
      "[78,   599] loss: 0.725043\n",
      "[78,   699] loss: 0.718692\n",
      "[79,    99] loss: 0.710675\n",
      "[79,   199] loss: 0.694190\n",
      "[79,   299] loss: 0.689529\n",
      "[79,   399] loss: 0.736025\n",
      "[79,   499] loss: 0.694845\n",
      "[79,   599] loss: 0.725043\n",
      "[79,   699] loss: 0.718692\n",
      "[80,    99] loss: 0.710675\n",
      "[80,   199] loss: 0.694190\n",
      "[80,   299] loss: 0.689529\n",
      "[80,   399] loss: 0.736025\n",
      "[80,   499] loss: 0.694845\n",
      "[80,   599] loss: 0.725043\n",
      "[80,   699] loss: 0.718692\n",
      "[81,    99] loss: 0.710675\n",
      "[81,   199] loss: 0.694190\n",
      "[81,   299] loss: 0.689529\n",
      "[81,   399] loss: 0.736025\n",
      "[81,   499] loss: 0.694845\n",
      "[81,   599] loss: 0.725043\n",
      "[81,   699] loss: 0.718692\n",
      "[82,    99] loss: 0.710675\n",
      "[82,   199] loss: 0.694190\n",
      "[82,   299] loss: 0.689529\n",
      "[82,   399] loss: 0.736025\n",
      "[82,   499] loss: 0.694845\n",
      "[82,   599] loss: 0.725043\n",
      "[82,   699] loss: 0.718692\n",
      "[83,    99] loss: 0.710675\n",
      "[83,   199] loss: 0.694190\n",
      "[83,   299] loss: 0.689529\n",
      "[83,   399] loss: 0.736025\n",
      "[83,   499] loss: 0.694845\n",
      "[83,   599] loss: 0.725043\n",
      "[83,   699] loss: 0.718692\n",
      "[84,    99] loss: 0.710675\n",
      "[84,   199] loss: 0.694190\n",
      "[84,   299] loss: 0.689529\n",
      "[84,   399] loss: 0.736025\n",
      "[84,   499] loss: 0.694845\n",
      "[84,   599] loss: 0.725043\n",
      "[84,   699] loss: 0.718692\n",
      "[85,    99] loss: 0.710675\n",
      "[85,   199] loss: 0.694190\n",
      "[85,   299] loss: 0.689529\n",
      "[85,   399] loss: 0.736025\n",
      "[85,   499] loss: 0.694845\n",
      "[85,   599] loss: 0.725043\n",
      "[85,   699] loss: 0.718692\n",
      "[86,    99] loss: 0.710675\n",
      "[86,   199] loss: 0.694190\n",
      "[86,   299] loss: 0.689529\n",
      "[86,   399] loss: 0.736025\n",
      "[86,   499] loss: 0.694845\n",
      "[86,   599] loss: 0.725043\n",
      "[86,   699] loss: 0.718692\n",
      "[87,    99] loss: 0.710675\n",
      "[87,   199] loss: 0.694190\n",
      "[87,   299] loss: 0.689529\n",
      "[87,   399] loss: 0.736025\n",
      "[87,   499] loss: 0.694845\n",
      "[87,   599] loss: 0.725043\n",
      "[87,   699] loss: 0.718692\n",
      "[88,    99] loss: 0.710675\n",
      "[88,   199] loss: 0.694190\n",
      "[88,   299] loss: 0.689529\n",
      "[88,   399] loss: 0.736025\n",
      "[88,   499] loss: 0.694845\n",
      "[88,   599] loss: 0.725043\n",
      "[88,   699] loss: 0.718692\n",
      "[89,    99] loss: 0.710675\n",
      "[89,   199] loss: 0.694190\n",
      "[89,   299] loss: 0.689529\n",
      "[89,   399] loss: 0.736025\n",
      "[89,   499] loss: 0.694845\n",
      "[89,   599] loss: 0.725043\n",
      "[89,   699] loss: 0.718692\n",
      "[90,    99] loss: 0.710675\n",
      "[90,   199] loss: 0.694190\n",
      "[90,   299] loss: 0.689529\n",
      "[90,   399] loss: 0.736025\n",
      "[90,   499] loss: 0.694845\n",
      "[90,   599] loss: 0.725043\n",
      "[90,   699] loss: 0.718692\n",
      "[91,    99] loss: 0.710675\n",
      "[91,   199] loss: 0.694190\n",
      "[91,   299] loss: 0.689529\n",
      "[91,   399] loss: 0.736025\n",
      "[91,   499] loss: 0.694845\n",
      "[91,   599] loss: 0.725043\n",
      "[91,   699] loss: 0.718692\n",
      "[92,    99] loss: 0.710675\n",
      "[92,   199] loss: 0.694190\n",
      "[92,   299] loss: 0.689529\n",
      "[92,   399] loss: 0.736025\n",
      "[92,   499] loss: 0.694845\n",
      "[92,   599] loss: 0.725043\n",
      "[92,   699] loss: 0.718692\n",
      "[93,    99] loss: 0.710675\n",
      "[93,   199] loss: 0.694190\n",
      "[93,   299] loss: 0.689529\n",
      "[93,   399] loss: 0.736025\n",
      "[93,   499] loss: 0.694845\n",
      "[93,   599] loss: 0.725043\n",
      "[93,   699] loss: 0.718692\n",
      "[94,    99] loss: 0.710675\n",
      "[94,   199] loss: 0.694190\n",
      "[94,   299] loss: 0.689529\n",
      "[94,   399] loss: 0.736025\n",
      "[94,   499] loss: 0.694845\n",
      "[94,   599] loss: 0.725043\n",
      "[94,   699] loss: 0.718692\n",
      "[95,    99] loss: 0.710675\n",
      "[95,   199] loss: 0.694190\n",
      "[95,   299] loss: 0.689529\n",
      "[95,   399] loss: 0.736025\n",
      "[95,   499] loss: 0.694845\n",
      "[95,   599] loss: 0.725043\n",
      "[95,   699] loss: 0.718692\n",
      "[96,    99] loss: 0.710675\n",
      "[96,   199] loss: 0.694190\n",
      "[96,   299] loss: 0.689529\n",
      "[96,   399] loss: 0.736025\n",
      "[96,   499] loss: 0.694845\n",
      "[96,   599] loss: 0.725043\n",
      "[96,   699] loss: 0.718692\n",
      "[97,    99] loss: 0.710675\n",
      "[97,   199] loss: 0.694190\n",
      "[97,   299] loss: 0.689529\n",
      "[97,   399] loss: 0.736025\n",
      "[97,   499] loss: 0.694845\n",
      "[97,   599] loss: 0.725043\n",
      "[97,   699] loss: 0.718692\n",
      "[98,    99] loss: 0.710675\n",
      "[98,   199] loss: 0.694190\n",
      "[98,   299] loss: 0.689529\n",
      "[98,   399] loss: 0.736025\n",
      "[98,   499] loss: 0.694845\n",
      "[98,   599] loss: 0.725043\n",
      "[98,   699] loss: 0.718692\n",
      "[99,    99] loss: 0.710675\n",
      "[99,   199] loss: 0.694190\n",
      "[99,   299] loss: 0.689529\n",
      "[99,   399] loss: 0.736025\n",
      "[99,   499] loss: 0.694845\n",
      "[99,   599] loss: 0.725043\n",
      "[99,   699] loss: 0.718692\n",
      "[100,    99] loss: 0.710675\n",
      "[100,   199] loss: 0.694190\n",
      "[100,   299] loss: 0.689529\n",
      "[100,   399] loss: 0.736025\n",
      "[100,   499] loss: 0.694845\n",
      "[100,   599] loss: 0.725043\n",
      "[100,   699] loss: 0.718692\n",
      "Finished Training\n",
      "[1,    99] loss: 1.083055\n",
      "[1,   199] loss: 0.747205\n",
      "[1,   299] loss: 0.708582\n",
      "[1,   399] loss: 0.743254\n",
      "[1,   499] loss: 0.722563\n",
      "[1,   599] loss: 0.714372\n",
      "[1,   699] loss: 0.716821\n",
      "[2,    99] loss: 0.710755"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2,   199] loss: 0.724341\n",
      "[2,   299] loss: 0.709213\n",
      "[2,   399] loss: 0.743969\n",
      "[2,   499] loss: 0.722944\n",
      "[2,   599] loss: 0.714560\n",
      "[2,   699] loss: 0.716800\n",
      "[3,    99] loss: 0.710805\n",
      "[3,   199] loss: 0.724330\n",
      "[3,   299] loss: 0.709290\n",
      "[3,   399] loss: 0.744085\n",
      "[3,   499] loss: 0.723024\n",
      "[3,   599] loss: 0.714605\n",
      "[3,   699] loss: 0.716795\n",
      "[4,    99] loss: 0.710821\n",
      "[4,   199] loss: 0.724328\n",
      "[4,   299] loss: 0.709315\n",
      "[4,   399] loss: 0.744125\n",
      "[4,   499] loss: 0.723052\n",
      "[4,   599] loss: 0.714621\n",
      "[4,   699] loss: 0.716793\n",
      "[5,    99] loss: 0.710827\n",
      "[5,   199] loss: 0.724327\n",
      "[5,   299] loss: 0.709325\n",
      "[5,   399] loss: 0.744141\n",
      "[5,   499] loss: 0.723065\n",
      "[5,   599] loss: 0.714629\n",
      "[5,   699] loss: 0.716792\n",
      "[6,    99] loss: 0.710830\n",
      "[6,   199] loss: 0.724326\n",
      "[6,   299] loss: 0.709330\n",
      "[6,   399] loss: 0.744149\n",
      "[6,   499] loss: 0.723070\n",
      "[6,   599] loss: 0.714632\n",
      "[6,   699] loss: 0.716792\n",
      "[7,    99] loss: 0.710831\n",
      "[7,   199] loss: 0.724326\n",
      "[7,   299] loss: 0.709332\n",
      "[7,   399] loss: 0.744152\n",
      "[7,   499] loss: 0.723073\n",
      "[7,   599] loss: 0.714634\n",
      "[7,   699] loss: 0.716792\n",
      "[8,    99] loss: 0.710832\n",
      "[8,   199] loss: 0.724326\n",
      "[8,   299] loss: 0.709333\n",
      "[8,   399] loss: 0.744154\n",
      "[8,   499] loss: 0.723074\n",
      "[8,   599] loss: 0.714634\n",
      "[8,   699] loss: 0.716792\n",
      "[9,    99] loss: 0.710832\n",
      "[9,   199] loss: 0.724326\n",
      "[9,   299] loss: 0.709334\n",
      "[9,   399] loss: 0.744155\n",
      "[9,   499] loss: 0.723075\n",
      "[9,   599] loss: 0.714635\n",
      "[9,   699] loss: 0.716792\n",
      "[10,    99] loss: 0.710832\n",
      "[10,   199] loss: 0.724326\n",
      "[10,   299] loss: 0.709334\n",
      "[10,   399] loss: 0.744155\n",
      "[10,   499] loss: 0.723075\n",
      "[10,   599] loss: 0.714635\n",
      "[10,   699] loss: 0.716792\n",
      "[11,    99] loss: 0.710832\n",
      "[11,   199] loss: 0.724326\n",
      "[11,   299] loss: 0.709334\n",
      "[11,   399] loss: 0.744155\n",
      "[11,   499] loss: 0.723075\n",
      "[11,   599] loss: 0.714635\n",
      "[11,   699] loss: 0.716792\n",
      "[12,    99] loss: 0.710832\n",
      "[12,   199] loss: 0.724326\n",
      "[12,   299] loss: 0.709334\n",
      "[12,   399] loss: 0.744155\n",
      "[12,   499] loss: 0.723075\n",
      "[12,   599] loss: 0.714635\n",
      "[12,   699] loss: 0.716792\n",
      "[13,    99] loss: 0.710832\n",
      "[13,   199] loss: 0.724326\n",
      "[13,   299] loss: 0.709334\n",
      "[13,   399] loss: 0.744155\n",
      "[13,   499] loss: 0.723075\n",
      "[13,   599] loss: 0.714635\n",
      "[13,   699] loss: 0.716792\n",
      "[14,    99] loss: 0.710832\n",
      "[14,   199] loss: 0.724326\n",
      "[14,   299] loss: 0.709334\n",
      "[14,   399] loss: 0.744155\n",
      "[14,   499] loss: 0.723076\n",
      "[14,   599] loss: 0.714635\n",
      "[14,   699] loss: 0.716792\n",
      "[15,    99] loss: 0.710832\n",
      "[15,   199] loss: 0.724326\n",
      "[15,   299] loss: 0.709334\n",
      "[15,   399] loss: 0.744155\n",
      "[15,   499] loss: 0.723076\n",
      "[15,   599] loss: 0.714635\n",
      "[15,   699] loss: 0.716792\n",
      "[16,    99] loss: 0.710832\n",
      "[16,   199] loss: 0.724326\n",
      "[16,   299] loss: 0.709334\n",
      "[16,   399] loss: 0.744155\n",
      "[16,   499] loss: 0.723076\n",
      "[16,   599] loss: 0.714635\n",
      "[16,   699] loss: 0.716792\n",
      "[17,    99] loss: 0.710832\n",
      "[17,   199] loss: 0.724326\n",
      "[17,   299] loss: 0.709334\n",
      "[17,   399] loss: 0.744155\n",
      "[17,   499] loss: 0.723076\n",
      "[17,   599] loss: 0.714635\n",
      "[17,   699] loss: 0.716792\n",
      "[18,    99] loss: 0.710832\n",
      "[18,   199] loss: 0.724326\n",
      "[18,   299] loss: 0.709334\n",
      "[18,   399] loss: 0.744155\n",
      "[18,   499] loss: 0.723076\n",
      "[18,   599] loss: 0.714635\n",
      "[18,   699] loss: 0.716792\n",
      "[19,    99] loss: 0.710832\n",
      "[19,   199] loss: 0.724326\n",
      "[19,   299] loss: 0.709334\n",
      "[19,   399] loss: 0.744155\n",
      "[19,   499] loss: 0.723076\n",
      "[19,   599] loss: 0.714635\n",
      "[19,   699] loss: 0.716792\n",
      "[20,    99] loss: 0.710832\n",
      "[20,   199] loss: 0.724326\n",
      "[20,   299] loss: 0.709334\n",
      "[20,   399] loss: 0.744155\n",
      "[20,   499] loss: 0.723076\n",
      "[20,   599] loss: 0.714635\n",
      "[20,   699] loss: 0.716792\n",
      "[21,    99] loss: 0.710832\n",
      "[21,   199] loss: 0.724326\n",
      "[21,   299] loss: 0.709334\n",
      "[21,   399] loss: 0.744155\n",
      "[21,   499] loss: 0.723076\n",
      "[21,   599] loss: 0.714635\n",
      "[21,   699] loss: 0.716792\n",
      "[22,    99] loss: 0.710832\n",
      "[22,   199] loss: 0.724326\n",
      "[22,   299] loss: 0.709334\n",
      "[22,   399] loss: 0.744155\n",
      "[22,   499] loss: 0.723076\n",
      "[22,   599] loss: 0.714635\n",
      "[22,   699] loss: 0.716792\n",
      "[23,    99] loss: 0.710832\n",
      "[23,   199] loss: 0.724326\n",
      "[23,   299] loss: 0.709334\n",
      "[23,   399] loss: 0.744155\n",
      "[23,   499] loss: 0.723076\n",
      "[23,   599] loss: 0.714635\n",
      "[23,   699] loss: 0.716792\n",
      "[24,    99] loss: 0.710832\n",
      "[24,   199] loss: 0.724326\n",
      "[24,   299] loss: 0.709334\n",
      "[24,   399] loss: 0.744155\n",
      "[24,   499] loss: 0.723076\n",
      "[24,   599] loss: 0.714635\n",
      "[24,   699] loss: 0.716792\n",
      "[25,    99] loss: 0.710832\n",
      "[25,   199] loss: 0.724326\n",
      "[25,   299] loss: 0.709334\n",
      "[25,   399] loss: 0.744155\n",
      "[25,   499] loss: 0.723076\n",
      "[25,   599] loss: 0.714635\n",
      "[25,   699] loss: 0.716792\n",
      "[26,    99] loss: 0.710832\n",
      "[26,   199] loss: 0.724326\n",
      "[26,   299] loss: 0.709334\n",
      "[26,   399] loss: 0.744155\n",
      "[26,   499] loss: 0.723076\n",
      "[26,   599] loss: 0.714635\n",
      "[26,   699] loss: 0.716792\n",
      "[27,    99] loss: 0.710832\n",
      "[27,   199] loss: 0.724326\n",
      "[27,   299] loss: 0.709334\n",
      "[27,   399] loss: 0.744155\n",
      "[27,   499] loss: 0.723076\n",
      "[27,   599] loss: 0.714635\n",
      "[27,   699] loss: 0.716792\n",
      "[28,    99] loss: 0.710832\n",
      "[28,   199] loss: 0.724326\n",
      "[28,   299] loss: 0.709334\n",
      "[28,   399] loss: 0.744155\n",
      "[28,   499] loss: 0.723076\n",
      "[28,   599] loss: 0.714635\n",
      "[28,   699] loss: 0.716792\n",
      "[29,    99] loss: 0.710832\n",
      "[29,   199] loss: 0.724326\n",
      "[29,   299] loss: 0.709334\n",
      "[29,   399] loss: 0.744155\n",
      "[29,   499] loss: 0.723076\n",
      "[29,   599] loss: 0.714635\n",
      "[29,   699] loss: 0.716792\n",
      "[30,    99] loss: 0.710832\n",
      "[30,   199] loss: 0.724326\n",
      "[30,   299] loss: 0.709334\n",
      "[30,   399] loss: 0.744155\n",
      "[30,   499] loss: 0.723076\n",
      "[30,   599] loss: 0.714635\n",
      "[30,   699] loss: 0.716792\n",
      "[31,    99] loss: 0.710832\n",
      "[31,   199] loss: 0.724326\n",
      "[31,   299] loss: 0.709334\n",
      "[31,   399] loss: 0.744155\n",
      "[31,   499] loss: 0.723076\n",
      "[31,   599] loss: 0.714635\n",
      "[31,   699] loss: 0.716792\n",
      "[32,    99] loss: 0.710832\n",
      "[32,   199] loss: 0.724326\n",
      "[32,   299] loss: 0.709334\n",
      "[32,   399] loss: 0.744155\n",
      "[32,   499] loss: 0.723076\n",
      "[32,   599] loss: 0.714635\n",
      "[32,   699] loss: 0.716792\n",
      "[33,    99] loss: 0.710832\n",
      "[33,   199] loss: 0.724326\n",
      "[33,   299] loss: 0.709334\n",
      "[33,   399] loss: 0.744155\n",
      "[33,   499] loss: 0.723076\n",
      "[33,   599] loss: 0.714635\n",
      "[33,   699] loss: 0.716792\n",
      "[34,    99] loss: 0.710832\n",
      "[34,   199] loss: 0.724326\n",
      "[34,   299] loss: 0.709334\n",
      "[34,   399] loss: 0.744155\n",
      "[34,   499] loss: 0.723076\n",
      "[34,   599] loss: 0.714635\n",
      "[34,   699] loss: 0.716792\n",
      "[35,    99] loss: 0.710832\n",
      "[35,   199] loss: 0.724326\n",
      "[35,   299] loss: 0.709334\n",
      "[35,   399] loss: 0.744155\n",
      "[35,   499] loss: 0.723076\n",
      "[35,   599] loss: 0.714635\n",
      "[35,   699] loss: 0.716792\n",
      "[36,    99] loss: 0.710832\n",
      "[36,   199] loss: 0.724326\n",
      "[36,   299] loss: 0.709334\n",
      "[36,   399] loss: 0.744155\n",
      "[36,   499] loss: 0.723076\n",
      "[36,   599] loss: 0.714635\n",
      "[36,   699] loss: 0.716792\n",
      "[37,    99] loss: 0.710832\n",
      "[37,   199] loss: 0.724326\n",
      "[37,   299] loss: 0.709334\n",
      "[37,   399] loss: 0.744155\n",
      "[37,   499] loss: 0.723076\n",
      "[37,   599] loss: 0.714635\n",
      "[37,   699] loss: 0.716792\n",
      "[38,    99] loss: 0.710832\n",
      "[38,   199] loss: 0.724326\n",
      "[38,   299] loss: 0.709334\n",
      "[38,   399] loss: 0.744155\n",
      "[38,   499] loss: 0.723076\n",
      "[38,   599] loss: 0.714635\n",
      "[38,   699] loss: 0.716792\n",
      "[39,    99] loss: 0.710832\n",
      "[39,   199] loss: 0.724326\n",
      "[39,   299] loss: 0.709334\n",
      "[39,   399] loss: 0.744155\n",
      "[39,   499] loss: 0.723076\n",
      "[39,   599] loss: 0.714635\n",
      "[39,   699] loss: 0.716792\n",
      "[40,    99] loss: 0.710832\n",
      "[40,   199] loss: 0.724326\n",
      "[40,   299] loss: 0.709334\n",
      "[40,   399] loss: 0.744155\n",
      "[40,   499] loss: 0.723076\n",
      "[40,   599] loss: 0.714635\n",
      "[40,   699] loss: 0.716792\n",
      "[41,    99] loss: 0.710832\n",
      "[41,   199] loss: 0.724326\n",
      "[41,   299] loss: 0.709334\n",
      "[41,   399] loss: 0.744155\n",
      "[41,   499] loss: 0.723076\n",
      "[41,   599] loss: 0.714635\n",
      "[41,   699] loss: 0.716792\n",
      "[42,    99] loss: 0.710832\n",
      "[42,   199] loss: 0.724326\n",
      "[42,   299] loss: 0.709334\n",
      "[42,   399] loss: 0.744155\n",
      "[42,   499] loss: 0.723076\n",
      "[42,   599] loss: 0.714635\n",
      "[42,   699] loss: 0.716792\n",
      "[43,    99] loss: 0.710832\n",
      "[43,   199] loss: 0.724326\n",
      "[43,   299] loss: 0.709334\n",
      "[43,   399] loss: 0.744155\n",
      "[43,   499] loss: 0.723076\n",
      "[43,   599] loss: 0.714635\n",
      "[43,   699] loss: 0.716792\n",
      "[44,    99] loss: 0.710832\n",
      "[44,   199] loss: 0.724326\n",
      "[44,   299] loss: 0.709334\n",
      "[44,   399] loss: 0.744155\n",
      "[44,   499] loss: 0.723076\n",
      "[44,   599] loss: 0.714635\n",
      "[44,   699] loss: 0.716792\n",
      "[45,    99] loss: 0.710832\n",
      "[45,   199] loss: 0.724326\n",
      "[45,   299] loss: 0.709334\n",
      "[45,   399] loss: 0.744155\n",
      "[45,   499] loss: 0.723076\n",
      "[45,   599] loss: 0.714635\n",
      "[45,   699] loss: 0.716792\n",
      "[46,    99] loss: 0.710832\n",
      "[46,   199] loss: 0.724326\n",
      "[46,   299] loss: 0.709334\n",
      "[46,   399] loss: 0.744155\n",
      "[46,   499] loss: 0.723076\n",
      "[46,   599] loss: 0.714635\n",
      "[46,   699] loss: 0.716792\n",
      "[47,    99] loss: 0.710832\n",
      "[47,   199] loss: 0.724326\n",
      "[47,   299] loss: 0.709334\n",
      "[47,   399] loss: 0.744155\n",
      "[47,   499] loss: 0.723076\n",
      "[47,   599] loss: 0.714635\n",
      "[47,   699] loss: 0.716792\n",
      "[48,    99] loss: 0.710832\n",
      "[48,   199] loss: 0.724326\n",
      "[48,   299] loss: 0.709334\n",
      "[48,   399] loss: 0.744155\n",
      "[48,   499] loss: 0.723076\n",
      "[48,   599] loss: 0.714635\n",
      "[48,   699] loss: 0.716792\n",
      "[49,    99] loss: 0.710832\n",
      "[49,   199] loss: 0.724326\n",
      "[49,   299] loss: 0.709334\n",
      "[49,   399] loss: 0.744155\n",
      "[49,   499] loss: 0.723076\n",
      "[49,   599] loss: 0.714635\n",
      "[49,   699] loss: 0.716792\n",
      "[50,    99] loss: 0.710832\n",
      "[50,   199] loss: 0.724326\n",
      "[50,   299] loss: 0.709334\n",
      "[50,   399] loss: 0.744155\n",
      "[50,   499] loss: 0.723076\n",
      "[50,   599] loss: 0.714635\n",
      "[50,   699] loss: 0.716792\n",
      "[51,    99] loss: 0.710832\n",
      "[51,   199] loss: 0.724326\n",
      "[51,   299] loss: 0.709334\n",
      "[51,   399] loss: 0.744155\n",
      "[51,   499] loss: 0.723076\n",
      "[51,   599] loss: 0.714635\n",
      "[51,   699] loss: 0.716792\n",
      "[52,    99] loss: 0.710832\n",
      "[52,   199] loss: 0.724326\n",
      "[52,   299] loss: 0.709334\n",
      "[52,   399] loss: 0.744155\n",
      "[52,   499] loss: 0.723076\n",
      "[52,   599] loss: 0.714635\n",
      "[52,   699] loss: 0.716792\n",
      "[53,    99] loss: 0.710832\n",
      "[53,   199] loss: 0.724326\n",
      "[53,   299] loss: 0.709334\n",
      "[53,   399] loss: 0.744155\n",
      "[53,   499] loss: 0.723076\n",
      "[53,   599] loss: 0.714635\n",
      "[53,   699] loss: 0.716792\n",
      "[54,    99] loss: 0.710832\n",
      "[54,   199] loss: 0.724326\n",
      "[54,   299] loss: 0.709334\n",
      "[54,   399] loss: 0.744155\n",
      "[54,   499] loss: 0.723076\n",
      "[54,   599] loss: 0.714635\n",
      "[54,   699] loss: 0.716792\n",
      "[55,    99] loss: 0.710832\n",
      "[55,   199] loss: 0.724326\n",
      "[55,   299] loss: 0.709334\n",
      "[55,   399] loss: 0.744155\n",
      "[55,   499] loss: 0.723076\n",
      "[55,   599] loss: 0.714635\n",
      "[55,   699] loss: 0.716792\n",
      "[56,    99] loss: 0.710832\n",
      "[56,   199] loss: 0.724326\n",
      "[56,   299] loss: 0.709334\n",
      "[56,   399] loss: 0.744155\n",
      "[56,   499] loss: 0.723076\n",
      "[56,   599] loss: 0.714635\n",
      "[56,   699] loss: 0.716792\n",
      "[57,    99] loss: 0.710832\n",
      "[57,   199] loss: 0.724326\n",
      "[57,   299] loss: 0.709334\n",
      "[57,   399] loss: 0.744155\n",
      "[57,   499] loss: 0.723076\n",
      "[57,   599] loss: 0.714635\n",
      "[57,   699] loss: 0.716792\n",
      "[58,    99] loss: 0.710832\n",
      "[58,   199] loss: 0.724326\n",
      "[58,   299] loss: 0.709334\n",
      "[58,   399] loss: 0.744155\n",
      "[58,   499] loss: 0.723076\n",
      "[58,   599] loss: 0.714635\n",
      "[58,   699] loss: 0.716792\n",
      "[59,    99] loss: 0.710832\n",
      "[59,   199] loss: 0.724326\n",
      "[59,   299] loss: 0.709334\n",
      "[59,   399] loss: 0.744155\n",
      "[59,   499] loss: 0.723076\n",
      "[59,   599] loss: 0.714635\n",
      "[59,   699] loss: 0.716792\n",
      "[60,    99] loss: 0.710832\n",
      "[60,   199] loss: 0.724326\n",
      "[60,   299] loss: 0.709334\n",
      "[60,   399] loss: 0.744155\n",
      "[60,   499] loss: 0.723076\n",
      "[60,   599] loss: 0.714635\n",
      "[60,   699] loss: 0.716792\n",
      "[61,    99] loss: 0.710832\n",
      "[61,   199] loss: 0.724326\n",
      "[61,   299] loss: 0.709334\n",
      "[61,   399] loss: 0.744155\n",
      "[61,   499] loss: 0.723076\n",
      "[61,   599] loss: 0.714635\n",
      "[61,   699] loss: 0.716792\n",
      "[62,    99] loss: 0.710832\n",
      "[62,   199] loss: 0.724326\n",
      "[62,   299] loss: 0.709334\n",
      "[62,   399] loss: 0.744155\n",
      "[62,   499] loss: 0.723076\n",
      "[62,   599] loss: 0.714635\n",
      "[62,   699] loss: 0.716792\n",
      "[63,    99] loss: 0.710832\n",
      "[63,   199] loss: 0.724326\n",
      "[63,   299] loss: 0.709334\n",
      "[63,   399] loss: 0.744155\n",
      "[63,   499] loss: 0.723076\n",
      "[63,   599] loss: 0.714635\n",
      "[63,   699] loss: 0.716792\n",
      "[64,    99] loss: 0.710832\n",
      "[64,   199] loss: 0.724326\n",
      "[64,   299] loss: 0.709334\n",
      "[64,   399] loss: 0.744155\n",
      "[64,   499] loss: 0.723076\n",
      "[64,   599] loss: 0.714635\n",
      "[64,   699] loss: 0.716792\n",
      "[65,    99] loss: 0.710832\n",
      "[65,   199] loss: 0.724326\n",
      "[65,   299] loss: 0.709334\n",
      "[65,   399] loss: 0.744155\n",
      "[65,   499] loss: 0.723076\n",
      "[65,   599] loss: 0.714635\n",
      "[65,   699] loss: 0.716792\n",
      "[66,    99] loss: 0.710832\n",
      "[66,   199] loss: 0.724326\n",
      "[66,   299] loss: 0.709334\n",
      "[66,   399] loss: 0.744155\n",
      "[66,   499] loss: 0.723076\n",
      "[66,   599] loss: 0.714635\n",
      "[66,   699] loss: 0.716792\n",
      "[67,    99] loss: 0.710832\n",
      "[67,   199] loss: 0.724326\n",
      "[67,   299] loss: 0.709334\n",
      "[67,   399] loss: 0.744155\n",
      "[67,   499] loss: 0.723076\n",
      "[67,   599] loss: 0.714635\n",
      "[67,   699] loss: 0.716792\n",
      "[68,    99] loss: 0.710832\n",
      "[68,   199] loss: 0.724326\n",
      "[68,   299] loss: 0.709334\n",
      "[68,   399] loss: 0.744155\n",
      "[68,   499] loss: 0.723076\n",
      "[68,   599] loss: 0.714635\n",
      "[68,   699] loss: 0.716792\n",
      "[69,    99] loss: 0.710832\n",
      "[69,   199] loss: 0.724326\n",
      "[69,   299] loss: 0.709334\n",
      "[69,   399] loss: 0.744155\n",
      "[69,   499] loss: 0.723076\n",
      "[69,   599] loss: 0.714635\n",
      "[69,   699] loss: 0.716792\n",
      "[70,    99] loss: 0.710832\n",
      "[70,   199] loss: 0.724326\n",
      "[70,   299] loss: 0.709334\n",
      "[70,   399] loss: 0.744155\n",
      "[70,   499] loss: 0.723076\n",
      "[70,   599] loss: 0.714635\n",
      "[70,   699] loss: 0.716792\n",
      "[71,    99] loss: 0.710832\n",
      "[71,   199] loss: 0.724326\n",
      "[71,   299] loss: 0.709334\n",
      "[71,   399] loss: 0.744155\n",
      "[71,   499] loss: 0.723076\n",
      "[71,   599] loss: 0.714635\n",
      "[71,   699] loss: 0.716792\n",
      "[72,    99] loss: 0.710832\n",
      "[72,   199] loss: 0.724326\n",
      "[72,   299] loss: 0.709334\n",
      "[72,   399] loss: 0.744155\n",
      "[72,   499] loss: 0.723076\n",
      "[72,   599] loss: 0.714635\n",
      "[72,   699] loss: 0.716792\n",
      "[73,    99] loss: 0.710832\n",
      "[73,   199] loss: 0.724326\n",
      "[73,   299] loss: 0.709334\n",
      "[73,   399] loss: 0.744155\n",
      "[73,   499] loss: 0.723076\n",
      "[73,   599] loss: 0.714635\n",
      "[73,   699] loss: 0.716792\n",
      "[74,    99] loss: 0.710832\n",
      "[74,   199] loss: 0.724326\n",
      "[74,   299] loss: 0.709334\n",
      "[74,   399] loss: 0.744155\n",
      "[74,   499] loss: 0.723076\n",
      "[74,   599] loss: 0.714635\n",
      "[74,   699] loss: 0.716792\n",
      "[75,    99] loss: 0.710832\n",
      "[75,   199] loss: 0.724326\n",
      "[75,   299] loss: 0.709334\n",
      "[75,   399] loss: 0.744155\n",
      "[75,   499] loss: 0.723076\n",
      "[75,   599] loss: 0.714635\n",
      "[75,   699] loss: 0.716792\n",
      "[76,    99] loss: 0.710832\n",
      "[76,   199] loss: 0.724326\n",
      "[76,   299] loss: 0.709334\n",
      "[76,   399] loss: 0.744155\n",
      "[76,   499] loss: 0.723076\n",
      "[76,   599] loss: 0.714635\n",
      "[76,   699] loss: 0.716792\n",
      "[77,    99] loss: 0.710832\n",
      "[77,   199] loss: 0.724326\n",
      "[77,   299] loss: 0.709334\n",
      "[77,   399] loss: 0.744155\n",
      "[77,   499] loss: 0.723076\n",
      "[77,   599] loss: 0.714635\n",
      "[77,   699] loss: 0.716792\n",
      "[78,    99] loss: 0.710832\n",
      "[78,   199] loss: 0.724326\n",
      "[78,   299] loss: 0.709334\n",
      "[78,   399] loss: 0.744155\n",
      "[78,   499] loss: 0.723076\n",
      "[78,   599] loss: 0.714635\n",
      "[78,   699] loss: 0.716792\n",
      "[79,    99] loss: 0.710832\n",
      "[79,   199] loss: 0.724326\n",
      "[79,   299] loss: 0.709334\n",
      "[79,   399] loss: 0.744155\n",
      "[79,   499] loss: 0.723076\n",
      "[79,   599] loss: 0.714635\n",
      "[79,   699] loss: 0.716792\n",
      "[80,    99] loss: 0.710832\n",
      "[80,   199] loss: 0.724326\n",
      "[80,   299] loss: 0.709334\n",
      "[80,   399] loss: 0.744155\n",
      "[80,   499] loss: 0.723076\n",
      "[80,   599] loss: 0.714635\n",
      "[80,   699] loss: 0.716792\n",
      "[81,    99] loss: 0.710832\n",
      "[81,   199] loss: 0.724326\n",
      "[81,   299] loss: 0.709334\n",
      "[81,   399] loss: 0.744155\n",
      "[81,   499] loss: 0.723076\n",
      "[81,   599] loss: 0.714635\n",
      "[81,   699] loss: 0.716792\n",
      "[82,    99] loss: 0.710832\n",
      "[82,   199] loss: 0.724326\n",
      "[82,   299] loss: 0.709334\n",
      "[82,   399] loss: 0.744155\n",
      "[82,   499] loss: 0.723076\n",
      "[82,   599] loss: 0.714635\n",
      "[82,   699] loss: 0.716792\n",
      "[83,    99] loss: 0.710832\n",
      "[83,   199] loss: 0.724326\n",
      "[83,   299] loss: 0.709334\n",
      "[83,   399] loss: 0.744155\n",
      "[83,   499] loss: 0.723076\n",
      "[83,   599] loss: 0.714635\n",
      "[83,   699] loss: 0.716792\n",
      "[84,    99] loss: 0.710832\n",
      "[84,   199] loss: 0.724326\n",
      "[84,   299] loss: 0.709334\n",
      "[84,   399] loss: 0.744155\n",
      "[84,   499] loss: 0.723076\n",
      "[84,   599] loss: 0.714635\n",
      "[84,   699] loss: 0.716792\n",
      "[85,    99] loss: 0.710832\n",
      "[85,   199] loss: 0.724326\n",
      "[85,   299] loss: 0.709334\n",
      "[85,   399] loss: 0.744155\n",
      "[85,   499] loss: 0.723076\n",
      "[85,   599] loss: 0.714635\n",
      "[85,   699] loss: 0.716792\n",
      "[86,    99] loss: 0.710832\n",
      "[86,   199] loss: 0.724326\n",
      "[86,   299] loss: 0.709334\n",
      "[86,   399] loss: 0.744155\n",
      "[86,   499] loss: 0.723076\n",
      "[86,   599] loss: 0.714635\n",
      "[86,   699] loss: 0.716792\n",
      "[87,    99] loss: 0.710832\n",
      "[87,   199] loss: 0.724326\n",
      "[87,   299] loss: 0.709334\n",
      "[87,   399] loss: 0.744155\n",
      "[87,   499] loss: 0.723076\n",
      "[87,   599] loss: 0.714635\n",
      "[87,   699] loss: 0.716792\n",
      "[88,    99] loss: 0.710832\n",
      "[88,   199] loss: 0.724326\n",
      "[88,   299] loss: 0.709334\n",
      "[88,   399] loss: 0.744155\n",
      "[88,   499] loss: 0.723076\n",
      "[88,   599] loss: 0.714635\n",
      "[88,   699] loss: 0.716792\n",
      "[89,    99] loss: 0.710832\n",
      "[89,   199] loss: 0.724326\n",
      "[89,   299] loss: 0.709334\n",
      "[89,   399] loss: 0.744155\n",
      "[89,   499] loss: 0.723076\n",
      "[89,   599] loss: 0.714635\n",
      "[89,   699] loss: 0.716792\n",
      "[90,    99] loss: 0.710832\n",
      "[90,   199] loss: 0.724326\n",
      "[90,   299] loss: 0.709334\n",
      "[90,   399] loss: 0.744155\n",
      "[90,   499] loss: 0.723076\n",
      "[90,   599] loss: 0.714635\n",
      "[90,   699] loss: 0.716792\n",
      "[91,    99] loss: 0.710832\n",
      "[91,   199] loss: 0.724326\n",
      "[91,   299] loss: 0.709334\n",
      "[91,   399] loss: 0.744155\n",
      "[91,   499] loss: 0.723076\n",
      "[91,   599] loss: 0.714635\n",
      "[91,   699] loss: 0.716792\n",
      "[92,    99] loss: 0.710832\n",
      "[92,   199] loss: 0.724326\n",
      "[92,   299] loss: 0.709334\n",
      "[92,   399] loss: 0.744155\n",
      "[92,   499] loss: 0.723076\n",
      "[92,   599] loss: 0.714635\n",
      "[92,   699] loss: 0.716792\n",
      "[93,    99] loss: 0.710832\n",
      "[93,   199] loss: 0.724326\n",
      "[93,   299] loss: 0.709334\n",
      "[93,   399] loss: 0.744155\n",
      "[93,   499] loss: 0.723076\n",
      "[93,   599] loss: 0.714635\n",
      "[93,   699] loss: 0.716792\n",
      "[94,    99] loss: 0.710832\n",
      "[94,   199] loss: 0.724326\n",
      "[94,   299] loss: 0.709334\n",
      "[94,   399] loss: 0.744155\n",
      "[94,   499] loss: 0.723076\n",
      "[94,   599] loss: 0.714635\n",
      "[94,   699] loss: 0.716792\n",
      "[95,    99] loss: 0.710832\n",
      "[95,   199] loss: 0.724326\n",
      "[95,   299] loss: 0.709334\n",
      "[95,   399] loss: 0.744155\n",
      "[95,   499] loss: 0.723076\n",
      "[95,   599] loss: 0.714635\n",
      "[95,   699] loss: 0.716792\n",
      "[96,    99] loss: 0.710832\n",
      "[96,   199] loss: 0.724326\n",
      "[96,   299] loss: 0.709334\n",
      "[96,   399] loss: 0.744155\n",
      "[96,   499] loss: 0.723076\n",
      "[96,   599] loss: 0.714635\n",
      "[96,   699] loss: 0.716792\n",
      "[97,    99] loss: 0.710832\n",
      "[97,   199] loss: 0.724326\n",
      "[97,   299] loss: 0.709334\n",
      "[97,   399] loss: 0.744155\n",
      "[97,   499] loss: 0.723076\n",
      "[97,   599] loss: 0.714635\n",
      "[97,   699] loss: 0.716792\n",
      "[98,    99] loss: 0.710832\n",
      "[98,   199] loss: 0.724326\n",
      "[98,   299] loss: 0.709334\n",
      "[98,   399] loss: 0.744155\n",
      "[98,   499] loss: 0.723076\n",
      "[98,   599] loss: 0.714635\n",
      "[98,   699] loss: 0.716792\n",
      "[99,    99] loss: 0.710832\n",
      "[99,   199] loss: 0.724326\n",
      "[99,   299] loss: 0.709334\n",
      "[99,   399] loss: 0.744155\n",
      "[99,   499] loss: 0.723076\n",
      "[99,   599] loss: 0.714635\n",
      "[99,   699] loss: 0.716792\n",
      "[100,    99] loss: 0.710832\n",
      "[100,   199] loss: 0.724326\n",
      "[100,   299] loss: 0.709334\n",
      "[100,   399] loss: 0.744155\n",
      "[100,   499] loss: 0.723076\n",
      "[100,   599] loss: 0.714635\n",
      "[100,   699] loss: 0.716792\n",
      "Finished Training\n",
      "[1,    99] loss: 6.654119\n",
      "[1,   199] loss: 0.938763\n",
      "[1,   299] loss: 0.708022\n",
      "[1,   399] loss: 0.712449\n",
      "[1,   499] loss: 0.745833\n",
      "[1,   599] loss: 0.707074\n",
      "[1,   699] loss: 0.739246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    99] loss: 0.717919\n",
      "[2,   199] loss: 0.720109\n",
      "[2,   299] loss: 0.711299\n",
      "[2,   399] loss: 0.715746\n",
      "[2,   499] loss: 0.747366\n",
      "[2,   599] loss: 0.707793\n",
      "[2,   699] loss: 0.739979\n",
      "[3,    99] loss: 0.716924\n",
      "[3,   199] loss: 0.720404\n",
      "[3,   299] loss: 0.711474\n",
      "[3,   399] loss: 0.715919\n",
      "[3,   499] loss: 0.747698\n",
      "[3,   599] loss: 0.707966\n",
      "[3,   699] loss: 0.740178\n",
      "[4,    99] loss: 0.716939\n",
      "[4,   199] loss: 0.720495\n",
      "[4,   299] loss: 0.711530\n",
      "[4,   399] loss: 0.715978\n",
      "[4,   499] loss: 0.747815\n",
      "[4,   599] loss: 0.708029\n",
      "[4,   699] loss: 0.740254\n",
      "[5,    99] loss: 0.716945\n",
      "[5,   199] loss: 0.720531\n",
      "[5,   299] loss: 0.711553\n",
      "[5,   399] loss: 0.716002\n",
      "[5,   499] loss: 0.747864\n",
      "[5,   599] loss: 0.708056\n",
      "[5,   699] loss: 0.740286\n",
      "[6,    99] loss: 0.716948\n",
      "[6,   199] loss: 0.720547\n",
      "[6,   299] loss: 0.711563\n",
      "[6,   399] loss: 0.716013\n",
      "[6,   499] loss: 0.747885\n",
      "[6,   599] loss: 0.708067\n",
      "[6,   699] loss: 0.740300\n",
      "[7,    99] loss: 0.716949\n",
      "[7,   199] loss: 0.720554\n",
      "[7,   299] loss: 0.711568\n",
      "[7,   399] loss: 0.716017\n",
      "[7,   499] loss: 0.747895\n",
      "[7,   599] loss: 0.708073\n",
      "[7,   699] loss: 0.740307\n",
      "[8,    99] loss: 0.716950\n",
      "[8,   199] loss: 0.720557\n",
      "[8,   299] loss: 0.711570\n",
      "[8,   399] loss: 0.716020\n",
      "[8,   499] loss: 0.747900\n",
      "[8,   599] loss: 0.708076\n",
      "[8,   699] loss: 0.740310\n",
      "[9,    99] loss: 0.716950\n",
      "[9,   199] loss: 0.720559\n",
      "[9,   299] loss: 0.711571\n",
      "[9,   399] loss: 0.716021\n",
      "[9,   499] loss: 0.747902\n",
      "[9,   599] loss: 0.708077\n",
      "[9,   699] loss: 0.740312\n",
      "[10,    99] loss: 0.716950\n",
      "[10,   199] loss: 0.720559\n",
      "[10,   299] loss: 0.711572\n",
      "[10,   399] loss: 0.716021\n",
      "[10,   499] loss: 0.747903\n",
      "[10,   599] loss: 0.708077\n",
      "[10,   699] loss: 0.740312\n",
      "[11,    99] loss: 0.716950\n",
      "[11,   199] loss: 0.720560\n",
      "[11,   299] loss: 0.711572\n",
      "[11,   399] loss: 0.716022\n",
      "[11,   499] loss: 0.747904\n",
      "[11,   599] loss: 0.708078\n",
      "[11,   699] loss: 0.740313\n",
      "[12,    99] loss: 0.716950\n",
      "[12,   199] loss: 0.720560\n",
      "[12,   299] loss: 0.711572\n",
      "[12,   399] loss: 0.716022\n",
      "[12,   499] loss: 0.747904\n",
      "[12,   599] loss: 0.708078\n",
      "[12,   699] loss: 0.740313\n",
      "[13,    99] loss: 0.716950\n",
      "[13,   199] loss: 0.720560\n",
      "[13,   299] loss: 0.711572\n",
      "[13,   399] loss: 0.716022\n",
      "[13,   499] loss: 0.747904\n",
      "[13,   599] loss: 0.708078\n",
      "[13,   699] loss: 0.740313\n",
      "[14,    99] loss: 0.716950\n",
      "[14,   199] loss: 0.720560\n",
      "[14,   299] loss: 0.711572\n",
      "[14,   399] loss: 0.716022\n",
      "[14,   499] loss: 0.747904\n",
      "[14,   599] loss: 0.708078\n",
      "[14,   699] loss: 0.740313\n",
      "[15,    99] loss: 0.716950\n",
      "[15,   199] loss: 0.720560\n",
      "[15,   299] loss: 0.711572\n",
      "[15,   399] loss: 0.716022\n",
      "[15,   499] loss: 0.747904\n",
      "[15,   599] loss: 0.708078\n",
      "[15,   699] loss: 0.740313\n",
      "[16,    99] loss: 0.716950\n",
      "[16,   199] loss: 0.720560\n",
      "[16,   299] loss: 0.711572\n",
      "[16,   399] loss: 0.716022\n",
      "[16,   499] loss: 0.747904\n",
      "[16,   599] loss: 0.708078\n",
      "[16,   699] loss: 0.740313\n",
      "[17,    99] loss: 0.716950\n",
      "[17,   199] loss: 0.720560\n",
      "[17,   299] loss: 0.711572\n",
      "[17,   399] loss: 0.716022\n",
      "[17,   499] loss: 0.747904\n",
      "[17,   599] loss: 0.708078\n",
      "[17,   699] loss: 0.740313\n",
      "[18,    99] loss: 0.716950\n",
      "[18,   199] loss: 0.720560\n",
      "[18,   299] loss: 0.711572\n",
      "[18,   399] loss: 0.716022\n",
      "[18,   499] loss: 0.747904\n",
      "[18,   599] loss: 0.708078\n",
      "[18,   699] loss: 0.740313\n",
      "[19,    99] loss: 0.716950\n",
      "[19,   199] loss: 0.720560\n",
      "[19,   299] loss: 0.711572\n",
      "[19,   399] loss: 0.716022\n",
      "[19,   499] loss: 0.747904\n",
      "[19,   599] loss: 0.708078\n",
      "[19,   699] loss: 0.740313\n",
      "[20,    99] loss: 0.716950\n",
      "[20,   199] loss: 0.720560\n",
      "[20,   299] loss: 0.711572\n",
      "[20,   399] loss: 0.716022\n",
      "[20,   499] loss: 0.747904\n",
      "[20,   599] loss: 0.708078\n",
      "[20,   699] loss: 0.740313\n",
      "[21,    99] loss: 0.716950\n",
      "[21,   199] loss: 0.720560\n",
      "[21,   299] loss: 0.711572\n",
      "[21,   399] loss: 0.716022\n",
      "[21,   499] loss: 0.747904\n",
      "[21,   599] loss: 0.708078\n",
      "[21,   699] loss: 0.740313\n",
      "[22,    99] loss: 0.716950\n",
      "[22,   199] loss: 0.720560\n",
      "[22,   299] loss: 0.711572\n",
      "[22,   399] loss: 0.716022\n",
      "[22,   499] loss: 0.747904\n",
      "[22,   599] loss: 0.708078\n",
      "[22,   699] loss: 0.740313\n",
      "[23,    99] loss: 0.716950\n",
      "[23,   199] loss: 0.720560\n",
      "[23,   299] loss: 0.711572\n",
      "[23,   399] loss: 0.716022\n",
      "[23,   499] loss: 0.747904\n",
      "[23,   599] loss: 0.708078\n",
      "[23,   699] loss: 0.740313\n",
      "[24,    99] loss: 0.716950\n",
      "[24,   199] loss: 0.720560\n",
      "[24,   299] loss: 0.711572\n",
      "[24,   399] loss: 0.716022\n",
      "[24,   499] loss: 0.747904\n",
      "[24,   599] loss: 0.708078\n",
      "[24,   699] loss: 0.740313\n",
      "[25,    99] loss: 0.716950\n",
      "[25,   199] loss: 0.720560\n",
      "[25,   299] loss: 0.711572\n",
      "[25,   399] loss: 0.716022\n",
      "[25,   499] loss: 0.747904\n",
      "[25,   599] loss: 0.708078\n",
      "[25,   699] loss: 0.740313\n",
      "[26,    99] loss: 0.716950\n",
      "[26,   199] loss: 0.720560\n",
      "[26,   299] loss: 0.711572\n",
      "[26,   399] loss: 0.716022\n",
      "[26,   499] loss: 0.747904\n",
      "[26,   599] loss: 0.708078\n",
      "[26,   699] loss: 0.740313\n",
      "[27,    99] loss: 0.716950\n",
      "[27,   199] loss: 0.720560\n",
      "[27,   299] loss: 0.711572\n",
      "[27,   399] loss: 0.716022\n",
      "[27,   499] loss: 0.747904\n",
      "[27,   599] loss: 0.708078\n",
      "[27,   699] loss: 0.740313\n",
      "[28,    99] loss: 0.716950\n",
      "[28,   199] loss: 0.720560\n",
      "[28,   299] loss: 0.711572\n",
      "[28,   399] loss: 0.716022\n",
      "[28,   499] loss: 0.747904\n",
      "[28,   599] loss: 0.708078\n",
      "[28,   699] loss: 0.740313\n",
      "[29,    99] loss: 0.716950\n",
      "[29,   199] loss: 0.720560\n",
      "[29,   299] loss: 0.711572\n",
      "[29,   399] loss: 0.716022\n",
      "[29,   499] loss: 0.747904\n",
      "[29,   599] loss: 0.708078\n",
      "[29,   699] loss: 0.740313\n",
      "[30,    99] loss: 0.716950\n",
      "[30,   199] loss: 0.720560\n",
      "[30,   299] loss: 0.711572\n",
      "[30,   399] loss: 0.716022\n",
      "[30,   499] loss: 0.747904\n",
      "[30,   599] loss: 0.708078\n",
      "[30,   699] loss: 0.740313\n",
      "[31,    99] loss: 0.716950\n",
      "[31,   199] loss: 0.720560\n",
      "[31,   299] loss: 0.711572\n",
      "[31,   399] loss: 0.716022\n",
      "[31,   499] loss: 0.747904\n",
      "[31,   599] loss: 0.708078\n",
      "[31,   699] loss: 0.740313\n",
      "[32,    99] loss: 0.716950\n",
      "[32,   199] loss: 0.720560\n",
      "[32,   299] loss: 0.711572\n",
      "[32,   399] loss: 0.716022\n",
      "[32,   499] loss: 0.747904\n",
      "[32,   599] loss: 0.708078\n",
      "[32,   699] loss: 0.740313\n",
      "[33,    99] loss: 0.716950\n",
      "[33,   199] loss: 0.720560\n",
      "[33,   299] loss: 0.711572\n",
      "[33,   399] loss: 0.716022\n",
      "[33,   499] loss: 0.747904\n",
      "[33,   599] loss: 0.708078\n",
      "[33,   699] loss: 0.740313\n",
      "[34,    99] loss: 0.716950\n",
      "[34,   199] loss: 0.720560\n",
      "[34,   299] loss: 0.711572\n",
      "[34,   399] loss: 0.716022\n",
      "[34,   499] loss: 0.747904\n",
      "[34,   599] loss: 0.708078\n",
      "[34,   699] loss: 0.740313\n",
      "[35,    99] loss: 0.716950\n",
      "[35,   199] loss: 0.720560\n",
      "[35,   299] loss: 0.711572\n",
      "[35,   399] loss: 0.716022\n",
      "[35,   499] loss: 0.747904\n",
      "[35,   599] loss: 0.708078\n",
      "[35,   699] loss: 0.740313\n",
      "[36,    99] loss: 0.716950\n",
      "[36,   199] loss: 0.720560\n",
      "[36,   299] loss: 0.711572\n",
      "[36,   399] loss: 0.716022\n",
      "[36,   499] loss: 0.747904\n",
      "[36,   599] loss: 0.708078\n",
      "[36,   699] loss: 0.740313\n",
      "[37,    99] loss: 0.716950\n",
      "[37,   199] loss: 0.720560\n",
      "[37,   299] loss: 0.711572\n",
      "[37,   399] loss: 0.716022\n",
      "[37,   499] loss: 0.747904\n",
      "[37,   599] loss: 0.708078\n",
      "[37,   699] loss: 0.740313\n",
      "[38,    99] loss: 0.716950\n",
      "[38,   199] loss: 0.720560\n",
      "[38,   299] loss: 0.711572\n",
      "[38,   399] loss: 0.716022\n",
      "[38,   499] loss: 0.747904\n",
      "[38,   599] loss: 0.708078\n",
      "[38,   699] loss: 0.740313\n",
      "[39,    99] loss: 0.716950\n",
      "[39,   199] loss: 0.720560\n",
      "[39,   299] loss: 0.711572\n",
      "[39,   399] loss: 0.716022\n",
      "[39,   499] loss: 0.747904\n",
      "[39,   599] loss: 0.708078\n",
      "[39,   699] loss: 0.740313\n",
      "[40,    99] loss: 0.716950\n",
      "[40,   199] loss: 0.720560\n",
      "[40,   299] loss: 0.711572\n",
      "[40,   399] loss: 0.716022\n",
      "[40,   499] loss: 0.747904\n",
      "[40,   599] loss: 0.708078\n",
      "[40,   699] loss: 0.740313\n",
      "[41,    99] loss: 0.716950\n",
      "[41,   199] loss: 0.720560\n",
      "[41,   299] loss: 0.711572\n",
      "[41,   399] loss: 0.716022\n",
      "[41,   499] loss: 0.747904\n",
      "[41,   599] loss: 0.708078\n",
      "[41,   699] loss: 0.740313\n",
      "[42,    99] loss: 0.716950\n",
      "[42,   199] loss: 0.720560\n",
      "[42,   299] loss: 0.711572\n",
      "[42,   399] loss: 0.716022\n",
      "[42,   499] loss: 0.747904\n",
      "[42,   599] loss: 0.708078\n",
      "[42,   699] loss: 0.740313\n",
      "[43,    99] loss: 0.716950\n",
      "[43,   199] loss: 0.720560\n",
      "[43,   299] loss: 0.711572\n",
      "[43,   399] loss: 0.716022\n",
      "[43,   499] loss: 0.747904\n",
      "[43,   599] loss: 0.708078\n",
      "[43,   699] loss: 0.740313\n",
      "[44,    99] loss: 0.716950\n",
      "[44,   199] loss: 0.720560\n",
      "[44,   299] loss: 0.711572\n",
      "[44,   399] loss: 0.716022\n",
      "[44,   499] loss: 0.747904\n",
      "[44,   599] loss: 0.708078\n",
      "[44,   699] loss: 0.740313\n",
      "[45,    99] loss: 0.716950\n",
      "[45,   199] loss: 0.720560\n",
      "[45,   299] loss: 0.711572\n",
      "[45,   399] loss: 0.716022\n",
      "[45,   499] loss: 0.747904\n",
      "[45,   599] loss: 0.708078\n",
      "[45,   699] loss: 0.740313\n",
      "[46,    99] loss: 0.716950\n",
      "[46,   199] loss: 0.720560\n",
      "[46,   299] loss: 0.711572\n",
      "[46,   399] loss: 0.716022\n",
      "[46,   499] loss: 0.747904\n",
      "[46,   599] loss: 0.708078\n",
      "[46,   699] loss: 0.740313\n",
      "[47,    99] loss: 0.716950\n",
      "[47,   199] loss: 0.720560\n",
      "[47,   299] loss: 0.711572\n",
      "[47,   399] loss: 0.716022\n",
      "[47,   499] loss: 0.747904\n",
      "[47,   599] loss: 0.708078\n",
      "[47,   699] loss: 0.740313\n",
      "[48,    99] loss: 0.716950\n",
      "[48,   199] loss: 0.720560\n",
      "[48,   299] loss: 0.711572\n",
      "[48,   399] loss: 0.716022\n",
      "[48,   499] loss: 0.747904\n",
      "[48,   599] loss: 0.708078\n",
      "[48,   699] loss: 0.740313\n",
      "[49,    99] loss: 0.716950\n",
      "[49,   199] loss: 0.720560\n",
      "[49,   299] loss: 0.711572\n",
      "[49,   399] loss: 0.716022\n",
      "[49,   499] loss: 0.747904\n",
      "[49,   599] loss: 0.708078\n",
      "[49,   699] loss: 0.740313\n",
      "[50,    99] loss: 0.716950\n",
      "[50,   199] loss: 0.720560\n",
      "[50,   299] loss: 0.711572\n",
      "[50,   399] loss: 0.716022\n",
      "[50,   499] loss: 0.747904\n",
      "[50,   599] loss: 0.708078\n",
      "[50,   699] loss: 0.740313\n",
      "[51,    99] loss: 0.716950\n",
      "[51,   199] loss: 0.720560\n",
      "[51,   299] loss: 0.711572\n",
      "[51,   399] loss: 0.716022\n",
      "[51,   499] loss: 0.747904\n",
      "[51,   599] loss: 0.708078\n",
      "[51,   699] loss: 0.740313\n",
      "[52,    99] loss: 0.716950\n",
      "[52,   199] loss: 0.720560\n",
      "[52,   299] loss: 0.711572\n",
      "[52,   399] loss: 0.716022\n",
      "[52,   499] loss: 0.747904\n",
      "[52,   599] loss: 0.708078\n",
      "[52,   699] loss: 0.740313\n",
      "[53,    99] loss: 0.716950\n",
      "[53,   199] loss: 0.720560\n",
      "[53,   299] loss: 0.711572\n",
      "[53,   399] loss: 0.716022\n",
      "[53,   499] loss: 0.747904\n",
      "[53,   599] loss: 0.708078\n",
      "[53,   699] loss: 0.740313\n",
      "[54,    99] loss: 0.716950\n",
      "[54,   199] loss: 0.720560\n",
      "[54,   299] loss: 0.711572\n",
      "[54,   399] loss: 0.716022\n",
      "[54,   499] loss: 0.747904\n",
      "[54,   599] loss: 0.708078\n",
      "[54,   699] loss: 0.740313\n",
      "[55,    99] loss: 0.716950\n",
      "[55,   199] loss: 0.720560\n",
      "[55,   299] loss: 0.711572\n",
      "[55,   399] loss: 0.716022\n",
      "[55,   499] loss: 0.747904\n",
      "[55,   599] loss: 0.708078\n",
      "[55,   699] loss: 0.740313\n",
      "[56,    99] loss: 0.716950\n",
      "[56,   199] loss: 0.720560\n",
      "[56,   299] loss: 0.711572\n",
      "[56,   399] loss: 0.716022\n",
      "[56,   499] loss: 0.747904\n",
      "[56,   599] loss: 0.708078\n",
      "[56,   699] loss: 0.740313\n",
      "[57,    99] loss: 0.716950\n",
      "[57,   199] loss: 0.720560\n",
      "[57,   299] loss: 0.711572\n",
      "[57,   399] loss: 0.716022\n",
      "[57,   499] loss: 0.747904\n",
      "[57,   599] loss: 0.708078\n",
      "[57,   699] loss: 0.740313\n",
      "[58,    99] loss: 0.716950\n",
      "[58,   199] loss: 0.720560\n",
      "[58,   299] loss: 0.711572\n",
      "[58,   399] loss: 0.716022\n",
      "[58,   499] loss: 0.747904\n",
      "[58,   599] loss: 0.708078\n",
      "[58,   699] loss: 0.740313\n",
      "[59,    99] loss: 0.716950\n",
      "[59,   199] loss: 0.720560\n",
      "[59,   299] loss: 0.711572\n",
      "[59,   399] loss: 0.716022\n",
      "[59,   499] loss: 0.747904\n",
      "[59,   599] loss: 0.708078\n",
      "[59,   699] loss: 0.740313\n",
      "[60,    99] loss: 0.716950\n",
      "[60,   199] loss: 0.720560\n",
      "[60,   299] loss: 0.711572\n",
      "[60,   399] loss: 0.716022\n",
      "[60,   499] loss: 0.747904\n",
      "[60,   599] loss: 0.708078\n",
      "[60,   699] loss: 0.740313\n",
      "[61,    99] loss: 0.716950\n",
      "[61,   199] loss: 0.720560\n",
      "[61,   299] loss: 0.711572\n",
      "[61,   399] loss: 0.716022\n",
      "[61,   499] loss: 0.747904\n",
      "[61,   599] loss: 0.708078\n",
      "[61,   699] loss: 0.740313\n",
      "[62,    99] loss: 0.716950\n",
      "[62,   199] loss: 0.720560\n",
      "[62,   299] loss: 0.711572\n",
      "[62,   399] loss: 0.716022\n",
      "[62,   499] loss: 0.747904\n",
      "[62,   599] loss: 0.708078\n",
      "[62,   699] loss: 0.740313\n",
      "[63,    99] loss: 0.716950\n",
      "[63,   199] loss: 0.720560\n",
      "[63,   299] loss: 0.711572\n",
      "[63,   399] loss: 0.716022\n",
      "[63,   499] loss: 0.747904\n",
      "[63,   599] loss: 0.708078\n",
      "[63,   699] loss: 0.740313\n",
      "[64,    99] loss: 0.716950\n",
      "[64,   199] loss: 0.720560\n",
      "[64,   299] loss: 0.711572\n",
      "[64,   399] loss: 0.716022\n",
      "[64,   499] loss: 0.747904\n",
      "[64,   599] loss: 0.708078\n",
      "[64,   699] loss: 0.740313\n",
      "[65,    99] loss: 0.716950\n",
      "[65,   199] loss: 0.720560\n",
      "[65,   299] loss: 0.711572\n",
      "[65,   399] loss: 0.716022\n",
      "[65,   499] loss: 0.747904\n",
      "[65,   599] loss: 0.708078\n",
      "[65,   699] loss: 0.740313\n",
      "[66,    99] loss: 0.716950\n",
      "[66,   199] loss: 0.720560\n",
      "[66,   299] loss: 0.711572\n",
      "[66,   399] loss: 0.716022\n",
      "[66,   499] loss: 0.747904\n",
      "[66,   599] loss: 0.708078\n",
      "[66,   699] loss: 0.740313\n",
      "[67,    99] loss: 0.716950\n",
      "[67,   199] loss: 0.720560\n",
      "[67,   299] loss: 0.711572\n",
      "[67,   399] loss: 0.716022\n",
      "[67,   499] loss: 0.747904\n",
      "[67,   599] loss: 0.708078\n",
      "[67,   699] loss: 0.740313\n",
      "[68,    99] loss: 0.716950\n",
      "[68,   199] loss: 0.720560\n",
      "[68,   299] loss: 0.711572\n",
      "[68,   399] loss: 0.716022\n",
      "[68,   499] loss: 0.747904\n",
      "[68,   599] loss: 0.708078\n",
      "[68,   699] loss: 0.740313\n",
      "[69,    99] loss: 0.716950\n",
      "[69,   199] loss: 0.720560\n",
      "[69,   299] loss: 0.711572\n",
      "[69,   399] loss: 0.716022\n",
      "[69,   499] loss: 0.747904\n",
      "[69,   599] loss: 0.708078\n",
      "[69,   699] loss: 0.740313\n",
      "[70,    99] loss: 0.716950\n",
      "[70,   199] loss: 0.720560\n",
      "[70,   299] loss: 0.711572\n",
      "[70,   399] loss: 0.716022\n",
      "[70,   499] loss: 0.747904\n",
      "[70,   599] loss: 0.708078\n",
      "[70,   699] loss: 0.740313\n",
      "[71,    99] loss: 0.716950\n",
      "[71,   199] loss: 0.720560\n",
      "[71,   299] loss: 0.711572\n",
      "[71,   399] loss: 0.716022\n",
      "[71,   499] loss: 0.747904\n",
      "[71,   599] loss: 0.708078\n",
      "[71,   699] loss: 0.740313\n",
      "[72,    99] loss: 0.716950\n",
      "[72,   199] loss: 0.720560\n",
      "[72,   299] loss: 0.711572\n",
      "[72,   399] loss: 0.716022\n",
      "[72,   499] loss: 0.747904\n",
      "[72,   599] loss: 0.708078\n",
      "[72,   699] loss: 0.740313\n",
      "[73,    99] loss: 0.716950\n",
      "[73,   199] loss: 0.720560\n",
      "[73,   299] loss: 0.711572\n",
      "[73,   399] loss: 0.716022\n",
      "[73,   499] loss: 0.747904\n",
      "[73,   599] loss: 0.708078\n",
      "[73,   699] loss: 0.740313\n",
      "[74,    99] loss: 0.716950\n",
      "[74,   199] loss: 0.720560\n",
      "[74,   299] loss: 0.711572\n",
      "[74,   399] loss: 0.716022\n",
      "[74,   499] loss: 0.747904\n",
      "[74,   599] loss: 0.708078\n",
      "[74,   699] loss: 0.740313\n",
      "[75,    99] loss: 0.716950\n",
      "[75,   199] loss: 0.720560\n",
      "[75,   299] loss: 0.711572\n",
      "[75,   399] loss: 0.716022\n",
      "[75,   499] loss: 0.747904\n",
      "[75,   599] loss: 0.708078\n",
      "[75,   699] loss: 0.740313\n",
      "[76,    99] loss: 0.716950\n",
      "[76,   199] loss: 0.720560\n",
      "[76,   299] loss: 0.711572\n",
      "[76,   399] loss: 0.716022\n",
      "[76,   499] loss: 0.747904\n",
      "[76,   599] loss: 0.708078\n",
      "[76,   699] loss: 0.740313\n",
      "[77,    99] loss: 0.716950\n",
      "[77,   199] loss: 0.720560\n",
      "[77,   299] loss: 0.711572\n",
      "[77,   399] loss: 0.716022\n",
      "[77,   499] loss: 0.747904\n",
      "[77,   599] loss: 0.708078\n",
      "[77,   699] loss: 0.740313\n",
      "[78,    99] loss: 0.716950\n",
      "[78,   199] loss: 0.720560\n",
      "[78,   299] loss: 0.711572\n",
      "[78,   399] loss: 0.716022\n",
      "[78,   499] loss: 0.747904\n",
      "[78,   599] loss: 0.708078\n",
      "[78,   699] loss: 0.740313\n",
      "[79,    99] loss: 0.716950\n",
      "[79,   199] loss: 0.720560\n",
      "[79,   299] loss: 0.711572\n",
      "[79,   399] loss: 0.716022\n",
      "[79,   499] loss: 0.747904\n",
      "[79,   599] loss: 0.708078\n",
      "[79,   699] loss: 0.740313\n",
      "[80,    99] loss: 0.716950\n",
      "[80,   199] loss: 0.720560\n",
      "[80,   299] loss: 0.711572\n",
      "[80,   399] loss: 0.716022\n",
      "[80,   499] loss: 0.747904\n",
      "[80,   599] loss: 0.708078\n",
      "[80,   699] loss: 0.740313\n",
      "[81,    99] loss: 0.716950\n",
      "[81,   199] loss: 0.720560\n",
      "[81,   299] loss: 0.711572\n",
      "[81,   399] loss: 0.716022\n",
      "[81,   499] loss: 0.747904\n",
      "[81,   599] loss: 0.708078\n",
      "[81,   699] loss: 0.740313\n",
      "[82,    99] loss: 0.716950\n",
      "[82,   199] loss: 0.720560\n",
      "[82,   299] loss: 0.711572\n",
      "[82,   399] loss: 0.716022\n",
      "[82,   499] loss: 0.747904\n",
      "[82,   599] loss: 0.708078\n",
      "[82,   699] loss: 0.740313\n",
      "[83,    99] loss: 0.716950\n",
      "[83,   199] loss: 0.720560\n",
      "[83,   299] loss: 0.711572\n",
      "[83,   399] loss: 0.716022\n",
      "[83,   499] loss: 0.747904\n",
      "[83,   599] loss: 0.708078\n",
      "[83,   699] loss: 0.740313\n",
      "[84,    99] loss: 0.716950\n",
      "[84,   199] loss: 0.720560\n",
      "[84,   299] loss: 0.711572\n",
      "[84,   399] loss: 0.716022\n",
      "[84,   499] loss: 0.747904\n",
      "[84,   599] loss: 0.708078\n",
      "[84,   699] loss: 0.740313\n",
      "[85,    99] loss: 0.716950\n",
      "[85,   199] loss: 0.720560\n",
      "[85,   299] loss: 0.711572\n",
      "[85,   399] loss: 0.716022\n",
      "[85,   499] loss: 0.747904\n",
      "[85,   599] loss: 0.708078\n",
      "[85,   699] loss: 0.740313\n",
      "[86,    99] loss: 0.716950\n",
      "[86,   199] loss: 0.720560\n",
      "[86,   299] loss: 0.711572\n",
      "[86,   399] loss: 0.716022\n",
      "[86,   499] loss: 0.747904\n",
      "[86,   599] loss: 0.708078\n",
      "[86,   699] loss: 0.740313\n",
      "[87,    99] loss: 0.716950\n",
      "[87,   199] loss: 0.720560\n",
      "[87,   299] loss: 0.711572\n",
      "[87,   399] loss: 0.716022\n",
      "[87,   499] loss: 0.747904\n",
      "[87,   599] loss: 0.708078\n",
      "[87,   699] loss: 0.740313\n",
      "[88,    99] loss: 0.716950\n",
      "[88,   199] loss: 0.720560\n",
      "[88,   299] loss: 0.711572\n",
      "[88,   399] loss: 0.716022\n",
      "[88,   499] loss: 0.747904\n",
      "[88,   599] loss: 0.708078\n",
      "[88,   699] loss: 0.740313\n",
      "[89,    99] loss: 0.716950\n",
      "[89,   199] loss: 0.720560\n",
      "[89,   299] loss: 0.711572\n",
      "[89,   399] loss: 0.716022\n",
      "[89,   499] loss: 0.747904\n",
      "[89,   599] loss: 0.708078\n",
      "[89,   699] loss: 0.740313\n",
      "[90,    99] loss: 0.716950\n",
      "[90,   199] loss: 0.720560\n",
      "[90,   299] loss: 0.711572\n",
      "[90,   399] loss: 0.716022\n",
      "[90,   499] loss: 0.747904\n",
      "[90,   599] loss: 0.708078\n",
      "[90,   699] loss: 0.740313\n",
      "[91,    99] loss: 0.716950\n",
      "[91,   199] loss: 0.720560\n",
      "[91,   299] loss: 0.711572\n",
      "[91,   399] loss: 0.716022\n",
      "[91,   499] loss: 0.747904\n",
      "[91,   599] loss: 0.708078\n",
      "[91,   699] loss: 0.740313\n",
      "[92,    99] loss: 0.716950\n",
      "[92,   199] loss: 0.720560\n",
      "[92,   299] loss: 0.711572\n",
      "[92,   399] loss: 0.716022\n",
      "[92,   499] loss: 0.747904\n",
      "[92,   599] loss: 0.708078\n",
      "[92,   699] loss: 0.740313\n",
      "[93,    99] loss: 0.716950\n",
      "[93,   199] loss: 0.720560\n",
      "[93,   299] loss: 0.711572\n",
      "[93,   399] loss: 0.716022\n",
      "[93,   499] loss: 0.747904\n",
      "[93,   599] loss: 0.708078\n",
      "[93,   699] loss: 0.740313\n",
      "[94,    99] loss: 0.716950\n",
      "[94,   199] loss: 0.720560\n",
      "[94,   299] loss: 0.711572\n",
      "[94,   399] loss: 0.716022\n",
      "[94,   499] loss: 0.747904\n",
      "[94,   599] loss: 0.708078\n",
      "[94,   699] loss: 0.740313\n",
      "[95,    99] loss: 0.716950\n",
      "[95,   199] loss: 0.720560\n",
      "[95,   299] loss: 0.711572\n",
      "[95,   399] loss: 0.716022\n",
      "[95,   499] loss: 0.747904\n",
      "[95,   599] loss: 0.708078\n",
      "[95,   699] loss: 0.740313\n",
      "[96,    99] loss: 0.716950\n",
      "[96,   199] loss: 0.720560\n",
      "[96,   299] loss: 0.711572\n",
      "[96,   399] loss: 0.716022\n",
      "[96,   499] loss: 0.747904\n",
      "[96,   599] loss: 0.708078\n",
      "[96,   699] loss: 0.740313\n",
      "[97,    99] loss: 0.716950\n",
      "[97,   199] loss: 0.720560\n",
      "[97,   299] loss: 0.711572\n",
      "[97,   399] loss: 0.716022\n",
      "[97,   499] loss: 0.747904\n",
      "[97,   599] loss: 0.708078\n",
      "[97,   699] loss: 0.740313\n",
      "[98,    99] loss: 0.716950\n",
      "[98,   199] loss: 0.720560\n",
      "[98,   299] loss: 0.711572\n",
      "[98,   399] loss: 0.716022\n",
      "[98,   499] loss: 0.747904\n",
      "[98,   599] loss: 0.708078\n",
      "[98,   699] loss: 0.740313\n",
      "[99,    99] loss: 0.716950\n",
      "[99,   199] loss: 0.720560\n",
      "[99,   299] loss: 0.711572\n",
      "[99,   399] loss: 0.716022\n",
      "[99,   499] loss: 0.747904\n",
      "[99,   599] loss: 0.708078\n",
      "[99,   699] loss: 0.740313\n",
      "[100,    99] loss: 0.716950\n",
      "[100,   199] loss: 0.720560\n",
      "[100,   299] loss: 0.711572\n",
      "[100,   399] loss: 0.716022\n",
      "[100,   499] loss: 0.747904\n",
      "[100,   599] loss: 0.708078\n",
      "[100,   699] loss: 0.740313\n",
      "Finished Training\n",
      "[1,    99] loss: 2.858600\n",
      "[1,   199] loss: 1.189359\n",
      "[1,   299] loss: 0.715529\n",
      "[1,   399] loss: 0.715257\n",
      "[1,   499] loss: 0.722615\n",
      "[1,   599] loss: 0.733424\n",
      "[1,   699] loss: 0.728439\n",
      "[2,    99] loss: 0.714896\n",
      "[2,   199] loss: 0.717107\n",
      "[2,   299] loss: 0.717485\n",
      "[2,   399] loss: 0.715831\n",
      "[2,   499] loss: 0.723306\n",
      "[2,   599] loss: 0.733687\n",
      "[2,   699] loss: 0.729066\n",
      "[3,    99] loss: 0.715060\n",
      "[3,   199] loss: 0.717341\n",
      "[3,   299] loss: 0.717633\n",
      "[3,   399] loss: 0.715934\n",
      "[3,   499] loss: 0.723451\n",
      "[3,   599] loss: 0.733749\n",
      "[3,   699] loss: 0.729229\n",
      "[4,    99] loss: 0.715107\n",
      "[4,   199] loss: 0.717414\n",
      "[4,   299] loss: 0.717681\n",
      "[4,   399] loss: 0.715969\n",
      "[4,   499] loss: 0.723503\n",
      "[4,   599] loss: 0.733771\n",
      "[4,   699] loss: 0.729291\n",
      "[5,    99] loss: 0.715126\n",
      "[5,   199] loss: 0.717444\n",
      "[5,   299] loss: 0.717701\n",
      "[5,   399] loss: 0.715984\n",
      "[5,   499] loss: 0.723525\n",
      "[5,   599] loss: 0.733781\n",
      "[5,   699] loss: 0.729318\n",
      "[6,    99] loss: 0.715134\n",
      "[6,   199] loss: 0.717457\n",
      "[6,   299] loss: 0.717710\n",
      "[6,   399] loss: 0.715991\n",
      "[6,   499] loss: 0.723535\n",
      "[6,   599] loss: 0.733785\n",
      "[6,   699] loss: 0.729330\n",
      "[7,    99] loss: 0.715138\n",
      "[7,   199] loss: 0.717463\n",
      "[7,   299] loss: 0.717714\n",
      "[7,   399] loss: 0.715994\n",
      "[7,   499] loss: 0.723540\n",
      "[7,   599] loss: 0.733787\n",
      "[7,   699] loss: 0.729336\n",
      "[8,    99] loss: 0.715139\n",
      "[8,   199] loss: 0.717466\n",
      "[8,   299] loss: 0.717716\n",
      "[8,   399] loss: 0.715996\n",
      "[8,   499] loss: 0.723542\n",
      "[8,   599] loss: 0.733788\n",
      "[8,   699] loss: 0.729339\n",
      "[9,    99] loss: 0.715140\n",
      "[9,   199] loss: 0.717468\n",
      "[9,   299] loss: 0.717717\n",
      "[9,   399] loss: 0.715996\n",
      "[9,   499] loss: 0.723543\n",
      "[9,   599] loss: 0.733789\n",
      "[9,   699] loss: 0.729340\n",
      "[10,    99] loss: 0.715141\n",
      "[10,   199] loss: 0.717468\n",
      "[10,   299] loss: 0.717718\n",
      "[10,   399] loss: 0.715997\n",
      "[10,   499] loss: 0.723544\n",
      "[10,   599] loss: 0.733789\n",
      "[10,   699] loss: 0.729341\n",
      "[11,    99] loss: 0.715141\n",
      "[11,   199] loss: 0.717469\n",
      "[11,   299] loss: 0.717718\n",
      "[11,   399] loss: 0.715997\n",
      "[11,   499] loss: 0.723544\n",
      "[11,   599] loss: 0.733789\n",
      "[11,   699] loss: 0.729341\n",
      "[12,    99] loss: 0.715141\n",
      "[12,   199] loss: 0.717469\n",
      "[12,   299] loss: 0.717718\n",
      "[12,   399] loss: 0.715997\n",
      "[12,   499] loss: 0.723544\n",
      "[12,   599] loss: 0.733789\n",
      "[12,   699] loss: 0.729341\n",
      "[13,    99] loss: 0.715141\n",
      "[13,   199] loss: 0.717469\n",
      "[13,   299] loss: 0.717718\n",
      "[13,   399] loss: 0.715997\n",
      "[13,   499] loss: 0.723544\n",
      "[13,   599] loss: 0.733789\n",
      "[13,   699] loss: 0.729341\n",
      "[14,    99] loss: 0.715141\n",
      "[14,   199] loss: 0.717469\n",
      "[14,   299] loss: 0.717718\n",
      "[14,   399] loss: 0.715997\n",
      "[14,   499] loss: 0.723544\n",
      "[14,   599] loss: 0.733789\n",
      "[14,   699] loss: 0.729341\n",
      "[15,    99] loss: 0.715141\n",
      "[15,   199] loss: 0.717469\n",
      "[15,   299] loss: 0.717718\n",
      "[15,   399] loss: 0.715997\n",
      "[15,   499] loss: 0.723544\n",
      "[15,   599] loss: 0.733789\n",
      "[15,   699] loss: 0.729341\n",
      "[16,    99] loss: 0.715141\n",
      "[16,   199] loss: 0.717469\n",
      "[16,   299] loss: 0.717718\n",
      "[16,   399] loss: 0.715997\n",
      "[16,   499] loss: 0.723544\n",
      "[16,   599] loss: 0.733789\n",
      "[16,   699] loss: 0.729341\n",
      "[17,    99] loss: 0.715141\n",
      "[17,   199] loss: 0.717469\n",
      "[17,   299] loss: 0.717718\n",
      "[17,   399] loss: 0.715997\n",
      "[17,   499] loss: 0.723544\n",
      "[17,   599] loss: 0.733789\n",
      "[17,   699] loss: 0.729342\n",
      "[18,    99] loss: 0.715141\n",
      "[18,   199] loss: 0.717469\n",
      "[18,   299] loss: 0.717718\n",
      "[18,   399] loss: 0.715997\n",
      "[18,   499] loss: 0.723544\n",
      "[18,   599] loss: 0.733789\n",
      "[18,   699] loss: 0.729342\n",
      "[19,    99] loss: 0.715141\n",
      "[19,   199] loss: 0.717469\n",
      "[19,   299] loss: 0.717718\n",
      "[19,   399] loss: 0.715997\n",
      "[19,   499] loss: 0.723544\n",
      "[19,   599] loss: 0.733789\n",
      "[19,   699] loss: 0.729342\n",
      "[20,    99] loss: 0.715141\n",
      "[20,   199] loss: 0.717469\n",
      "[20,   299] loss: 0.717718\n",
      "[20,   399] loss: 0.715997\n",
      "[20,   499] loss: 0.723544\n",
      "[20,   599] loss: 0.733789\n",
      "[20,   699] loss: 0.729342\n",
      "[21,    99] loss: 0.715141\n",
      "[21,   199] loss: 0.717469\n",
      "[21,   299] loss: 0.717718\n",
      "[21,   399] loss: 0.715997\n",
      "[21,   499] loss: 0.723544\n",
      "[21,   599] loss: 0.733789\n",
      "[21,   699] loss: 0.729342\n",
      "[22,    99] loss: 0.715141\n",
      "[22,   199] loss: 0.717469\n",
      "[22,   299] loss: 0.717718\n",
      "[22,   399] loss: 0.715997\n",
      "[22,   499] loss: 0.723544\n",
      "[22,   599] loss: 0.733789\n",
      "[22,   699] loss: 0.729342\n",
      "[23,    99] loss: 0.715141\n",
      "[23,   199] loss: 0.717469\n",
      "[23,   299] loss: 0.717718\n",
      "[23,   399] loss: 0.715997\n",
      "[23,   499] loss: 0.723544\n",
      "[23,   599] loss: 0.733789\n",
      "[23,   699] loss: 0.729342\n",
      "[24,    99] loss: 0.715141\n",
      "[24,   199] loss: 0.717469\n",
      "[24,   299] loss: 0.717718\n",
      "[24,   399] loss: 0.715997\n",
      "[24,   499] loss: 0.723544\n",
      "[24,   599] loss: 0.733789\n",
      "[24,   699] loss: 0.729342\n",
      "[25,    99] loss: 0.715141\n",
      "[25,   199] loss: 0.717469\n",
      "[25,   299] loss: 0.717718\n",
      "[25,   399] loss: 0.715997\n",
      "[25,   499] loss: 0.723544\n",
      "[25,   599] loss: 0.733789\n",
      "[25,   699] loss: 0.729342\n",
      "[26,    99] loss: 0.715141\n",
      "[26,   199] loss: 0.717469\n",
      "[26,   299] loss: 0.717718\n",
      "[26,   399] loss: 0.715997\n",
      "[26,   499] loss: 0.723544\n",
      "[26,   599] loss: 0.733789\n",
      "[26,   699] loss: 0.729342\n",
      "[27,    99] loss: 0.715141\n",
      "[27,   199] loss: 0.717469\n",
      "[27,   299] loss: 0.717718\n",
      "[27,   399] loss: 0.715997\n",
      "[27,   499] loss: 0.723544\n",
      "[27,   599] loss: 0.733789\n",
      "[27,   699] loss: 0.729342\n",
      "[28,    99] loss: 0.715141\n",
      "[28,   199] loss: 0.717469\n",
      "[28,   299] loss: 0.717718\n",
      "[28,   399] loss: 0.715997\n",
      "[28,   499] loss: 0.723544\n",
      "[28,   599] loss: 0.733789\n",
      "[28,   699] loss: 0.729342\n",
      "[29,    99] loss: 0.715141\n",
      "[29,   199] loss: 0.717469\n",
      "[29,   299] loss: 0.717718\n",
      "[29,   399] loss: 0.715997\n",
      "[29,   499] loss: 0.723544\n",
      "[29,   599] loss: 0.733789\n",
      "[29,   699] loss: 0.729342\n",
      "[30,    99] loss: 0.715141\n",
      "[30,   199] loss: 0.717469\n",
      "[30,   299] loss: 0.717718\n",
      "[30,   399] loss: 0.715997\n",
      "[30,   499] loss: 0.723544\n",
      "[30,   599] loss: 0.733789\n",
      "[30,   699] loss: 0.729342\n",
      "[31,    99] loss: 0.715141\n",
      "[31,   199] loss: 0.717469\n",
      "[31,   299] loss: 0.717718\n",
      "[31,   399] loss: 0.715997\n",
      "[31,   499] loss: 0.723544\n",
      "[31,   599] loss: 0.733789\n",
      "[31,   699] loss: 0.729342\n",
      "[32,    99] loss: 0.715141\n",
      "[32,   199] loss: 0.717469\n",
      "[32,   299] loss: 0.717718\n",
      "[32,   399] loss: 0.715997\n",
      "[32,   499] loss: 0.723544\n",
      "[32,   599] loss: 0.733789\n",
      "[32,   699] loss: 0.729342\n",
      "[33,    99] loss: 0.715141\n",
      "[33,   199] loss: 0.717469\n",
      "[33,   299] loss: 0.717718\n",
      "[33,   399] loss: 0.715997\n",
      "[33,   499] loss: 0.723544\n",
      "[33,   599] loss: 0.733789\n",
      "[33,   699] loss: 0.729342\n",
      "[34,    99] loss: 0.715141\n",
      "[34,   199] loss: 0.717469\n",
      "[34,   299] loss: 0.717718\n",
      "[34,   399] loss: 0.715997\n",
      "[34,   499] loss: 0.723544\n",
      "[34,   599] loss: 0.733789\n",
      "[34,   699] loss: 0.729342\n",
      "[35,    99] loss: 0.715141\n",
      "[35,   199] loss: 0.717469\n",
      "[35,   299] loss: 0.717718\n",
      "[35,   399] loss: 0.715997\n",
      "[35,   499] loss: 0.723544\n",
      "[35,   599] loss: 0.733789\n",
      "[35,   699] loss: 0.729342\n",
      "[36,    99] loss: 0.715141\n",
      "[36,   199] loss: 0.717469\n",
      "[36,   299] loss: 0.717718\n",
      "[36,   399] loss: 0.715997\n",
      "[36,   499] loss: 0.723544\n",
      "[36,   599] loss: 0.733789\n",
      "[36,   699] loss: 0.729342\n",
      "[37,    99] loss: 0.715141\n",
      "[37,   199] loss: 0.717469\n",
      "[37,   299] loss: 0.717718\n",
      "[37,   399] loss: 0.715997\n",
      "[37,   499] loss: 0.723544\n",
      "[37,   599] loss: 0.733789\n",
      "[37,   699] loss: 0.729342\n",
      "[38,    99] loss: 0.715141\n",
      "[38,   199] loss: 0.717469\n",
      "[38,   299] loss: 0.717718\n",
      "[38,   399] loss: 0.715997\n",
      "[38,   499] loss: 0.723544\n",
      "[38,   599] loss: 0.733789\n",
      "[38,   699] loss: 0.729342\n",
      "[39,    99] loss: 0.715141\n",
      "[39,   199] loss: 0.717469\n",
      "[39,   299] loss: 0.717718\n",
      "[39,   399] loss: 0.715997\n",
      "[39,   499] loss: 0.723544\n",
      "[39,   599] loss: 0.733789\n",
      "[39,   699] loss: 0.729342\n",
      "[40,    99] loss: 0.715141\n",
      "[40,   199] loss: 0.717469\n",
      "[40,   299] loss: 0.717718\n",
      "[40,   399] loss: 0.715997\n",
      "[40,   499] loss: 0.723544\n",
      "[40,   599] loss: 0.733789\n",
      "[40,   699] loss: 0.729342\n",
      "[41,    99] loss: 0.715141\n",
      "[41,   199] loss: 0.717469\n",
      "[41,   299] loss: 0.717718\n",
      "[41,   399] loss: 0.715997\n",
      "[41,   499] loss: 0.723544\n",
      "[41,   599] loss: 0.733789\n",
      "[41,   699] loss: 0.729342\n",
      "[42,    99] loss: 0.715141\n",
      "[42,   199] loss: 0.717469\n",
      "[42,   299] loss: 0.717718\n",
      "[42,   399] loss: 0.715997\n",
      "[42,   499] loss: 0.723544\n",
      "[42,   599] loss: 0.733789\n",
      "[42,   699] loss: 0.729342\n",
      "[43,    99] loss: 0.715141\n",
      "[43,   199] loss: 0.717469\n",
      "[43,   299] loss: 0.717718\n",
      "[43,   399] loss: 0.715997\n",
      "[43,   499] loss: 0.723544\n",
      "[43,   599] loss: 0.733789\n",
      "[43,   699] loss: 0.729342\n",
      "[44,    99] loss: 0.715141\n",
      "[44,   199] loss: 0.717469\n",
      "[44,   299] loss: 0.717718\n",
      "[44,   399] loss: 0.715997\n",
      "[44,   499] loss: 0.723544\n",
      "[44,   599] loss: 0.733789\n",
      "[44,   699] loss: 0.729342\n",
      "[45,    99] loss: 0.715141\n",
      "[45,   199] loss: 0.717469\n",
      "[45,   299] loss: 0.717718\n",
      "[45,   399] loss: 0.715997\n",
      "[45,   499] loss: 0.723544\n",
      "[45,   599] loss: 0.733789\n",
      "[45,   699] loss: 0.729342\n",
      "[46,    99] loss: 0.715141\n",
      "[46,   199] loss: 0.717469\n",
      "[46,   299] loss: 0.717718\n",
      "[46,   399] loss: 0.715997\n",
      "[46,   499] loss: 0.723544\n",
      "[46,   599] loss: 0.733789\n",
      "[46,   699] loss: 0.729342\n",
      "[47,    99] loss: 0.715141\n",
      "[47,   199] loss: 0.717469\n",
      "[47,   299] loss: 0.717718\n",
      "[47,   399] loss: 0.715997\n",
      "[47,   499] loss: 0.723544\n",
      "[47,   599] loss: 0.733789\n",
      "[47,   699] loss: 0.729342\n",
      "[48,    99] loss: 0.715141\n",
      "[48,   199] loss: 0.717469\n",
      "[48,   299] loss: 0.717718\n",
      "[48,   399] loss: 0.715997\n",
      "[48,   499] loss: 0.723544\n",
      "[48,   599] loss: 0.733789\n",
      "[48,   699] loss: 0.729342\n",
      "[49,    99] loss: 0.715141\n",
      "[49,   199] loss: 0.717469\n",
      "[49,   299] loss: 0.717718\n",
      "[49,   399] loss: 0.715997\n",
      "[49,   499] loss: 0.723544\n",
      "[49,   599] loss: 0.733789\n",
      "[49,   699] loss: 0.729342\n",
      "[50,    99] loss: 0.715141\n",
      "[50,   199] loss: 0.717469\n",
      "[50,   299] loss: 0.717718\n",
      "[50,   399] loss: 0.715997\n",
      "[50,   499] loss: 0.723544\n",
      "[50,   599] loss: 0.733789\n",
      "[50,   699] loss: 0.729342\n",
      "[51,    99] loss: 0.715141\n",
      "[51,   199] loss: 0.717469\n",
      "[51,   299] loss: 0.717718\n",
      "[51,   399] loss: 0.715997\n",
      "[51,   499] loss: 0.723544\n",
      "[51,   599] loss: 0.733789\n",
      "[51,   699] loss: 0.729342\n",
      "[52,    99] loss: 0.715141\n",
      "[52,   199] loss: 0.717469\n",
      "[52,   299] loss: 0.717718\n",
      "[52,   399] loss: 0.715997\n",
      "[52,   499] loss: 0.723544\n",
      "[52,   599] loss: 0.733789\n",
      "[52,   699] loss: 0.729342\n",
      "[53,    99] loss: 0.715141\n",
      "[53,   199] loss: 0.717469\n",
      "[53,   299] loss: 0.717718\n",
      "[53,   399] loss: 0.715997\n",
      "[53,   499] loss: 0.723544\n",
      "[53,   599] loss: 0.733789\n",
      "[53,   699] loss: 0.729342\n",
      "[54,    99] loss: 0.715141\n",
      "[54,   199] loss: 0.717469\n",
      "[54,   299] loss: 0.717718\n",
      "[54,   399] loss: 0.715997\n",
      "[54,   499] loss: 0.723544\n",
      "[54,   599] loss: 0.733789\n",
      "[54,   699] loss: 0.729342\n",
      "[55,    99] loss: 0.715141\n",
      "[55,   199] loss: 0.717469\n",
      "[55,   299] loss: 0.717718\n",
      "[55,   399] loss: 0.715997\n",
      "[55,   499] loss: 0.723544\n",
      "[55,   599] loss: 0.733789\n",
      "[55,   699] loss: 0.729342\n",
      "[56,    99] loss: 0.715141\n",
      "[56,   199] loss: 0.717469\n",
      "[56,   299] loss: 0.717718\n",
      "[56,   399] loss: 0.715997\n",
      "[56,   499] loss: 0.723544\n",
      "[56,   599] loss: 0.733789\n",
      "[56,   699] loss: 0.729342\n",
      "[57,    99] loss: 0.715141\n",
      "[57,   199] loss: 0.717469\n",
      "[57,   299] loss: 0.717718\n",
      "[57,   399] loss: 0.715997\n",
      "[57,   499] loss: 0.723544\n",
      "[57,   599] loss: 0.733789\n",
      "[57,   699] loss: 0.729342\n",
      "[58,    99] loss: 0.715141\n",
      "[58,   199] loss: 0.717469\n",
      "[58,   299] loss: 0.717718\n",
      "[58,   399] loss: 0.715997\n",
      "[58,   499] loss: 0.723544\n",
      "[58,   599] loss: 0.733789\n",
      "[58,   699] loss: 0.729342\n",
      "[59,    99] loss: 0.715141\n",
      "[59,   199] loss: 0.717469\n",
      "[59,   299] loss: 0.717718\n",
      "[59,   399] loss: 0.715997\n",
      "[59,   499] loss: 0.723544\n",
      "[59,   599] loss: 0.733789\n",
      "[59,   699] loss: 0.729342\n",
      "[60,    99] loss: 0.715141\n",
      "[60,   199] loss: 0.717469\n",
      "[60,   299] loss: 0.717718\n",
      "[60,   399] loss: 0.715997\n",
      "[60,   499] loss: 0.723544\n",
      "[60,   599] loss: 0.733789\n",
      "[60,   699] loss: 0.729342\n",
      "[61,    99] loss: 0.715141\n",
      "[61,   199] loss: 0.717469\n",
      "[61,   299] loss: 0.717718\n",
      "[61,   399] loss: 0.715997\n",
      "[61,   499] loss: 0.723544\n",
      "[61,   599] loss: 0.733789\n",
      "[61,   699] loss: 0.729342\n",
      "[62,    99] loss: 0.715141\n",
      "[62,   199] loss: 0.717469\n",
      "[62,   299] loss: 0.717718\n",
      "[62,   399] loss: 0.715997\n",
      "[62,   499] loss: 0.723544\n",
      "[62,   599] loss: 0.733789\n",
      "[62,   699] loss: 0.729342\n",
      "[63,    99] loss: 0.715141\n",
      "[63,   199] loss: 0.717469\n",
      "[63,   299] loss: 0.717718\n",
      "[63,   399] loss: 0.715997\n",
      "[63,   499] loss: 0.723544\n",
      "[63,   599] loss: 0.733789\n",
      "[63,   699] loss: 0.729342\n",
      "[64,    99] loss: 0.715141\n",
      "[64,   199] loss: 0.717469\n",
      "[64,   299] loss: 0.717718\n",
      "[64,   399] loss: 0.715997\n",
      "[64,   499] loss: 0.723544\n",
      "[64,   599] loss: 0.733789\n",
      "[64,   699] loss: 0.729342\n",
      "[65,    99] loss: 0.715141\n",
      "[65,   199] loss: 0.717469\n",
      "[65,   299] loss: 0.717718\n",
      "[65,   399] loss: 0.715997\n",
      "[65,   499] loss: 0.723544\n",
      "[65,   599] loss: 0.733789\n",
      "[65,   699] loss: 0.729342\n",
      "[66,    99] loss: 0.715141\n",
      "[66,   199] loss: 0.717469\n",
      "[66,   299] loss: 0.717718\n",
      "[66,   399] loss: 0.715997\n",
      "[66,   499] loss: 0.723544\n",
      "[66,   599] loss: 0.733789\n",
      "[66,   699] loss: 0.729342\n",
      "[67,    99] loss: 0.715141\n",
      "[67,   199] loss: 0.717469\n",
      "[67,   299] loss: 0.717718\n",
      "[67,   399] loss: 0.715997\n",
      "[67,   499] loss: 0.723544\n",
      "[67,   599] loss: 0.733789\n",
      "[67,   699] loss: 0.729342\n",
      "[68,    99] loss: 0.715141\n",
      "[68,   199] loss: 0.717469\n",
      "[68,   299] loss: 0.717718\n",
      "[68,   399] loss: 0.715997\n",
      "[68,   499] loss: 0.723544\n",
      "[68,   599] loss: 0.733789\n",
      "[68,   699] loss: 0.729342\n",
      "[69,    99] loss: 0.715141\n",
      "[69,   199] loss: 0.717469\n",
      "[69,   299] loss: 0.717718\n",
      "[69,   399] loss: 0.715997\n",
      "[69,   499] loss: 0.723544\n",
      "[69,   599] loss: 0.733789\n",
      "[69,   699] loss: 0.729342\n",
      "[70,    99] loss: 0.715141\n",
      "[70,   199] loss: 0.717469\n",
      "[70,   299] loss: 0.717718\n",
      "[70,   399] loss: 0.715997\n",
      "[70,   499] loss: 0.723544\n",
      "[70,   599] loss: 0.733789\n",
      "[70,   699] loss: 0.729342\n",
      "[71,    99] loss: 0.715141\n",
      "[71,   199] loss: 0.717469\n",
      "[71,   299] loss: 0.717718\n",
      "[71,   399] loss: 0.715997\n",
      "[71,   499] loss: 0.723544\n",
      "[71,   599] loss: 0.733789\n",
      "[71,   699] loss: 0.729342\n",
      "[72,    99] loss: 0.715141\n",
      "[72,   199] loss: 0.717469\n",
      "[72,   299] loss: 0.717718\n",
      "[72,   399] loss: 0.715997\n",
      "[72,   499] loss: 0.723544\n",
      "[72,   599] loss: 0.733789\n",
      "[72,   699] loss: 0.729342\n",
      "[73,    99] loss: 0.715141\n",
      "[73,   199] loss: 0.717469\n",
      "[73,   299] loss: 0.717718\n",
      "[73,   399] loss: 0.715997\n",
      "[73,   499] loss: 0.723544\n",
      "[73,   599] loss: 0.733789\n",
      "[73,   699] loss: 0.729342\n",
      "[74,    99] loss: 0.715141\n",
      "[74,   199] loss: 0.717469\n",
      "[74,   299] loss: 0.717718\n",
      "[74,   399] loss: 0.715997\n",
      "[74,   499] loss: 0.723544\n",
      "[74,   599] loss: 0.733789\n",
      "[74,   699] loss: 0.729342\n",
      "[75,    99] loss: 0.715141\n",
      "[75,   199] loss: 0.717469\n",
      "[75,   299] loss: 0.717718\n",
      "[75,   399] loss: 0.715997\n",
      "[75,   499] loss: 0.723544\n",
      "[75,   599] loss: 0.733789\n",
      "[75,   699] loss: 0.729342\n",
      "[76,    99] loss: 0.715141\n",
      "[76,   199] loss: 0.717469\n",
      "[76,   299] loss: 0.717718\n",
      "[76,   399] loss: 0.715997\n",
      "[76,   499] loss: 0.723544\n",
      "[76,   599] loss: 0.733789\n",
      "[76,   699] loss: 0.729342\n",
      "[77,    99] loss: 0.715141\n",
      "[77,   199] loss: 0.717469\n",
      "[77,   299] loss: 0.717718\n",
      "[77,   399] loss: 0.715997\n",
      "[77,   499] loss: 0.723544\n",
      "[77,   599] loss: 0.733789\n",
      "[77,   699] loss: 0.729342\n",
      "[78,    99] loss: 0.715141\n",
      "[78,   199] loss: 0.717469\n",
      "[78,   299] loss: 0.717718\n",
      "[78,   399] loss: 0.715997\n",
      "[78,   499] loss: 0.723544\n",
      "[78,   599] loss: 0.733789\n",
      "[78,   699] loss: 0.729342\n",
      "[79,    99] loss: 0.715141\n",
      "[79,   199] loss: 0.717469\n",
      "[79,   299] loss: 0.717718\n",
      "[79,   399] loss: 0.715997\n",
      "[79,   499] loss: 0.723544\n",
      "[79,   599] loss: 0.733789\n",
      "[79,   699] loss: 0.729342\n",
      "[80,    99] loss: 0.715141\n",
      "[80,   199] loss: 0.717469\n",
      "[80,   299] loss: 0.717718\n",
      "[80,   399] loss: 0.715997\n",
      "[80,   499] loss: 0.723544\n",
      "[80,   599] loss: 0.733789\n",
      "[80,   699] loss: 0.729342\n",
      "[81,    99] loss: 0.715141\n",
      "[81,   199] loss: 0.717469\n",
      "[81,   299] loss: 0.717718\n",
      "[81,   399] loss: 0.715997\n",
      "[81,   499] loss: 0.723544\n",
      "[81,   599] loss: 0.733789\n",
      "[81,   699] loss: 0.729342\n",
      "[82,    99] loss: 0.715141\n",
      "[82,   199] loss: 0.717469\n",
      "[82,   299] loss: 0.717718\n",
      "[82,   399] loss: 0.715997\n",
      "[82,   499] loss: 0.723544\n",
      "[82,   599] loss: 0.733789\n",
      "[82,   699] loss: 0.729342\n",
      "[83,    99] loss: 0.715141\n",
      "[83,   199] loss: 0.717469\n",
      "[83,   299] loss: 0.717718\n",
      "[83,   399] loss: 0.715997\n",
      "[83,   499] loss: 0.723544\n",
      "[83,   599] loss: 0.733789\n",
      "[83,   699] loss: 0.729342\n",
      "[84,    99] loss: 0.715141\n",
      "[84,   199] loss: 0.717469\n",
      "[84,   299] loss: 0.717718\n",
      "[84,   399] loss: 0.715997\n",
      "[84,   499] loss: 0.723544\n",
      "[84,   599] loss: 0.733789\n",
      "[84,   699] loss: 0.729342\n",
      "[85,    99] loss: 0.715141\n",
      "[85,   199] loss: 0.717469\n",
      "[85,   299] loss: 0.717718\n",
      "[85,   399] loss: 0.715997\n",
      "[85,   499] loss: 0.723544\n",
      "[85,   599] loss: 0.733789\n",
      "[85,   699] loss: 0.729342\n",
      "[86,    99] loss: 0.715141\n",
      "[86,   199] loss: 0.717469\n",
      "[86,   299] loss: 0.717718\n",
      "[86,   399] loss: 0.715997\n",
      "[86,   499] loss: 0.723544\n",
      "[86,   599] loss: 0.733789\n",
      "[86,   699] loss: 0.729342\n",
      "[87,    99] loss: 0.715141\n",
      "[87,   199] loss: 0.717469\n",
      "[87,   299] loss: 0.717718\n",
      "[87,   399] loss: 0.715997\n",
      "[87,   499] loss: 0.723544\n",
      "[87,   599] loss: 0.733789\n",
      "[87,   699] loss: 0.729342\n",
      "[88,    99] loss: 0.715141\n",
      "[88,   199] loss: 0.717469\n",
      "[88,   299] loss: 0.717718\n",
      "[88,   399] loss: 0.715997\n",
      "[88,   499] loss: 0.723544\n",
      "[88,   599] loss: 0.733789\n",
      "[88,   699] loss: 0.729342\n",
      "[89,    99] loss: 0.715141\n",
      "[89,   199] loss: 0.717469\n",
      "[89,   299] loss: 0.717718\n",
      "[89,   399] loss: 0.715997\n",
      "[89,   499] loss: 0.723544\n",
      "[89,   599] loss: 0.733789\n",
      "[89,   699] loss: 0.729342\n",
      "[90,    99] loss: 0.715141\n",
      "[90,   199] loss: 0.717469\n",
      "[90,   299] loss: 0.717718\n",
      "[90,   399] loss: 0.715997\n",
      "[90,   499] loss: 0.723544\n",
      "[90,   599] loss: 0.733789\n",
      "[90,   699] loss: 0.729342\n",
      "[91,    99] loss: 0.715141\n",
      "[91,   199] loss: 0.717469\n",
      "[91,   299] loss: 0.717718\n",
      "[91,   399] loss: 0.715997\n",
      "[91,   499] loss: 0.723544\n",
      "[91,   599] loss: 0.733789\n",
      "[91,   699] loss: 0.729342\n",
      "[92,    99] loss: 0.715141\n",
      "[92,   199] loss: 0.717469\n",
      "[92,   299] loss: 0.717718\n",
      "[92,   399] loss: 0.715997\n",
      "[92,   499] loss: 0.723544\n",
      "[92,   599] loss: 0.733789\n",
      "[92,   699] loss: 0.729342\n",
      "[93,    99] loss: 0.715141\n",
      "[93,   199] loss: 0.717469\n",
      "[93,   299] loss: 0.717718\n",
      "[93,   399] loss: 0.715997\n",
      "[93,   499] loss: 0.723544\n",
      "[93,   599] loss: 0.733789\n",
      "[93,   699] loss: 0.729342\n",
      "[94,    99] loss: 0.715141\n",
      "[94,   199] loss: 0.717469\n",
      "[94,   299] loss: 0.717718\n",
      "[94,   399] loss: 0.715997\n",
      "[94,   499] loss: 0.723544\n",
      "[94,   599] loss: 0.733789\n",
      "[94,   699] loss: 0.729342\n",
      "[95,    99] loss: 0.715141\n",
      "[95,   199] loss: 0.717469\n",
      "[95,   299] loss: 0.717718\n",
      "[95,   399] loss: 0.715997\n",
      "[95,   499] loss: 0.723544\n",
      "[95,   599] loss: 0.733789\n",
      "[95,   699] loss: 0.729342\n",
      "[96,    99] loss: 0.715141\n",
      "[96,   199] loss: 0.717469\n",
      "[96,   299] loss: 0.717718\n",
      "[96,   399] loss: 0.715997\n",
      "[96,   499] loss: 0.723544\n",
      "[96,   599] loss: 0.733789\n",
      "[96,   699] loss: 0.729342\n",
      "[97,    99] loss: 0.715141\n",
      "[97,   199] loss: 0.717469\n",
      "[97,   299] loss: 0.717718\n",
      "[97,   399] loss: 0.715997\n",
      "[97,   499] loss: 0.723544\n",
      "[97,   599] loss: 0.733789\n",
      "[97,   699] loss: 0.729342\n",
      "[98,    99] loss: 0.715141\n",
      "[98,   199] loss: 0.717469\n",
      "[98,   299] loss: 0.717718\n",
      "[98,   399] loss: 0.715997\n",
      "[98,   499] loss: 0.723544\n",
      "[98,   599] loss: 0.733789\n",
      "[98,   699] loss: 0.729342\n",
      "[99,    99] loss: 0.715141\n",
      "[99,   199] loss: 0.717469\n",
      "[99,   299] loss: 0.717718\n",
      "[99,   399] loss: 0.715997\n",
      "[99,   499] loss: 0.723544\n",
      "[99,   599] loss: 0.733789\n",
      "[99,   699] loss: 0.729342\n",
      "[100,    99] loss: 0.715141\n",
      "[100,   199] loss: 0.717469\n",
      "[100,   299] loss: 0.717718\n",
      "[100,   399] loss: 0.715997\n",
      "[100,   499] loss: 0.723544\n",
      "[100,   599] loss: 0.733789\n",
      "[100,   699] loss: 0.729342\n",
      "Finished Training\n",
      "[1,    99] loss: 0.727037\n",
      "[1,   199] loss: 0.698243\n",
      "[1,   299] loss: 0.779793\n",
      "[1,   399] loss: 0.661792\n",
      "[1,   499] loss: 0.755633\n",
      "[1,   599] loss: 0.718629\n",
      "[1,   699] loss: 0.721167\n",
      "[2,    99] loss: 0.614376\n",
      "[2,   199] loss: 0.687502\n",
      "[2,   299] loss: 0.567440\n",
      "[2,   399] loss: 0.660127\n",
      "[2,   499] loss: 0.732164\n",
      "[2,   599] loss: 0.590892\n",
      "[2,   699] loss: 0.705455\n",
      "[3,    99] loss: 0.556063\n",
      "[3,   199] loss: 0.623728\n",
      "[3,   299] loss: 1.078300\n",
      "[3,   399] loss: 0.637898\n",
      "[3,   499] loss: 0.722960\n",
      "[3,   599] loss: 0.639573\n",
      "[3,   699] loss: 0.655258\n",
      "[4,    99] loss: 0.603188\n",
      "[4,   199] loss: 0.579483\n",
      "[4,   299] loss: 0.468126\n",
      "[4,   399] loss: 0.628491\n",
      "[4,   499] loss: 0.681433\n",
      "[4,   599] loss: 0.579144\n",
      "[4,   699] loss: 0.662920\n",
      "[5,    99] loss: 0.514798\n",
      "[5,   199] loss: 0.537934\n",
      "[5,   299] loss: 0.471648\n",
      "[5,   399] loss: 0.570820\n",
      "[5,   499] loss: 0.749564\n",
      "[5,   599] loss: 0.693383\n",
      "[5,   699] loss: 0.643376\n",
      "[6,    99] loss: 0.468564\n",
      "[6,   199] loss: 0.527118\n",
      "[6,   299] loss: 0.481654\n",
      "[6,   399] loss: 0.566933\n",
      "[6,   499] loss: 1.027683\n",
      "[6,   599] loss: 0.499950\n",
      "[6,   699] loss: 0.594824\n",
      "[7,    99] loss: 0.409334\n",
      "[7,   199] loss: 0.605739\n",
      "[7,   299] loss: 0.469244\n",
      "[7,   399] loss: 0.493079\n",
      "[7,   499] loss: 0.481475\n",
      "[7,   599] loss: 0.513728\n",
      "[7,   699] loss: 0.555486\n",
      "[8,    99] loss: 0.433917\n",
      "[8,   199] loss: 0.533409\n",
      "[8,   299] loss: 0.400583\n",
      "[8,   399] loss: 0.492539\n",
      "[8,   499] loss: 0.519058\n",
      "[8,   599] loss: 0.490738\n",
      "[8,   699] loss: 0.491167\n",
      "[9,    99] loss: 0.351487\n",
      "[9,   199] loss: 0.488944\n",
      "[9,   299] loss: 0.363007\n",
      "[9,   399] loss: 0.492658\n",
      "[9,   499] loss: 0.539700\n",
      "[9,   599] loss: 0.439279\n",
      "[9,   699] loss: 0.473148\n",
      "[10,    99] loss: 0.477605\n",
      "[10,   199] loss: 0.469706\n",
      "[10,   299] loss: 0.404554\n",
      "[10,   399] loss: 0.571692\n",
      "[10,   499] loss: 0.551154\n",
      "[10,   599] loss: 0.424269\n",
      "[10,   699] loss: 0.387249\n",
      "[11,    99] loss: 0.357562\n",
      "[11,   199] loss: 0.431512\n",
      "[11,   299] loss: 0.365029\n",
      "[11,   399] loss: 0.529739\n",
      "[11,   499] loss: 0.368813\n",
      "[11,   599] loss: 0.406549\n",
      "[11,   699] loss: 0.377840\n",
      "[12,    99] loss: 0.380569\n",
      "[12,   199] loss: 0.436190\n",
      "[12,   299] loss: 0.351867\n",
      "[12,   399] loss: 0.469937\n",
      "[12,   499] loss: 0.341672\n",
      "[12,   599] loss: 0.417277\n",
      "[12,   699] loss: 0.492349\n",
      "[13,    99] loss: 0.361056\n",
      "[13,   199] loss: 0.499289\n",
      "[13,   299] loss: 0.437782\n",
      "[13,   399] loss: 0.575844\n",
      "[13,   499] loss: 0.401977\n",
      "[13,   599] loss: 0.445845\n",
      "[13,   699] loss: 0.398830\n",
      "[14,    99] loss: 0.324521\n",
      "[14,   199] loss: 0.327760\n",
      "[14,   299] loss: 0.328056\n",
      "[14,   399] loss: 0.425979\n",
      "[14,   499] loss: 0.398305\n",
      "[14,   599] loss: 0.380824\n",
      "[14,   699] loss: 0.335914\n",
      "[15,    99] loss: 0.282075\n",
      "[15,   199] loss: 0.346755\n",
      "[15,   299] loss: 0.274056\n",
      "[15,   399] loss: 0.423985\n",
      "[15,   499] loss: 0.395474\n",
      "[15,   599] loss: 0.362142\n",
      "[15,   699] loss: 0.378364\n",
      "[16,    99] loss: 0.298213\n",
      "[16,   199] loss: 0.290760\n",
      "[16,   299] loss: 0.301168\n",
      "[16,   399] loss: 0.473761\n",
      "[16,   499] loss: 0.335753\n",
      "[16,   599] loss: 0.331639\n",
      "[16,   699] loss: 0.348313\n",
      "[17,    99] loss: 0.249533\n",
      "[17,   199] loss: 0.281783\n",
      "[17,   299] loss: 0.423657\n",
      "[17,   399] loss: 0.420053\n",
      "[17,   499] loss: 0.430605\n",
      "[17,   599] loss: 0.381508\n",
      "[17,   699] loss: 0.425268\n",
      "[18,    99] loss: 0.302526\n",
      "[18,   199] loss: 0.351253\n",
      "[18,   299] loss: 0.331875\n",
      "[18,   399] loss: 0.406338\n",
      "[18,   499] loss: 0.306027\n",
      "[18,   599] loss: 0.304457\n",
      "[18,   699] loss: 0.371355\n",
      "[19,    99] loss: 0.255127\n",
      "[19,   199] loss: 0.366183\n",
      "[19,   299] loss: 0.334356\n",
      "[19,   399] loss: 0.447536\n",
      "[19,   499] loss: 0.375201\n",
      "[19,   599] loss: 0.356635\n",
      "[19,   699] loss: 0.400353\n",
      "[20,    99] loss: 0.260739\n",
      "[20,   199] loss: 0.404657\n",
      "[20,   299] loss: 0.234406\n",
      "[20,   399] loss: 0.482878\n",
      "[20,   499] loss: 0.300795\n",
      "[20,   599] loss: 0.312969\n",
      "[20,   699] loss: 0.383092\n",
      "[21,    99] loss: 0.241871\n",
      "[21,   199] loss: 0.321209\n",
      "[21,   299] loss: 0.271223\n",
      "[21,   399] loss: 0.376629\n",
      "[21,   499] loss: 0.266687\n",
      "[21,   599] loss: 0.434030\n",
      "[21,   699] loss: 0.403876\n",
      "[22,    99] loss: 0.339931\n",
      "[22,   199] loss: 0.329589\n",
      "[22,   299] loss: 0.381549\n",
      "[22,   399] loss: 0.350434\n",
      "[22,   499] loss: 0.290915\n",
      "[22,   599] loss: 0.364781\n",
      "[22,   699] loss: 0.360992\n",
      "[23,    99] loss: 0.276027\n",
      "[23,   199] loss: 0.342450\n",
      "[23,   299] loss: 0.225421\n",
      "[23,   399] loss: 0.317388\n",
      "[23,   499] loss: 0.267450\n",
      "[23,   599] loss: 0.400837\n",
      "[23,   699] loss: 0.356422\n",
      "[24,    99] loss: 0.259867\n",
      "[24,   199] loss: 0.261980\n",
      "[24,   299] loss: 0.241065\n",
      "[24,   399] loss: 0.484921\n",
      "[24,   499] loss: 0.328651\n",
      "[24,   599] loss: 0.298528\n",
      "[24,   699] loss: 0.292318\n",
      "[25,    99] loss: 0.288712\n",
      "[25,   199] loss: 0.387601\n",
      "[25,   299] loss: 0.260634\n",
      "[25,   399] loss: 0.407000\n",
      "[25,   499] loss: 0.307562\n",
      "[25,   599] loss: 0.285547\n",
      "[25,   699] loss: 0.335710\n",
      "[26,    99] loss: 0.391594\n",
      "[26,   199] loss: 0.342757\n",
      "[26,   299] loss: 0.244916\n",
      "[26,   399] loss: 0.325193\n",
      "[26,   499] loss: 0.246554\n",
      "[26,   599] loss: 0.227283\n",
      "[26,   699] loss: 0.273496\n",
      "[27,    99] loss: 0.290862\n",
      "[27,   199] loss: 0.261111\n",
      "[27,   299] loss: 0.231179\n",
      "[27,   399] loss: 0.333935\n",
      "[27,   499] loss: 0.203529\n",
      "[27,   599] loss: 0.252939\n",
      "[27,   699] loss: 0.378160\n",
      "[28,    99] loss: 0.337364\n",
      "[28,   199] loss: 0.424091\n",
      "[28,   299] loss: 0.300927\n",
      "[28,   399] loss: 0.384575\n",
      "[28,   499] loss: 0.328033\n",
      "[28,   599] loss: 0.305704\n",
      "[28,   699] loss: 0.350458\n",
      "[29,    99] loss: 0.312856\n",
      "[29,   199] loss: 0.318842\n",
      "[29,   299] loss: 0.250415\n",
      "[29,   399] loss: 0.373566\n",
      "[29,   499] loss: 0.268257\n",
      "[29,   599] loss: 0.243810\n",
      "[29,   699] loss: 0.283986\n",
      "[30,    99] loss: 0.556162\n",
      "[30,   199] loss: 0.341086\n",
      "[30,   299] loss: 0.356472\n",
      "[30,   399] loss: 0.304363\n",
      "[30,   499] loss: 0.238725\n",
      "[30,   599] loss: 0.268088\n",
      "[30,   699] loss: 0.438481\n",
      "[31,    99] loss: 0.273644\n",
      "[31,   199] loss: 0.324593\n",
      "[31,   299] loss: 0.300395\n",
      "[31,   399] loss: 0.420789\n",
      "[31,   499] loss: 0.330135\n",
      "[31,   599] loss: 0.375277\n",
      "[31,   699] loss: 0.346814\n",
      "[32,    99] loss: 0.279330\n",
      "[32,   199] loss: 0.281877\n",
      "[32,   299] loss: 0.305388\n",
      "[32,   399] loss: 0.336363\n",
      "[32,   499] loss: 0.305087\n",
      "[32,   599] loss: 0.268187\n",
      "[32,   699] loss: 0.287653\n",
      "[33,    99] loss: 0.335316\n",
      "[33,   199] loss: 0.360312\n",
      "[33,   299] loss: 0.226999\n",
      "[33,   399] loss: 0.298977\n",
      "[33,   499] loss: 0.281664\n",
      "[33,   599] loss: 0.648930\n",
      "[33,   699] loss: 0.455458\n",
      "[34,    99] loss: 0.263647\n",
      "[34,   199] loss: 0.354244\n",
      "[34,   299] loss: 0.272870\n",
      "[34,   399] loss: 0.467729\n",
      "[34,   499] loss: 0.236837\n",
      "[34,   599] loss: 0.372515\n",
      "[34,   699] loss: 0.349487\n",
      "[35,    99] loss: 0.277375\n",
      "[35,   199] loss: 0.265270\n",
      "[35,   299] loss: 0.263617\n",
      "[35,   399] loss: 0.306240\n",
      "[35,   499] loss: 0.220668\n",
      "[35,   599] loss: 0.282002\n",
      "[35,   699] loss: 0.301792\n",
      "[36,    99] loss: 0.291858\n",
      "[36,   199] loss: 0.268407\n",
      "[36,   299] loss: 0.248611\n",
      "[36,   399] loss: 0.315644\n",
      "[36,   499] loss: 0.212099\n",
      "[36,   599] loss: 0.245602\n",
      "[36,   699] loss: 0.254056\n",
      "[37,    99] loss: 0.269018\n",
      "[37,   199] loss: 0.248097\n",
      "[37,   299] loss: 0.285031\n",
      "[37,   399] loss: 0.363890\n",
      "[37,   499] loss: 0.203863\n",
      "[37,   599] loss: 0.215658\n",
      "[37,   699] loss: 0.233826\n",
      "[38,    99] loss: 0.221467\n",
      "[38,   199] loss: 0.258797\n",
      "[38,   299] loss: 0.324612\n",
      "[38,   399] loss: 0.351161\n",
      "[38,   499] loss: 0.237461\n",
      "[38,   599] loss: 0.221042\n",
      "[38,   699] loss: 0.275787\n",
      "[39,    99] loss: 0.322149\n",
      "[39,   199] loss: 0.401599\n",
      "[39,   299] loss: 0.268005\n",
      "[39,   399] loss: 0.297900\n",
      "[39,   499] loss: 0.210120\n",
      "[39,   599] loss: 0.285399\n",
      "[39,   699] loss: 0.275643\n",
      "[40,    99] loss: 0.247934\n",
      "[40,   199] loss: 0.238371\n",
      "[40,   299] loss: 0.208193\n",
      "[40,   399] loss: 0.307738\n",
      "[40,   499] loss: 0.217860\n",
      "[40,   599] loss: 0.199652\n",
      "[40,   699] loss: 0.277085\n",
      "[41,    99] loss: 0.234612\n",
      "[41,   199] loss: 0.229754\n",
      "[41,   299] loss: 0.231531\n",
      "[41,   399] loss: 0.406621\n",
      "[41,   499] loss: 0.231289\n",
      "[41,   599] loss: 0.310687\n",
      "[41,   699] loss: 0.242174\n",
      "[42,    99] loss: 0.239998\n",
      "[42,   199] loss: 0.193417\n",
      "[42,   299] loss: 0.214271\n",
      "[42,   399] loss: 0.404654\n",
      "[42,   499] loss: 0.212228\n",
      "[42,   599] loss: 0.437531\n",
      "[42,   699] loss: 0.272551\n",
      "[43,    99] loss: 0.369670\n",
      "[43,   199] loss: 0.564489\n",
      "[43,   299] loss: 0.234327\n",
      "[43,   399] loss: 0.285389\n",
      "[43,   499] loss: 0.196047\n",
      "[43,   599] loss: 0.207364\n",
      "[43,   699] loss: 0.127501\n",
      "[44,    99] loss: 0.358430\n",
      "[44,   199] loss: 0.279841\n",
      "[44,   299] loss: 0.223277\n",
      "[44,   399] loss: 0.300298\n",
      "[44,   499] loss: 0.220329\n",
      "[44,   599] loss: 0.204154\n",
      "[44,   699] loss: 0.216598\n",
      "[45,    99] loss: 0.239788\n",
      "[45,   199] loss: 1.444515\n",
      "[45,   299] loss: 0.367410\n",
      "[45,   399] loss: 0.436461\n",
      "[45,   499] loss: 0.271468\n",
      "[45,   599] loss: 0.283382\n",
      "[45,   699] loss: 0.266377\n",
      "[46,    99] loss: 0.216649\n",
      "[46,   199] loss: 0.199254\n",
      "[46,   299] loss: 0.138059\n",
      "[46,   399] loss: 0.258960\n",
      "[46,   499] loss: 0.241049\n",
      "[46,   599] loss: 0.224904\n",
      "[46,   699] loss: 0.212500\n",
      "[47,    99] loss: 0.217649\n",
      "[47,   199] loss: 0.185833\n",
      "[47,   299] loss: 0.188198\n",
      "[47,   399] loss: 0.347087\n",
      "[47,   499] loss: 0.183977\n",
      "[47,   599] loss: 0.189539\n",
      "[47,   699] loss: 0.268739\n",
      "[48,    99] loss: 0.207414\n",
      "[48,   199] loss: 0.225730\n",
      "[48,   299] loss: 0.248809\n",
      "[48,   399] loss: 0.468572\n",
      "[48,   499] loss: 0.377788\n",
      "[48,   599] loss: 0.348393\n",
      "[48,   699] loss: 0.331938\n",
      "[49,    99] loss: 0.241196\n",
      "[49,   199] loss: 0.290522\n",
      "[49,   299] loss: 0.203039\n",
      "[49,   399] loss: 0.283124\n",
      "[49,   499] loss: 0.210700\n",
      "[49,   599] loss: 0.208058\n",
      "[49,   699] loss: 0.289705\n",
      "[50,    99] loss: 0.218853\n",
      "[50,   199] loss: 0.231563\n",
      "[50,   299] loss: 0.183452\n",
      "[50,   399] loss: 0.291766\n",
      "[50,   499] loss: 0.159069\n",
      "[50,   599] loss: 0.264427\n",
      "[50,   699] loss: 0.323979\n",
      "[51,    99] loss: 0.293072\n",
      "[51,   199] loss: 0.233622\n",
      "[51,   299] loss: 0.215187\n",
      "[51,   399] loss: 0.305201\n",
      "[51,   499] loss: 0.166184\n",
      "[51,   599] loss: 0.182769\n",
      "[51,   699] loss: 0.177191\n",
      "[52,    99] loss: 0.257107\n",
      "[52,   199] loss: 0.213156\n",
      "[52,   299] loss: 0.292097\n",
      "[52,   399] loss: 0.367926\n",
      "[52,   499] loss: 0.224018\n",
      "[52,   599] loss: 0.330725\n",
      "[52,   699] loss: 0.210313\n",
      "[53,    99] loss: 0.287528\n",
      "[53,   199] loss: 0.257109\n",
      "[53,   299] loss: 0.215811\n",
      "[53,   399] loss: 0.548092\n",
      "[53,   499] loss: 0.204473\n",
      "[53,   599] loss: 0.184683\n",
      "[53,   699] loss: 0.204856\n",
      "[54,    99] loss: 0.286693\n",
      "[54,   199] loss: 0.276875\n",
      "[54,   299] loss: 0.220840\n",
      "[54,   399] loss: 0.313996\n",
      "[54,   499] loss: 0.192112\n",
      "[54,   599] loss: 1.397411\n",
      "[54,   699] loss: 0.406364\n",
      "[55,    99] loss: 0.199739\n",
      "[55,   199] loss: 0.217572\n",
      "[55,   299] loss: 0.204870\n",
      "[55,   399] loss: 0.467300\n",
      "[55,   499] loss: 0.163741\n",
      "[55,   599] loss: 0.210403\n",
      "[55,   699] loss: 0.219840\n",
      "[56,    99] loss: 0.217694\n",
      "[56,   199] loss: 0.218977\n",
      "[56,   299] loss: 0.192367\n",
      "[56,   399] loss: 0.284322\n",
      "[56,   499] loss: 0.156254\n",
      "[56,   599] loss: 0.185506\n",
      "[56,   699] loss: 0.129312\n",
      "[57,    99] loss: 0.231331\n",
      "[57,   199] loss: 0.190397\n",
      "[57,   299] loss: 0.184265\n",
      "[57,   399] loss: 0.298290\n",
      "[57,   499] loss: 0.220570\n",
      "[57,   599] loss: 0.227381\n",
      "[57,   699] loss: 0.173487\n",
      "[58,    99] loss: 0.164756\n",
      "[58,   199] loss: 0.243542\n",
      "[58,   299] loss: 0.162256\n",
      "[58,   399] loss: 0.274063\n",
      "[58,   499] loss: 0.716819\n",
      "[58,   599] loss: 0.220921\n",
      "[58,   699] loss: 0.235039\n",
      "[59,    99] loss: 0.240186\n",
      "[59,   199] loss: 0.244408\n",
      "[59,   299] loss: 0.215259\n",
      "[59,   399] loss: 0.283166\n",
      "[59,   499] loss: 0.176679\n",
      "[59,   599] loss: 0.188668\n",
      "[59,   699] loss: 0.222892\n",
      "[60,    99] loss: 0.205694\n",
      "[60,   199] loss: 0.193356\n",
      "[60,   299] loss: 0.185931\n",
      "[60,   399] loss: 0.282462\n",
      "[60,   499] loss: 0.183199\n",
      "[60,   599] loss: 0.277335\n",
      "[60,   699] loss: 0.187258\n",
      "[61,    99] loss: 0.268192\n",
      "[61,   199] loss: 0.217768\n",
      "[61,   299] loss: 0.226407\n",
      "[61,   399] loss: 0.300103\n",
      "[61,   499] loss: 0.157686\n",
      "[61,   599] loss: 0.264818\n",
      "[61,   699] loss: 0.228046\n",
      "[62,    99] loss: 0.232825\n",
      "[62,   199] loss: 0.151035\n",
      "[62,   299] loss: 0.182042\n",
      "[62,   399] loss: 0.252303\n",
      "[62,   499] loss: 0.492292\n",
      "[62,   599] loss: 0.259801\n",
      "[62,   699] loss: 0.486837\n",
      "[63,    99] loss: 0.256739\n",
      "[63,   199] loss: 0.231198\n",
      "[63,   299] loss: 0.475724\n",
      "[63,   399] loss: 0.312104\n",
      "[63,   499] loss: 0.174782\n",
      "[63,   599] loss: 0.252312\n",
      "[63,   699] loss: 0.252468\n",
      "[64,    99] loss: 0.199037\n",
      "[64,   199] loss: 0.286669\n",
      "[64,   299] loss: 0.209556\n",
      "[64,   399] loss: 0.285641\n",
      "[64,   499] loss: 0.184689\n",
      "[64,   599] loss: 0.219070\n",
      "[64,   699] loss: 0.208525\n",
      "[65,    99] loss: 0.198242\n",
      "[65,   199] loss: 0.485906\n",
      "[65,   299] loss: 0.200495\n",
      "[65,   399] loss: 0.275407\n",
      "[65,   499] loss: 0.178082\n",
      "[65,   599] loss: 0.203747\n",
      "[65,   699] loss: 0.164331\n",
      "[66,    99] loss: 0.432771\n",
      "[66,   199] loss: 0.130203\n",
      "[66,   299] loss: 0.210458\n",
      "[66,   399] loss: 0.286530\n",
      "[66,   499] loss: 0.161796\n",
      "[66,   599] loss: 0.216641\n",
      "[66,   699] loss: 0.244045\n",
      "[67,    99] loss: 0.244127\n",
      "[67,   199] loss: 0.171653\n",
      "[67,   299] loss: 0.184012\n",
      "[67,   399] loss: 0.330318\n",
      "[67,   499] loss: 0.500476\n",
      "[67,   599] loss: 0.253830\n",
      "[67,   699] loss: 0.249179\n",
      "[68,    99] loss: 0.197664\n",
      "[68,   199] loss: 0.161297\n",
      "[68,   299] loss: 0.235279\n",
      "[68,   399] loss: 0.340684\n",
      "[68,   499] loss: 0.138080\n",
      "[68,   599] loss: 0.186580\n",
      "[68,   699] loss: 0.171217\n",
      "[69,    99] loss: 0.216157\n",
      "[69,   199] loss: 0.114484\n",
      "[69,   299] loss: 0.159992\n",
      "[69,   399] loss: 0.295595\n",
      "[69,   499] loss: 0.132434\n",
      "[69,   599] loss: 0.256621\n",
      "[69,   699] loss: 0.155673\n",
      "[70,    99] loss: 0.269766\n",
      "[70,   199] loss: 0.172345\n",
      "[70,   299] loss: 0.185470\n",
      "[70,   399] loss: 0.290221\n",
      "[70,   499] loss: 0.158458\n",
      "[70,   599] loss: 0.200013\n",
      "[70,   699] loss: 0.169382\n",
      "[71,    99] loss: 0.183976\n",
      "[71,   199] loss: 0.269540\n",
      "[71,   299] loss: 0.135795\n",
      "[71,   399] loss: 0.291855\n",
      "[71,   499] loss: 0.196295\n",
      "[71,   599] loss: 0.208658\n",
      "[71,   699] loss: 0.154504\n",
      "[72,    99] loss: 0.108305\n",
      "[72,   199] loss: 0.076263\n",
      "[72,   299] loss: 0.215752\n",
      "[72,   399] loss: 0.302081\n",
      "[72,   499] loss: 0.173855\n",
      "[72,   599] loss: 0.215958\n",
      "[72,   699] loss: 0.215072\n",
      "[73,    99] loss: 0.275023\n",
      "[73,   199] loss: 0.170232\n",
      "[73,   299] loss: 0.150695\n",
      "[73,   399] loss: 0.310258\n",
      "[73,   499] loss: 0.151143\n",
      "[73,   599] loss: 0.178389\n",
      "[73,   699] loss: 0.122382\n",
      "[74,    99] loss: 0.176075\n",
      "[74,   199] loss: 0.101567\n",
      "[74,   299] loss: 0.130086\n",
      "[74,   399] loss: 0.284674\n",
      "[74,   499] loss: 0.122091\n",
      "[74,   599] loss: 0.174992\n",
      "[74,   699] loss: 0.099938\n",
      "[75,    99] loss: 0.271893\n",
      "[75,   199] loss: 0.118744\n",
      "[75,   299] loss: 0.122621\n",
      "[75,   399] loss: 0.328196\n",
      "[75,   499] loss: 0.159750\n",
      "[75,   599] loss: 0.151032\n",
      "[75,   699] loss: 0.100531\n",
      "[76,    99] loss: 0.286774\n",
      "[76,   199] loss: 0.164521\n",
      "[76,   299] loss: 0.180539\n",
      "[76,   399] loss: 0.304573\n",
      "[76,   499] loss: 0.174644\n",
      "[76,   599] loss: 0.200238\n",
      "[76,   699] loss: 0.243765\n",
      "[77,    99] loss: 0.176951\n",
      "[77,   199] loss: 0.147810\n",
      "[77,   299] loss: 0.316202\n",
      "[77,   399] loss: 0.349224\n",
      "[77,   499] loss: 0.159893\n",
      "[77,   599] loss: 0.244741\n",
      "[77,   699] loss: 0.231134\n",
      "[78,    99] loss: 0.303516\n",
      "[78,   199] loss: 0.196643\n",
      "[78,   299] loss: 0.178212\n",
      "[78,   399] loss: 0.272680\n",
      "[78,   499] loss: 0.124366\n",
      "[78,   599] loss: 0.177947\n",
      "[78,   699] loss: 0.183280\n",
      "[79,    99] loss: 0.315629\n",
      "[79,   199] loss: 0.160608\n",
      "[79,   299] loss: 0.194145\n",
      "[79,   399] loss: 0.319255\n",
      "[79,   499] loss: 1.233871\n",
      "[79,   599] loss: 0.354102\n",
      "[79,   699] loss: 0.405756\n",
      "[80,    99] loss: 0.299089\n",
      "[80,   199] loss: 0.721448\n",
      "[80,   299] loss: 0.135589\n",
      "[80,   399] loss: 0.270424\n",
      "[80,   499] loss: 0.138573\n",
      "[80,   599] loss: 0.171746\n",
      "[80,   699] loss: 0.214958\n",
      "[81,    99] loss: 0.162770\n",
      "[81,   199] loss: 0.205302\n",
      "[81,   299] loss: 0.131453\n",
      "[81,   399] loss: 0.215875\n",
      "[81,   499] loss: 0.114419\n",
      "[81,   599] loss: 0.091842\n",
      "[81,   699] loss: 0.123961\n",
      "[82,    99] loss: 0.145767\n",
      "[82,   199] loss: 0.166395\n",
      "[82,   299] loss: 0.062000\n",
      "[82,   399] loss: 0.242361\n",
      "[82,   499] loss: 0.187423\n",
      "[82,   599] loss: 0.088825\n",
      "[82,   699] loss: 0.098087\n",
      "[83,    99] loss: 0.095244\n",
      "[83,   199] loss: 1.025774\n",
      "[83,   299] loss: 0.283902\n",
      "[83,   399] loss: 0.495132\n",
      "[83,   499] loss: 0.135124\n",
      "[83,   599] loss: 0.144658\n",
      "[83,   699] loss: 0.307518\n",
      "[84,    99] loss: 0.107577\n",
      "[84,   199] loss: 0.102108\n",
      "[84,   299] loss: 0.068942\n",
      "[84,   399] loss: 0.191736\n",
      "[84,   499] loss: 0.243999\n",
      "[84,   599] loss: 0.142702\n",
      "[84,   699] loss: 0.103146\n",
      "[85,    99] loss: 0.087801\n",
      "[85,   199] loss: 0.156717\n",
      "[85,   299] loss: 0.063388\n",
      "[85,   399] loss: 0.198183\n",
      "[85,   499] loss: 0.133119\n",
      "[85,   599] loss: 0.080694\n",
      "[85,   699] loss: 0.425926\n",
      "[86,    99] loss: 0.143154\n",
      "[86,   199] loss: 0.159861\n",
      "[86,   299] loss: 0.143199\n",
      "[86,   399] loss: 0.248790\n",
      "[86,   499] loss: 0.182985\n",
      "[86,   599] loss: 0.119264\n",
      "[86,   699] loss: 0.224037\n",
      "[87,    99] loss: 0.104620\n",
      "[87,   199] loss: 0.126106\n",
      "[87,   299] loss: 0.147854\n",
      "[87,   399] loss: 0.200949\n",
      "[87,   499] loss: 0.132107\n",
      "[87,   599] loss: 0.109094\n",
      "[87,   699] loss: 0.244903\n",
      "[88,    99] loss: 0.142091\n",
      "[88,   199] loss: 0.135083\n",
      "[88,   299] loss: 0.138006\n",
      "[88,   399] loss: 0.199549\n",
      "[88,   499] loss: 0.124676\n",
      "[88,   599] loss: 0.089468\n",
      "[88,   699] loss: 0.124311\n",
      "[89,    99] loss: 0.086595\n",
      "[89,   199] loss: 0.214601\n",
      "[89,   299] loss: 0.213295\n",
      "[89,   399] loss: 0.405127\n",
      "[89,   499] loss: 0.144006\n",
      "[89,   599] loss: 0.176408\n",
      "[89,   699] loss: 0.124485\n",
      "[90,    99] loss: 0.106703\n",
      "[90,   199] loss: 0.257412\n",
      "[90,   299] loss: 0.107399\n",
      "[90,   399] loss: 0.288236\n",
      "[90,   499] loss: 0.283387\n",
      "[90,   599] loss: 0.271363\n",
      "[90,   699] loss: 0.205844\n",
      "[91,    99] loss: 0.119800\n",
      "[91,   199] loss: 0.163001\n",
      "[91,   299] loss: 0.126652\n",
      "[91,   399] loss: 0.242158\n",
      "[91,   499] loss: 0.351912\n",
      "[91,   599] loss: 0.155191\n",
      "[91,   699] loss: 0.179010\n",
      "[92,    99] loss: 0.134784\n",
      "[92,   199] loss: 0.156724\n",
      "[92,   299] loss: 0.121302\n",
      "[92,   399] loss: 0.252701\n",
      "[92,   499] loss: 0.160520\n",
      "[92,   599] loss: 0.234301\n",
      "[92,   699] loss: 0.210402\n",
      "[93,    99] loss: 0.099316\n",
      "[93,   199] loss: 0.156189\n",
      "[93,   299] loss: 0.135604\n",
      "[93,   399] loss: 0.304633\n",
      "[93,   499] loss: 0.172701\n",
      "[93,   599] loss: 0.269088\n",
      "[93,   699] loss: 0.175100\n",
      "[94,    99] loss: 0.137256\n",
      "[94,   199] loss: 0.209501\n",
      "[94,   299] loss: 0.173456\n",
      "[94,   399] loss: 0.292434\n",
      "[94,   499] loss: 0.375643\n",
      "[94,   599] loss: 0.206162\n",
      "[94,   699] loss: 0.240550\n",
      "[95,    99] loss: 0.142126\n",
      "[95,   199] loss: 0.163787\n",
      "[95,   299] loss: 0.123077\n",
      "[95,   399] loss: 0.246378\n",
      "[95,   499] loss: 0.144012\n",
      "[95,   599] loss: 0.097645\n",
      "[95,   699] loss: 0.148175\n",
      "[96,    99] loss: 0.062905\n",
      "[96,   199] loss: 0.292388\n",
      "[96,   299] loss: 0.152414\n",
      "[96,   399] loss: 0.251986\n",
      "[96,   499] loss: 0.255046\n",
      "[96,   599] loss: 0.245988\n",
      "[96,   699] loss: 0.462916\n",
      "[97,    99] loss: 0.234660\n",
      "[97,   199] loss: 0.130403\n",
      "[97,   299] loss: 0.189138\n",
      "[97,   399] loss: 0.879364\n",
      "[97,   499] loss: 0.723705\n",
      "[97,   599] loss: 0.096653\n",
      "[97,   699] loss: 0.154764\n",
      "[98,    99] loss: 0.213846\n",
      "[98,   199] loss: 0.132630\n",
      "[98,   299] loss: 0.275091\n",
      "[98,   399] loss: 0.284842\n",
      "[98,   499] loss: 0.108545\n",
      "[98,   599] loss: 0.131919\n",
      "[98,   699] loss: 0.180567\n",
      "[99,    99] loss: 0.131480\n",
      "[99,   199] loss: 0.144418\n",
      "[99,   299] loss: 0.106071\n",
      "[99,   399] loss: 0.225700\n",
      "[99,   499] loss: 0.075537\n",
      "[99,   599] loss: 0.067549\n",
      "[99,   699] loss: 0.262132\n",
      "[100,    99] loss: 0.149655\n",
      "[100,   199] loss: 0.125479\n",
      "[100,   299] loss: 0.119899\n",
      "[100,   399] loss: 0.230021\n",
      "[100,   499] loss: 0.097366\n",
      "[100,   599] loss: 0.094800\n",
      "[100,   699] loss: 0.148279\n",
      "Finished Training\n",
      "[1,    99] loss: 0.747643\n",
      "[1,   199] loss: 0.709258\n",
      "[1,   299] loss: 0.715215\n",
      "[1,   399] loss: 0.737692\n",
      "[1,   499] loss: 0.708992\n",
      "[1,   599] loss: 0.750840\n",
      "[1,   699] loss: 0.637305\n",
      "[2,    99] loss: 0.699921\n",
      "[2,   199] loss: 0.854403\n",
      "[2,   299] loss: 0.654421\n",
      "[2,   399] loss: 0.738342\n",
      "[2,   499] loss: 0.660667\n",
      "[2,   599] loss: 0.687394\n",
      "[2,   699] loss: 0.522925\n",
      "[3,    99] loss: 0.790067\n",
      "[3,   199] loss: 0.704101\n",
      "[3,   299] loss: 0.642645\n",
      "[3,   399] loss: 0.731644\n",
      "[3,   499] loss: 0.639805\n",
      "[3,   599] loss: 0.730838\n",
      "[3,   699] loss: 0.788192\n",
      "[4,    99] loss: 0.664549\n",
      "[4,   199] loss: 0.711678\n",
      "[4,   299] loss: 0.573549\n",
      "[4,   399] loss: 0.676918\n",
      "[4,   499] loss: 0.639698\n",
      "[4,   599] loss: 0.662696\n",
      "[4,   699] loss: 0.479049\n",
      "[5,    99] loss: 0.596921\n",
      "[5,   199] loss: 0.610466\n",
      "[5,   299] loss: 0.582999\n",
      "[5,   399] loss: 0.675027\n",
      "[5,   499] loss: 0.585153\n",
      "[5,   599] loss: 0.705207\n",
      "[5,   699] loss: 0.461437\n",
      "[6,    99] loss: 0.555742\n",
      "[6,   199] loss: 0.577806\n",
      "[6,   299] loss: 0.541026\n",
      "[6,   399] loss: 0.601299\n",
      "[6,   499] loss: 0.494903\n",
      "[6,   599] loss: 0.616758\n",
      "[6,   699] loss: 0.438258\n",
      "[7,    99] loss: 0.523592\n",
      "[7,   199] loss: 0.619872\n",
      "[7,   299] loss: 0.515703\n",
      "[7,   399] loss: 0.569549\n",
      "[7,   499] loss: 0.493961\n",
      "[7,   599] loss: 0.620021\n",
      "[7,   699] loss: 0.426156\n",
      "[8,    99] loss: 0.481719\n",
      "[8,   199] loss: 0.486017\n",
      "[8,   299] loss: 0.449486\n",
      "[8,   399] loss: 0.632807\n",
      "[8,   499] loss: 0.446213\n",
      "[8,   599] loss: 0.514784\n",
      "[8,   699] loss: 0.395412\n",
      "[9,    99] loss: 0.504653\n",
      "[9,   199] loss: 0.509579\n",
      "[9,   299] loss: 0.397281\n",
      "[9,   399] loss: 0.551179\n",
      "[9,   499] loss: 0.443058\n",
      "[9,   599] loss: 0.520454\n",
      "[9,   699] loss: 0.379645\n",
      "[10,    99] loss: 0.474225\n",
      "[10,   199] loss: 0.479635\n",
      "[10,   299] loss: 0.471939\n",
      "[10,   399] loss: 0.465241\n",
      "[10,   499] loss: 0.463009\n",
      "[10,   599] loss: 0.440200\n",
      "[10,   699] loss: 0.371217\n",
      "[11,    99] loss: 0.348609\n",
      "[11,   199] loss: 0.594708\n",
      "[11,   299] loss: 0.446929\n",
      "[11,   399] loss: 0.425771\n",
      "[11,   499] loss: 0.433004\n",
      "[11,   599] loss: 0.488757\n",
      "[11,   699] loss: 0.329423\n",
      "[12,    99] loss: 0.441207\n",
      "[12,   199] loss: 0.439393\n",
      "[12,   299] loss: 0.434306\n",
      "[12,   399] loss: 0.457019\n",
      "[12,   499] loss: 0.461472\n",
      "[12,   599] loss: 0.498744\n",
      "[12,   699] loss: 0.374388\n",
      "[13,    99] loss: 0.393166\n",
      "[13,   199] loss: 0.372537\n",
      "[13,   299] loss: 0.431859\n",
      "[13,   399] loss: 0.465190\n",
      "[13,   499] loss: 0.402126\n",
      "[13,   599] loss: 0.494945\n",
      "[13,   699] loss: 0.360239\n",
      "[14,    99] loss: 0.361491\n",
      "[14,   199] loss: 0.432628\n",
      "[14,   299] loss: 0.432368\n",
      "[14,   399] loss: 0.503668\n",
      "[14,   499] loss: 0.407024\n",
      "[14,   599] loss: 0.455876\n",
      "[14,   699] loss: 0.365672\n",
      "[15,    99] loss: 0.419354\n",
      "[15,   199] loss: 0.368207\n",
      "[15,   299] loss: 0.417110\n",
      "[15,   399] loss: 0.424168\n",
      "[15,   499] loss: 0.395814\n",
      "[15,   599] loss: 0.394331\n",
      "[15,   699] loss: 0.340330\n",
      "[16,    99] loss: 0.341202\n",
      "[16,   199] loss: 0.417973\n",
      "[16,   299] loss: 0.481762\n",
      "[16,   399] loss: 0.464137\n",
      "[16,   499] loss: 0.387056\n",
      "[16,   599] loss: 0.464909\n",
      "[16,   699] loss: 0.307806\n",
      "[17,    99] loss: 0.386161\n",
      "[17,   199] loss: 0.394012\n",
      "[17,   299] loss: 0.460328\n",
      "[17,   399] loss: 0.491817\n",
      "[17,   499] loss: 0.389544\n",
      "[17,   599] loss: 0.456927\n",
      "[17,   699] loss: 0.371614\n",
      "[18,    99] loss: 0.418732\n",
      "[18,   199] loss: 0.328485\n",
      "[18,   299] loss: 0.360556\n",
      "[18,   399] loss: 0.513040\n",
      "[18,   499] loss: 0.386342\n",
      "[18,   599] loss: 0.423805\n",
      "[18,   699] loss: 0.346812\n",
      "[19,    99] loss: 0.347642\n",
      "[19,   199] loss: 0.320502\n",
      "[19,   299] loss: 0.528932\n",
      "[19,   399] loss: 0.514744\n",
      "[19,   499] loss: 0.369804\n",
      "[19,   599] loss: 0.435141\n",
      "[19,   699] loss: 0.370775\n",
      "[20,    99] loss: 0.332248\n",
      "[20,   199] loss: 0.400759\n",
      "[20,   299] loss: 0.356173\n",
      "[20,   399] loss: 0.420161\n",
      "[20,   499] loss: 0.359730\n",
      "[20,   599] loss: 0.497143\n",
      "[20,   699] loss: 0.340746\n",
      "[21,    99] loss: 0.383390\n",
      "[21,   199] loss: 0.325807\n",
      "[21,   299] loss: 0.368449\n",
      "[21,   399] loss: 0.336279\n",
      "[21,   499] loss: 0.389733\n",
      "[21,   599] loss: 0.420172\n",
      "[21,   699] loss: 0.339064\n",
      "[22,    99] loss: 0.313839\n",
      "[22,   199] loss: 0.306913\n",
      "[22,   299] loss: 0.374389\n",
      "[22,   399] loss: 0.330729\n",
      "[22,   499] loss: 0.403023\n",
      "[22,   599] loss: 0.414654\n",
      "[22,   699] loss: 0.335869\n",
      "[23,    99] loss: 0.363491\n",
      "[23,   199] loss: 0.271392\n",
      "[23,   299] loss: 0.400556\n",
      "[23,   399] loss: 0.361638\n",
      "[23,   499] loss: 0.340705\n",
      "[23,   599] loss: 0.317476\n",
      "[23,   699] loss: 0.420649\n",
      "[24,    99] loss: 0.334755\n",
      "[24,   199] loss: 0.259451\n",
      "[24,   299] loss: 0.405764\n",
      "[24,   399] loss: 0.303698\n",
      "[24,   499] loss: 0.353528\n",
      "[24,   599] loss: 0.385302\n",
      "[24,   699] loss: 0.304722\n",
      "[25,    99] loss: 0.338307\n",
      "[25,   199] loss: 0.365751\n",
      "[25,   299] loss: 0.507120\n",
      "[25,   399] loss: 0.374332\n",
      "[25,   499] loss: 0.387539\n",
      "[25,   599] loss: 0.603626\n",
      "[25,   699] loss: 0.352648\n",
      "[26,    99] loss: 0.324729\n",
      "[26,   199] loss: 0.374110\n",
      "[26,   299] loss: 0.330774\n",
      "[26,   399] loss: 0.367763\n",
      "[26,   499] loss: 0.345502\n",
      "[26,   599] loss: 0.394719\n",
      "[26,   699] loss: 0.373502\n",
      "[27,    99] loss: 0.421617\n",
      "[27,   199] loss: 0.380622\n",
      "[27,   299] loss: 0.371666\n",
      "[27,   399] loss: 0.351775\n",
      "[27,   499] loss: 0.576657\n",
      "[27,   599] loss: 0.446750\n",
      "[27,   699] loss: 0.302201\n",
      "[28,    99] loss: 0.678260\n",
      "[28,   199] loss: 0.311046\n",
      "[28,   299] loss: 0.283852\n",
      "[28,   399] loss: 0.349069\n",
      "[28,   499] loss: 0.511705\n",
      "[28,   599] loss: 0.523935\n",
      "[28,   699] loss: 0.303492\n",
      "[29,    99] loss: 0.310828\n",
      "[29,   199] loss: 0.315671\n",
      "[29,   299] loss: 0.333895\n",
      "[29,   399] loss: 0.291224\n",
      "[29,   499] loss: 0.309847\n",
      "[29,   599] loss: 0.342580\n",
      "[29,   699] loss: 0.303232\n",
      "[30,    99] loss: 0.284539\n",
      "[30,   199] loss: 0.307188\n",
      "[30,   299] loss: 0.368497\n",
      "[30,   399] loss: 0.302036\n",
      "[30,   499] loss: 0.288509\n",
      "[30,   599] loss: 0.297361\n",
      "[30,   699] loss: 0.272129\n",
      "[31,    99] loss: 0.232007\n",
      "[31,   199] loss: 0.274832\n",
      "[31,   299] loss: 0.355794\n",
      "[31,   399] loss: 0.322350\n",
      "[31,   499] loss: 0.299631\n",
      "[31,   599] loss: 0.292672\n",
      "[31,   699] loss: 0.480973\n",
      "[32,    99] loss: 0.270460\n",
      "[32,   199] loss: 0.360999\n",
      "[32,   299] loss: 0.256606\n",
      "[32,   399] loss: 0.548577\n",
      "[32,   499] loss: 0.420640\n",
      "[32,   599] loss: 1.644509\n",
      "[32,   699] loss: 0.431763\n",
      "[33,    99] loss: 0.309324\n",
      "[33,   199] loss: 0.266100\n",
      "[33,   299] loss: 0.357963\n",
      "[33,   399] loss: 0.316591\n",
      "[33,   499] loss: 0.297882\n",
      "[33,   599] loss: 0.265307\n",
      "[33,   699] loss: 0.291350\n",
      "[34,    99] loss: 0.242285\n",
      "[34,   199] loss: 0.211913\n",
      "[34,   299] loss: 0.342616\n",
      "[34,   399] loss: 0.274879\n",
      "[34,   499] loss: 0.326615\n",
      "[34,   599] loss: 0.275189\n",
      "[34,   699] loss: 0.253530\n",
      "[35,    99] loss: 0.246737\n",
      "[35,   199] loss: 0.296636\n",
      "[35,   299] loss: 0.235995\n",
      "[35,   399] loss: 0.327278\n",
      "[35,   499] loss: 0.255569\n",
      "[35,   599] loss: 0.282739\n",
      "[35,   699] loss: 0.260160\n",
      "[36,    99] loss: 0.290127\n",
      "[36,   199] loss: 0.274906\n",
      "[36,   299] loss: 0.239231\n",
      "[36,   399] loss: 0.281317\n",
      "[36,   499] loss: 0.250200\n",
      "[36,   599] loss: 0.239343\n",
      "[36,   699] loss: 0.205637\n",
      "[37,    99] loss: 0.248448\n",
      "[37,   199] loss: 0.272212\n",
      "[37,   299] loss: 0.368859\n",
      "[37,   399] loss: 0.329803\n",
      "[37,   499] loss: 0.317832\n",
      "[37,   599] loss: 0.214118\n",
      "[37,   699] loss: 0.230544\n",
      "[38,    99] loss: 0.249139\n",
      "[38,   199] loss: 0.237748\n",
      "[38,   299] loss: 0.245035\n",
      "[38,   399] loss: 0.299385\n",
      "[38,   499] loss: 0.311950\n",
      "[38,   599] loss: 0.482995\n",
      "[38,   699] loss: 0.328672\n",
      "[39,    99] loss: 0.303777\n",
      "[39,   199] loss: 0.323409\n",
      "[39,   299] loss: 0.301086\n",
      "[39,   399] loss: 0.264704\n",
      "[39,   499] loss: 0.238173\n",
      "[39,   599] loss: 0.291398\n",
      "[39,   699] loss: 0.625642\n",
      "[40,    99] loss: 0.273031\n",
      "[40,   199] loss: 0.251166\n",
      "[40,   299] loss: 0.229258\n",
      "[40,   399] loss: 0.584413\n",
      "[40,   499] loss: 0.251758\n",
      "[40,   599] loss: 0.280623\n",
      "[40,   699] loss: 0.205414\n",
      "[41,    99] loss: 0.235331\n",
      "[41,   199] loss: 0.298991\n",
      "[41,   299] loss: 0.224633\n",
      "[41,   399] loss: 0.210335\n",
      "[41,   499] loss: 0.269304\n",
      "[41,   599] loss: 0.461779\n",
      "[41,   699] loss: 0.281610\n",
      "[42,    99] loss: 0.317894\n",
      "[42,   199] loss: 0.530632\n",
      "[42,   299] loss: 0.383441\n",
      "[42,   399] loss: 0.350466\n",
      "[42,   499] loss: 0.273783\n",
      "[42,   599] loss: 0.267460\n",
      "[42,   699] loss: 0.250991\n",
      "[43,    99] loss: 0.276680\n",
      "[43,   199] loss: 0.273679\n",
      "[43,   299] loss: 0.309632\n",
      "[43,   399] loss: 0.850101\n",
      "[43,   499] loss: 0.262546\n",
      "[43,   599] loss: 0.319253\n",
      "[43,   699] loss: 0.495510\n",
      "[44,    99] loss: 0.267242\n",
      "[44,   199] loss: 0.231248\n",
      "[44,   299] loss: 0.529937\n",
      "[44,   399] loss: 0.267660\n",
      "[44,   499] loss: 0.288049\n",
      "[44,   599] loss: 0.218981\n",
      "[44,   699] loss: 0.285843\n",
      "[45,    99] loss: 0.506080\n",
      "[45,   199] loss: 0.288554\n",
      "[45,   299] loss: 0.313908\n",
      "[45,   399] loss: 0.294345\n",
      "[45,   499] loss: 0.426965\n",
      "[45,   599] loss: 0.374831\n",
      "[45,   699] loss: 0.262041\n",
      "[46,    99] loss: 0.254412\n",
      "[46,   199] loss: 0.348967\n",
      "[46,   299] loss: 0.322554\n",
      "[46,   399] loss: 0.269519\n",
      "[46,   499] loss: 0.268695\n",
      "[46,   599] loss: 0.266793\n",
      "[46,   699] loss: 0.273035\n",
      "[47,    99] loss: 0.242801\n",
      "[47,   199] loss: 0.210552\n",
      "[47,   299] loss: 0.354043\n",
      "[47,   399] loss: 0.285312\n",
      "[47,   499] loss: 0.302740\n",
      "[47,   599] loss: 0.297837\n",
      "[47,   699] loss: 0.260688\n",
      "[48,    99] loss: 0.304818\n",
      "[48,   199] loss: 0.224683\n",
      "[48,   299] loss: 0.274006\n",
      "[48,   399] loss: 0.216759\n",
      "[48,   499] loss: 0.193643\n",
      "[48,   599] loss: 0.446546\n",
      "[48,   699] loss: 0.208159\n",
      "[49,    99] loss: 0.204126\n",
      "[49,   199] loss: 0.363065\n",
      "[49,   299] loss: 0.290376\n",
      "[49,   399] loss: 0.235886\n",
      "[49,   499] loss: 0.305062\n",
      "[49,   599] loss: 0.240191\n",
      "[49,   699] loss: 0.260241\n",
      "[50,    99] loss: 0.353637\n",
      "[50,   199] loss: 0.319571\n",
      "[50,   299] loss: 0.354143\n",
      "[50,   399] loss: 0.330608\n",
      "[50,   499] loss: 0.192394\n",
      "[50,   599] loss: 0.232999\n",
      "[50,   699] loss: 0.273755\n",
      "[51,    99] loss: 0.240580\n",
      "[51,   199] loss: 0.304700\n",
      "[51,   299] loss: 0.299674\n",
      "[51,   399] loss: 0.195225\n",
      "[51,   499] loss: 0.273047\n",
      "[51,   599] loss: 0.319510\n",
      "[51,   699] loss: 0.225491\n",
      "[52,    99] loss: 0.195207\n",
      "[52,   199] loss: 0.219532\n",
      "[52,   299] loss: 0.388723\n",
      "[52,   399] loss: 0.603002\n",
      "[52,   499] loss: 0.323622\n",
      "[52,   599] loss: 0.293183\n",
      "[52,   699] loss: 0.210010\n",
      "[53,    99] loss: 0.190707\n",
      "[53,   199] loss: 0.332891\n",
      "[53,   299] loss: 0.390408\n",
      "[53,   399] loss: 0.205387\n",
      "[53,   499] loss: 0.178898\n",
      "[53,   599] loss: 0.189992\n",
      "[53,   699] loss: 0.353438\n",
      "[54,    99] loss: 0.194224\n",
      "[54,   199] loss: 0.299582\n",
      "[54,   299] loss: 0.290672\n",
      "[54,   399] loss: 0.283242\n",
      "[54,   499] loss: 0.278991\n",
      "[54,   599] loss: 0.168619\n",
      "[54,   699] loss: 0.336297\n",
      "[55,    99] loss: 0.233945\n",
      "[55,   199] loss: 0.416392\n",
      "[55,   299] loss: 0.329892\n",
      "[55,   399] loss: 0.154361\n",
      "[55,   499] loss: 0.170801\n",
      "[55,   599] loss: 0.332534\n",
      "[55,   699] loss: 0.183473\n",
      "[56,    99] loss: 0.196650\n",
      "[56,   199] loss: 0.965451\n",
      "[56,   299] loss: 0.211001\n",
      "[56,   399] loss: 0.127880\n",
      "[56,   499] loss: 0.169297\n",
      "[56,   599] loss: 0.204473\n",
      "[56,   699] loss: 0.219766\n",
      "[57,    99] loss: 0.248524\n",
      "[57,   199] loss: 0.174891\n",
      "[57,   299] loss: 0.214460\n",
      "[57,   399] loss: 0.221849\n",
      "[57,   499] loss: 0.163691\n",
      "[57,   599] loss: 0.196865\n",
      "[57,   699] loss: 0.166544\n",
      "[58,    99] loss: 0.322738\n",
      "[58,   199] loss: 0.223294\n",
      "[58,   299] loss: 0.219418\n",
      "[58,   399] loss: 0.132052\n",
      "[58,   499] loss: 0.147208\n",
      "[58,   599] loss: 0.206469\n",
      "[58,   699] loss: 0.181073\n",
      "[59,    99] loss: 0.220845\n",
      "[59,   199] loss: 0.209905\n",
      "[59,   299] loss: 0.191815\n",
      "[59,   399] loss: 0.175611\n",
      "[59,   499] loss: 0.153334\n",
      "[59,   599] loss: 0.139474\n",
      "[59,   699] loss: 0.135059\n",
      "[60,    99] loss: 0.169298\n",
      "[60,   199] loss: 0.259308\n",
      "[60,   299] loss: 0.804702\n",
      "[60,   399] loss: 0.795817\n",
      "[60,   499] loss: 0.308794\n",
      "[60,   599] loss: 0.321949\n",
      "[60,   699] loss: 0.207715\n",
      "[61,    99] loss: 0.216457\n",
      "[61,   199] loss: 0.154194\n",
      "[61,   299] loss: 0.343467\n",
      "[61,   399] loss: 0.228024\n",
      "[61,   499] loss: 0.221967\n",
      "[61,   599] loss: 0.257927\n",
      "[61,   699] loss: 0.289857\n",
      "[62,    99] loss: 0.193643\n",
      "[62,   199] loss: 0.252449\n",
      "[62,   299] loss: 0.227792\n",
      "[62,   399] loss: 0.247929\n",
      "[62,   499] loss: 0.166356\n",
      "[62,   599] loss: 0.204620\n",
      "[62,   699] loss: 0.344970\n",
      "[63,    99] loss: 0.220492\n",
      "[63,   199] loss: 0.313333\n",
      "[63,   299] loss: 0.214302\n",
      "[63,   399] loss: 0.268598\n",
      "[63,   499] loss: 0.177259\n",
      "[63,   599] loss: 0.254896\n",
      "[63,   699] loss: 0.194003\n",
      "[64,    99] loss: 0.164644\n",
      "[64,   199] loss: 0.265884\n",
      "[64,   299] loss: 0.173717\n",
      "[64,   399] loss: 0.209129\n",
      "[64,   499] loss: 0.276292\n",
      "[64,   599] loss: 0.193417\n",
      "[64,   699] loss: 0.259936\n",
      "[65,    99] loss: 0.225847\n",
      "[65,   199] loss: 0.224155\n",
      "[65,   299] loss: 0.214156\n",
      "[65,   399] loss: 0.204073\n",
      "[65,   499] loss: 0.266617\n",
      "[65,   599] loss: 0.195226\n",
      "[65,   699] loss: 0.144812\n",
      "[66,    99] loss: 0.152585\n",
      "[66,   199] loss: 0.173595\n",
      "[66,   299] loss: 0.685567\n",
      "[66,   399] loss: 3.118305\n",
      "[66,   499] loss: 0.398253\n",
      "[66,   599] loss: 0.569396\n",
      "[66,   699] loss: 0.221740\n",
      "[67,    99] loss: 0.134352\n",
      "[67,   199] loss: 0.288293\n",
      "[67,   299] loss: 0.225036\n",
      "[67,   399] loss: 0.178991\n",
      "[67,   499] loss: 0.209896\n",
      "[67,   599] loss: 0.313929\n",
      "[67,   699] loss: 0.377505\n",
      "[68,    99] loss: 0.158139\n",
      "[68,   199] loss: 0.167757\n",
      "[68,   299] loss: 0.259496\n",
      "[68,   399] loss: 0.186071\n",
      "[68,   499] loss: 0.171186\n",
      "[68,   599] loss: 0.237351\n",
      "[68,   699] loss: 0.162155\n",
      "[69,    99] loss: 0.123275\n",
      "[69,   199] loss: 0.157665\n",
      "[69,   299] loss: 0.207273\n",
      "[69,   399] loss: 0.151872\n",
      "[69,   499] loss: 0.194563\n",
      "[69,   599] loss: 0.286675\n",
      "[69,   699] loss: 0.223774\n",
      "[70,    99] loss: 0.217555\n",
      "[70,   199] loss: 0.219887\n",
      "[70,   299] loss: 0.281304\n",
      "[70,   399] loss: 0.232800\n",
      "[70,   499] loss: 0.211669\n",
      "[70,   599] loss: 0.279378\n",
      "[70,   699] loss: 0.279219\n",
      "[71,    99] loss: 0.198236\n",
      "[71,   199] loss: 0.197727\n",
      "[71,   299] loss: 0.181088\n",
      "[71,   399] loss: 0.431703\n",
      "[71,   499] loss: 0.141793\n",
      "[71,   599] loss: 0.187077\n",
      "[71,   699] loss: 0.337407\n",
      "[72,    99] loss: 0.268646\n",
      "[72,   199] loss: 0.197685\n",
      "[72,   299] loss: 0.209105\n",
      "[72,   399] loss: 0.184266\n",
      "[72,   499] loss: 0.217551\n",
      "[72,   599] loss: 0.159228\n",
      "[72,   699] loss: 0.198195\n",
      "[73,    99] loss: 0.120457\n",
      "[73,   199] loss: 0.160935\n",
      "[73,   299] loss: 0.177230\n",
      "[73,   399] loss: 0.211371\n",
      "[73,   499] loss: 0.247918\n",
      "[73,   599] loss: 0.214017\n",
      "[73,   699] loss: 0.169256\n",
      "[74,    99] loss: 0.114696\n",
      "[74,   199] loss: 0.273834\n",
      "[74,   299] loss: 0.552870\n",
      "[74,   399] loss: 0.209437\n",
      "[74,   499] loss: 0.282595\n",
      "[74,   599] loss: 0.193587\n",
      "[74,   699] loss: 0.190387\n",
      "[75,    99] loss: 0.250725\n",
      "[75,   199] loss: 0.233623\n",
      "[75,   299] loss: 0.231334\n",
      "[75,   399] loss: 0.205806\n",
      "[75,   499] loss: 0.171788\n",
      "[75,   599] loss: 0.133961\n",
      "[75,   699] loss: 0.163033\n",
      "[76,    99] loss: 0.246657\n",
      "[76,   199] loss: 0.370644\n",
      "[76,   299] loss: 0.233103\n",
      "[76,   399] loss: 1.767548\n",
      "[76,   499] loss: 0.168826\n",
      "[76,   599] loss: 0.314371\n",
      "[76,   699] loss: 0.215710\n",
      "[77,    99] loss: 0.122626\n",
      "[77,   199] loss: 0.185362\n",
      "[77,   299] loss: 0.270999\n",
      "[77,   399] loss: 0.256362\n",
      "[77,   499] loss: 0.315019\n",
      "[77,   599] loss: 1.098338\n",
      "[77,   699] loss: 0.219097\n",
      "[78,    99] loss: 0.208526\n",
      "[78,   199] loss: 0.667053\n",
      "[78,   299] loss: 0.367151\n",
      "[78,   399] loss: 0.262138\n",
      "[78,   499] loss: 0.190920\n",
      "[78,   599] loss: 0.202397\n",
      "[78,   699] loss: 0.146694\n",
      "[79,    99] loss: 0.146065\n",
      "[79,   199] loss: 0.144051\n",
      "[79,   299] loss: 0.174393\n",
      "[79,   399] loss: 0.123990\n",
      "[79,   499] loss: 0.190693\n",
      "[79,   599] loss: 0.283265\n",
      "[79,   699] loss: 0.153081\n",
      "[80,    99] loss: 0.198114\n",
      "[80,   199] loss: 0.186294\n",
      "[80,   299] loss: 0.266095\n",
      "[80,   399] loss: 0.207758\n",
      "[80,   499] loss: 0.254967\n",
      "[80,   599] loss: 0.195515\n",
      "[80,   699] loss: 0.200661\n",
      "[81,    99] loss: 0.168075\n",
      "[81,   199] loss: 0.244423\n",
      "[81,   299] loss: 0.190843\n",
      "[81,   399] loss: 0.181933\n",
      "[81,   499] loss: 0.141548\n",
      "[81,   599] loss: 0.130297\n",
      "[81,   699] loss: 0.227831\n",
      "[82,    99] loss: 0.326574\n",
      "[82,   199] loss: 0.293971\n",
      "[82,   299] loss: 0.135471\n",
      "[82,   399] loss: 0.156066\n",
      "[82,   499] loss: 0.269290\n",
      "[82,   599] loss: 0.295188\n",
      "[82,   699] loss: 0.192967\n",
      "[83,    99] loss: 0.134492\n",
      "[83,   199] loss: 0.172120\n",
      "[83,   299] loss: 0.178681\n",
      "[83,   399] loss: 0.118960\n",
      "[83,   499] loss: 0.288724\n",
      "[83,   599] loss: 0.303786\n",
      "[83,   699] loss: 0.176890\n",
      "[84,    99] loss: 0.170494\n",
      "[84,   199] loss: 0.152540\n",
      "[84,   299] loss: 0.356509\n",
      "[84,   399] loss: 0.154466\n",
      "[84,   499] loss: 0.199283\n",
      "[84,   599] loss: 0.317711\n",
      "[84,   699] loss: 0.157379\n",
      "[85,    99] loss: 0.168806\n",
      "[85,   199] loss: 0.161850\n",
      "[85,   299] loss: 0.169336\n",
      "[85,   399] loss: 0.106711\n",
      "[85,   499] loss: 0.238441\n",
      "[85,   599] loss: 0.134761\n",
      "[85,   699] loss: 0.137185\n",
      "[86,    99] loss: 0.117170\n",
      "[86,   199] loss: 0.206809\n",
      "[86,   299] loss: 0.306958\n",
      "[86,   399] loss: 0.293223\n",
      "[86,   499] loss: 0.188732\n",
      "[86,   599] loss: 0.162144\n",
      "[86,   699] loss: 0.154641\n",
      "[87,    99] loss: 0.108197\n",
      "[87,   199] loss: 0.132328\n",
      "[87,   299] loss: 0.147381\n",
      "[87,   399] loss: 0.107467\n",
      "[87,   499] loss: 0.285039\n",
      "[87,   599] loss: 0.191601\n",
      "[87,   699] loss: 0.357653\n",
      "[88,    99] loss: 0.205592\n",
      "[88,   199] loss: 0.324374\n",
      "[88,   299] loss: 0.336935\n",
      "[88,   399] loss: 0.271599\n",
      "[88,   499] loss: 0.507331\n",
      "[88,   599] loss: 0.177861\n",
      "[88,   699] loss: 0.153914\n",
      "[89,    99] loss: 0.187109\n",
      "[89,   199] loss: 0.410464\n",
      "[89,   299] loss: 0.166460\n",
      "[89,   399] loss: 0.176641\n",
      "[89,   499] loss: 0.215211\n",
      "[89,   599] loss: 0.403207\n",
      "[89,   699] loss: 0.239786\n",
      "[90,    99] loss: 0.098711\n",
      "[90,   199] loss: 0.261027\n",
      "[90,   299] loss: 0.155186\n",
      "[90,   399] loss: 0.130279\n",
      "[90,   499] loss: 0.128614\n",
      "[90,   599] loss: 0.112845\n",
      "[90,   699] loss: 0.116468\n",
      "[91,    99] loss: 0.112720\n",
      "[91,   199] loss: 0.303040\n",
      "[91,   299] loss: 0.181642\n",
      "[91,   399] loss: 0.113198\n",
      "[91,   499] loss: 0.158376\n",
      "[91,   599] loss: 0.143667\n",
      "[91,   699] loss: 0.140711\n",
      "[92,    99] loss: 0.184976\n",
      "[92,   199] loss: 0.249124\n",
      "[92,   299] loss: 0.280067\n",
      "[92,   399] loss: 0.357589\n",
      "[92,   499] loss: 0.307693\n",
      "[92,   599] loss: 0.321337\n",
      "[92,   699] loss: 0.260194\n",
      "[93,    99] loss: 0.167248\n",
      "[93,   199] loss: 0.259909\n",
      "[93,   299] loss: 0.229199\n",
      "[93,   399] loss: 0.176552\n",
      "[93,   499] loss: 0.092383\n",
      "[93,   599] loss: 0.160579\n",
      "[93,   699] loss: 0.144478\n",
      "[94,    99] loss: 0.088913\n",
      "[94,   199] loss: 0.196054\n",
      "[94,   299] loss: 0.091943\n",
      "[94,   399] loss: 0.152483\n",
      "[94,   499] loss: 0.127142\n",
      "[94,   599] loss: 0.138536\n",
      "[94,   699] loss: 0.119819\n",
      "[95,    99] loss: 0.091891\n",
      "[95,   199] loss: 0.071697\n",
      "[95,   299] loss: 0.199578\n",
      "[95,   399] loss: 0.098263\n",
      "[95,   499] loss: 0.167884\n",
      "[95,   599] loss: 0.241968\n",
      "[95,   699] loss: 0.121721\n",
      "[96,    99] loss: 0.099871\n",
      "[96,   199] loss: 0.096567\n",
      "[96,   299] loss: 0.095229\n",
      "[96,   399] loss: 0.121276\n",
      "[96,   499] loss: 0.201630\n",
      "[96,   599] loss: 0.196472\n",
      "[96,   699] loss: 0.169426\n",
      "[97,    99] loss: 0.114521\n",
      "[97,   199] loss: 0.125181\n",
      "[97,   299] loss: 0.136271\n",
      "[97,   399] loss: 0.173162\n",
      "[97,   499] loss: 0.168370\n",
      "[97,   599] loss: 0.579034\n",
      "[97,   699] loss: 0.229624\n",
      "[98,    99] loss: 0.177509\n",
      "[98,   199] loss: 0.200173\n",
      "[98,   299] loss: 0.275291\n",
      "[98,   399] loss: 0.229160\n",
      "[98,   499] loss: 0.231128\n",
      "[98,   599] loss: 0.137511\n",
      "[98,   699] loss: 0.191416\n",
      "[99,    99] loss: 0.229444\n",
      "[99,   199] loss: 1.486697\n",
      "[99,   299] loss: 0.151408\n",
      "[99,   399] loss: 0.452029\n",
      "[99,   499] loss: 0.157809\n",
      "[99,   599] loss: 0.123328\n",
      "[99,   699] loss: 0.101623\n",
      "[100,    99] loss: 0.132135\n",
      "[100,   199] loss: 0.144115\n",
      "[100,   299] loss: 0.121551\n",
      "[100,   399] loss: 0.126840\n",
      "[100,   499] loss: 0.131519\n",
      "[100,   599] loss: 0.135504\n",
      "[100,   699] loss: 0.099298\n",
      "Finished Training\n",
      "[1,    99] loss: 0.724264\n",
      "[1,   199] loss: 0.690432\n",
      "[1,   299] loss: 0.692786\n",
      "[1,   399] loss: 0.683774\n",
      "[1,   499] loss: 0.709779\n",
      "[1,   599] loss: 0.763351\n",
      "[1,   699] loss: 0.693615\n",
      "[2,    99] loss: 0.710577\n",
      "[2,   199] loss: 0.682262\n",
      "[2,   299] loss: 0.621669\n",
      "[2,   399] loss: 0.647045\n",
      "[2,   499] loss: 0.537423\n",
      "[2,   599] loss: 0.704945\n",
      "[2,   699] loss: 0.642096\n",
      "[3,    99] loss: 0.673575\n",
      "[3,   199] loss: 0.732491\n",
      "[3,   299] loss: 0.624363\n",
      "[3,   399] loss: 0.632974\n",
      "[3,   499] loss: 0.553401\n",
      "[3,   599] loss: 0.700154\n",
      "[3,   699] loss: 0.633002\n",
      "[4,    99] loss: 0.702007\n",
      "[4,   199] loss: 0.565302\n",
      "[4,   299] loss: 0.673249\n",
      "[4,   399] loss: 0.580213\n",
      "[4,   499] loss: 0.496465\n",
      "[4,   599] loss: 0.649164\n",
      "[4,   699] loss: 0.587168\n",
      "[5,    99] loss: 0.553005\n",
      "[5,   199] loss: 0.550043\n",
      "[5,   299] loss: 0.653406\n",
      "[5,   399] loss: 0.578669\n",
      "[5,   499] loss: 0.526183\n",
      "[5,   599] loss: 0.600994\n",
      "[5,   699] loss: 0.855707\n",
      "[6,    99] loss: 0.629637\n",
      "[6,   199] loss: 0.516870\n",
      "[6,   299] loss: 0.514284\n",
      "[6,   399] loss: 0.496618\n",
      "[6,   499] loss: 0.786485\n",
      "[6,   599] loss: 0.521917\n",
      "[6,   699] loss: 0.545493\n",
      "[7,    99] loss: 0.521172\n",
      "[7,   199] loss: 0.473511\n",
      "[7,   299] loss: 0.632560\n",
      "[7,   399] loss: 0.495933\n",
      "[7,   499] loss: 0.409749\n",
      "[7,   599] loss: 0.519348\n",
      "[7,   699] loss: 0.448573\n",
      "[8,    99] loss: 0.578390\n",
      "[8,   199] loss: 0.420700\n",
      "[8,   299] loss: 0.489585\n",
      "[8,   399] loss: 0.464469\n",
      "[8,   499] loss: 0.410526\n",
      "[8,   599] loss: 0.478799\n",
      "[8,   699] loss: 0.444365\n",
      "[9,    99] loss: 0.543104\n",
      "[9,   199] loss: 0.405715\n",
      "[9,   299] loss: 0.450055\n",
      "[9,   399] loss: 0.404457\n",
      "[9,   499] loss: 0.315048\n",
      "[9,   599] loss: 0.446603\n",
      "[9,   699] loss: 0.436295\n",
      "[10,    99] loss: 0.675117\n",
      "[10,   199] loss: 0.455980\n",
      "[10,   299] loss: 0.527978\n",
      "[10,   399] loss: 0.426608\n",
      "[10,   499] loss: 0.303901\n",
      "[10,   599] loss: 0.598331\n",
      "[10,   699] loss: 0.452069\n",
      "[11,    99] loss: 0.525115\n",
      "[11,   199] loss: 0.441641\n",
      "[11,   299] loss: 0.508246\n",
      "[11,   399] loss: 0.411237\n",
      "[11,   499] loss: 0.346663\n",
      "[11,   599] loss: 0.370324\n",
      "[11,   699] loss: 0.462649\n",
      "[12,    99] loss: 0.373487\n",
      "[12,   199] loss: 0.364947\n",
      "[12,   299] loss: 0.363783\n",
      "[12,   399] loss: 0.376388\n",
      "[12,   499] loss: 0.305652\n",
      "[12,   599] loss: 0.384214\n",
      "[12,   699] loss: 0.413383\n",
      "[13,    99] loss: 0.570563\n",
      "[13,   199] loss: 0.343509\n",
      "[13,   299] loss: 0.477152\n",
      "[13,   399] loss: 0.396999\n",
      "[13,   499] loss: 0.344164\n",
      "[13,   599] loss: 0.410029\n",
      "[13,   699] loss: 0.484665\n",
      "[14,    99] loss: 0.257189\n",
      "[14,   199] loss: 0.334324\n",
      "[14,   299] loss: 0.409283\n",
      "[14,   399] loss: 0.352541\n",
      "[14,   499] loss: 0.330484\n",
      "[14,   599] loss: 0.265141\n",
      "[14,   699] loss: 0.351091\n",
      "[15,    99] loss: 0.220460\n",
      "[15,   199] loss: 0.290325\n",
      "[15,   299] loss: 0.356552\n",
      "[15,   399] loss: 0.695367\n",
      "[15,   499] loss: 0.252811\n",
      "[15,   599] loss: 0.637695\n",
      "[15,   699] loss: 0.415504\n",
      "[16,    99] loss: 0.293255\n",
      "[16,   199] loss: 0.316194\n",
      "[16,   299] loss: 0.412371\n",
      "[16,   399] loss: 0.419024\n",
      "[16,   499] loss: 0.298612\n",
      "[16,   599] loss: 0.605151\n",
      "[16,   699] loss: 0.369004\n",
      "[17,    99] loss: 0.310724\n",
      "[17,   199] loss: 0.370729\n",
      "[17,   299] loss: 0.426601\n",
      "[17,   399] loss: 0.301805\n",
      "[17,   499] loss: 0.246446\n",
      "[17,   599] loss: 0.275827\n",
      "[17,   699] loss: 0.371301\n",
      "[18,    99] loss: 0.317422\n",
      "[18,   199] loss: 0.230492\n",
      "[18,   299] loss: 0.261170\n",
      "[18,   399] loss: 0.324292\n",
      "[18,   499] loss: 0.333447\n",
      "[18,   599] loss: 0.361348\n",
      "[18,   699] loss: 0.366829\n",
      "[19,    99] loss: 0.304694\n",
      "[19,   199] loss: 0.341592\n",
      "[19,   299] loss: 0.534363\n",
      "[19,   399] loss: 0.313043\n",
      "[19,   499] loss: 0.287327\n",
      "[19,   599] loss: 0.406180\n",
      "[19,   699] loss: 0.334504\n",
      "[20,    99] loss: 0.219631\n",
      "[20,   199] loss: 0.276699\n",
      "[20,   299] loss: 0.293675\n",
      "[20,   399] loss: 0.259623\n",
      "[20,   499] loss: 0.240585\n",
      "[20,   599] loss: 0.250307\n",
      "[20,   699] loss: 0.313571\n",
      "[21,    99] loss: 0.287168\n",
      "[21,   199] loss: 0.219365\n",
      "[21,   299] loss: 0.267431\n",
      "[21,   399] loss: 0.235703\n",
      "[21,   499] loss: 0.238896\n",
      "[21,   599] loss: 0.164521\n",
      "[21,   699] loss: 0.377058\n",
      "[22,    99] loss: 0.245014\n",
      "[22,   199] loss: 0.272038\n",
      "[22,   299] loss: 0.293216\n",
      "[22,   399] loss: 0.227229\n",
      "[22,   499] loss: 0.197578\n",
      "[22,   599] loss: 0.705763\n",
      "[22,   699] loss: 0.801249\n",
      "[23,    99] loss: 0.779816\n",
      "[23,   199] loss: 0.339361\n",
      "[23,   299] loss: 0.540157\n",
      "[23,   399] loss: 0.418682\n",
      "[23,   499] loss: 0.261119\n",
      "[23,   599] loss: 0.271801\n",
      "[23,   699] loss: 0.370516\n",
      "[24,    99] loss: 0.241321\n",
      "[24,   199] loss: 0.246709\n",
      "[24,   299] loss: 0.345015\n",
      "[24,   399] loss: 0.347419\n",
      "[24,   499] loss: 0.213966\n",
      "[24,   599] loss: 0.205333\n",
      "[24,   699] loss: 0.306616\n",
      "[25,    99] loss: 0.163461\n",
      "[25,   199] loss: 0.198751\n",
      "[25,   299] loss: 0.336086\n",
      "[25,   399] loss: 0.243345\n",
      "[25,   499] loss: 0.236009\n",
      "[25,   599] loss: 0.171768\n",
      "[25,   699] loss: 0.344072\n",
      "[26,    99] loss: 0.305782\n",
      "[26,   199] loss: 0.308271\n",
      "[26,   299] loss: 0.376719\n",
      "[26,   399] loss: 0.329028\n",
      "[26,   499] loss: 0.267696\n",
      "[26,   599] loss: 0.471158\n",
      "[26,   699] loss: 0.296283\n",
      "[27,    99] loss: 0.180073\n",
      "[27,   199] loss: 0.232954\n",
      "[27,   299] loss: 0.310697\n",
      "[27,   399] loss: 0.753925\n",
      "[27,   499] loss: 0.193701\n",
      "[27,   599] loss: 0.536225\n",
      "[27,   699] loss: 0.251881\n",
      "[28,    99] loss: 0.474931\n",
      "[28,   199] loss: 0.189747\n",
      "[28,   299] loss: 0.394421\n",
      "[28,   399] loss: 0.255542\n",
      "[28,   499] loss: 0.269552\n",
      "[28,   599] loss: 0.122934\n",
      "[28,   699] loss: 0.222485\n",
      "[29,    99] loss: 0.266421\n",
      "[29,   199] loss: 0.641650\n",
      "[29,   299] loss: 0.271016\n",
      "[29,   399] loss: 0.331522\n",
      "[29,   499] loss: 0.204777\n",
      "[29,   599] loss: 0.300574\n",
      "[29,   699] loss: 0.481264\n",
      "[30,    99] loss: 0.248031\n",
      "[30,   199] loss: 0.183659\n",
      "[30,   299] loss: 0.234007\n",
      "[30,   399] loss: 0.212379\n",
      "[30,   499] loss: 0.180451\n",
      "[30,   599] loss: 0.498252\n",
      "[30,   699] loss: 0.304528\n",
      "[31,    99] loss: 0.238995\n",
      "[31,   199] loss: 0.221495\n",
      "[31,   299] loss: 0.234117\n",
      "[31,   399] loss: 0.378654\n",
      "[31,   499] loss: 0.219235\n",
      "[31,   599] loss: 0.155132\n",
      "[31,   699] loss: 0.267843\n",
      "[32,    99] loss: 0.200864\n",
      "[32,   199] loss: 0.251267\n",
      "[32,   299] loss: 0.372666\n",
      "[32,   399] loss: 0.230581\n",
      "[32,   499] loss: 0.302933\n",
      "[32,   599] loss: 0.146168\n",
      "[32,   699] loss: 0.295604\n",
      "[33,    99] loss: 0.299208\n",
      "[33,   199] loss: 0.289980\n",
      "[33,   299] loss: 0.250236\n",
      "[33,   399] loss: 0.230914\n",
      "[33,   499] loss: 0.230609\n",
      "[33,   599] loss: 0.135565\n",
      "[33,   699] loss: 0.275492\n",
      "[34,    99] loss: 0.163876\n",
      "[34,   199] loss: 0.204792\n",
      "[34,   299] loss: 0.301831\n",
      "[34,   399] loss: 0.225882\n",
      "[34,   499] loss: 0.213655\n",
      "[34,   599] loss: 0.187569\n",
      "[34,   699] loss: 0.343000\n",
      "[35,    99] loss: 0.328385\n",
      "[35,   199] loss: 0.211120\n",
      "[35,   299] loss: 0.688645\n",
      "[35,   399] loss: 0.352892\n",
      "[35,   499] loss: 0.348167\n",
      "[35,   599] loss: 0.502651\n",
      "[35,   699] loss: 0.327717\n",
      "[36,    99] loss: 0.185258\n",
      "[36,   199] loss: 0.511557\n",
      "[36,   299] loss: 0.354969\n",
      "[36,   399] loss: 0.217315\n",
      "[36,   499] loss: 0.198624\n",
      "[36,   599] loss: 0.167544\n",
      "[36,   699] loss: 0.275775\n",
      "[37,    99] loss: 0.274818\n",
      "[37,   199] loss: 0.319692\n",
      "[37,   299] loss: 0.333965\n",
      "[37,   399] loss: 0.224241\n",
      "[37,   499] loss: 0.182663\n",
      "[37,   599] loss: 0.129550\n",
      "[37,   699] loss: 0.325795\n",
      "[38,    99] loss: 0.181712\n",
      "[38,   199] loss: 0.246213\n",
      "[38,   299] loss: 0.484433\n",
      "[38,   399] loss: 0.189835\n",
      "[38,   499] loss: 0.220496\n",
      "[38,   599] loss: 0.180039\n",
      "[38,   699] loss: 0.305803\n",
      "[39,    99] loss: 0.161503\n",
      "[39,   199] loss: 0.195546\n",
      "[39,   299] loss: 0.242020\n",
      "[39,   399] loss: 0.150276\n",
      "[39,   499] loss: 0.279785\n",
      "[39,   599] loss: 0.103656\n",
      "[39,   699] loss: 0.455429\n",
      "[40,    99] loss: 0.162748\n",
      "[40,   199] loss: 0.197298\n",
      "[40,   299] loss: 0.218374\n",
      "[40,   399] loss: 0.280798\n",
      "[40,   499] loss: 0.234148\n",
      "[40,   599] loss: 0.271556\n",
      "[40,   699] loss: 0.375046\n",
      "[41,    99] loss: 0.469712\n",
      "[41,   199] loss: 0.234667\n",
      "[41,   299] loss: 0.259551\n",
      "[41,   399] loss: 0.212900\n",
      "[41,   499] loss: 0.165869\n",
      "[41,   599] loss: 0.223719\n",
      "[41,   699] loss: 0.236537\n",
      "[42,    99] loss: 0.156030\n",
      "[42,   199] loss: 0.182135\n",
      "[42,   299] loss: 0.306001\n",
      "[42,   399] loss: 0.370781\n",
      "[42,   499] loss: 0.207293\n",
      "[42,   599] loss: 0.171453\n",
      "[42,   699] loss: 0.560677\n",
      "[43,    99] loss: 0.275731\n",
      "[43,   199] loss: 0.341173\n",
      "[43,   299] loss: 0.464039\n",
      "[43,   399] loss: 0.257991\n",
      "[43,   499] loss: 0.256208\n",
      "[43,   599] loss: 0.205014\n",
      "[43,   699] loss: 0.244674\n",
      "[44,    99] loss: 0.135559\n",
      "[44,   199] loss: 0.195951\n",
      "[44,   299] loss: 0.420521\n",
      "[44,   399] loss: 0.208911\n",
      "[44,   499] loss: 0.144300\n",
      "[44,   599] loss: 0.192109\n",
      "[44,   699] loss: 0.250429\n",
      "[45,    99] loss: 0.177636\n",
      "[45,   199] loss: 0.217001\n",
      "[45,   299] loss: 0.250858\n",
      "[45,   399] loss: 0.260495\n",
      "[45,   499] loss: 0.192002\n",
      "[45,   599] loss: 0.235411\n",
      "[45,   699] loss: 0.264968\n",
      "[46,    99] loss: 0.141094\n",
      "[46,   199] loss: 0.307401\n",
      "[46,   299] loss: 0.252989\n",
      "[46,   399] loss: 0.336025\n",
      "[46,   499] loss: 0.190945\n",
      "[46,   599] loss: 0.267886\n",
      "[46,   699] loss: 0.247343\n",
      "[47,    99] loss: 0.104554\n",
      "[47,   199] loss: 0.157419\n",
      "[47,   299] loss: 0.221453\n",
      "[47,   399] loss: 0.233042\n",
      "[47,   499] loss: 0.101014\n",
      "[47,   599] loss: 0.205153\n",
      "[47,   699] loss: 0.266906\n",
      "[48,    99] loss: 0.140735\n",
      "[48,   199] loss: 0.169769\n",
      "[48,   299] loss: 0.362022\n",
      "[48,   399] loss: 0.219049\n",
      "[48,   499] loss: 0.187042\n",
      "[48,   599] loss: 0.172142\n",
      "[48,   699] loss: 0.247471\n",
      "[49,    99] loss: 0.140266\n",
      "[49,   199] loss: 0.186256\n",
      "[49,   299] loss: 0.296104\n",
      "[49,   399] loss: 0.217213\n",
      "[49,   499] loss: 0.192801\n",
      "[49,   599] loss: 0.232169\n",
      "[49,   699] loss: 0.420931\n",
      "[50,    99] loss: 0.104777\n",
      "[50,   199] loss: 0.206409\n",
      "[50,   299] loss: 0.294730\n",
      "[50,   399] loss: 0.194310\n",
      "[50,   499] loss: 0.162134\n",
      "[50,   599] loss: 0.142814\n",
      "[50,   699] loss: 0.252729\n",
      "[51,    99] loss: 0.152808\n",
      "[51,   199] loss: 0.264517\n",
      "[51,   299] loss: 0.273995\n",
      "[51,   399] loss: 0.332654\n",
      "[51,   499] loss: 0.154517\n",
      "[51,   599] loss: 0.417157\n",
      "[51,   699] loss: 0.315499\n",
      "[52,    99] loss: 0.294650\n",
      "[52,   199] loss: 0.231267\n",
      "[52,   299] loss: 0.239664\n",
      "[52,   399] loss: 0.249220\n",
      "[52,   499] loss: 0.283413\n",
      "[52,   599] loss: 0.217467\n",
      "[52,   699] loss: 0.248069\n",
      "[53,    99] loss: 0.142349\n",
      "[53,   199] loss: 0.193788\n",
      "[53,   299] loss: 0.275260\n",
      "[53,   399] loss: 0.250855\n",
      "[53,   499] loss: 0.183413\n",
      "[53,   599] loss: 0.217503\n",
      "[53,   699] loss: 0.250235\n",
      "[54,    99] loss: 0.266085\n",
      "[54,   199] loss: 0.202924\n",
      "[54,   299] loss: 0.417033\n",
      "[54,   399] loss: 0.340882\n",
      "[54,   499] loss: 0.171898\n",
      "[54,   599] loss: 0.269209\n",
      "[54,   699] loss: 0.465164\n",
      "[55,    99] loss: 0.204224\n",
      "[55,   199] loss: 0.197757\n",
      "[55,   299] loss: 0.182840\n",
      "[55,   399] loss: 0.259728\n",
      "[55,   499] loss: 0.100671\n",
      "[55,   599] loss: 0.158402\n",
      "[55,   699] loss: 0.292775\n",
      "[56,    99] loss: 0.130696\n",
      "[56,   199] loss: 0.213778\n",
      "[56,   299] loss: 0.178504\n",
      "[56,   399] loss: 0.170693\n",
      "[56,   499] loss: 0.200220\n",
      "[56,   599] loss: 0.279383\n",
      "[56,   699] loss: 0.195323\n",
      "[57,    99] loss: 0.318804\n",
      "[57,   199] loss: 0.388045\n",
      "[57,   299] loss: 0.342748\n",
      "[57,   399] loss: 0.203559\n",
      "[57,   499] loss: 0.239772\n",
      "[57,   599] loss: 0.160646\n",
      "[57,   699] loss: 0.532885\n",
      "[58,    99] loss: 0.132360\n",
      "[58,   199] loss: 0.234536\n",
      "[58,   299] loss: 0.184247\n",
      "[58,   399] loss: 0.156087\n",
      "[58,   499] loss: 0.123450\n",
      "[58,   599] loss: 0.172529\n",
      "[58,   699] loss: 0.227111\n",
      "[59,    99] loss: 0.204247\n",
      "[59,   199] loss: 0.218591\n",
      "[59,   299] loss: 1.483014\n",
      "[59,   399] loss: 0.259979\n",
      "[59,   499] loss: 0.162283\n",
      "[59,   599] loss: 0.139114\n",
      "[59,   699] loss: 0.277470\n",
      "[60,    99] loss: 0.572333\n",
      "[60,   199] loss: 0.236893\n",
      "[60,   299] loss: 0.493779\n",
      "[60,   399] loss: 0.219717\n",
      "[60,   499] loss: 0.148301\n",
      "[60,   599] loss: 0.116544\n",
      "[60,   699] loss: 0.224635\n",
      "[61,    99] loss: 0.720807\n",
      "[61,   199] loss: 0.269484\n",
      "[61,   299] loss: 0.209971\n",
      "[61,   399] loss: 0.266332\n",
      "[61,   499] loss: 0.208495\n",
      "[61,   599] loss: 0.173722\n",
      "[61,   699] loss: 0.205846\n",
      "[62,    99] loss: 0.204852\n",
      "[62,   199] loss: 0.225559\n",
      "[62,   299] loss: 0.283832\n",
      "[62,   399] loss: 0.225102\n",
      "[62,   499] loss: 0.165665\n",
      "[62,   599] loss: 0.185672\n",
      "[62,   699] loss: 0.182515\n",
      "[63,    99] loss: 0.140671\n",
      "[63,   199] loss: 0.227505\n",
      "[63,   299] loss: 0.432482\n",
      "[63,   399] loss: 0.312322\n",
      "[63,   499] loss: 0.169129\n",
      "[63,   599] loss: 0.509131\n",
      "[63,   699] loss: 0.261075\n",
      "[64,    99] loss: 0.180360\n",
      "[64,   199] loss: 0.296984\n",
      "[64,   299] loss: 0.211609\n",
      "[64,   399] loss: 0.303934\n",
      "[64,   499] loss: 0.161982\n",
      "[64,   599] loss: 0.191655\n",
      "[64,   699] loss: 0.183953\n",
      "[65,    99] loss: 0.126475\n",
      "[65,   199] loss: 0.531088\n",
      "[65,   299] loss: 0.281723\n",
      "[65,   399] loss: 0.226639\n",
      "[65,   499] loss: 0.144218\n",
      "[65,   599] loss: 0.084539\n",
      "[65,   699] loss: 0.170885\n",
      "[66,    99] loss: 0.095378\n",
      "[66,   199] loss: 0.168675\n",
      "[66,   299] loss: 0.238758\n",
      "[66,   399] loss: 0.392092\n",
      "[66,   499] loss: 0.133248\n",
      "[66,   599] loss: 0.078062\n",
      "[66,   699] loss: 0.180726\n",
      "[67,    99] loss: 0.122350\n",
      "[67,   199] loss: 0.216482\n",
      "[67,   299] loss: 0.120528\n",
      "[67,   399] loss: 0.206090\n",
      "[67,   499] loss: 0.125213\n",
      "[67,   599] loss: 0.094977\n",
      "[67,   699] loss: 0.112557\n",
      "[68,    99] loss: 0.118964\n",
      "[68,   199] loss: 0.169324\n",
      "[68,   299] loss: 0.133716\n",
      "[68,   399] loss: 0.312168\n",
      "[68,   499] loss: 0.180538\n",
      "[68,   599] loss: 0.117541\n",
      "[68,   699] loss: 0.220585\n",
      "[69,    99] loss: 0.122416\n",
      "[69,   199] loss: 0.160516\n",
      "[69,   299] loss: 0.188397\n",
      "[69,   399] loss: 0.190248\n",
      "[69,   499] loss: 0.143098\n",
      "[69,   599] loss: 0.109233\n",
      "[69,   699] loss: 0.296740\n",
      "[70,    99] loss: 0.197652\n",
      "[70,   199] loss: 0.240594\n",
      "[70,   299] loss: 0.186681\n",
      "[70,   399] loss: 0.122724\n",
      "[70,   499] loss: 0.093987\n",
      "[70,   599] loss: 0.207930\n",
      "[70,   699] loss: 0.239499\n",
      "[71,    99] loss: 0.202799\n",
      "[71,   199] loss: 0.197551\n",
      "[71,   299] loss: 0.219745\n",
      "[71,   399] loss: 0.114940\n",
      "[71,   499] loss: 0.158336\n",
      "[71,   599] loss: 0.096563\n",
      "[71,   699] loss: 0.166970\n",
      "[72,    99] loss: 0.106066\n",
      "[72,   199] loss: 0.182814\n",
      "[72,   299] loss: 0.195832\n",
      "[72,   399] loss: 0.142495\n",
      "[72,   499] loss: 0.123375\n",
      "[72,   599] loss: 0.089305\n",
      "[72,   699] loss: 0.174594\n",
      "[73,    99] loss: 0.192532\n",
      "[73,   199] loss: 0.218530\n",
      "[73,   299] loss: 0.224863\n",
      "[73,   399] loss: 0.155909\n",
      "[73,   499] loss: 0.160836\n",
      "[73,   599] loss: 0.140189\n",
      "[73,   699] loss: 0.140043\n",
      "[74,    99] loss: 0.104480\n",
      "[74,   199] loss: 0.186323\n",
      "[74,   299] loss: 0.211017\n",
      "[74,   399] loss: 0.176988\n",
      "[74,   499] loss: 0.243932\n",
      "[74,   599] loss: 0.193415\n",
      "[74,   699] loss: 0.137948\n",
      "[75,    99] loss: 0.210467\n",
      "[75,   199] loss: 0.172354\n",
      "[75,   299] loss: 0.145795\n",
      "[75,   399] loss: 0.054028\n",
      "[75,   499] loss: 0.123609\n",
      "[75,   599] loss: 0.187250\n",
      "[75,   699] loss: 0.385334\n",
      "[76,    99] loss: 0.083915\n",
      "[76,   199] loss: 0.205863\n",
      "[76,   299] loss: 0.230034\n",
      "[76,   399] loss: 0.117803\n",
      "[76,   499] loss: 0.106400\n",
      "[76,   599] loss: 0.295754\n",
      "[76,   699] loss: 0.133916\n",
      "[77,    99] loss: 2.166897\n",
      "[77,   199] loss: 0.341604\n",
      "[77,   299] loss: 0.165735\n",
      "[77,   399] loss: 0.156933\n",
      "[77,   499] loss: 0.162555\n",
      "[77,   599] loss: 0.147249\n",
      "[77,   699] loss: 0.169390\n",
      "[78,    99] loss: 0.152258\n",
      "[78,   199] loss: 0.350040\n",
      "[78,   299] loss: 0.383513\n",
      "[78,   399] loss: 0.202382\n",
      "[78,   499] loss: 0.098894\n",
      "[78,   599] loss: 0.132839\n",
      "[78,   699] loss: 0.470590\n",
      "[79,    99] loss: 0.158401\n",
      "[79,   199] loss: 0.189583\n",
      "[79,   299] loss: 0.159041\n",
      "[79,   399] loss: 0.092400\n",
      "[79,   499] loss: 0.108725\n",
      "[79,   599] loss: 0.087605\n",
      "[79,   699] loss: 0.296405\n",
      "[80,    99] loss: 0.522484\n",
      "[80,   199] loss: 0.184490\n",
      "[80,   299] loss: 0.397050\n",
      "[80,   399] loss: 0.185899\n",
      "[80,   499] loss: 0.189731\n",
      "[80,   599] loss: 0.146906\n",
      "[80,   699] loss: 0.124428\n",
      "[81,    99] loss: 0.114262\n",
      "[81,   199] loss: 0.229229\n",
      "[81,   299] loss: 0.168334\n",
      "[81,   399] loss: 0.142906\n",
      "[81,   499] loss: 0.102254\n",
      "[81,   599] loss: 0.100579\n",
      "[81,   699] loss: 1.371299\n",
      "[82,    99] loss: 0.795837\n",
      "[82,   199] loss: 0.233657\n",
      "[82,   299] loss: 0.210017\n",
      "[82,   399] loss: 0.146395\n",
      "[82,   499] loss: 0.412316\n",
      "[82,   599] loss: 0.159163\n",
      "[82,   699] loss: 0.108556\n",
      "[83,    99] loss: 0.095861\n",
      "[83,   199] loss: 0.159018\n",
      "[83,   299] loss: 0.131395\n",
      "[83,   399] loss: 0.383403\n",
      "[83,   499] loss: 0.119954\n",
      "[83,   599] loss: 0.178378\n",
      "[83,   699] loss: 0.193762\n",
      "[84,    99] loss: 0.229927\n",
      "[84,   199] loss: 0.174685\n",
      "[84,   299] loss: 0.130916\n",
      "[84,   399] loss: 0.125158\n",
      "[84,   499] loss: 0.072806\n",
      "[84,   599] loss: 0.090380\n",
      "[84,   699] loss: 0.081085\n",
      "[85,    99] loss: 0.044789\n",
      "[85,   199] loss: 0.092620\n",
      "[85,   299] loss: 0.307053\n",
      "[85,   399] loss: 0.220188\n",
      "[85,   499] loss: 0.058231\n",
      "[85,   599] loss: 0.055874\n",
      "[85,   699] loss: 0.181334\n",
      "[86,    99] loss: 0.040576\n",
      "[86,   199] loss: 0.088647\n",
      "[86,   299] loss: 0.208106\n",
      "[86,   399] loss: 0.117808\n",
      "[86,   499] loss: 0.132678\n",
      "[86,   599] loss: 0.172416\n",
      "[86,   699] loss: 0.162269\n",
      "[87,    99] loss: 0.181786\n",
      "[87,   199] loss: 0.165391\n",
      "[87,   299] loss: 0.437281\n",
      "[87,   399] loss: 0.084405\n",
      "[87,   499] loss: 0.072059\n",
      "[87,   599] loss: 0.159179\n",
      "[87,   699] loss: 0.274257\n",
      "[88,    99] loss: 0.072970\n",
      "[88,   199] loss: 0.145676\n",
      "[88,   299] loss: 0.105833\n",
      "[88,   399] loss: 0.108317\n",
      "[88,   499] loss: 0.092065\n",
      "[88,   599] loss: 0.303246\n",
      "[88,   699] loss: 0.173216\n",
      "[89,    99] loss: 0.109591\n",
      "[89,   199] loss: 0.189428\n",
      "[89,   299] loss: 0.179695\n",
      "[89,   399] loss: 0.121519\n",
      "[89,   499] loss: 0.109566\n",
      "[89,   599] loss: 0.127796\n",
      "[89,   699] loss: 0.118016\n",
      "[90,    99] loss: 0.096049\n",
      "[90,   199] loss: 0.165625\n",
      "[90,   299] loss: 0.246511\n",
      "[90,   399] loss: 0.177938\n",
      "[90,   499] loss: 0.090520\n",
      "[90,   599] loss: 0.122841\n",
      "[90,   699] loss: 0.039550\n",
      "[91,    99] loss: 0.328457\n",
      "[91,   199] loss: 0.291221\n",
      "[91,   299] loss: 0.147687\n",
      "[91,   399] loss: 0.102190\n",
      "[91,   499] loss: 0.381143\n",
      "[91,   599] loss: 0.152124\n",
      "[91,   699] loss: 0.116222\n",
      "[92,    99] loss: 0.128127\n",
      "[92,   199] loss: 0.138570\n",
      "[92,   299] loss: 0.315924\n",
      "[92,   399] loss: 0.157561\n",
      "[92,   499] loss: 0.110316\n",
      "[92,   599] loss: 0.277530\n",
      "[92,   699] loss: 0.069726\n",
      "[93,    99] loss: 0.434625\n",
      "[93,   199] loss: 0.119457\n",
      "[93,   299] loss: 0.177442\n",
      "[93,   399] loss: 0.212163\n",
      "[93,   499] loss: 0.623970\n",
      "[93,   599] loss: 0.204068\n",
      "[93,   699] loss: 0.092419\n",
      "[94,    99] loss: 0.079303\n",
      "[94,   199] loss: 0.155447\n",
      "[94,   299] loss: 0.114149\n",
      "[94,   399] loss: 0.039319\n",
      "[94,   499] loss: 0.147660\n",
      "[94,   599] loss: 0.084338\n",
      "[94,   699] loss: 0.046711\n",
      "[95,    99] loss: 0.237000\n",
      "[95,   199] loss: 0.562042\n",
      "[95,   299] loss: 0.481808\n",
      "[95,   399] loss: 0.268781\n",
      "[95,   499] loss: 0.232752\n",
      "[95,   599] loss: 0.177476\n",
      "[95,   699] loss: 0.309897\n",
      "[96,    99] loss: 0.302681\n",
      "[96,   199] loss: 0.181098\n",
      "[96,   299] loss: 0.923842\n",
      "[96,   399] loss: 0.355872\n",
      "[96,   499] loss: 0.119099\n",
      "[96,   599] loss: 0.279793\n",
      "[96,   699] loss: 0.076590\n",
      "[97,    99] loss: 0.086759\n",
      "[97,   199] loss: 0.089002\n",
      "[97,   299] loss: 0.063052\n",
      "[97,   399] loss: 0.067532\n",
      "[97,   499] loss: 0.200093\n",
      "[97,   599] loss: 0.065378\n",
      "[97,   699] loss: 0.035162\n",
      "[98,    99] loss: 0.057146\n",
      "[98,   199] loss: 0.721509\n",
      "[98,   299] loss: 0.080712\n",
      "[98,   399] loss: 0.083649\n",
      "[98,   499] loss: 0.061896\n",
      "[98,   599] loss: 0.196038\n",
      "[98,   699] loss: 0.070783\n",
      "[99,    99] loss: 0.131833\n",
      "[99,   199] loss: 0.108620\n",
      "[99,   299] loss: 0.179747\n",
      "[99,   399] loss: 0.331941\n",
      "[99,   499] loss: 0.057450\n",
      "[99,   599] loss: 0.081784\n",
      "[99,   699] loss: 0.218325\n",
      "[100,    99] loss: 0.084326\n",
      "[100,   199] loss: 0.247398\n",
      "[100,   299] loss: 0.089191\n",
      "[100,   399] loss: 0.034828\n",
      "[100,   499] loss: 0.024160\n",
      "[100,   599] loss: 0.111928\n",
      "[100,   699] loss: 0.083471\n",
      "Finished Training\n",
      "[1,    99] loss: 0.726103\n",
      "[1,   199] loss: 0.699614\n",
      "[1,   299] loss: 0.723693\n",
      "[1,   399] loss: 0.704895\n",
      "[1,   499] loss: 0.703057\n",
      "[1,   599] loss: 0.701728\n",
      "[1,   699] loss: 0.775444\n",
      "[2,    99] loss: 0.762603\n",
      "[2,   199] loss: 0.687798\n",
      "[2,   299] loss: 0.666149\n",
      "[2,   399] loss: 0.725911\n",
      "[2,   499] loss: 0.666040\n",
      "[2,   599] loss: 0.663528\n",
      "[2,   699] loss: 0.718644\n",
      "[3,    99] loss: 0.713923\n",
      "[3,   199] loss: 0.661165\n",
      "[3,   299] loss: 0.527103\n",
      "[3,   399] loss: 0.559969\n",
      "[3,   499] loss: 0.672659\n",
      "[3,   599] loss: 0.733115\n",
      "[3,   699] loss: 0.671271\n",
      "[4,    99] loss: 0.609990\n",
      "[4,   199] loss: 0.766582\n",
      "[4,   299] loss: 0.478934\n",
      "[4,   399] loss: 0.547244\n",
      "[4,   499] loss: 0.517000\n",
      "[4,   599] loss: 0.490644\n",
      "[4,   699] loss: 0.659892\n",
      "[5,    99] loss: 0.548503\n",
      "[5,   199] loss: 0.507302\n",
      "[5,   299] loss: 0.418459\n",
      "[5,   399] loss: 0.422127\n",
      "[5,   499] loss: 0.506357\n",
      "[5,   599] loss: 0.475416\n",
      "[5,   699] loss: 0.667127\n",
      "[6,    99] loss: 0.522719\n",
      "[6,   199] loss: 0.426781\n",
      "[6,   299] loss: 0.772021\n",
      "[6,   399] loss: 0.487132\n",
      "[6,   499] loss: 0.565036\n",
      "[6,   599] loss: 0.541896\n",
      "[6,   699] loss: 0.534118\n",
      "[7,    99] loss: 0.499058\n",
      "[7,   199] loss: 0.457931\n",
      "[7,   299] loss: 0.419828\n",
      "[7,   399] loss: 0.488471\n",
      "[7,   499] loss: 0.497483\n",
      "[7,   599] loss: 0.503198\n",
      "[7,   699] loss: 0.654459\n",
      "[8,    99] loss: 0.540818\n",
      "[8,   199] loss: 0.483378\n",
      "[8,   299] loss: 0.448046\n",
      "[8,   399] loss: 0.500769\n",
      "[8,   499] loss: 0.570393\n",
      "[8,   599] loss: 0.495898\n",
      "[8,   699] loss: 0.508832\n",
      "[9,    99] loss: 0.477167\n",
      "[9,   199] loss: 0.370695\n",
      "[9,   299] loss: 0.345399\n",
      "[9,   399] loss: 0.360239\n",
      "[9,   499] loss: 0.478956\n",
      "[9,   599] loss: 0.436962\n",
      "[9,   699] loss: 0.501510\n",
      "[10,    99] loss: 0.462331\n",
      "[10,   199] loss: 0.519974\n",
      "[10,   299] loss: 0.385287\n",
      "[10,   399] loss: 0.410798\n",
      "[10,   499] loss: 0.510820\n",
      "[10,   599] loss: 0.432586\n",
      "[10,   699] loss: 0.483434\n",
      "[11,    99] loss: 0.448080\n",
      "[11,   199] loss: 0.379185\n",
      "[11,   299] loss: 0.420076\n",
      "[11,   399] loss: 0.454194\n",
      "[11,   499] loss: 0.486726\n",
      "[11,   599] loss: 0.641323\n",
      "[11,   699] loss: 0.461921\n",
      "[12,    99] loss: 0.561937\n",
      "[12,   199] loss: 0.425117\n",
      "[12,   299] loss: 0.550471\n",
      "[12,   399] loss: 0.419366\n",
      "[12,   499] loss: 0.470433\n",
      "[12,   599] loss: 0.440020\n",
      "[12,   699] loss: 0.425159\n",
      "[13,    99] loss: 0.418145\n",
      "[13,   199] loss: 0.297802\n",
      "[13,   299] loss: 0.394037\n",
      "[13,   399] loss: 0.659042\n",
      "[13,   499] loss: 0.502752\n",
      "[13,   599] loss: 0.518028\n",
      "[13,   699] loss: 0.654119\n",
      "[14,    99] loss: 0.594748\n",
      "[14,   199] loss: 0.471417\n",
      "[14,   299] loss: 0.416023\n",
      "[14,   399] loss: 0.534162\n",
      "[14,   499] loss: 0.527553\n",
      "[14,   599] loss: 0.419581\n",
      "[14,   699] loss: 0.469161\n",
      "[15,    99] loss: 0.434982\n",
      "[15,   199] loss: 0.327593\n",
      "[15,   299] loss: 0.333381\n",
      "[15,   399] loss: 0.306624\n",
      "[15,   499] loss: 0.510405\n",
      "[15,   599] loss: 0.389430\n",
      "[15,   699] loss: 0.418358\n",
      "[16,    99] loss: 0.340319\n",
      "[16,   199] loss: 0.323696\n",
      "[16,   299] loss: 0.400405\n",
      "[16,   399] loss: 0.403133\n",
      "[16,   499] loss: 0.459005\n",
      "[16,   599] loss: 0.399790\n",
      "[16,   699] loss: 0.400433\n",
      "[17,    99] loss: 0.372495\n",
      "[17,   199] loss: 0.354988\n",
      "[17,   299] loss: 0.302055\n",
      "[17,   399] loss: 0.344015\n",
      "[17,   499] loss: 0.557758\n",
      "[17,   599] loss: 0.340207\n",
      "[17,   699] loss: 0.552503\n",
      "[18,    99] loss: 0.396559\n",
      "[18,   199] loss: 0.365513\n",
      "[18,   299] loss: 0.309320\n",
      "[18,   399] loss: 0.406353\n",
      "[18,   499] loss: 0.420939\n",
      "[18,   599] loss: 0.346053\n",
      "[18,   699] loss: 0.373470\n",
      "[19,    99] loss: 0.458873\n",
      "[19,   199] loss: 0.379238\n",
      "[19,   299] loss: 0.324681\n",
      "[19,   399] loss: 0.338493\n",
      "[19,   499] loss: 0.435281\n",
      "[19,   599] loss: 0.359339\n",
      "[19,   699] loss: 0.473776\n",
      "[20,    99] loss: 0.380603\n",
      "[20,   199] loss: 0.312418\n",
      "[20,   299] loss: 0.373339\n",
      "[20,   399] loss: 0.357600\n",
      "[20,   499] loss: 2.001331\n",
      "[20,   599] loss: 0.705200\n",
      "[20,   699] loss: 0.502478\n",
      "[21,    99] loss: 0.466397\n",
      "[21,   199] loss: 0.400530\n",
      "[21,   299] loss: 0.534800\n",
      "[21,   399] loss: 0.303725\n",
      "[21,   499] loss: 0.453529\n",
      "[21,   599] loss: 0.358524\n",
      "[21,   699] loss: 0.565020\n",
      "[22,    99] loss: 0.368873\n",
      "[22,   199] loss: 0.294736\n",
      "[22,   299] loss: 0.649439\n",
      "[22,   399] loss: 0.346850\n",
      "[22,   499] loss: 0.433354\n",
      "[22,   599] loss: 0.416140\n",
      "[22,   699] loss: 0.383723\n",
      "[23,    99] loss: 0.342990\n",
      "[23,   199] loss: 0.286173\n",
      "[23,   299] loss: 0.421231\n",
      "[23,   399] loss: 0.389041\n",
      "[23,   499] loss: 0.405477\n",
      "[23,   599] loss: 0.322425\n",
      "[23,   699] loss: 0.374399\n",
      "[24,    99] loss: 0.337734\n",
      "[24,   199] loss: 0.356533\n",
      "[24,   299] loss: 0.312865\n",
      "[24,   399] loss: 0.349032\n",
      "[24,   499] loss: 0.436552\n",
      "[24,   599] loss: 0.398762\n",
      "[24,   699] loss: 0.425979\n",
      "[25,    99] loss: 0.457670\n",
      "[25,   199] loss: 0.347792\n",
      "[25,   299] loss: 0.326265\n",
      "[25,   399] loss: 0.332972\n",
      "[25,   499] loss: 0.518293\n",
      "[25,   599] loss: 0.419300\n",
      "[25,   699] loss: 0.400685\n",
      "[26,    99] loss: 0.305182\n",
      "[26,   199] loss: 0.290049\n",
      "[26,   299] loss: 0.425519\n",
      "[26,   399] loss: 0.319486\n",
      "[26,   499] loss: 0.573711\n",
      "[26,   599] loss: 0.391905\n",
      "[26,   699] loss: 0.406931\n",
      "[27,    99] loss: 0.321531\n",
      "[27,   199] loss: 0.299559\n",
      "[27,   299] loss: 0.343433\n",
      "[27,   399] loss: 0.510803\n",
      "[27,   499] loss: 0.430278\n",
      "[27,   599] loss: 0.434858\n",
      "[27,   699] loss: 0.408577\n",
      "[28,    99] loss: 0.337426\n",
      "[28,   199] loss: 0.308323\n",
      "[28,   299] loss: 0.344335\n",
      "[28,   399] loss: 0.352890\n",
      "[28,   499] loss: 0.428331\n",
      "[28,   599] loss: 0.334880\n",
      "[28,   699] loss: 0.957354\n",
      "[29,    99] loss: 0.355201\n",
      "[29,   199] loss: 0.356954\n",
      "[29,   299] loss: 0.315112\n",
      "[29,   399] loss: 0.371684\n",
      "[29,   499] loss: 0.334332\n",
      "[29,   599] loss: 0.305790\n",
      "[29,   699] loss: 0.355559\n",
      "[30,    99] loss: 0.339938\n",
      "[30,   199] loss: 0.272705\n",
      "[30,   299] loss: 0.354728\n",
      "[30,   399] loss: 0.313206\n",
      "[30,   499] loss: 0.507696\n",
      "[30,   599] loss: 0.269367\n",
      "[30,   699] loss: 0.431297\n",
      "[31,    99] loss: 0.400808\n",
      "[31,   199] loss: 0.289606\n",
      "[31,   299] loss: 0.298737\n",
      "[31,   399] loss: 0.239646\n",
      "[31,   499] loss: 0.271989\n",
      "[31,   599] loss: 0.310170\n",
      "[31,   699] loss: 0.324730\n",
      "[32,    99] loss: 0.313993\n",
      "[32,   199] loss: 0.329952\n",
      "[32,   299] loss: 0.528437\n",
      "[32,   399] loss: 0.358580\n",
      "[32,   499] loss: 0.369376\n",
      "[32,   599] loss: 0.479265\n",
      "[32,   699] loss: 0.300927\n",
      "[33,    99] loss: 0.247430\n",
      "[33,   199] loss: 0.269596\n",
      "[33,   299] loss: 0.500483\n",
      "[33,   399] loss: 0.266032\n",
      "[33,   499] loss: 0.304139\n",
      "[33,   599] loss: 0.259570\n",
      "[33,   699] loss: 0.282736\n",
      "[34,    99] loss: 0.310390\n",
      "[34,   199] loss: 0.287540\n",
      "[34,   299] loss: 0.264837\n",
      "[34,   399] loss: 0.324802\n",
      "[34,   499] loss: 0.380840\n",
      "[34,   599] loss: 0.599416\n",
      "[34,   699] loss: 0.364525\n",
      "[35,    99] loss: 0.185119\n",
      "[35,   199] loss: 0.187309\n",
      "[35,   299] loss: 0.231518\n",
      "[35,   399] loss: 0.254009\n",
      "[35,   499] loss: 0.197389\n",
      "[35,   599] loss: 0.230357\n",
      "[35,   699] loss: 0.293193\n",
      "[36,    99] loss: 0.260207\n",
      "[36,   199] loss: 0.132109\n",
      "[36,   299] loss: 0.280260\n",
      "[36,   399] loss: 0.241363\n",
      "[36,   499] loss: 0.286225\n",
      "[36,   599] loss: 0.261889\n",
      "[36,   699] loss: 0.323131\n",
      "[37,    99] loss: 0.139982\n",
      "[37,   199] loss: 0.174650\n",
      "[37,   299] loss: 0.191211\n",
      "[37,   399] loss: 0.240131\n",
      "[37,   499] loss: 0.328952\n",
      "[37,   599] loss: 0.164386\n",
      "[37,   699] loss: 0.286081\n",
      "[38,    99] loss: 0.187028\n",
      "[38,   199] loss: 0.535532\n",
      "[38,   299] loss: 0.309080\n",
      "[38,   399] loss: 0.245052\n",
      "[38,   499] loss: 0.145654\n",
      "[38,   599] loss: 0.158415\n",
      "[38,   699] loss: 0.357956\n",
      "[39,    99] loss: 0.164439\n",
      "[39,   199] loss: 0.199754\n",
      "[39,   299] loss: 0.219482\n",
      "[39,   399] loss: 0.220801\n",
      "[39,   499] loss: 0.730398\n",
      "[39,   599] loss: 0.588468\n",
      "[39,   699] loss: 0.438558\n",
      "[40,    99] loss: 0.401125\n",
      "[40,   199] loss: 0.240947\n",
      "[40,   299] loss: 0.248858\n",
      "[40,   399] loss: 0.254444\n",
      "[40,   499] loss: 0.176350\n",
      "[40,   599] loss: 0.252317\n",
      "[40,   699] loss: 0.293967\n",
      "[41,    99] loss: 0.287700\n",
      "[41,   199] loss: 0.153334\n",
      "[41,   299] loss: 0.222981\n",
      "[41,   399] loss: 0.137101\n",
      "[41,   499] loss: 0.114082\n",
      "[41,   599] loss: 1.061171\n",
      "[41,   699] loss: 0.280354\n",
      "[42,    99] loss: 0.100657\n",
      "[42,   199] loss: 0.165590\n",
      "[42,   299] loss: 0.217750\n",
      "[42,   399] loss: 0.128487\n",
      "[42,   499] loss: 0.101381\n",
      "[42,   599] loss: 0.152619\n",
      "[42,   699] loss: 0.244555\n",
      "[43,    99] loss: 0.114856\n",
      "[43,   199] loss: 0.074458\n",
      "[43,   299] loss: 0.238421\n",
      "[43,   399] loss: 0.255895\n",
      "[43,   499] loss: 0.160289\n",
      "[43,   599] loss: 0.195994\n",
      "[43,   699] loss: 0.223188\n",
      "[44,    99] loss: 0.107403\n",
      "[44,   199] loss: 0.353677\n",
      "[44,   299] loss: 0.241224\n",
      "[44,   399] loss: 0.191000\n",
      "[44,   499] loss: 0.121268\n",
      "[44,   599] loss: 0.141132\n",
      "[44,   699] loss: 0.380679\n",
      "[45,    99] loss: 0.111074\n",
      "[45,   199] loss: 0.137980\n",
      "[45,   299] loss: 0.313960\n",
      "[45,   399] loss: 0.321239\n",
      "[45,   499] loss: 0.219192\n",
      "[45,   599] loss: 0.173844\n",
      "[45,   699] loss: 0.276812\n",
      "[46,    99] loss: 0.245749\n",
      "[46,   199] loss: 0.137618\n",
      "[46,   299] loss: 0.476484\n",
      "[46,   399] loss: 0.312095\n",
      "[46,   499] loss: 0.288441\n",
      "[46,   599] loss: 0.250601\n",
      "[46,   699] loss: 0.292427\n",
      "[47,    99] loss: 0.143506\n",
      "[47,   199] loss: 0.115315\n",
      "[47,   299] loss: 0.218147\n",
      "[47,   399] loss: 0.207747\n",
      "[47,   499] loss: 0.199048\n",
      "[47,   599] loss: 0.181778\n",
      "[47,   699] loss: 0.327185\n",
      "[48,    99] loss: 0.164673\n",
      "[48,   199] loss: 0.183990\n",
      "[48,   299] loss: 0.227857\n",
      "[48,   399] loss: 0.308724\n",
      "[48,   499] loss: 0.138280\n",
      "[48,   599] loss: 0.431066\n",
      "[48,   699] loss: 0.334135\n",
      "[49,    99] loss: 0.181578\n",
      "[49,   199] loss: 0.151665\n",
      "[49,   299] loss: 1.214745\n",
      "[49,   399] loss: 0.464626\n",
      "[49,   499] loss: 0.178375\n",
      "[49,   599] loss: 0.282907\n",
      "[49,   699] loss: 0.315788\n",
      "[50,    99] loss: 0.181518\n",
      "[50,   199] loss: 0.141285\n",
      "[50,   299] loss: 0.231764\n",
      "[50,   399] loss: 0.241478\n",
      "[50,   499] loss: 0.085237\n",
      "[50,   599] loss: 0.257357\n",
      "[50,   699] loss: 0.263941\n",
      "[51,    99] loss: 0.124485\n",
      "[51,   199] loss: 0.103738\n",
      "[51,   299] loss: 0.249247\n",
      "[51,   399] loss: 0.075525\n",
      "[51,   499] loss: 0.082562\n",
      "[51,   599] loss: 0.163990\n",
      "[51,   699] loss: 0.354817\n",
      "[52,    99] loss: 0.135675\n",
      "[52,   199] loss: 0.077197\n",
      "[52,   299] loss: 0.265624\n",
      "[52,   399] loss: 0.188504\n",
      "[52,   499] loss: 0.205423\n",
      "[52,   599] loss: 0.218214\n",
      "[52,   699] loss: 0.277224\n",
      "[53,    99] loss: 0.117804\n",
      "[53,   199] loss: 0.147029\n",
      "[53,   299] loss: 0.256576\n",
      "[53,   399] loss: 0.211265\n",
      "[53,   499] loss: 0.124756\n",
      "[53,   599] loss: 0.352803\n",
      "[53,   699] loss: 0.298534\n",
      "[54,    99] loss: 0.199309\n",
      "[54,   199] loss: 0.097336\n",
      "[54,   299] loss: 0.419016\n",
      "[54,   399] loss: 0.115461\n",
      "[54,   499] loss: 0.134981\n",
      "[54,   599] loss: 0.149476\n",
      "[54,   699] loss: 0.330007\n",
      "[55,    99] loss: 0.107545\n",
      "[55,   199] loss: 0.072688\n",
      "[55,   299] loss: 0.192812\n",
      "[55,   399] loss: 0.214343\n",
      "[55,   499] loss: 0.186442\n",
      "[55,   599] loss: 0.156049\n",
      "[55,   699] loss: 0.286905\n",
      "[56,    99] loss: 0.134502\n",
      "[56,   199] loss: 0.078951\n",
      "[56,   299] loss: 0.210728\n",
      "[56,   399] loss: 0.189873\n",
      "[56,   499] loss: 0.086170\n",
      "[56,   599] loss: 0.280003\n",
      "[56,   699] loss: 0.279662\n",
      "[57,    99] loss: 0.104150\n",
      "[57,   199] loss: 0.086306\n",
      "[57,   299] loss: 0.262157\n",
      "[57,   399] loss: 0.225317\n",
      "[57,   499] loss: 0.161669\n",
      "[57,   599] loss: 0.246610\n",
      "[57,   699] loss: 0.700342\n",
      "[58,    99] loss: 0.156781\n",
      "[58,   199] loss: 0.171819\n",
      "[58,   299] loss: 0.365585\n",
      "[58,   399] loss: 0.187339\n",
      "[58,   499] loss: 0.130039\n",
      "[58,   599] loss: 0.292388\n",
      "[58,   699] loss: 0.278102\n",
      "[59,    99] loss: 0.081225\n",
      "[59,   199] loss: 0.063247\n",
      "[59,   299] loss: 0.396235\n",
      "[59,   399] loss: 0.220563\n",
      "[59,   499] loss: 0.178728\n",
      "[59,   599] loss: 0.118504\n",
      "[59,   699] loss: 0.211180\n",
      "[60,    99] loss: 0.075617\n",
      "[60,   199] loss: 0.059519\n",
      "[60,   299] loss: 0.195162\n",
      "[60,   399] loss: 0.096248\n",
      "[60,   499] loss: 0.066801\n",
      "[60,   599] loss: 0.088561\n",
      "[60,   699] loss: 0.250129\n",
      "[61,    99] loss: 0.191885\n",
      "[61,   199] loss: 0.106066\n",
      "[61,   299] loss: 0.764570\n",
      "[61,   399] loss: 0.241031\n",
      "[61,   499] loss: 0.185460\n",
      "[61,   599] loss: 0.507783\n",
      "[61,   699] loss: 0.385404\n",
      "[62,    99] loss: 0.143664\n",
      "[62,   199] loss: 0.129616\n",
      "[62,   299] loss: 0.302312\n",
      "[62,   399] loss: 0.195746\n",
      "[62,   499] loss: 0.148539\n",
      "[62,   599] loss: 0.185240\n",
      "[62,   699] loss: 0.253032\n",
      "[63,    99] loss: 0.097937\n",
      "[63,   199] loss: 0.071672\n",
      "[63,   299] loss: 0.217757\n",
      "[63,   399] loss: 0.260293\n",
      "[63,   499] loss: 0.234403\n",
      "[63,   599] loss: 0.235219\n",
      "[63,   699] loss: 0.253641\n",
      "[64,    99] loss: 0.102772\n",
      "[64,   199] loss: 0.073465\n",
      "[64,   299] loss: 0.322329\n",
      "[64,   399] loss: 0.235782\n",
      "[64,   499] loss: 0.101369\n",
      "[64,   599] loss: 0.311811\n",
      "[64,   699] loss: 0.291075\n",
      "[65,    99] loss: 0.083044\n",
      "[65,   199] loss: 0.065833\n",
      "[65,   299] loss: 0.171175\n",
      "[65,   399] loss: 0.194716\n",
      "[65,   499] loss: 0.111415\n",
      "[65,   599] loss: 0.079493\n",
      "[65,   699] loss: 0.222716\n",
      "[66,    99] loss: 0.081030\n",
      "[66,   199] loss: 0.058218\n",
      "[66,   299] loss: 0.135152\n",
      "[66,   399] loss: 0.150989\n",
      "[66,   499] loss: 0.149901\n",
      "[66,   599] loss: 0.095051\n",
      "[66,   699] loss: 0.233430\n",
      "[67,    99] loss: 0.062699\n",
      "[67,   199] loss: 0.061235\n",
      "[67,   299] loss: 0.225562\n",
      "[67,   399] loss: 0.392909\n",
      "[67,   499] loss: 0.169696\n",
      "[67,   599] loss: 0.411585\n",
      "[67,   699] loss: 0.293615\n",
      "[68,    99] loss: 0.334913\n",
      "[68,   199] loss: 0.201097\n",
      "[68,   299] loss: 0.435205\n",
      "[68,   399] loss: 0.577185\n",
      "[68,   499] loss: 0.179507\n",
      "[68,   599] loss: 0.249913\n",
      "[68,   699] loss: 0.284277\n",
      "[69,    99] loss: 0.480173\n",
      "[69,   199] loss: 0.261728\n",
      "[69,   299] loss: 0.267725\n",
      "[69,   399] loss: 0.213321\n",
      "[69,   499] loss: 0.108313\n",
      "[69,   599] loss: 0.485468\n",
      "[69,   699] loss: 0.218801\n",
      "[70,    99] loss: 0.102454\n",
      "[70,   199] loss: 0.117124\n",
      "[70,   299] loss: 0.223323\n",
      "[70,   399] loss: 0.151206\n",
      "[70,   499] loss: 0.121078\n",
      "[70,   599] loss: 0.184324\n",
      "[70,   699] loss: 0.198429\n",
      "[71,    99] loss: 0.100280\n",
      "[71,   199] loss: 0.103281\n",
      "[71,   299] loss: 0.169277\n",
      "[71,   399] loss: 2.069029\n",
      "[71,   499] loss: 0.130048\n",
      "[71,   599] loss: 0.106371\n",
      "[71,   699] loss: 0.238292\n",
      "[72,    99] loss: 0.121483\n",
      "[72,   199] loss: 0.149652\n",
      "[72,   299] loss: 0.176220\n",
      "[72,   399] loss: 0.077700\n",
      "[72,   499] loss: 0.123075\n",
      "[72,   599] loss: 0.121965\n",
      "[72,   699] loss: 0.241776\n",
      "[73,    99] loss: 0.098972\n",
      "[73,   199] loss: 0.063197\n",
      "[73,   299] loss: 0.156963\n",
      "[73,   399] loss: 0.111778\n",
      "[73,   499] loss: 0.099176\n",
      "[73,   599] loss: 0.345650\n",
      "[73,   699] loss: 0.272369\n",
      "[74,    99] loss: 0.173956\n",
      "[74,   199] loss: 0.108968\n",
      "[74,   299] loss: 0.177320\n",
      "[74,   399] loss: 0.179686\n",
      "[74,   499] loss: 0.076595\n",
      "[74,   599] loss: 0.113863\n",
      "[74,   699] loss: 0.364118\n",
      "[75,    99] loss: 0.128904\n",
      "[75,   199] loss: 0.067017\n",
      "[75,   299] loss: 0.159987\n",
      "[75,   399] loss: 0.196151\n",
      "[75,   499] loss: 0.099383\n",
      "[75,   599] loss: 0.123733\n",
      "[75,   699] loss: 0.245180\n",
      "[76,    99] loss: 0.144561\n",
      "[76,   199] loss: 0.074678\n",
      "[76,   299] loss: 0.147409\n",
      "[76,   399] loss: 0.181763\n",
      "[76,   499] loss: 0.081938\n",
      "[76,   599] loss: 0.344416\n",
      "[76,   699] loss: 0.291098\n",
      "[77,    99] loss: 0.079408\n",
      "[77,   199] loss: 0.092655\n",
      "[77,   299] loss: 0.143015\n",
      "[77,   399] loss: 0.164939\n",
      "[77,   499] loss: 0.186258\n",
      "[77,   599] loss: 0.138620\n",
      "[77,   699] loss: 0.349508\n",
      "[78,    99] loss: 0.125780\n",
      "[78,   199] loss: 0.065395\n",
      "[78,   299] loss: 0.398387\n",
      "[78,   399] loss: 0.126328\n",
      "[78,   499] loss: 0.087264\n",
      "[78,   599] loss: 0.115011\n",
      "[78,   699] loss: 0.307341\n",
      "[79,    99] loss: 0.123300\n",
      "[79,   199] loss: 0.067825\n",
      "[79,   299] loss: 0.137824\n",
      "[79,   399] loss: 0.137230\n",
      "[79,   499] loss: 0.108027\n",
      "[79,   599] loss: 0.139213\n",
      "[79,   699] loss: 0.286079\n",
      "[80,    99] loss: 0.205318\n",
      "[80,   199] loss: 0.174485\n",
      "[80,   299] loss: 0.268680\n",
      "[80,   399] loss: 0.326392\n",
      "[80,   499] loss: 0.158934\n",
      "[80,   599] loss: 0.192492\n",
      "[80,   699] loss: 0.265818\n",
      "[81,    99] loss: 0.351310\n",
      "[81,   199] loss: 0.225657\n",
      "[81,   299] loss: 0.154791\n",
      "[81,   399] loss: 0.152677\n",
      "[81,   499] loss: 0.073782\n",
      "[81,   599] loss: 0.232561\n",
      "[81,   699] loss: 0.622098\n",
      "[82,    99] loss: 0.212539\n",
      "[82,   199] loss: 0.225599\n",
      "[82,   299] loss: 0.183577\n",
      "[82,   399] loss: 0.044081\n",
      "[82,   499] loss: 0.102971\n",
      "[82,   599] loss: 0.149701\n",
      "[82,   699] loss: 0.282962\n",
      "[83,    99] loss: 0.523764\n",
      "[83,   199] loss: 0.093946\n",
      "[83,   299] loss: 0.166350\n",
      "[83,   399] loss: 0.201158\n",
      "[83,   499] loss: 0.267937\n",
      "[83,   599] loss: 0.139840\n",
      "[83,   699] loss: 0.298269\n",
      "[84,    99] loss: 0.095427\n",
      "[84,   199] loss: 0.090928\n",
      "[84,   299] loss: 0.168670\n",
      "[84,   399] loss: 0.117658\n",
      "[84,   499] loss: 0.230831\n",
      "[84,   599] loss: 0.096197\n",
      "[84,   699] loss: 0.220812\n",
      "[85,    99] loss: 0.079253\n",
      "[85,   199] loss: 0.047208\n",
      "[85,   299] loss: 0.251296\n",
      "[85,   399] loss: 0.068034\n",
      "[85,   499] loss: 0.051400\n",
      "[85,   599] loss: 0.164157\n",
      "[85,   699] loss: 0.190037\n",
      "[86,    99] loss: 0.093728\n",
      "[86,   199] loss: 0.074864\n",
      "[86,   299] loss: 0.128673\n",
      "[86,   399] loss: 0.080051\n",
      "[86,   499] loss: 0.102570\n",
      "[86,   599] loss: 0.284046\n",
      "[86,   699] loss: 0.324825\n",
      "[87,    99] loss: 0.126494\n",
      "[87,   199] loss: 0.069098\n",
      "[87,   299] loss: 0.144049\n",
      "[87,   399] loss: 0.400108\n",
      "[87,   499] loss: 0.557951\n",
      "[87,   599] loss: 0.258566\n",
      "[87,   699] loss: 0.290727\n",
      "[88,    99] loss: 0.107538\n",
      "[88,   199] loss: 0.186490\n",
      "[88,   299] loss: 0.186032\n",
      "[88,   399] loss: 0.424396\n",
      "[88,   499] loss: 0.070635\n",
      "[88,   599] loss: 0.083463\n",
      "[88,   699] loss: 0.332593\n",
      "[89,    99] loss: 0.104304\n",
      "[89,   199] loss: 0.091213\n",
      "[89,   299] loss: 0.158615\n",
      "[89,   399] loss: 0.163613\n",
      "[89,   499] loss: 0.088800\n",
      "[89,   599] loss: 0.095987\n",
      "[89,   699] loss: 0.378560\n",
      "[90,    99] loss: 0.114220\n",
      "[90,   199] loss: 0.096784\n",
      "[90,   299] loss: 0.120397\n",
      "[90,   399] loss: 0.077466\n",
      "[90,   499] loss: 0.092310\n",
      "[90,   599] loss: 0.161859\n",
      "[90,   699] loss: 0.250907\n",
      "[91,    99] loss: 0.099147\n",
      "[91,   199] loss: 0.158005\n",
      "[91,   299] loss: 0.135341\n",
      "[91,   399] loss: 0.165938\n",
      "[91,   499] loss: 0.203413\n",
      "[91,   599] loss: 0.148752\n",
      "[91,   699] loss: 0.222137\n",
      "[92,    99] loss: 0.095311\n",
      "[92,   199] loss: 0.092975\n",
      "[92,   299] loss: 0.223788\n",
      "[92,   399] loss: 0.200042\n",
      "[92,   499] loss: 0.149210\n",
      "[92,   599] loss: 0.147600\n",
      "[92,   699] loss: 0.427642\n",
      "[93,    99] loss: 0.080203\n",
      "[93,   199] loss: 0.066104\n",
      "[93,   299] loss: 0.240519\n",
      "[93,   399] loss: 0.216949\n",
      "[93,   499] loss: 0.122662\n",
      "[93,   599] loss: 0.218963\n",
      "[93,   699] loss: 0.270792\n",
      "[94,    99] loss: 0.122613\n",
      "[94,   199] loss: 0.131929\n",
      "[94,   299] loss: 0.135563\n",
      "[94,   399] loss: 0.145089\n",
      "[94,   499] loss: 0.053907\n",
      "[94,   599] loss: 0.431153\n",
      "[94,   699] loss: 0.337456\n",
      "[95,    99] loss: 0.510956\n",
      "[95,   199] loss: 0.115638\n",
      "[95,   299] loss: 0.182080\n",
      "[95,   399] loss: 0.262234\n",
      "[95,   499] loss: 0.129515\n",
      "[95,   599] loss: 0.388914\n",
      "[95,   699] loss: 0.577404\n",
      "[96,    99] loss: 0.121675\n",
      "[96,   199] loss: 0.152820\n",
      "[96,   299] loss: 0.152959\n",
      "[96,   399] loss: 0.233586\n",
      "[96,   499] loss: 0.055550\n",
      "[96,   599] loss: 0.162814\n",
      "[96,   699] loss: 0.235386\n",
      "[97,    99] loss: 0.095588\n",
      "[97,   199] loss: 0.129070\n",
      "[97,   299] loss: 0.085214\n",
      "[97,   399] loss: 0.120257\n",
      "[97,   499] loss: 0.409029\n",
      "[97,   599] loss: 0.190100\n",
      "[97,   699] loss: 0.393186\n",
      "[98,    99] loss: 0.193441\n",
      "[98,   199] loss: 0.093514\n",
      "[98,   299] loss: 0.273407\n",
      "[98,   399] loss: 0.189707\n",
      "[98,   499] loss: 0.119836\n",
      "[98,   599] loss: 0.275416\n",
      "[98,   699] loss: 0.378284\n",
      "[99,    99] loss: 0.067219\n",
      "[99,   199] loss: 0.052361\n",
      "[99,   299] loss: 0.121105\n",
      "[99,   399] loss: 0.044299\n",
      "[99,   499] loss: 0.165869\n",
      "[99,   599] loss: 0.070219\n",
      "[99,   699] loss: 0.223090\n",
      "[100,    99] loss: 0.137196\n",
      "[100,   199] loss: 0.053172\n",
      "[100,   299] loss: 0.156856\n",
      "[100,   399] loss: 0.190984\n",
      "[100,   499] loss: 0.124905\n",
      "[100,   599] loss: 0.078386\n",
      "[100,   699] loss: 0.235757\n",
      "Finished Training\n",
      "[1,    99] loss: 0.736694\n",
      "[1,   199] loss: 0.680151\n",
      "[1,   299] loss: 0.776866\n",
      "[1,   399] loss: 0.681215\n",
      "[1,   499] loss: 0.751521\n",
      "[1,   599] loss: 0.690290\n",
      "[1,   699] loss: 0.659165\n",
      "[2,    99] loss: 0.689145\n",
      "[2,   199] loss: 0.643798\n",
      "[2,   299] loss: 0.789816\n",
      "[2,   399] loss: 0.603961\n",
      "[2,   499] loss: 0.745820\n",
      "[2,   599] loss: 0.624307\n",
      "[2,   699] loss: 0.576794\n",
      "[3,    99] loss: 0.685075\n",
      "[3,   199] loss: 0.628960\n",
      "[3,   299] loss: 0.646745\n",
      "[3,   399] loss: 0.525998\n",
      "[3,   499] loss: 0.641141\n",
      "[3,   599] loss: 0.638867\n",
      "[3,   699] loss: 0.578436\n",
      "[4,    99] loss: 0.598169\n",
      "[4,   199] loss: 0.543715\n",
      "[4,   299] loss: 0.550364\n",
      "[4,   399] loss: 0.509987\n",
      "[4,   499] loss: 0.713433\n",
      "[4,   599] loss: 0.618850\n",
      "[4,   699] loss: 0.551872\n",
      "[5,    99] loss: 0.587420\n",
      "[5,   199] loss: 0.596424\n",
      "[5,   299] loss: 0.676478\n",
      "[5,   399] loss: 0.491757\n",
      "[5,   499] loss: 0.672402\n",
      "[5,   599] loss: 0.528667\n",
      "[5,   699] loss: 0.531859\n",
      "[6,    99] loss: 0.562444\n",
      "[6,   199] loss: 0.492902\n",
      "[6,   299] loss: 0.504166\n",
      "[6,   399] loss: 0.490465\n",
      "[6,   499] loss: 0.654790\n",
      "[6,   599] loss: 0.534141\n",
      "[6,   699] loss: 0.531055\n",
      "[7,    99] loss: 0.556546\n",
      "[7,   199] loss: 0.491778\n",
      "[7,   299] loss: 0.492186\n",
      "[7,   399] loss: 0.440320\n",
      "[7,   499] loss: 0.693594\n",
      "[7,   599] loss: 0.538939\n",
      "[7,   699] loss: 0.509233\n",
      "[8,    99] loss: 0.546903\n",
      "[8,   199] loss: 0.515433\n",
      "[8,   299] loss: 0.494737\n",
      "[8,   399] loss: 0.447539\n",
      "[8,   499] loss: 0.588301\n",
      "[8,   599] loss: 0.461462\n",
      "[8,   699] loss: 0.533694\n",
      "[9,    99] loss: 0.538183\n",
      "[9,   199] loss: 0.445590\n",
      "[9,   299] loss: 0.444159\n",
      "[9,   399] loss: 0.630581\n",
      "[9,   499] loss: 1.022992\n",
      "[9,   599] loss: 0.462137\n",
      "[9,   699] loss: 0.491837\n",
      "[10,    99] loss: 0.506661\n",
      "[10,   199] loss: 0.456595\n",
      "[10,   299] loss: 0.976095\n",
      "[10,   399] loss: 0.551459\n",
      "[10,   499] loss: 0.480327\n",
      "[10,   599] loss: 0.459651\n",
      "[10,   699] loss: 0.478448\n",
      "[11,    99] loss: 0.719278\n",
      "[11,   199] loss: 0.449215\n",
      "[11,   299] loss: 0.381820\n",
      "[11,   399] loss: 0.348515\n",
      "[11,   499] loss: 0.506529\n",
      "[11,   599] loss: 0.347310\n",
      "[11,   699] loss: 0.369901\n",
      "[12,    99] loss: 0.856470\n",
      "[12,   199] loss: 0.440310\n",
      "[12,   299] loss: 0.368341\n",
      "[12,   399] loss: 0.391019\n",
      "[12,   499] loss: 0.436279\n",
      "[12,   599] loss: 0.419727\n",
      "[12,   699] loss: 0.457643\n",
      "[13,    99] loss: 0.445206\n",
      "[13,   199] loss: 0.447473\n",
      "[13,   299] loss: 0.372112\n",
      "[13,   399] loss: 0.576128\n",
      "[13,   499] loss: 0.580352\n",
      "[13,   599] loss: 0.475217\n",
      "[13,   699] loss: 0.416341\n",
      "[14,    99] loss: 0.454022\n",
      "[14,   199] loss: 0.490010\n",
      "[14,   299] loss: 0.407906\n",
      "[14,   399] loss: 0.329931\n",
      "[14,   499] loss: 0.415410\n",
      "[14,   599] loss: 0.310873\n",
      "[14,   699] loss: 0.332739\n",
      "[15,    99] loss: 0.449500\n",
      "[15,   199] loss: 0.385137\n",
      "[15,   299] loss: 0.323074\n",
      "[15,   399] loss: 0.410746\n",
      "[15,   499] loss: 0.562493\n",
      "[15,   599] loss: 0.343999\n",
      "[15,   699] loss: 0.440822\n",
      "[16,    99] loss: 0.469514\n",
      "[16,   199] loss: 0.366338\n",
      "[16,   299] loss: 0.259514\n",
      "[16,   399] loss: 0.396912\n",
      "[16,   499] loss: 0.683898\n",
      "[16,   599] loss: 0.377776\n",
      "[16,   699] loss: 0.413394\n",
      "[17,    99] loss: 0.403403\n",
      "[17,   199] loss: 0.417805\n",
      "[17,   299] loss: 0.313650\n",
      "[17,   399] loss: 0.358636\n",
      "[17,   499] loss: 0.390484\n",
      "[17,   599] loss: 0.316499\n",
      "[17,   699] loss: 0.354357\n",
      "[18,    99] loss: 0.382908\n",
      "[18,   199] loss: 0.394645\n",
      "[18,   299] loss: 0.343055\n",
      "[18,   399] loss: 0.286196\n",
      "[18,   499] loss: 0.299248\n",
      "[18,   599] loss: 0.508966\n",
      "[18,   699] loss: 0.344485\n",
      "[19,    99] loss: 0.364614\n",
      "[19,   199] loss: 0.342774\n",
      "[19,   299] loss: 0.301734\n",
      "[19,   399] loss: 0.320830\n",
      "[19,   499] loss: 0.305387\n",
      "[19,   599] loss: 0.344059\n",
      "[19,   699] loss: 0.423974\n",
      "[20,    99] loss: 0.980485\n",
      "[20,   199] loss: 0.291313\n",
      "[20,   299] loss: 0.498745\n",
      "[20,   399] loss: 0.523287\n",
      "[20,   499] loss: 0.348084\n",
      "[20,   599] loss: 0.297163\n",
      "[20,   699] loss: 0.269457\n",
      "[21,    99] loss: 0.395273\n",
      "[21,   199] loss: 0.247576\n",
      "[21,   299] loss: 0.275258\n",
      "[21,   399] loss: 0.303302\n",
      "[21,   499] loss: 0.263891\n",
      "[21,   599] loss: 0.309167\n",
      "[21,   699] loss: 0.209609\n",
      "[22,    99] loss: 0.530394\n",
      "[22,   199] loss: 0.351886\n",
      "[22,   299] loss: 0.262348\n",
      "[22,   399] loss: 0.277478\n",
      "[22,   499] loss: 0.342807\n",
      "[22,   599] loss: 0.226090\n",
      "[22,   699] loss: 0.258151\n",
      "[23,    99] loss: 0.335227\n",
      "[23,   199] loss: 0.251388\n",
      "[23,   299] loss: 0.194851\n",
      "[23,   399] loss: 0.285357\n",
      "[23,   499] loss: 0.225506\n",
      "[23,   599] loss: 0.303832\n",
      "[23,   699] loss: 0.393772\n",
      "[24,    99] loss: 0.326947\n",
      "[24,   199] loss: 0.261408\n",
      "[24,   299] loss: 0.495487\n",
      "[24,   399] loss: 0.271761\n",
      "[24,   499] loss: 0.245074\n",
      "[24,   599] loss: 0.256667\n",
      "[24,   699] loss: 0.293330\n",
      "[25,    99] loss: 0.387504\n",
      "[25,   199] loss: 0.255309\n",
      "[25,   299] loss: 0.307639\n",
      "[25,   399] loss: 0.227701\n",
      "[25,   499] loss: 0.274338\n",
      "[25,   599] loss: 0.260546\n",
      "[25,   699] loss: 0.247842\n",
      "[26,    99] loss: 0.479156\n",
      "[26,   199] loss: 0.254141\n",
      "[26,   299] loss: 0.193120\n",
      "[26,   399] loss: 0.334465\n",
      "[26,   499] loss: 0.215769\n",
      "[26,   599] loss: 0.261764\n",
      "[26,   699] loss: 0.334797\n",
      "[27,    99] loss: 0.333879\n",
      "[27,   199] loss: 0.292349\n",
      "[27,   299] loss: 0.238944\n",
      "[27,   399] loss: 0.292261\n",
      "[27,   499] loss: 0.312508\n",
      "[27,   599] loss: 0.256397\n",
      "[27,   699] loss: 0.225821\n",
      "[28,    99] loss: 0.327389\n",
      "[28,   199] loss: 0.356228\n",
      "[28,   299] loss: 0.178378\n",
      "[28,   399] loss: 0.237037\n",
      "[28,   499] loss: 0.274616\n",
      "[28,   599] loss: 0.226707\n",
      "[28,   699] loss: 0.236609\n",
      "[29,    99] loss: 0.276027\n",
      "[29,   199] loss: 0.244060\n",
      "[29,   299] loss: 0.192864\n",
      "[29,   399] loss: 0.237336\n",
      "[29,   499] loss: 0.582675\n",
      "[29,   599] loss: 0.286683\n",
      "[29,   699] loss: 0.206498\n",
      "[30,    99] loss: 0.368225\n",
      "[30,   199] loss: 0.246153\n",
      "[30,   299] loss: 0.192617\n",
      "[30,   399] loss: 0.190950\n",
      "[30,   499] loss: 0.258768\n",
      "[30,   599] loss: 0.184204\n",
      "[30,   699] loss: 0.257346\n",
      "[31,    99] loss: 0.451926\n",
      "[31,   199] loss: 0.298148\n",
      "[31,   299] loss: 0.229533\n",
      "[31,   399] loss: 0.279447\n",
      "[31,   499] loss: 0.365435\n",
      "[31,   599] loss: 0.224955\n",
      "[31,   699] loss: 0.203903\n",
      "[32,    99] loss: 0.365465\n",
      "[32,   199] loss: 0.264406\n",
      "[32,   299] loss: 0.181799\n",
      "[32,   399] loss: 0.190713\n",
      "[32,   499] loss: 0.248149\n",
      "[32,   599] loss: 0.224369\n",
      "[32,   699] loss: 0.187804\n",
      "[33,    99] loss: 0.323765\n",
      "[33,   199] loss: 0.191231\n",
      "[33,   299] loss: 0.186560\n",
      "[33,   399] loss: 0.219427\n",
      "[33,   499] loss: 0.195804\n",
      "[33,   599] loss: 0.149416\n",
      "[33,   699] loss: 0.495772\n",
      "[34,    99] loss: 0.656331\n",
      "[34,   199] loss: 0.232748\n",
      "[34,   299] loss: 0.185008\n",
      "[34,   399] loss: 0.238156\n",
      "[34,   499] loss: 0.198415\n",
      "[34,   599] loss: 0.217305\n",
      "[34,   699] loss: 0.162414\n",
      "[35,    99] loss: 0.227167\n",
      "[35,   199] loss: 0.536833\n",
      "[35,   299] loss: 0.208265\n",
      "[35,   399] loss: 0.302028\n",
      "[35,   499] loss: 0.199722\n",
      "[35,   599] loss: 0.199064\n",
      "[35,   699] loss: 0.204787\n",
      "[36,    99] loss: 0.167280\n",
      "[36,   199] loss: 0.181287\n",
      "[36,   299] loss: 0.170606\n",
      "[36,   399] loss: 0.196840\n",
      "[36,   499] loss: 0.258087\n",
      "[36,   599] loss: 0.184238\n",
      "[36,   699] loss: 0.154357\n",
      "[37,    99] loss: 0.163698\n",
      "[37,   199] loss: 0.151121\n",
      "[37,   299] loss: 0.133845\n",
      "[37,   399] loss: 0.289914\n",
      "[37,   499] loss: 0.188384\n",
      "[37,   599] loss: 0.224544\n",
      "[37,   699] loss: 0.330531\n",
      "[38,    99] loss: 0.319956\n",
      "[38,   199] loss: 0.264530\n",
      "[38,   299] loss: 0.425021\n",
      "[38,   399] loss: 0.226032\n",
      "[38,   499] loss: 0.283431\n",
      "[38,   599] loss: 0.187359\n",
      "[38,   699] loss: 0.163851\n",
      "[39,    99] loss: 0.196303\n",
      "[39,   199] loss: 0.157915\n",
      "[39,   299] loss: 0.329323\n",
      "[39,   399] loss: 0.235830\n",
      "[39,   499] loss: 0.321624\n",
      "[39,   599] loss: 0.242016\n",
      "[39,   699] loss: 0.202657\n",
      "[40,    99] loss: 0.334341\n",
      "[40,   199] loss: 0.255488\n",
      "[40,   299] loss: 0.183937\n",
      "[40,   399] loss: 0.196949\n",
      "[40,   499] loss: 0.168672\n",
      "[40,   599] loss: 0.201717\n",
      "[40,   699] loss: 0.179574\n",
      "[41,    99] loss: 0.219305\n",
      "[41,   199] loss: 0.175900\n",
      "[41,   299] loss: 0.151118\n",
      "[41,   399] loss: 0.176160\n",
      "[41,   499] loss: 0.151305\n",
      "[41,   599] loss: 0.248004\n",
      "[41,   699] loss: 0.327290\n",
      "[42,    99] loss: 0.291783\n",
      "[42,   199] loss: 0.132881\n",
      "[42,   299] loss: 0.155717\n",
      "[42,   399] loss: 0.483166\n",
      "[42,   499] loss: 0.326260\n",
      "[42,   599] loss: 0.181887\n",
      "[42,   699] loss: 0.205885\n",
      "[43,    99] loss: 0.117483\n",
      "[43,   199] loss: 0.177876\n",
      "[43,   299] loss: 0.188191\n",
      "[43,   399] loss: 0.158109\n",
      "[43,   499] loss: 0.289115\n",
      "[43,   599] loss: 0.499273\n",
      "[43,   699] loss: 0.233609\n",
      "[44,    99] loss: 0.243164\n",
      "[44,   199] loss: 0.188952\n",
      "[44,   299] loss: 0.127289\n",
      "[44,   399] loss: 0.193072\n",
      "[44,   499] loss: 0.175288\n",
      "[44,   599] loss: 0.278554\n",
      "[44,   699] loss: 0.409349\n",
      "[45,    99] loss: 0.152513\n",
      "[45,   199] loss: 0.248047\n",
      "[45,   299] loss: 0.319649\n",
      "[45,   399] loss: 0.257663\n",
      "[45,   499] loss: 0.310888\n",
      "[45,   599] loss: 0.147941\n",
      "[45,   699] loss: 0.129575\n",
      "[46,    99] loss: 0.550070\n",
      "[46,   199] loss: 0.146761\n",
      "[46,   299] loss: 0.187803\n",
      "[46,   399] loss: 0.150458\n",
      "[46,   499] loss: 0.232510\n",
      "[46,   599] loss: 0.410702\n",
      "[46,   699] loss: 0.188364\n",
      "[47,    99] loss: 0.157450\n",
      "[47,   199] loss: 0.136325\n",
      "[47,   299] loss: 0.116939\n",
      "[47,   399] loss: 0.149277\n",
      "[47,   499] loss: 0.169098\n",
      "[47,   599] loss: 0.119937\n",
      "[47,   699] loss: 0.384180\n",
      "[48,    99] loss: 0.249865\n",
      "[48,   199] loss: 0.166031\n",
      "[48,   299] loss: 0.120769\n",
      "[48,   399] loss: 0.152522\n",
      "[48,   499] loss: 0.227042\n",
      "[48,   599] loss: 0.149971\n",
      "[48,   699] loss: 0.509102\n",
      "[49,    99] loss: 0.288936\n",
      "[49,   199] loss: 0.118951\n",
      "[49,   299] loss: 0.088629\n",
      "[49,   399] loss: 0.102249\n",
      "[49,   499] loss: 0.333462\n",
      "[49,   599] loss: 0.143358\n",
      "[49,   699] loss: 0.164289\n",
      "[50,    99] loss: 0.151666\n",
      "[50,   199] loss: 0.222567\n",
      "[50,   299] loss: 0.116094\n",
      "[50,   399] loss: 0.211761\n",
      "[50,   499] loss: 0.383024\n",
      "[50,   599] loss: 0.196611\n",
      "[50,   699] loss: 0.149489\n",
      "[51,    99] loss: 0.121677\n",
      "[51,   199] loss: 0.186680\n",
      "[51,   299] loss: 0.146475\n",
      "[51,   399] loss: 0.182543\n",
      "[51,   499] loss: 0.248983\n",
      "[51,   599] loss: 0.109889\n",
      "[51,   699] loss: 0.163234\n",
      "[52,    99] loss: 0.165869\n",
      "[52,   199] loss: 0.211426\n",
      "[52,   299] loss: 0.132937\n",
      "[52,   399] loss: 0.162963\n",
      "[52,   499] loss: 0.173711\n",
      "[52,   599] loss: 0.121140\n",
      "[52,   699] loss: 0.190852\n",
      "[53,    99] loss: 0.208654\n",
      "[53,   199] loss: 0.149217\n",
      "[53,   299] loss: 0.182119\n",
      "[53,   399] loss: 0.172053\n",
      "[53,   499] loss: 0.190938\n",
      "[53,   599] loss: 0.100751\n",
      "[53,   699] loss: 0.246570\n",
      "[54,    99] loss: 0.096280\n",
      "[54,   199] loss: 0.239777\n",
      "[54,   299] loss: 0.149388\n",
      "[54,   399] loss: 0.162089\n",
      "[54,   499] loss: 0.192676\n",
      "[54,   599] loss: 0.114043\n",
      "[54,   699] loss: 1.139808\n",
      "[55,    99] loss: 0.359912\n",
      "[55,   199] loss: 0.241003\n",
      "[55,   299] loss: 0.205755\n",
      "[55,   399] loss: 0.172257\n",
      "[55,   499] loss: 0.147997\n",
      "[55,   599] loss: 0.147732\n",
      "[55,   699] loss: 0.176228\n",
      "[56,    99] loss: 0.093679\n",
      "[56,   199] loss: 0.143205\n",
      "[56,   299] loss: 0.321333\n",
      "[56,   399] loss: 0.124009\n",
      "[56,   499] loss: 0.331633\n",
      "[56,   599] loss: 0.113955\n",
      "[56,   699] loss: 0.176903\n",
      "[57,    99] loss: 0.196088\n",
      "[57,   199] loss: 0.185882\n",
      "[57,   299] loss: 0.071177\n",
      "[57,   399] loss: 0.128266\n",
      "[57,   499] loss: 0.167837\n",
      "[57,   599] loss: 0.166408\n",
      "[57,   699] loss: 0.224297\n",
      "[58,    99] loss: 0.216178\n",
      "[58,   199] loss: 0.151385\n",
      "[58,   299] loss: 0.134906\n",
      "[58,   399] loss: 0.132030\n",
      "[58,   499] loss: 0.169517\n",
      "[58,   599] loss: 0.091811\n",
      "[58,   699] loss: 0.174064\n",
      "[59,    99] loss: 0.178715\n",
      "[59,   199] loss: 0.145831\n",
      "[59,   299] loss: 0.083652\n",
      "[59,   399] loss: 0.132308\n",
      "[59,   499] loss: 0.206575\n",
      "[59,   599] loss: 0.046266\n",
      "[59,   699] loss: 0.172253\n",
      "[60,    99] loss: 0.102348\n",
      "[60,   199] loss: 0.151307\n",
      "[60,   299] loss: 0.115109\n",
      "[60,   399] loss: 0.098739\n",
      "[60,   499] loss: 0.218477\n",
      "[60,   599] loss: 0.064949\n",
      "[60,   699] loss: 0.081919\n",
      "[61,    99] loss: 0.325943\n",
      "[61,   199] loss: 0.192526\n",
      "[61,   299] loss: 0.155290\n",
      "[61,   399] loss: 0.175124\n",
      "[61,   499] loss: 0.249564\n",
      "[61,   599] loss: 0.177990\n",
      "[61,   699] loss: 0.171158\n",
      "[62,    99] loss: 0.169825\n",
      "[62,   199] loss: 0.258465\n",
      "[62,   299] loss: 0.129656\n",
      "[62,   399] loss: 0.171499\n",
      "[62,   499] loss: 0.206997\n",
      "[62,   599] loss: 0.131347\n",
      "[62,   699] loss: 0.307524\n",
      "[63,    99] loss: 0.107083\n",
      "[63,   199] loss: 0.134773\n",
      "[63,   299] loss: 0.112645\n",
      "[63,   399] loss: 0.147986\n",
      "[63,   499] loss: 0.263414\n",
      "[63,   599] loss: 0.108091\n",
      "[63,   699] loss: 0.431331\n",
      "[64,    99] loss: 0.195605\n",
      "[64,   199] loss: 0.200148\n",
      "[64,   299] loss: 0.161688\n",
      "[64,   399] loss: 0.317070\n",
      "[64,   499] loss: 0.205541\n",
      "[64,   599] loss: 0.153741\n",
      "[64,   699] loss: 0.146194\n",
      "[65,    99] loss: 0.127857\n",
      "[65,   199] loss: 0.086137\n",
      "[65,   299] loss: 0.104089\n",
      "[65,   399] loss: 0.088637\n",
      "[65,   499] loss: 0.148053\n",
      "[65,   599] loss: 0.054938\n",
      "[65,   699] loss: 0.070994\n",
      "[66,    99] loss: 0.080544\n",
      "[66,   199] loss: 0.069270\n",
      "[66,   299] loss: 0.093612\n",
      "[66,   399] loss: 0.090386\n",
      "[66,   499] loss: 0.192364\n",
      "[66,   599] loss: 0.055365\n",
      "[66,   699] loss: 0.023353\n",
      "[67,    99] loss: 0.072453\n",
      "[67,   199] loss: 0.222069\n",
      "[67,   299] loss: 0.325251\n",
      "[67,   399] loss: 0.169516\n",
      "[67,   499] loss: 0.311525\n",
      "[67,   599] loss: 0.153832\n",
      "[67,   699] loss: 0.320560\n",
      "[68,    99] loss: 0.067037\n",
      "[68,   199] loss: 0.309850\n",
      "[68,   299] loss: 0.079977\n",
      "[68,   399] loss: 0.274781\n",
      "[68,   499] loss: 0.229183\n",
      "[68,   599] loss: 0.119484\n",
      "[68,   699] loss: 0.287237\n",
      "[69,    99] loss: 0.115310\n",
      "[69,   199] loss: 0.144527\n",
      "[69,   299] loss: 0.089283\n",
      "[69,   399] loss: 0.155841\n",
      "[69,   499] loss: 0.208802\n",
      "[69,   599] loss: 0.373797\n",
      "[69,   699] loss: 0.796313\n",
      "[70,    99] loss: 0.210779\n",
      "[70,   199] loss: 0.114360\n",
      "[70,   299] loss: 0.064457\n",
      "[70,   399] loss: 0.092910\n",
      "[70,   499] loss: 0.381603\n",
      "[70,   599] loss: 0.358865\n",
      "[70,   699] loss: 0.233345\n",
      "[71,    99] loss: 0.100901\n",
      "[71,   199] loss: 0.126688\n",
      "[71,   299] loss: 0.117570\n",
      "[71,   399] loss: 0.176815\n",
      "[71,   499] loss: 0.140350\n",
      "[71,   599] loss: 0.089923\n",
      "[71,   699] loss: 0.093546\n",
      "[72,    99] loss: 0.033716\n",
      "[72,   199] loss: 0.182907\n",
      "[72,   299] loss: 0.403038\n",
      "[72,   399] loss: 0.086910\n",
      "[72,   499] loss: 0.378718\n",
      "[72,   599] loss: 0.133521\n",
      "[72,   699] loss: 0.099287\n",
      "[73,    99] loss: 0.544104\n",
      "[73,   199] loss: 0.188647\n",
      "[73,   299] loss: 0.093696\n",
      "[73,   399] loss: 0.174660\n",
      "[73,   499] loss: 0.141960\n",
      "[73,   599] loss: 0.116121\n",
      "[73,   699] loss: 0.192740\n",
      "[74,    99] loss: 0.076095\n",
      "[74,   199] loss: 0.131968\n",
      "[74,   299] loss: 0.085972\n",
      "[74,   399] loss: 0.160910\n",
      "[74,   499] loss: 0.215510\n",
      "[74,   599] loss: 0.095667\n",
      "[74,   699] loss: 0.152062\n",
      "[75,    99] loss: 0.103403\n",
      "[75,   199] loss: 0.124277\n",
      "[75,   299] loss: 0.237472\n",
      "[75,   399] loss: 0.172357\n",
      "[75,   499] loss: 0.130734\n",
      "[75,   599] loss: 0.117292\n",
      "[75,   699] loss: 0.151381\n",
      "[76,    99] loss: 0.071994\n",
      "[76,   199] loss: 0.122817\n",
      "[76,   299] loss: 0.085798\n",
      "[76,   399] loss: 0.151976\n",
      "[76,   499] loss: 0.142784\n",
      "[76,   599] loss: 0.101024\n",
      "[76,   699] loss: 0.276519\n",
      "[77,    99] loss: 0.152170\n",
      "[77,   199] loss: 0.113470\n",
      "[77,   299] loss: 0.168580\n",
      "[77,   399] loss: 0.090016\n",
      "[77,   499] loss: 0.121338\n",
      "[77,   599] loss: 0.125761\n",
      "[77,   699] loss: 0.142905\n",
      "[78,    99] loss: 0.204953\n",
      "[78,   199] loss: 0.140654\n",
      "[78,   299] loss: 0.103083\n",
      "[78,   399] loss: 0.424279\n",
      "[78,   499] loss: 0.449846\n",
      "[78,   599] loss: 0.176827\n",
      "[78,   699] loss: 0.160797\n",
      "[79,    99] loss: 0.083097\n",
      "[79,   199] loss: 0.195530\n",
      "[79,   299] loss: 0.087868\n",
      "[79,   399] loss: 0.136153\n",
      "[79,   499] loss: 0.222260\n",
      "[79,   599] loss: 0.090441\n",
      "[79,   699] loss: 0.130071\n",
      "[80,    99] loss: 0.181288\n",
      "[80,   199] loss: 0.131356\n",
      "[80,   299] loss: 0.072734\n",
      "[80,   399] loss: 0.154951\n",
      "[80,   499] loss: 0.152426\n",
      "[80,   599] loss: 0.125602\n",
      "[80,   699] loss: 0.174909\n",
      "[81,    99] loss: 0.221831\n",
      "[81,   199] loss: 0.146660\n",
      "[81,   299] loss: 0.063080\n",
      "[81,   399] loss: 0.122076\n",
      "[81,   499] loss: 0.386172\n",
      "[81,   599] loss: 0.098685\n",
      "[81,   699] loss: 0.063837\n",
      "[82,    99] loss: 0.024956\n",
      "[82,   199] loss: 0.097505\n",
      "[82,   299] loss: 0.050191\n",
      "[82,   399] loss: 0.092346\n",
      "[82,   499] loss: 0.286200\n",
      "[82,   599] loss: 0.046898\n",
      "[82,   699] loss: 0.294431\n",
      "[83,    99] loss: 0.177090\n",
      "[83,   199] loss: 0.097553\n",
      "[83,   299] loss: 0.111616\n",
      "[83,   399] loss: 0.106969\n",
      "[83,   499] loss: 0.128352\n",
      "[83,   599] loss: 0.086318\n",
      "[83,   699] loss: 0.225568\n",
      "[84,    99] loss: 0.221576\n",
      "[84,   199] loss: 0.092784\n",
      "[84,   299] loss: 0.113187\n",
      "[84,   399] loss: 0.166747\n",
      "[84,   499] loss: 0.245781\n",
      "[84,   599] loss: 0.034480\n",
      "[84,   699] loss: 0.058693\n",
      "[85,    99] loss: 0.523736\n",
      "[85,   199] loss: 0.174474\n",
      "[85,   299] loss: 0.116994\n",
      "[85,   399] loss: 0.165723\n",
      "[85,   499] loss: 0.277504\n",
      "[85,   599] loss: 0.079557\n",
      "[85,   699] loss: 0.126859\n",
      "[86,    99] loss: 0.318560\n",
      "[86,   199] loss: 0.180573\n",
      "[86,   299] loss: 0.083589\n",
      "[86,   399] loss: 0.092732\n",
      "[86,   499] loss: 0.138454\n",
      "[86,   599] loss: 0.024899\n",
      "[86,   699] loss: 0.062058\n",
      "[87,    99] loss: 0.233474\n",
      "[87,   199] loss: 0.173499\n",
      "[87,   299] loss: 0.074434\n",
      "[87,   399] loss: 0.096401\n",
      "[87,   499] loss: 0.223179\n",
      "[87,   599] loss: 0.038240\n",
      "[87,   699] loss: 0.076757\n",
      "[88,    99] loss: 0.193765\n",
      "[88,   199] loss: 0.135312\n",
      "[88,   299] loss: 0.107141\n",
      "[88,   399] loss: 0.091184\n",
      "[88,   499] loss: 0.162919\n",
      "[88,   599] loss: 0.206744\n",
      "[88,   699] loss: 0.061004\n",
      "[89,    99] loss: 0.057331\n",
      "[89,   199] loss: 0.144146\n",
      "[89,   299] loss: 0.058645\n",
      "[89,   399] loss: 0.106841\n",
      "[89,   499] loss: 0.185296\n",
      "[89,   599] loss: 0.059910\n",
      "[89,   699] loss: 0.054466\n",
      "[90,    99] loss: 0.166684\n",
      "[90,   199] loss: 0.078394\n",
      "[90,   299] loss: 0.111755\n",
      "[90,   399] loss: 0.093925\n",
      "[90,   499] loss: 0.121733\n",
      "[90,   599] loss: 0.051047\n",
      "[90,   699] loss: 0.110151\n",
      "[91,    99] loss: 0.264098\n",
      "[91,   199] loss: 0.203336\n",
      "[91,   299] loss: 0.132333\n",
      "[91,   399] loss: 0.096979\n",
      "[91,   499] loss: 0.159993\n",
      "[91,   599] loss: 0.061404\n",
      "[91,   699] loss: 0.048681\n",
      "[92,    99] loss: 0.108067\n",
      "[92,   199] loss: 0.125361\n",
      "[92,   299] loss: 0.100545\n",
      "[92,   399] loss: 0.138048\n",
      "[92,   499] loss: 0.247268\n",
      "[92,   599] loss: 0.053510\n",
      "[92,   699] loss: 0.277840\n",
      "[93,    99] loss: 0.358717\n",
      "[93,   199] loss: 0.643185\n",
      "[93,   299] loss: 0.181425\n",
      "[93,   399] loss: 0.262221\n",
      "[93,   499] loss: 0.306712\n",
      "[93,   599] loss: 0.141270\n",
      "[93,   699] loss: 0.135356\n",
      "[94,    99] loss: 0.180227\n",
      "[94,   199] loss: 0.180529\n",
      "[94,   299] loss: 0.125888\n",
      "[94,   399] loss: 0.113968\n",
      "[94,   499] loss: 0.147695\n",
      "[94,   599] loss: 0.048337\n",
      "[94,   699] loss: 0.191308\n",
      "[95,    99] loss: 0.146847\n",
      "[95,   199] loss: 0.166741\n",
      "[95,   299] loss: 0.085267\n",
      "[95,   399] loss: 0.119351\n",
      "[95,   499] loss: 0.116178\n",
      "[95,   599] loss: 0.216754\n",
      "[95,   699] loss: 0.027888\n",
      "[96,    99] loss: 0.021703\n",
      "[96,   199] loss: 0.122819\n",
      "[96,   299] loss: 0.146124\n",
      "[96,   399] loss: 0.094763\n",
      "[96,   499] loss: 0.517362\n",
      "[96,   599] loss: 0.019609\n",
      "[96,   699] loss: 0.056821\n",
      "[97,    99] loss: 0.420431\n",
      "[97,   199] loss: 0.145556\n",
      "[97,   299] loss: 0.118732\n",
      "[97,   399] loss: 0.127573\n",
      "[97,   499] loss: 0.122949\n",
      "[97,   599] loss: 0.059166\n",
      "[97,   699] loss: 0.064061\n",
      "[98,    99] loss: 0.073894\n",
      "[98,   199] loss: 0.103886\n",
      "[98,   299] loss: 0.050603\n",
      "[98,   399] loss: 0.092532\n",
      "[98,   499] loss: 0.270744\n",
      "[98,   599] loss: 0.082991\n",
      "[98,   699] loss: 0.053091\n",
      "[99,    99] loss: 0.030250\n",
      "[99,   199] loss: 0.203525\n",
      "[99,   299] loss: 0.564245\n",
      "[99,   399] loss: 0.095810\n",
      "[99,   499] loss: 0.174253\n",
      "[99,   599] loss: 0.035225\n",
      "[99,   699] loss: 0.026261\n",
      "[100,    99] loss: 0.014210\n",
      "[100,   199] loss: 0.130164\n",
      "[100,   299] loss: 0.228240\n",
      "[100,   399] loss: 0.094515\n",
      "[100,   499] loss: 0.208751\n",
      "[100,   599] loss: 0.367168\n",
      "[100,   699] loss: 0.011622\n",
      "Finished Training\n",
      "[1,    99] loss: 0.699452\n",
      "[1,   199] loss: 0.687070\n",
      "[1,   299] loss: 0.665290\n",
      "[1,   399] loss: 0.635929\n",
      "[1,   499] loss: 0.655163\n",
      "[1,   599] loss: 0.665004\n",
      "[1,   699] loss: 0.624494\n",
      "[2,    99] loss: 0.557970\n",
      "[2,   199] loss: 0.568292\n",
      "[2,   299] loss: 0.572337\n",
      "[2,   399] loss: 0.540689\n",
      "[2,   499] loss: 0.588616\n",
      "[2,   599] loss: 0.563791\n",
      "[2,   699] loss: 0.547196\n",
      "[3,    99] loss: 0.464515\n",
      "[3,   199] loss: 0.471279\n",
      "[3,   299] loss: 0.448142\n",
      "[3,   399] loss: 0.437139\n",
      "[3,   499] loss: 0.518834\n",
      "[3,   599] loss: 0.474261\n",
      "[3,   699] loss: 0.473910\n",
      "[4,    99] loss: 0.379346\n",
      "[4,   199] loss: 0.397498\n",
      "[4,   299] loss: 0.361926\n",
      "[4,   399] loss: 0.337694\n",
      "[4,   499] loss: 0.440966\n",
      "[4,   599] loss: 0.440449\n",
      "[4,   699] loss: 0.402443\n",
      "[5,    99] loss: 0.310346\n",
      "[5,   199] loss: 0.329277\n",
      "[5,   299] loss: 0.305100\n",
      "[5,   399] loss: 0.274988\n",
      "[5,   499] loss: 0.389807\n",
      "[5,   599] loss: 0.384947\n",
      "[5,   699] loss: 0.334639\n",
      "[6,    99] loss: 0.258946\n",
      "[6,   199] loss: 0.278152\n",
      "[6,   299] loss: 0.231801\n",
      "[6,   399] loss: 0.223528\n",
      "[6,   499] loss: 0.312157\n",
      "[6,   599] loss: 0.330227\n",
      "[6,   699] loss: 0.290619\n",
      "[7,    99] loss: 0.219720\n",
      "[7,   199] loss: 0.238558\n",
      "[7,   299] loss: 0.187530\n",
      "[7,   399] loss: 0.184355\n",
      "[7,   499] loss: 0.256462\n",
      "[7,   599] loss: 0.278204\n",
      "[7,   699] loss: 0.282410\n",
      "[8,    99] loss: 0.188436\n",
      "[8,   199] loss: 0.213416\n",
      "[8,   299] loss: 0.165045\n",
      "[8,   399] loss: 0.153635\n",
      "[8,   499] loss: 0.228045\n",
      "[8,   599] loss: 0.242173\n",
      "[8,   699] loss: 0.277104\n",
      "[9,    99] loss: 0.168150\n",
      "[9,   199] loss: 0.178971\n",
      "[9,   299] loss: 0.127188\n",
      "[9,   399] loss: 0.136280\n",
      "[9,   499] loss: 0.234323\n",
      "[9,   599] loss: 0.203527\n",
      "[9,   699] loss: 0.260016\n",
      "[10,    99] loss: 0.137545\n",
      "[10,   199] loss: 0.170963\n",
      "[10,   299] loss: 0.105469\n",
      "[10,   399] loss: 0.114449\n",
      "[10,   499] loss: 0.225877\n",
      "[10,   599] loss: 0.230129\n",
      "[10,   699] loss: 0.245639\n",
      "[11,    99] loss: 0.120389\n",
      "[11,   199] loss: 0.167932\n",
      "[11,   299] loss: 0.092481\n",
      "[11,   399] loss: 0.109073\n",
      "[11,   499] loss: 0.205349\n",
      "[11,   599] loss: 0.181604\n",
      "[11,   699] loss: 0.261509\n",
      "[12,    99] loss: 0.121284\n",
      "[12,   199] loss: 0.139671\n",
      "[12,   299] loss: 0.090295\n",
      "[12,   399] loss: 0.094474\n",
      "[12,   499] loss: 0.196342\n",
      "[12,   599] loss: 0.182152\n",
      "[12,   699] loss: 0.177713\n",
      "[13,    99] loss: 0.106103\n",
      "[13,   199] loss: 0.113197\n",
      "[13,   299] loss: 0.072275\n",
      "[13,   399] loss: 0.074018\n",
      "[13,   499] loss: 0.174479\n",
      "[13,   599] loss: 0.152632\n",
      "[13,   699] loss: 0.216226\n",
      "[14,    99] loss: 0.084983\n",
      "[14,   199] loss: 0.110932\n",
      "[14,   299] loss: 0.062542\n",
      "[14,   399] loss: 0.073200\n",
      "[14,   499] loss: 0.151956\n",
      "[14,   599] loss: 0.106009\n",
      "[14,   699] loss: 0.153472\n",
      "[15,    99] loss: 0.099072\n",
      "[15,   199] loss: 0.082721\n",
      "[15,   299] loss: 0.068176\n",
      "[15,   399] loss: 0.083269\n",
      "[15,   499] loss: 0.132368\n",
      "[15,   599] loss: 0.133018\n",
      "[15,   699] loss: 0.181289\n",
      "[16,    99] loss: 0.087930\n",
      "[16,   199] loss: 0.103962\n",
      "[16,   299] loss: 0.050872\n",
      "[16,   399] loss: 0.070475\n",
      "[16,   499] loss: 0.150018\n",
      "[16,   599] loss: 0.144298\n",
      "[16,   699] loss: 0.342245\n",
      "[17,    99] loss: 0.098907\n",
      "[17,   199] loss: 0.108811\n",
      "[17,   299] loss: 0.092638\n",
      "[17,   399] loss: 0.070228\n",
      "[17,   499] loss: 0.176338\n",
      "[17,   599] loss: 0.125707\n",
      "[17,   699] loss: 0.086014\n",
      "[18,    99] loss: 0.064762\n",
      "[18,   199] loss: 0.071424\n",
      "[18,   299] loss: 0.048394\n",
      "[18,   399] loss: 0.037470\n",
      "[18,   499] loss: 0.133666\n",
      "[18,   599] loss: 0.093933\n",
      "[18,   699] loss: 0.101258\n",
      "[19,    99] loss: 0.063369\n",
      "[19,   199] loss: 0.085391\n",
      "[19,   299] loss: 0.081301\n",
      "[19,   399] loss: 0.047883\n",
      "[19,   499] loss: 0.159392\n",
      "[19,   599] loss: 0.073623\n",
      "[19,   699] loss: 0.142230\n",
      "[20,    99] loss: 0.057117\n",
      "[20,   199] loss: 0.059539\n",
      "[20,   299] loss: 0.050142\n",
      "[20,   399] loss: 0.050832\n",
      "[20,   499] loss: 0.102557\n",
      "[20,   599] loss: 0.091774\n",
      "[20,   699] loss: 0.172827\n",
      "[21,    99] loss: 0.058395\n",
      "[21,   199] loss: 0.068606\n",
      "[21,   299] loss: 0.054637\n",
      "[21,   399] loss: 0.056196\n",
      "[21,   499] loss: 0.106709\n",
      "[21,   599] loss: 0.185908\n",
      "[21,   699] loss: 0.083290\n",
      "[22,    99] loss: 0.073495\n",
      "[22,   199] loss: 0.070935\n",
      "[22,   299] loss: 0.041824\n",
      "[22,   399] loss: 0.038623\n",
      "[22,   499] loss: 0.094520\n",
      "[22,   599] loss: 0.058001\n",
      "[22,   699] loss: 0.040575\n",
      "[23,    99] loss: 0.045206\n",
      "[23,   199] loss: 0.081663\n",
      "[23,   299] loss: 0.034505\n",
      "[23,   399] loss: 0.034313\n",
      "[23,   499] loss: 0.158624\n",
      "[23,   599] loss: 0.113266\n",
      "[23,   699] loss: 0.132700\n",
      "[24,    99] loss: 0.055414\n",
      "[24,   199] loss: 0.083647\n",
      "[24,   299] loss: 0.071092\n",
      "[24,   399] loss: 0.044568\n",
      "[24,   499] loss: 0.114776\n",
      "[24,   599] loss: 0.094907\n",
      "[24,   699] loss: 0.050846\n",
      "[25,    99] loss: 0.044483\n",
      "[25,   199] loss: 0.061251\n",
      "[25,   299] loss: 0.024898\n",
      "[25,   399] loss: 0.035468\n",
      "[25,   499] loss: 0.110986\n",
      "[25,   599] loss: 0.083468\n",
      "[25,   699] loss: 0.067502\n",
      "[26,    99] loss: 0.054988\n",
      "[26,   199] loss: 0.085196\n",
      "[26,   299] loss: 0.029468\n",
      "[26,   399] loss: 0.045860\n",
      "[26,   499] loss: 0.083524\n",
      "[26,   599] loss: 0.069016\n",
      "[26,   699] loss: 0.031347\n",
      "[27,    99] loss: 0.041864\n",
      "[27,   199] loss: 0.059372\n",
      "[27,   299] loss: 0.035133\n",
      "[27,   399] loss: 0.027966\n",
      "[27,   499] loss: 0.091706\n",
      "[27,   599] loss: 0.082654\n",
      "[27,   699] loss: 0.177364\n",
      "[28,    99] loss: 0.044865\n",
      "[28,   199] loss: 0.064636\n",
      "[28,   299] loss: 0.056755\n",
      "[28,   399] loss: 0.076412\n",
      "[28,   499] loss: 0.146464\n",
      "[28,   599] loss: 0.113415\n",
      "[28,   699] loss: 0.075887\n",
      "[29,    99] loss: 0.079296\n",
      "[29,   199] loss: 0.092530\n",
      "[29,   299] loss: 0.044207\n",
      "[29,   399] loss: 0.040373\n",
      "[29,   499] loss: 0.083248\n",
      "[29,   599] loss: 0.049080\n",
      "[29,   699] loss: 0.014621\n",
      "[30,    99] loss: 0.037421\n",
      "[30,   199] loss: 0.034767\n",
      "[30,   299] loss: 0.020290\n",
      "[30,   399] loss: 0.022749\n",
      "[30,   499] loss: 0.086391\n",
      "[30,   599] loss: 0.086005\n",
      "[30,   699] loss: 0.186756\n",
      "[31,    99] loss: 0.064347\n",
      "[31,   199] loss: 0.110832\n",
      "[31,   299] loss: 0.036801\n",
      "[31,   399] loss: 0.023687\n",
      "[31,   499] loss: 0.076146\n",
      "[31,   599] loss: 0.050327\n",
      "[31,   699] loss: 0.023279\n",
      "[32,    99] loss: 0.028434\n",
      "[32,   199] loss: 0.020473\n",
      "[32,   299] loss: 0.033634\n",
      "[32,   399] loss: 0.025303\n",
      "[32,   499] loss: 0.094152\n",
      "[32,   599] loss: 0.021844\n",
      "[32,   699] loss: 0.020190\n",
      "[33,    99] loss: 0.039247\n",
      "[33,   199] loss: 0.047359\n",
      "[33,   299] loss: 0.010631\n",
      "[33,   399] loss: 0.019227\n",
      "[33,   499] loss: 0.094119\n",
      "[33,   599] loss: 0.128657\n",
      "[33,   699] loss: 0.313329\n",
      "[34,    99] loss: 0.051653\n",
      "[34,   199] loss: 0.053997\n",
      "[34,   299] loss: 0.047146\n",
      "[34,   399] loss: 0.064756\n",
      "[34,   499] loss: 0.115251\n",
      "[34,   599] loss: 0.145829\n",
      "[34,   699] loss: 0.022942\n",
      "[35,    99] loss: 0.023429\n",
      "[35,   199] loss: 0.038964\n",
      "[35,   299] loss: 0.045998\n",
      "[35,   399] loss: 0.025939\n",
      "[35,   499] loss: 0.164386\n",
      "[35,   599] loss: 0.141775\n",
      "[35,   699] loss: 0.026711\n",
      "[36,    99] loss: 0.043718\n",
      "[36,   199] loss: 0.056641\n",
      "[36,   299] loss: 0.056721\n",
      "[36,   399] loss: 0.073714\n",
      "[36,   499] loss: 0.064254\n",
      "[36,   599] loss: 0.054292\n",
      "[36,   699] loss: 0.023907\n",
      "[37,    99] loss: 0.018198\n",
      "[37,   199] loss: 0.043764\n",
      "[37,   299] loss: 0.029512\n",
      "[37,   399] loss: 0.019471\n",
      "[37,   499] loss: 0.072321\n",
      "[37,   599] loss: 0.016136\n",
      "[37,   699] loss: 0.011686\n",
      "[38,    99] loss: 0.034343\n",
      "[38,   199] loss: 0.014616\n",
      "[38,   299] loss: 0.021120\n",
      "[38,   399] loss: 0.018708\n",
      "[38,   499] loss: 0.072366\n",
      "[38,   599] loss: 0.012148\n",
      "[38,   699] loss: 0.008001\n",
      "[39,    99] loss: 0.026074\n",
      "[39,   199] loss: 0.015370\n",
      "[39,   299] loss: 0.016969\n",
      "[39,   399] loss: 0.028365\n",
      "[39,   499] loss: 0.098612\n",
      "[39,   599] loss: 0.207782\n",
      "[39,   699] loss: 0.018920\n",
      "[40,    99] loss: 0.044998\n",
      "[40,   199] loss: 0.058712\n",
      "[40,   299] loss: 0.181802\n",
      "[40,   399] loss: 0.063980\n",
      "[40,   499] loss: 0.117519\n",
      "[40,   599] loss: 0.123505\n",
      "[40,   699] loss: 0.023676\n",
      "[41,    99] loss: 0.019026\n",
      "[41,   199] loss: 0.020535\n",
      "[41,   299] loss: 0.034481\n",
      "[41,   399] loss: 0.073498\n",
      "[41,   499] loss: 0.098970\n",
      "[41,   599] loss: 0.078322\n",
      "[41,   699] loss: 0.097694\n",
      "[42,    99] loss: 0.008612\n",
      "[42,   199] loss: 0.028335\n",
      "[42,   299] loss: 0.049293\n",
      "[42,   399] loss: 0.017004\n",
      "[42,   499] loss: 0.068485\n",
      "[42,   599] loss: 0.035462\n",
      "[42,   699] loss: 0.007285\n",
      "[43,    99] loss: 0.017308\n",
      "[43,   199] loss: 0.030981\n",
      "[43,   299] loss: 0.023747\n",
      "[43,   399] loss: 0.014107\n",
      "[43,   499] loss: 0.169676\n",
      "[43,   599] loss: 0.056006\n",
      "[43,   699] loss: 0.032989\n",
      "[44,    99] loss: 0.011968\n",
      "[44,   199] loss: 0.130418\n",
      "[44,   299] loss: 0.028456\n",
      "[44,   399] loss: 0.028242\n",
      "[44,   499] loss: 0.051497\n",
      "[44,   599] loss: 0.085761\n",
      "[44,   699] loss: 0.045083\n",
      "[45,    99] loss: 0.007298\n",
      "[45,   199] loss: 0.169801\n",
      "[45,   299] loss: 0.048570\n",
      "[45,   399] loss: 0.110138\n",
      "[45,   499] loss: 0.066169\n",
      "[45,   599] loss: 0.164976\n",
      "[45,   699] loss: 0.017784\n",
      "[46,    99] loss: 0.056641\n",
      "[46,   199] loss: 0.015070\n",
      "[46,   299] loss: 0.007311\n",
      "[46,   399] loss: 0.017196\n",
      "[46,   499] loss: 0.023230\n",
      "[46,   599] loss: 0.035010\n",
      "[46,   699] loss: 0.037545\n",
      "[47,    99] loss: 0.038774\n",
      "[47,   199] loss: 0.010128\n",
      "[47,   299] loss: 0.005484\n",
      "[47,   399] loss: 0.017539\n",
      "[47,   499] loss: 0.032855\n",
      "[47,   599] loss: 0.007762\n",
      "[47,   699] loss: 0.005954\n",
      "[48,    99] loss: 0.074456\n",
      "[48,   199] loss: 0.004280\n",
      "[48,   299] loss: 0.004820\n",
      "[48,   399] loss: 0.008677\n",
      "[48,   499] loss: 0.045174\n",
      "[48,   599] loss: 0.023738\n",
      "[48,   699] loss: 0.046290\n",
      "[49,    99] loss: 0.080064\n",
      "[49,   199] loss: 0.083202\n",
      "[49,   299] loss: 0.058248\n",
      "[49,   399] loss: 0.029855\n",
      "[49,   499] loss: 0.093090\n",
      "[49,   599] loss: 0.104426\n",
      "[49,   699] loss: 0.050671\n",
      "[50,    99] loss: 0.031904\n",
      "[50,   199] loss: 0.065906\n",
      "[50,   299] loss: 0.020255\n",
      "[50,   399] loss: 0.010132\n",
      "[50,   499] loss: 0.044983\n",
      "[50,   599] loss: 0.040945\n",
      "[50,   699] loss: 0.004027\n",
      "[51,    99] loss: 0.016780\n",
      "[51,   199] loss: 0.080638\n",
      "[51,   299] loss: 0.049166\n",
      "[51,   399] loss: 0.022609\n",
      "[51,   499] loss: 0.050057\n",
      "[51,   599] loss: 0.007860\n",
      "[51,   699] loss: 0.004334\n",
      "[52,    99] loss: 0.015851\n",
      "[52,   199] loss: 0.010733\n",
      "[52,   299] loss: 0.004848\n",
      "[52,   399] loss: 0.005867\n",
      "[52,   499] loss: 0.022428\n",
      "[52,   599] loss: 0.042363\n",
      "[52,   699] loss: 0.060451\n",
      "[53,    99] loss: 0.037352\n",
      "[53,   199] loss: 0.011661\n",
      "[53,   299] loss: 0.032354\n",
      "[53,   399] loss: 0.134830\n",
      "[53,   499] loss: 0.089587\n",
      "[53,   599] loss: 0.095753\n",
      "[53,   699] loss: 0.089193\n",
      "[54,    99] loss: 0.039726\n",
      "[54,   199] loss: 0.125819\n",
      "[54,   299] loss: 0.020375\n",
      "[54,   399] loss: 0.016259\n",
      "[54,   499] loss: 0.036213\n",
      "[54,   599] loss: 0.018665\n",
      "[54,   699] loss: 0.006768\n",
      "[55,    99] loss: 0.023146\n",
      "[55,   199] loss: 0.057242\n",
      "[55,   299] loss: 0.026279\n",
      "[55,   399] loss: 0.012252\n",
      "[55,   499] loss: 0.041354\n",
      "[55,   599] loss: 0.040494\n",
      "[55,   699] loss: 0.004177\n",
      "[56,    99] loss: 0.016697\n",
      "[56,   199] loss: 0.024946\n",
      "[56,   299] loss: 0.004629\n",
      "[56,   399] loss: 0.004357\n",
      "[56,   499] loss: 0.014456\n",
      "[56,   599] loss: 0.006687\n",
      "[56,   699] loss: 0.002592\n",
      "[57,    99] loss: 0.022492\n",
      "[57,   199] loss: 0.002243\n",
      "[57,   299] loss: 0.002410\n",
      "[57,   399] loss: 0.002657\n",
      "[57,   499] loss: 0.022386\n",
      "[57,   599] loss: 0.046963\n",
      "[57,   699] loss: 0.002953\n",
      "[58,    99] loss: 0.014147\n",
      "[58,   199] loss: 0.017519\n",
      "[58,   299] loss: 0.005929\n",
      "[58,   399] loss: 0.020916\n",
      "[58,   499] loss: 0.032766\n",
      "[58,   599] loss: 0.115572\n",
      "[58,   699] loss: 0.055532\n",
      "[59,    99] loss: 0.032550\n",
      "[59,   199] loss: 0.029896\n",
      "[59,   299] loss: 0.049507\n",
      "[59,   399] loss: 0.189612\n",
      "[59,   499] loss: 0.157097\n",
      "[59,   599] loss: 0.094675\n",
      "[59,   699] loss: 0.012977\n",
      "[60,    99] loss: 0.019316\n",
      "[60,   199] loss: 0.016081\n",
      "[60,   299] loss: 0.029231\n",
      "[60,   399] loss: 0.027418\n",
      "[60,   499] loss: 0.028959\n",
      "[60,   599] loss: 0.014027\n",
      "[60,   699] loss: 0.005411\n",
      "[61,    99] loss: 0.021288\n",
      "[61,   199] loss: 0.009464\n",
      "[61,   299] loss: 0.011028\n",
      "[61,   399] loss: 0.002923\n",
      "[61,   499] loss: 0.038634\n",
      "[61,   599] loss: 0.007465\n",
      "[61,   699] loss: 0.015142\n",
      "[62,    99] loss: 0.027579\n",
      "[62,   199] loss: 0.004798\n",
      "[62,   299] loss: 0.002205\n",
      "[62,   399] loss: 0.001742\n",
      "[62,   499] loss: 0.015327\n",
      "[62,   599] loss: 0.017569\n",
      "[62,   699] loss: 0.007688\n",
      "[63,    99] loss: 0.045828\n",
      "[63,   199] loss: 0.006983\n",
      "[63,   299] loss: 0.008915\n",
      "[63,   399] loss: 0.003562\n",
      "[63,   499] loss: 0.024436\n",
      "[63,   599] loss: 0.039430\n",
      "[63,   699] loss: 0.002064\n",
      "[64,    99] loss: 0.026924\n",
      "[64,   199] loss: 0.022653\n",
      "[64,   299] loss: 0.019958\n",
      "[64,   399] loss: 0.019202\n",
      "[64,   499] loss: 0.046376\n",
      "[64,   599] loss: 0.057004\n",
      "[64,   699] loss: 0.015113\n",
      "[65,    99] loss: 0.009720\n",
      "[65,   199] loss: 0.016484\n",
      "[65,   299] loss: 0.012933\n",
      "[65,   399] loss: 0.241934\n",
      "[65,   499] loss: 0.028503\n",
      "[65,   599] loss: 0.094981\n",
      "[65,   699] loss: 0.013555\n",
      "[66,    99] loss: 0.020517\n",
      "[66,   199] loss: 0.027435\n",
      "[66,   299] loss: 0.093596\n",
      "[66,   399] loss: 0.016011\n",
      "[66,   499] loss: 0.043049\n",
      "[66,   599] loss: 0.021622\n",
      "[66,   699] loss: 0.003839\n",
      "[67,    99] loss: 0.020088\n",
      "[67,   199] loss: 0.016524\n",
      "[67,   299] loss: 0.014737\n",
      "[67,   399] loss: 0.003830\n",
      "[67,   499] loss: 0.006960\n",
      "[67,   599] loss: 0.023763\n",
      "[67,   699] loss: 0.002726\n",
      "[68,    99] loss: 0.003845\n",
      "[68,   199] loss: 0.007045\n",
      "[68,   299] loss: 0.100933\n",
      "[68,   399] loss: 0.004802\n",
      "[68,   499] loss: 0.038331\n",
      "[68,   599] loss: 0.044480\n",
      "[68,   699] loss: 0.004929\n",
      "[69,    99] loss: 0.006050\n",
      "[69,   199] loss: 0.002949\n",
      "[69,   299] loss: 0.008180\n",
      "[69,   399] loss: 0.001336\n",
      "[69,   499] loss: 0.021770\n",
      "[69,   599] loss: 0.075869\n",
      "[69,   699] loss: 0.220037\n",
      "[70,    99] loss: 0.182671\n",
      "[70,   199] loss: 0.027211\n",
      "[70,   299] loss: 0.021713\n",
      "[70,   399] loss: 0.006054\n",
      "[70,   499] loss: 0.023044\n",
      "[70,   599] loss: 0.002031\n",
      "[70,   699] loss: 0.004689\n",
      "[71,    99] loss: 0.040252\n",
      "[71,   199] loss: 0.006843\n",
      "[71,   299] loss: 0.002350\n",
      "[71,   399] loss: 0.005122\n",
      "[71,   499] loss: 0.011830\n",
      "[71,   599] loss: 0.001005\n",
      "[71,   699] loss: 0.001949\n",
      "[72,    99] loss: 0.006747\n",
      "[72,   199] loss: 0.006089\n",
      "[72,   299] loss: 0.001464\n",
      "[72,   399] loss: 0.002125\n",
      "[72,   499] loss: 0.014521\n",
      "[72,   599] loss: 0.001179\n",
      "[72,   699] loss: 0.001064\n",
      "[73,    99] loss: 0.014887\n",
      "[73,   199] loss: 0.007816\n",
      "[73,   299] loss: 0.082342\n",
      "[73,   399] loss: 0.072028\n",
      "[73,   499] loss: 0.191188\n",
      "[73,   599] loss: 0.178091\n",
      "[73,   699] loss: 0.024186\n",
      "[74,    99] loss: 0.006551\n",
      "[74,   199] loss: 0.118757\n",
      "[74,   299] loss: 0.010471\n",
      "[74,   399] loss: 0.072784\n",
      "[74,   499] loss: 0.037722\n",
      "[74,   599] loss: 0.014385\n",
      "[74,   699] loss: 0.011796\n",
      "[75,    99] loss: 0.008296\n",
      "[75,   199] loss: 0.002807\n",
      "[75,   299] loss: 0.041251\n",
      "[75,   399] loss: 0.012387\n",
      "[75,   499] loss: 0.072417\n",
      "[75,   599] loss: 0.002318\n",
      "[75,   699] loss: 0.001643\n",
      "[76,    99] loss: 0.004779\n",
      "[76,   199] loss: 0.004773\n",
      "[76,   299] loss: 0.016314\n",
      "[76,   399] loss: 0.006341\n",
      "[76,   499] loss: 0.024555\n",
      "[76,   599] loss: 0.003174\n",
      "[76,   699] loss: 0.002096\n",
      "[77,    99] loss: 0.008547\n",
      "[77,   199] loss: 0.004395\n",
      "[77,   299] loss: 0.003284\n",
      "[77,   399] loss: 0.002385\n",
      "[77,   499] loss: 0.008839\n",
      "[77,   599] loss: 0.015346\n",
      "[77,   699] loss: 0.009550\n",
      "[78,    99] loss: 0.065634\n",
      "[78,   199] loss: 0.018798\n",
      "[78,   299] loss: 0.128230\n",
      "[78,   399] loss: 0.031834\n",
      "[78,   499] loss: 0.033496\n",
      "[78,   599] loss: 0.055003\n",
      "[78,   699] loss: 0.061993\n",
      "[79,    99] loss: 0.004524\n",
      "[79,   199] loss: 0.083387\n",
      "[79,   299] loss: 0.013604\n",
      "[79,   399] loss: 0.071624\n",
      "[79,   499] loss: 0.026775\n",
      "[79,   599] loss: 0.077074\n",
      "[79,   699] loss: 0.092753\n",
      "[80,    99] loss: 0.005755\n",
      "[80,   199] loss: 0.004064\n",
      "[80,   299] loss: 0.007280\n",
      "[80,   399] loss: 0.059913\n",
      "[80,   499] loss: 0.007785\n",
      "[80,   599] loss: 0.005605\n",
      "[80,   699] loss: 0.001820\n",
      "[81,    99] loss: 0.006166\n",
      "[81,   199] loss: 0.002374\n",
      "[81,   299] loss: 0.003738\n",
      "[81,   399] loss: 0.001189\n",
      "[81,   499] loss: 0.003959\n",
      "[81,   599] loss: 0.004648\n",
      "[81,   699] loss: 0.001148\n",
      "[82,    99] loss: 0.012107\n",
      "[82,   199] loss: 0.003995\n",
      "[82,   299] loss: 0.002907\n",
      "[82,   399] loss: 0.001360\n",
      "[82,   499] loss: 0.009125\n",
      "[82,   599] loss: 0.085805\n",
      "[82,   699] loss: 0.094949\n",
      "[83,    99] loss: 0.017680\n",
      "[83,   199] loss: 0.018616\n",
      "[83,   299] loss: 0.010883\n",
      "[83,   399] loss: 0.009377\n",
      "[83,   499] loss: 0.040296\n",
      "[83,   599] loss: 0.057010\n",
      "[83,   699] loss: 0.023469\n",
      "[84,    99] loss: 0.024796\n",
      "[84,   199] loss: 0.092876\n",
      "[84,   299] loss: 0.239358\n",
      "[84,   399] loss: 0.079182\n",
      "[84,   499] loss: 0.054808\n",
      "[84,   599] loss: 0.134619\n",
      "[84,   699] loss: 0.004129\n",
      "[85,    99] loss: 0.002738\n",
      "[85,   199] loss: 0.030058\n",
      "[85,   299] loss: 0.014851\n",
      "[85,   399] loss: 0.004070\n",
      "[85,   499] loss: 0.010587\n",
      "[85,   599] loss: 0.010224\n",
      "[85,   699] loss: 0.002036\n",
      "[86,    99] loss: 0.007571\n",
      "[86,   199] loss: 0.003350\n",
      "[86,   299] loss: 0.002165\n",
      "[86,   399] loss: 0.001316\n",
      "[86,   499] loss: 0.002444\n",
      "[86,   599] loss: 0.006536\n",
      "[86,   699] loss: 0.001046\n",
      "[87,    99] loss: 0.010946\n",
      "[87,   199] loss: 0.002678\n",
      "[87,   299] loss: 0.001196\n",
      "[87,   399] loss: 0.000899\n",
      "[87,   499] loss: 0.002859\n",
      "[87,   599] loss: 0.017544\n",
      "[87,   699] loss: 0.001503\n",
      "[88,    99] loss: 0.017623\n",
      "[88,   199] loss: 0.002790\n",
      "[88,   299] loss: 0.001932\n",
      "[88,   399] loss: 0.001032\n",
      "[88,   499] loss: 0.002394\n",
      "[88,   599] loss: 0.013328\n",
      "[88,   699] loss: 0.001251\n",
      "[89,    99] loss: 0.013474\n",
      "[89,   199] loss: 0.001089\n",
      "[89,   299] loss: 0.000731\n",
      "[89,   399] loss: 0.000656\n",
      "[89,   499] loss: 0.001821\n",
      "[89,   599] loss: 0.018212\n",
      "[89,   699] loss: 0.000690\n",
      "[90,    99] loss: 0.005116\n",
      "[90,   199] loss: 0.002291\n",
      "[90,   299] loss: 0.001675\n",
      "[90,   399] loss: 0.023091\n",
      "[90,   499] loss: 0.027124\n",
      "[90,   599] loss: 0.155861\n",
      "[90,   699] loss: 0.148174\n",
      "[91,    99] loss: 0.015308\n",
      "[91,   199] loss: 0.033080\n",
      "[91,   299] loss: 0.128832\n",
      "[91,   399] loss: 0.226893\n",
      "[91,   499] loss: 0.132777\n",
      "[91,   599] loss: 0.134778\n",
      "[91,   699] loss: 0.020271\n",
      "[92,    99] loss: 0.007843\n",
      "[92,   199] loss: 0.123386\n",
      "[92,   299] loss: 0.008911\n",
      "[92,   399] loss: 0.010623\n",
      "[92,   499] loss: 0.017949\n",
      "[92,   599] loss: 0.014009\n",
      "[92,   699] loss: 0.001843\n",
      "[93,    99] loss: 0.007331\n",
      "[93,   199] loss: 0.011464\n",
      "[93,   299] loss: 0.001350\n",
      "[93,   399] loss: 0.000716\n",
      "[93,   499] loss: 0.005108\n",
      "[93,   599] loss: 0.014262\n",
      "[93,   699] loss: 0.001505\n",
      "[94,    99] loss: 0.006874\n",
      "[94,   199] loss: 0.001769\n",
      "[94,   299] loss: 0.000958\n",
      "[94,   399] loss: 0.000694\n",
      "[94,   499] loss: 0.004064\n",
      "[94,   599] loss: 0.002132\n",
      "[94,   699] loss: 0.000747\n",
      "[95,    99] loss: 0.002427\n",
      "[95,   199] loss: 0.003657\n",
      "[95,   299] loss: 0.000689\n",
      "[95,   399] loss: 0.000458\n",
      "[95,   499] loss: 0.006494\n",
      "[95,   599] loss: 0.005683\n",
      "[95,   699] loss: 0.001698\n",
      "[96,    99] loss: 0.014122\n",
      "[96,   199] loss: 0.001252\n",
      "[96,   299] loss: 0.000825\n",
      "[96,   399] loss: 0.000539\n",
      "[96,   499] loss: 0.016774\n",
      "[96,   599] loss: 0.007734\n",
      "[96,   699] loss: 0.001300\n",
      "[97,    99] loss: 0.022216\n",
      "[97,   199] loss: 0.002242\n",
      "[97,   299] loss: 0.001444\n",
      "[97,   399] loss: 0.000676\n",
      "[97,   499] loss: 0.005635\n",
      "[97,   599] loss: 0.036474\n",
      "[97,   699] loss: 0.213049\n",
      "[98,    99] loss: 0.030802\n",
      "[98,   199] loss: 0.013732\n",
      "[98,   299] loss: 0.139836\n",
      "[98,   399] loss: 0.110368\n",
      "[98,   499] loss: 0.079870\n",
      "[98,   599] loss: 0.016516\n",
      "[98,   699] loss: 0.016318\n",
      "[99,    99] loss: 0.003299\n",
      "[99,   199] loss: 0.028371\n",
      "[99,   299] loss: 0.023243\n",
      "[99,   399] loss: 0.001564\n",
      "[99,   499] loss: 0.021322\n",
      "[99,   599] loss: 0.003011\n",
      "[99,   699] loss: 0.001740\n",
      "[100,    99] loss: 0.001056\n",
      "[100,   199] loss: 0.018594\n",
      "[100,   299] loss: 0.000568\n",
      "[100,   399] loss: 0.003808\n",
      "[100,   499] loss: 0.010046\n",
      "[100,   599] loss: 0.028977\n",
      "[100,   699] loss: 0.003201\n",
      "Finished Training\n",
      "[1,    99] loss: 0.709232\n",
      "[1,   199] loss: 0.669425\n",
      "[1,   299] loss: 0.679458\n",
      "[1,   399] loss: 0.640426\n",
      "[1,   499] loss: 0.639929\n",
      "[1,   599] loss: 0.596078\n",
      "[1,   699] loss: 0.643982\n",
      "[2,    99] loss: 0.610006\n",
      "[2,   199] loss: 0.568049\n",
      "[2,   299] loss: 0.601854\n",
      "[2,   399] loss: 0.544926\n",
      "[2,   499] loss: 0.531507\n",
      "[2,   599] loss: 0.513975\n",
      "[2,   699] loss: 0.526941\n",
      "[3,    99] loss: 0.520278\n",
      "[3,   199] loss: 0.458481\n",
      "[3,   299] loss: 0.513008\n",
      "[3,   399] loss: 0.453764\n",
      "[3,   499] loss: 0.429374\n",
      "[3,   599] loss: 0.442484\n",
      "[3,   699] loss: 0.414597\n",
      "[4,    99] loss: 0.388171\n",
      "[4,   199] loss: 0.380969\n",
      "[4,   299] loss: 0.439914\n",
      "[4,   399] loss: 0.381343\n",
      "[4,   499] loss: 0.335602\n",
      "[4,   599] loss: 0.406678\n",
      "[4,   699] loss: 0.344050\n",
      "[5,    99] loss: 0.304847\n",
      "[5,   199] loss: 0.328261\n",
      "[5,   299] loss: 0.383170\n",
      "[5,   399] loss: 0.331850\n",
      "[5,   499] loss: 0.270887\n",
      "[5,   599] loss: 0.349783\n",
      "[5,   699] loss: 0.310344\n",
      "[6,    99] loss: 0.252652\n",
      "[6,   199] loss: 0.292191\n",
      "[6,   299] loss: 0.343838\n",
      "[6,   399] loss: 0.286083\n",
      "[6,   499] loss: 0.227917\n",
      "[6,   599] loss: 0.289005\n",
      "[6,   699] loss: 0.277156\n",
      "[7,    99] loss: 0.214266\n",
      "[7,   199] loss: 0.269806\n",
      "[7,   299] loss: 0.317600\n",
      "[7,   399] loss: 0.254636\n",
      "[7,   499] loss: 0.181486\n",
      "[7,   599] loss: 0.243967\n",
      "[7,   699] loss: 0.256550\n",
      "[8,    99] loss: 0.179825\n",
      "[8,   199] loss: 0.252578\n",
      "[8,   299] loss: 0.287382\n",
      "[8,   399] loss: 0.226515\n",
      "[8,   499] loss: 0.152684\n",
      "[8,   599] loss: 0.203194\n",
      "[8,   699] loss: 0.221905\n",
      "[9,    99] loss: 0.146955\n",
      "[9,   199] loss: 0.211419\n",
      "[9,   299] loss: 0.256659\n",
      "[9,   399] loss: 0.211297\n",
      "[9,   499] loss: 0.114066\n",
      "[9,   599] loss: 0.185690\n",
      "[9,   699] loss: 0.206794\n",
      "[10,    99] loss: 0.129932\n",
      "[10,   199] loss: 0.181255\n",
      "[10,   299] loss: 0.241968\n",
      "[10,   399] loss: 0.184062\n",
      "[10,   499] loss: 0.085431\n",
      "[10,   599] loss: 0.149837\n",
      "[10,   699] loss: 0.205260\n",
      "[11,    99] loss: 0.109536\n",
      "[11,   199] loss: 0.168764\n",
      "[11,   299] loss: 0.198662\n",
      "[11,   399] loss: 0.159095\n",
      "[11,   499] loss: 0.072469\n",
      "[11,   599] loss: 0.117430\n",
      "[11,   699] loss: 0.178018\n",
      "[12,    99] loss: 0.097141\n",
      "[12,   199] loss: 0.136138\n",
      "[12,   299] loss: 0.210004\n",
      "[12,   399] loss: 0.141596\n",
      "[12,   499] loss: 0.066298\n",
      "[12,   599] loss: 0.086442\n",
      "[12,   699] loss: 0.166958\n",
      "[13,    99] loss: 0.082941\n",
      "[13,   199] loss: 0.139671\n",
      "[13,   299] loss: 0.179197\n",
      "[13,   399] loss: 0.112612\n",
      "[13,   499] loss: 0.065160\n",
      "[13,   599] loss: 0.074665\n",
      "[13,   699] loss: 0.138625\n",
      "[14,    99] loss: 0.074865\n",
      "[14,   199] loss: 0.121565\n",
      "[14,   299] loss: 0.204971\n",
      "[14,   399] loss: 0.127907\n",
      "[14,   499] loss: 0.035570\n",
      "[14,   599] loss: 0.070499\n",
      "[14,   699] loss: 0.157260\n",
      "[15,    99] loss: 0.088332\n",
      "[15,   199] loss: 0.141404\n",
      "[15,   299] loss: 0.157398\n",
      "[15,   399] loss: 0.085113\n",
      "[15,   499] loss: 0.055920\n",
      "[15,   599] loss: 0.083905\n",
      "[15,   699] loss: 0.142013\n",
      "[16,    99] loss: 0.074222\n",
      "[16,   199] loss: 0.106908\n",
      "[16,   299] loss: 0.127087\n",
      "[16,   399] loss: 0.071773\n",
      "[16,   499] loss: 0.022331\n",
      "[16,   599] loss: 0.037884\n",
      "[16,   699] loss: 0.078605\n",
      "[17,    99] loss: 0.051309\n",
      "[17,   199] loss: 0.106304\n",
      "[17,   299] loss: 0.115023\n",
      "[17,   399] loss: 0.056834\n",
      "[17,   499] loss: 0.025018\n",
      "[17,   599] loss: 0.048509\n",
      "[17,   699] loss: 0.132579\n",
      "[18,    99] loss: 0.076209\n",
      "[18,   199] loss: 0.253325\n",
      "[18,   299] loss: 0.234136\n",
      "[18,   399] loss: 0.110443\n",
      "[18,   499] loss: 0.039234\n",
      "[18,   599] loss: 0.080911\n",
      "[18,   699] loss: 0.145955\n",
      "[19,    99] loss: 0.038045\n",
      "[19,   199] loss: 0.060485\n",
      "[19,   299] loss: 0.107003\n",
      "[19,   399] loss: 0.050815\n",
      "[19,   499] loss: 0.020656\n",
      "[19,   599] loss: 0.036144\n",
      "[19,   699] loss: 0.044339\n",
      "[20,    99] loss: 0.027070\n",
      "[20,   199] loss: 0.037488\n",
      "[20,   299] loss: 0.093739\n",
      "[20,   399] loss: 0.046202\n",
      "[20,   499] loss: 0.010722\n",
      "[20,   599] loss: 0.030416\n",
      "[20,   699] loss: 0.047292\n",
      "[21,    99] loss: 0.040560\n",
      "[21,   199] loss: 0.169974\n",
      "[21,   299] loss: 0.206073\n",
      "[21,   399] loss: 0.100826\n",
      "[21,   499] loss: 0.104869\n",
      "[21,   599] loss: 0.108808\n",
      "[21,   699] loss: 0.103225\n",
      "[22,    99] loss: 0.042649\n",
      "[22,   199] loss: 0.057354\n",
      "[22,   299] loss: 0.071845\n",
      "[22,   399] loss: 0.032159\n",
      "[22,   499] loss: 0.030576\n",
      "[22,   599] loss: 0.021021\n",
      "[22,   699] loss: 0.048949\n",
      "[23,    99] loss: 0.017067\n",
      "[23,   199] loss: 0.031306\n",
      "[23,   299] loss: 0.090549\n",
      "[23,   399] loss: 0.040157\n",
      "[23,   499] loss: 0.010283\n",
      "[23,   599] loss: 0.069724\n",
      "[23,   699] loss: 0.130751\n",
      "[24,    99] loss: 0.065182\n",
      "[24,   199] loss: 0.113664\n",
      "[24,   299] loss: 0.109386\n",
      "[24,   399] loss: 0.179863\n",
      "[24,   499] loss: 0.017078\n",
      "[24,   599] loss: 0.034590\n",
      "[24,   699] loss: 0.051168\n",
      "[25,    99] loss: 0.035039\n",
      "[25,   199] loss: 0.043113\n",
      "[25,   299] loss: 0.114125\n",
      "[25,   399] loss: 0.066304\n",
      "[25,   499] loss: 0.010443\n",
      "[25,   599] loss: 0.060789\n",
      "[25,   699] loss: 0.042637\n",
      "[26,    99] loss: 0.035756\n",
      "[26,   199] loss: 0.038516\n",
      "[26,   299] loss: 0.084330\n",
      "[26,   399] loss: 0.022212\n",
      "[26,   499] loss: 0.019864\n",
      "[26,   599] loss: 0.037392\n",
      "[26,   699] loss: 0.062339\n",
      "[27,    99] loss: 0.013293\n",
      "[27,   199] loss: 0.070677\n",
      "[27,   299] loss: 0.101858\n",
      "[27,   399] loss: 0.038629\n",
      "[27,   499] loss: 0.008029\n",
      "[27,   599] loss: 0.040015\n",
      "[27,   699] loss: 0.035603\n",
      "[28,    99] loss: 0.011094\n",
      "[28,   199] loss: 0.013712\n",
      "[28,   299] loss: 0.043408\n",
      "[28,   399] loss: 0.036205\n",
      "[28,   499] loss: 0.005954\n",
      "[28,   599] loss: 0.030537\n",
      "[28,   699] loss: 0.025560\n",
      "[29,    99] loss: 0.017301\n",
      "[29,   199] loss: 0.076169\n",
      "[29,   299] loss: 0.118649\n",
      "[29,   399] loss: 0.191560\n",
      "[29,   499] loss: 0.096019\n",
      "[29,   599] loss: 0.282892\n",
      "[29,   699] loss: 0.252217\n",
      "[30,    99] loss: 0.089429\n",
      "[30,   199] loss: 0.081244\n",
      "[30,   299] loss: 0.056248\n",
      "[30,   399] loss: 0.023605\n",
      "[30,   499] loss: 0.016253\n",
      "[30,   599] loss: 0.024870\n",
      "[30,   699] loss: 0.030143\n",
      "[31,    99] loss: 0.010653\n",
      "[31,   199] loss: 0.020682\n",
      "[31,   299] loss: 0.046712\n",
      "[31,   399] loss: 0.020652\n",
      "[31,   499] loss: 0.005640\n",
      "[31,   599] loss: 0.008287\n",
      "[31,   699] loss: 0.030629\n",
      "[32,    99] loss: 0.037653\n",
      "[32,   199] loss: 0.082469\n",
      "[32,   299] loss: 0.092161\n",
      "[32,   399] loss: 0.027836\n",
      "[32,   499] loss: 0.013377\n",
      "[32,   599] loss: 0.066084\n",
      "[32,   699] loss: 0.299454\n",
      "[33,    99] loss: 0.031228\n",
      "[33,   199] loss: 0.048448\n",
      "[33,   299] loss: 0.111375\n",
      "[33,   399] loss: 0.094462\n",
      "[33,   499] loss: 0.021425\n",
      "[33,   599] loss: 0.025876\n",
      "[33,   699] loss: 0.022373\n",
      "[34,    99] loss: 0.019577\n",
      "[34,   199] loss: 0.024762\n",
      "[34,   299] loss: 0.060161\n",
      "[34,   399] loss: 0.017864\n",
      "[34,   499] loss: 0.033386\n",
      "[34,   599] loss: 0.051377\n",
      "[34,   699] loss: 0.085639\n",
      "[35,    99] loss: 0.025059\n",
      "[35,   199] loss: 0.066868\n",
      "[35,   299] loss: 0.041877\n",
      "[35,   399] loss: 0.027353\n",
      "[35,   499] loss: 0.002954\n",
      "[35,   599] loss: 0.022693\n",
      "[35,   699] loss: 0.014684\n",
      "[36,    99] loss: 0.006079\n",
      "[36,   199] loss: 0.019756\n",
      "[36,   299] loss: 0.093031\n",
      "[36,   399] loss: 0.026667\n",
      "[36,   499] loss: 0.004547\n",
      "[36,   599] loss: 0.007463\n",
      "[36,   699] loss: 0.011564\n",
      "[37,    99] loss: 0.004614\n",
      "[37,   199] loss: 0.012891\n",
      "[37,   299] loss: 0.023282\n",
      "[37,   399] loss: 0.014261\n",
      "[37,   499] loss: 0.002029\n",
      "[37,   599] loss: 0.017455\n",
      "[37,   699] loss: 0.012592\n",
      "[38,    99] loss: 0.004788\n",
      "[38,   199] loss: 0.013967\n",
      "[38,   299] loss: 0.085106\n",
      "[38,   399] loss: 0.021248\n",
      "[38,   499] loss: 0.003314\n",
      "[38,   599] loss: 0.016552\n",
      "[38,   699] loss: 0.024598\n",
      "[39,    99] loss: 0.068598\n",
      "[39,   199] loss: 0.284218\n",
      "[39,   299] loss: 0.161292\n",
      "[39,   399] loss: 0.047534\n",
      "[39,   499] loss: 0.009679\n",
      "[39,   599] loss: 0.011932\n",
      "[39,   699] loss: 0.019261\n",
      "[40,    99] loss: 0.009874\n",
      "[40,   199] loss: 0.024093\n",
      "[40,   299] loss: 0.034461\n",
      "[40,   399] loss: 0.005189\n",
      "[40,   499] loss: 0.027015\n",
      "[40,   599] loss: 0.055967\n",
      "[40,   699] loss: 0.017676\n",
      "[41,    99] loss: 0.009497\n",
      "[41,   199] loss: 0.143129\n",
      "[41,   299] loss: 0.126629\n",
      "[41,   399] loss: 0.036675\n",
      "[41,   499] loss: 0.069695\n",
      "[41,   599] loss: 0.130406\n",
      "[41,   699] loss: 0.086333\n",
      "[42,    99] loss: 0.047904\n",
      "[42,   199] loss: 0.083235\n",
      "[42,   299] loss: 0.028892\n",
      "[42,   399] loss: 0.018072\n",
      "[42,   499] loss: 0.021587\n",
      "[42,   599] loss: 0.017160\n",
      "[42,   699] loss: 0.062070\n",
      "[43,    99] loss: 0.016501\n",
      "[43,   199] loss: 0.018338\n",
      "[43,   299] loss: 0.034104\n",
      "[43,   399] loss: 0.022649\n",
      "[43,   499] loss: 0.005190\n",
      "[43,   599] loss: 0.045008\n",
      "[43,   699] loss: 0.179668\n",
      "[44,    99] loss: 0.026129\n",
      "[44,   199] loss: 0.039019\n",
      "[44,   299] loss: 0.016746\n",
      "[44,   399] loss: 0.103238\n",
      "[44,   499] loss: 0.076040\n",
      "[44,   599] loss: 0.050901\n",
      "[44,   699] loss: 0.039207\n",
      "[45,    99] loss: 0.029603\n",
      "[45,   199] loss: 0.027796\n",
      "[45,   299] loss: 0.067923\n",
      "[45,   399] loss: 0.022931\n",
      "[45,   499] loss: 0.005994\n",
      "[45,   599] loss: 0.006671\n",
      "[45,   699] loss: 0.008720\n",
      "[46,    99] loss: 0.006853\n",
      "[46,   199] loss: 0.009092\n",
      "[46,   299] loss: 0.008473\n",
      "[46,   399] loss: 0.007328\n",
      "[46,   499] loss: 0.004127\n",
      "[46,   599] loss: 0.003436\n",
      "[46,   699] loss: 0.004659\n",
      "[47,    99] loss: 0.002259\n",
      "[47,   199] loss: 0.006102\n",
      "[47,   299] loss: 0.003910\n",
      "[47,   399] loss: 0.003340\n",
      "[47,   499] loss: 0.002308\n",
      "[47,   599] loss: 0.002953\n",
      "[47,   699] loss: 0.008830\n",
      "[48,    99] loss: 0.008316\n",
      "[48,   199] loss: 0.013230\n",
      "[48,   299] loss: 0.014944\n",
      "[48,   399] loss: 0.006765\n",
      "[48,   499] loss: 0.004298\n",
      "[48,   599] loss: 0.009629\n",
      "[48,   699] loss: 0.011018\n",
      "[49,    99] loss: 0.005810\n",
      "[49,   199] loss: 0.121432\n",
      "[49,   299] loss: 0.653087\n",
      "[49,   399] loss: 0.214180\n",
      "[49,   499] loss: 0.030789\n",
      "[49,   599] loss: 0.045236\n",
      "[49,   699] loss: 0.076706\n",
      "[50,    99] loss: 0.044703\n",
      "[50,   199] loss: 0.173330\n",
      "[50,   299] loss: 0.026762\n",
      "[50,   399] loss: 0.009821\n",
      "[50,   499] loss: 0.016296\n",
      "[50,   599] loss: 0.011072\n",
      "[50,   699] loss: 0.009675\n",
      "[51,    99] loss: 0.005656\n",
      "[51,   199] loss: 0.006453\n",
      "[51,   299] loss: 0.004450\n",
      "[51,   399] loss: 0.005196\n",
      "[51,   499] loss: 0.003305\n",
      "[51,   599] loss: 0.003076\n",
      "[51,   699] loss: 0.005071\n",
      "[52,    99] loss: 0.002426\n",
      "[52,   199] loss: 0.004811\n",
      "[52,   299] loss: 0.003952\n",
      "[52,   399] loss: 0.002541\n",
      "[52,   499] loss: 0.001667\n",
      "[52,   599] loss: 0.002751\n",
      "[52,   699] loss: 0.005046\n",
      "[53,    99] loss: 0.001598\n",
      "[53,   199] loss: 0.006419\n",
      "[53,   299] loss: 0.158881\n",
      "[53,   399] loss: 0.005208\n",
      "[53,   499] loss: 0.006822\n",
      "[53,   599] loss: 0.003081\n",
      "[53,   699] loss: 0.014425\n",
      "[54,    99] loss: 0.009521\n",
      "[54,   199] loss: 0.055524\n",
      "[54,   299] loss: 0.030210\n",
      "[54,   399] loss: 0.026353\n",
      "[54,   499] loss: 0.100250\n",
      "[54,   599] loss: 0.129830\n",
      "[54,   699] loss: 0.333774\n",
      "[55,    99] loss: 0.068577\n",
      "[55,   199] loss: 0.168101\n",
      "[55,   299] loss: 0.047476\n",
      "[55,   399] loss: 0.011169\n",
      "[55,   499] loss: 0.060290\n",
      "[55,   599] loss: 0.046711\n",
      "[55,   699] loss: 0.051940\n",
      "[56,    99] loss: 0.009923\n",
      "[56,   199] loss: 0.015964\n",
      "[56,   299] loss: 0.006244\n",
      "[56,   399] loss: 0.004139\n",
      "[56,   499] loss: 0.017848\n",
      "[56,   599] loss: 0.072024\n",
      "[56,   699] loss: 0.024161\n",
      "[57,    99] loss: 0.003199\n",
      "[57,   199] loss: 0.041025\n",
      "[57,   299] loss: 0.009124\n",
      "[57,   399] loss: 0.003651\n",
      "[57,   499] loss: 0.001682\n",
      "[57,   599] loss: 0.005075\n",
      "[57,   699] loss: 0.014897\n",
      "[58,    99] loss: 0.008686\n",
      "[58,   199] loss: 0.009286\n",
      "[58,   299] loss: 0.037500\n",
      "[58,   399] loss: 0.057696\n",
      "[58,   499] loss: 0.074331\n",
      "[58,   599] loss: 0.106575\n",
      "[58,   699] loss: 0.077010\n",
      "[59,    99] loss: 0.015055\n",
      "[59,   199] loss: 0.015301\n",
      "[59,   299] loss: 0.166927\n",
      "[59,   399] loss: 0.028912\n",
      "[59,   499] loss: 0.005937\n",
      "[59,   599] loss: 0.013065\n",
      "[59,   699] loss: 0.020624\n",
      "[60,    99] loss: 0.005286\n",
      "[60,   199] loss: 0.008224\n",
      "[60,   299] loss: 0.010358\n",
      "[60,   399] loss: 0.023935\n",
      "[60,   499] loss: 0.001049\n",
      "[60,   599] loss: 0.015234\n",
      "[60,   699] loss: 0.105662\n",
      "[61,    99] loss: 0.002128\n",
      "[61,   199] loss: 0.010227\n",
      "[61,   299] loss: 0.028784\n",
      "[61,   399] loss: 0.011854\n",
      "[61,   499] loss: 0.018384\n",
      "[61,   599] loss: 0.051203\n",
      "[61,   699] loss: 0.004116\n",
      "[62,    99] loss: 0.013065\n",
      "[62,   199] loss: 0.018652\n",
      "[62,   299] loss: 0.041568\n",
      "[62,   399] loss: 0.016791\n",
      "[62,   499] loss: 0.001828\n",
      "[62,   599] loss: 0.006423\n",
      "[62,   699] loss: 0.113147\n",
      "[63,    99] loss: 0.062011\n",
      "[63,   199] loss: 0.214039\n",
      "[63,   299] loss: 0.110885\n",
      "[63,   399] loss: 0.047477\n",
      "[63,   499] loss: 0.028979\n",
      "[63,   599] loss: 0.075565\n",
      "[63,   699] loss: 0.041666\n",
      "[64,    99] loss: 0.006832\n",
      "[64,   199] loss: 0.016539\n",
      "[64,   299] loss: 0.005676\n",
      "[64,   399] loss: 0.006756\n",
      "[64,   499] loss: 0.004757\n",
      "[64,   599] loss: 0.002717\n",
      "[64,   699] loss: 0.002978\n",
      "[65,    99] loss: 0.002622\n",
      "[65,   199] loss: 0.008251\n",
      "[65,   299] loss: 0.007099\n",
      "[65,   399] loss: 0.001953\n",
      "[65,   499] loss: 0.000862\n",
      "[65,   599] loss: 0.004926\n",
      "[65,   699] loss: 0.004054\n",
      "[66,    99] loss: 0.000959\n",
      "[66,   199] loss: 0.002056\n",
      "[66,   299] loss: 0.001690\n",
      "[66,   399] loss: 0.000840\n",
      "[66,   499] loss: 0.000506\n",
      "[66,   599] loss: 0.002169\n",
      "[66,   699] loss: 0.002755\n",
      "[67,    99] loss: 0.002889\n",
      "[67,   199] loss: 0.004008\n",
      "[67,   299] loss: 0.065134\n",
      "[67,   399] loss: 0.044255\n",
      "[67,   499] loss: 0.001000\n",
      "[67,   599] loss: 0.021899\n",
      "[67,   699] loss: 0.194246\n",
      "[68,    99] loss: 0.004241\n",
      "[68,   199] loss: 0.009160\n",
      "[68,   299] loss: 0.031926\n",
      "[68,   399] loss: 0.015068\n",
      "[68,   499] loss: 0.003047\n",
      "[68,   599] loss: 0.032142\n",
      "[68,   699] loss: 0.062806\n",
      "[69,    99] loss: 0.028746\n",
      "[69,   199] loss: 0.139860\n",
      "[69,   299] loss: 0.167332\n",
      "[69,   399] loss: 0.127638\n",
      "[69,   499] loss: 0.029995\n",
      "[69,   599] loss: 0.022278\n",
      "[69,   699] loss: 0.058374\n",
      "[70,    99] loss: 0.004725\n",
      "[70,   199] loss: 0.040110\n",
      "[70,   299] loss: 0.039600\n",
      "[70,   399] loss: 0.029155\n",
      "[70,   499] loss: 0.002280\n",
      "[70,   599] loss: 0.017381\n",
      "[70,   699] loss: 0.032840\n",
      "[71,    99] loss: 0.100805\n",
      "[71,   199] loss: 0.017444\n",
      "[71,   299] loss: 0.029784\n",
      "[71,   399] loss: 0.005903\n",
      "[71,   499] loss: 0.037198\n",
      "[71,   599] loss: 0.038954\n",
      "[71,   699] loss: 0.012861\n",
      "[72,    99] loss: 0.006427\n",
      "[72,   199] loss: 0.008988\n",
      "[72,   299] loss: 0.003578\n",
      "[72,   399] loss: 0.001639\n",
      "[72,   499] loss: 0.001982\n",
      "[72,   599] loss: 0.007804\n",
      "[72,   699] loss: 0.047676\n",
      "[73,    99] loss: 0.004388\n",
      "[73,   199] loss: 0.004251\n",
      "[73,   299] loss: 0.011056\n",
      "[73,   399] loss: 0.002862\n",
      "[73,   499] loss: 0.000688\n",
      "[73,   599] loss: 0.004859\n",
      "[73,   699] loss: 0.013375\n",
      "[74,    99] loss: 0.006696\n",
      "[74,   199] loss: 0.131307\n",
      "[74,   299] loss: 0.037134\n",
      "[74,   399] loss: 0.092120\n",
      "[74,   499] loss: 0.004774\n",
      "[74,   599] loss: 0.052796\n",
      "[74,   699] loss: 0.045142\n",
      "[75,    99] loss: 0.005895\n",
      "[75,   199] loss: 0.012987\n",
      "[75,   299] loss: 0.055683\n",
      "[75,   399] loss: 0.345049\n",
      "[75,   499] loss: 0.015805\n",
      "[75,   599] loss: 0.242591\n",
      "[75,   699] loss: 0.111352\n",
      "[76,    99] loss: 0.037877\n",
      "[76,   199] loss: 0.029661\n",
      "[76,   299] loss: 0.036758\n",
      "[76,   399] loss: 0.026941\n",
      "[76,   499] loss: 0.004202\n",
      "[76,   599] loss: 0.008940\n",
      "[76,   699] loss: 0.005250\n",
      "[77,    99] loss: 0.002942\n",
      "[77,   199] loss: 0.008310\n",
      "[77,   299] loss: 0.004074\n",
      "[77,   399] loss: 0.001157\n",
      "[77,   499] loss: 0.001393\n",
      "[77,   599] loss: 0.003985\n",
      "[77,   699] loss: 0.002381\n",
      "[78,    99] loss: 0.001202\n",
      "[78,   199] loss: 0.004338\n",
      "[78,   299] loss: 0.069194\n",
      "[78,   399] loss: 0.006150\n",
      "[78,   499] loss: 0.001797\n",
      "[78,   599] loss: 0.007432\n",
      "[78,   699] loss: 0.017639\n",
      "[79,    99] loss: 0.003609\n",
      "[79,   199] loss: 0.018067\n",
      "[79,   299] loss: 0.042970\n",
      "[79,   399] loss: 0.001529\n",
      "[79,   499] loss: 0.000661\n",
      "[79,   599] loss: 0.001917\n",
      "[79,   699] loss: 0.002645\n",
      "[80,    99] loss: 0.000990\n",
      "[80,   199] loss: 0.004879\n",
      "[80,   299] loss: 0.001785\n",
      "[80,   399] loss: 0.000788\n",
      "[80,   499] loss: 0.000490\n",
      "[80,   599] loss: 0.002093\n",
      "[80,   699] loss: 0.005242\n",
      "[81,    99] loss: 0.001789\n",
      "[81,   199] loss: 0.005187\n",
      "[81,   299] loss: 0.001646\n",
      "[81,   399] loss: 0.000960\n",
      "[81,   499] loss: 0.000455\n",
      "[81,   599] loss: 0.037654\n",
      "[81,   699] loss: 0.100200\n",
      "[82,    99] loss: 0.097914\n",
      "[82,   199] loss: 0.204750\n",
      "[82,   299] loss: 0.073062\n",
      "[82,   399] loss: 0.060620\n",
      "[82,   499] loss: 0.034076\n",
      "[82,   599] loss: 0.006363\n",
      "[82,   699] loss: 0.045155\n",
      "[83,    99] loss: 0.009602\n",
      "[83,   199] loss: 0.006924\n",
      "[83,   299] loss: 0.118759\n",
      "[83,   399] loss: 0.005517\n",
      "[83,   499] loss: 0.002362\n",
      "[83,   599] loss: 0.045298\n",
      "[83,   699] loss: 0.055695\n",
      "[84,    99] loss: 0.010099\n",
      "[84,   199] loss: 0.005394\n",
      "[84,   299] loss: 0.072968\n",
      "[84,   399] loss: 0.166336\n",
      "[84,   499] loss: 0.020967\n",
      "[84,   599] loss: 0.019517\n",
      "[84,   699] loss: 0.009231\n",
      "[85,    99] loss: 0.038421\n",
      "[85,   199] loss: 0.008632\n",
      "[85,   299] loss: 0.003826\n",
      "[85,   399] loss: 0.025893\n",
      "[85,   499] loss: 0.015157\n",
      "[85,   599] loss: 0.004784\n",
      "[85,   699] loss: 0.003982\n",
      "[86,    99] loss: 0.000830\n",
      "[86,   199] loss: 0.001972\n",
      "[86,   299] loss: 0.011198\n",
      "[86,   399] loss: 0.010002\n",
      "[86,   499] loss: 0.005252\n",
      "[86,   599] loss: 0.001525\n",
      "[86,   699] loss: 0.004829\n",
      "[87,    99] loss: 0.000716\n",
      "[87,   199] loss: 0.001060\n",
      "[87,   299] loss: 0.001489\n",
      "[87,   399] loss: 0.001382\n",
      "[87,   499] loss: 0.000622\n",
      "[87,   599] loss: 0.002344\n",
      "[87,   699] loss: 0.000867\n",
      "[88,    99] loss: 0.000840\n",
      "[88,   199] loss: 0.002792\n",
      "[88,   299] loss: 0.136136\n",
      "[88,   399] loss: 0.011047\n",
      "[88,   499] loss: 0.006403\n",
      "[88,   599] loss: 0.006178\n",
      "[88,   699] loss: 0.005666\n",
      "[89,    99] loss: 0.065978\n",
      "[89,   199] loss: 0.122854\n",
      "[89,   299] loss: 0.173531\n",
      "[89,   399] loss: 0.061931\n",
      "[89,   499] loss: 0.001428\n",
      "[89,   599] loss: 0.047578\n",
      "[89,   699] loss: 0.066572\n",
      "[90,    99] loss: 0.081792\n",
      "[90,   199] loss: 0.013352\n",
      "[90,   299] loss: 0.316155\n",
      "[90,   399] loss: 0.010184\n",
      "[90,   499] loss: 0.096570\n",
      "[90,   599] loss: 0.038748\n",
      "[90,   699] loss: 0.011861\n",
      "[91,    99] loss: 0.006059\n",
      "[91,   199] loss: 0.007125\n",
      "[91,   299] loss: 0.016655\n",
      "[91,   399] loss: 0.004816\n",
      "[91,   499] loss: 0.003058\n",
      "[91,   599] loss: 0.004158\n",
      "[91,   699] loss: 0.006724\n",
      "[92,    99] loss: 0.003732\n",
      "[92,   199] loss: 0.011823\n",
      "[92,   299] loss: 0.054233\n",
      "[92,   399] loss: 0.005666\n",
      "[92,   499] loss: 0.055702\n",
      "[92,   599] loss: 0.064147\n",
      "[92,   699] loss: 0.004409\n",
      "[93,    99] loss: 0.001985\n",
      "[93,   199] loss: 0.001692\n",
      "[93,   299] loss: 0.002854\n",
      "[93,   399] loss: 0.002205\n",
      "[93,   499] loss: 0.001190\n",
      "[93,   599] loss: 0.003209\n",
      "[93,   699] loss: 0.001703\n",
      "[94,    99] loss: 0.001166\n",
      "[94,   199] loss: 0.002803\n",
      "[94,   299] loss: 0.066739\n",
      "[94,   399] loss: 0.001111\n",
      "[94,   499] loss: 0.001965\n",
      "[94,   599] loss: 0.007739\n",
      "[94,   699] loss: 0.007504\n",
      "[95,    99] loss: 0.000625\n",
      "[95,   199] loss: 0.001169\n",
      "[95,   299] loss: 0.002476\n",
      "[95,   399] loss: 0.001073\n",
      "[95,   499] loss: 0.000372\n",
      "[95,   599] loss: 0.001884\n",
      "[95,   699] loss: 0.001494\n",
      "[96,    99] loss: 0.000471\n",
      "[96,   199] loss: 0.001672\n",
      "[96,   299] loss: 0.035386\n",
      "[96,   399] loss: 0.019834\n",
      "[96,   499] loss: 0.000554\n",
      "[96,   599] loss: 0.005230\n",
      "[96,   699] loss: 0.030441\n",
      "[97,    99] loss: 0.005128\n",
      "[97,   199] loss: 0.005396\n",
      "[97,   299] loss: 0.017680\n",
      "[97,   399] loss: 0.006759\n",
      "[97,   499] loss: 0.000956\n",
      "[97,   599] loss: 0.022682\n",
      "[97,   699] loss: 0.103940\n",
      "[98,    99] loss: 0.004628\n",
      "[98,   199] loss: 0.108289\n",
      "[98,   299] loss: 0.111333\n",
      "[98,   399] loss: 0.024314\n",
      "[98,   499] loss: 0.010020\n",
      "[98,   599] loss: 0.012380\n",
      "[98,   699] loss: 0.009445\n",
      "[99,    99] loss: 0.001451\n",
      "[99,   199] loss: 0.013479\n",
      "[99,   299] loss: 0.044435\n",
      "[99,   399] loss: 0.001796\n",
      "[99,   499] loss: 0.004421\n",
      "[99,   599] loss: 0.002859\n",
      "[99,   699] loss: 0.001756\n",
      "[100,    99] loss: 0.000728\n",
      "[100,   199] loss: 0.004612\n",
      "[100,   299] loss: 0.001559\n",
      "[100,   399] loss: 0.000785\n",
      "[100,   499] loss: 0.000648\n",
      "[100,   599] loss: 0.001471\n",
      "[100,   699] loss: 0.000884\n",
      "Finished Training\n",
      "[1,    99] loss: 0.701709\n",
      "[1,   199] loss: 0.665893\n",
      "[1,   299] loss: 0.701005\n",
      "[1,   399] loss: 0.689022\n",
      "[1,   499] loss: 0.651816\n",
      "[1,   599] loss: 0.654436\n",
      "[1,   699] loss: 0.640700\n",
      "[2,    99] loss: 0.557924\n",
      "[2,   199] loss: 0.579964\n",
      "[2,   299] loss: 0.652328\n",
      "[2,   399] loss: 0.649811\n",
      "[2,   499] loss: 0.541286\n",
      "[2,   599] loss: 0.553878\n",
      "[2,   699] loss: 0.559296\n",
      "[3,    99] loss: 0.443092\n",
      "[3,   199] loss: 0.499889\n",
      "[3,   299] loss: 0.534370\n",
      "[3,   399] loss: 0.573170\n",
      "[3,   499] loss: 0.428637\n",
      "[3,   599] loss: 0.435227\n",
      "[3,   699] loss: 0.468820\n",
      "[4,    99] loss: 0.325708\n",
      "[4,   199] loss: 0.409458\n",
      "[4,   299] loss: 0.415949\n",
      "[4,   399] loss: 0.478924\n",
      "[4,   499] loss: 0.316724\n",
      "[4,   599] loss: 0.329105\n",
      "[4,   699] loss: 0.399383\n",
      "[5,    99] loss: 0.239008\n",
      "[5,   199] loss: 0.336349\n",
      "[5,   299] loss: 0.308471\n",
      "[5,   399] loss: 0.380681\n",
      "[5,   499] loss: 0.246502\n",
      "[5,   599] loss: 0.261791\n",
      "[5,   699] loss: 0.347611\n",
      "[6,    99] loss: 0.186415\n",
      "[6,   199] loss: 0.274798\n",
      "[6,   299] loss: 0.213271\n",
      "[6,   399] loss: 0.299571\n",
      "[6,   499] loss: 0.188475\n",
      "[6,   599] loss: 0.209431\n",
      "[6,   699] loss: 0.310279\n",
      "[7,    99] loss: 0.143905\n",
      "[7,   199] loss: 0.259613\n",
      "[7,   299] loss: 0.175847\n",
      "[7,   399] loss: 0.250681\n",
      "[7,   499] loss: 0.159366\n",
      "[7,   599] loss: 0.198911\n",
      "[7,   699] loss: 0.289404\n",
      "[8,    99] loss: 0.121864\n",
      "[8,   199] loss: 0.221839\n",
      "[8,   299] loss: 0.148726\n",
      "[8,   399] loss: 0.194564\n",
      "[8,   499] loss: 0.140324\n",
      "[8,   599] loss: 0.167760\n",
      "[8,   699] loss: 0.232382\n",
      "[9,    99] loss: 0.100092\n",
      "[9,   199] loss: 0.204720\n",
      "[9,   299] loss: 0.115436\n",
      "[9,   399] loss: 0.188744\n",
      "[9,   499] loss: 0.141922\n",
      "[9,   599] loss: 0.187028\n",
      "[9,   699] loss: 0.195020\n",
      "[10,    99] loss: 0.089988\n",
      "[10,   199] loss: 0.182896\n",
      "[10,   299] loss: 0.090615\n",
      "[10,   399] loss: 0.122869\n",
      "[10,   499] loss: 0.114059\n",
      "[10,   599] loss: 0.159274\n",
      "[10,   699] loss: 0.197306\n",
      "[11,    99] loss: 0.081771\n",
      "[11,   199] loss: 0.165186\n",
      "[11,   299] loss: 0.083808\n",
      "[11,   399] loss: 0.105524\n",
      "[11,   499] loss: 0.094725\n",
      "[11,   599] loss: 0.144146\n",
      "[11,   699] loss: 0.193742\n",
      "[12,    99] loss: 0.083380\n",
      "[12,   199] loss: 0.172897\n",
      "[12,   299] loss: 0.085418\n",
      "[12,   399] loss: 0.085909\n",
      "[12,   499] loss: 0.097952\n",
      "[12,   599] loss: 0.127043\n",
      "[12,   699] loss: 0.141077\n",
      "[13,    99] loss: 0.074263\n",
      "[13,   199] loss: 0.171044\n",
      "[13,   299] loss: 0.068837\n",
      "[13,   399] loss: 0.079865\n",
      "[13,   499] loss: 0.089783\n",
      "[13,   599] loss: 0.087866\n",
      "[13,   699] loss: 0.126028\n",
      "[14,    99] loss: 0.072036\n",
      "[14,   199] loss: 0.162841\n",
      "[14,   299] loss: 0.093362\n",
      "[14,   399] loss: 0.079521\n",
      "[14,   499] loss: 0.152531\n",
      "[14,   599] loss: 0.159135\n",
      "[14,   699] loss: 0.137909\n",
      "[15,    99] loss: 0.065129\n",
      "[15,   199] loss: 0.121437\n",
      "[15,   299] loss: 0.070172\n",
      "[15,   399] loss: 0.060572\n",
      "[15,   499] loss: 0.077889\n",
      "[15,   599] loss: 0.051698\n",
      "[15,   699] loss: 0.120842\n",
      "[16,    99] loss: 0.054013\n",
      "[16,   199] loss: 0.106854\n",
      "[16,   299] loss: 0.079654\n",
      "[16,   399] loss: 0.094475\n",
      "[16,   499] loss: 0.129400\n",
      "[16,   599] loss: 0.077278\n",
      "[16,   699] loss: 0.113958\n",
      "[17,    99] loss: 0.052303\n",
      "[17,   199] loss: 0.112212\n",
      "[17,   299] loss: 0.053711\n",
      "[17,   399] loss: 0.041570\n",
      "[17,   499] loss: 0.073180\n",
      "[17,   599] loss: 0.048959\n",
      "[17,   699] loss: 0.124444\n",
      "[18,    99] loss: 0.063464\n",
      "[18,   199] loss: 0.111505\n",
      "[18,   299] loss: 0.093033\n",
      "[18,   399] loss: 0.089005\n",
      "[18,   499] loss: 0.070054\n",
      "[18,   599] loss: 0.045750\n",
      "[18,   699] loss: 0.074958\n",
      "[19,    99] loss: 0.041972\n",
      "[19,   199] loss: 0.077870\n",
      "[19,   299] loss: 0.065576\n",
      "[19,   399] loss: 0.049223\n",
      "[19,   499] loss: 0.086439\n",
      "[19,   599] loss: 0.118492\n",
      "[19,   699] loss: 0.130549\n",
      "[20,    99] loss: 0.067788\n",
      "[20,   199] loss: 0.097321\n",
      "[20,   299] loss: 0.068458\n",
      "[20,   399] loss: 0.028951\n",
      "[20,   499] loss: 0.093626\n",
      "[20,   599] loss: 0.025530\n",
      "[20,   699] loss: 0.056403\n",
      "[21,    99] loss: 0.073028\n",
      "[21,   199] loss: 0.125239\n",
      "[21,   299] loss: 0.041575\n",
      "[21,   399] loss: 0.023073\n",
      "[21,   499] loss: 0.115696\n",
      "[21,   599] loss: 0.034602\n",
      "[21,   699] loss: 0.078870\n",
      "[22,    99] loss: 0.055667\n",
      "[22,   199] loss: 0.084370\n",
      "[22,   299] loss: 0.063520\n",
      "[22,   399] loss: 0.263412\n",
      "[22,   499] loss: 0.060049\n",
      "[22,   599] loss: 0.043906\n",
      "[22,   699] loss: 0.056682\n",
      "[23,    99] loss: 0.032464\n",
      "[23,   199] loss: 0.031912\n",
      "[23,   299] loss: 0.027445\n",
      "[23,   399] loss: 0.040920\n",
      "[23,   499] loss: 0.068945\n",
      "[23,   599] loss: 0.023286\n",
      "[23,   699] loss: 0.056009\n",
      "[24,    99] loss: 0.031201\n",
      "[24,   199] loss: 0.065030\n",
      "[24,   299] loss: 0.027824\n",
      "[24,   399] loss: 0.091211\n",
      "[24,   499] loss: 0.097049\n",
      "[24,   599] loss: 0.065280\n",
      "[24,   699] loss: 0.093676\n",
      "[25,    99] loss: 0.050897\n",
      "[25,   199] loss: 0.029709\n",
      "[25,   299] loss: 0.044372\n",
      "[25,   399] loss: 0.019023\n",
      "[25,   499] loss: 0.078220\n",
      "[25,   599] loss: 0.041737\n",
      "[25,   699] loss: 0.139549\n",
      "[26,    99] loss: 0.045496\n",
      "[26,   199] loss: 0.054479\n",
      "[26,   299] loss: 0.042310\n",
      "[26,   399] loss: 0.074283\n",
      "[26,   499] loss: 0.080299\n",
      "[26,   599] loss: 0.019635\n",
      "[26,   699] loss: 0.070316\n",
      "[27,    99] loss: 0.105632\n",
      "[27,   199] loss: 0.093451\n",
      "[27,   299] loss: 0.062100\n",
      "[27,   399] loss: 0.070980\n",
      "[27,   499] loss: 0.091292\n",
      "[27,   599] loss: 0.018297\n",
      "[27,   699] loss: 0.145842\n",
      "[28,    99] loss: 0.055311\n",
      "[28,   199] loss: 0.067873\n",
      "[28,   299] loss: 0.056934\n",
      "[28,   399] loss: 0.033759\n",
      "[28,   499] loss: 0.044880\n",
      "[28,   599] loss: 0.025406\n",
      "[28,   699] loss: 0.035703\n",
      "[29,    99] loss: 0.050501\n",
      "[29,   199] loss: 0.020257\n",
      "[29,   299] loss: 0.010833\n",
      "[29,   399] loss: 0.011205\n",
      "[29,   499] loss: 0.048596\n",
      "[29,   599] loss: 0.011641\n",
      "[29,   699] loss: 0.012968\n",
      "[30,    99] loss: 0.053449\n",
      "[30,   199] loss: 0.011282\n",
      "[30,   299] loss: 0.013094\n",
      "[30,   399] loss: 0.007279\n",
      "[30,   499] loss: 0.083872\n",
      "[30,   599] loss: 0.009233\n",
      "[30,   699] loss: 0.037197\n",
      "[31,    99] loss: 0.035858\n",
      "[31,   199] loss: 0.028125\n",
      "[31,   299] loss: 0.046922\n",
      "[31,   399] loss: 0.068278\n",
      "[31,   499] loss: 0.198906\n",
      "[31,   599] loss: 0.119634\n",
      "[31,   699] loss: 0.106908\n",
      "[32,    99] loss: 0.024936\n",
      "[32,   199] loss: 0.058801\n",
      "[32,   299] loss: 0.069251\n",
      "[32,   399] loss: 0.023753\n",
      "[32,   499] loss: 0.023094\n",
      "[32,   599] loss: 0.024398\n",
      "[32,   699] loss: 0.057133\n",
      "[33,    99] loss: 0.140759\n",
      "[33,   199] loss: 0.078277\n",
      "[33,   299] loss: 0.032008\n",
      "[33,   399] loss: 0.022884\n",
      "[33,   499] loss: 0.056684\n",
      "[33,   599] loss: 0.020439\n",
      "[33,   699] loss: 0.068848\n",
      "[34,    99] loss: 0.048087\n",
      "[34,   199] loss: 0.033619\n",
      "[34,   299] loss: 0.029521\n",
      "[34,   399] loss: 0.013165\n",
      "[34,   499] loss: 0.056901\n",
      "[34,   599] loss: 0.068628\n",
      "[34,   699] loss: 0.143807\n",
      "[35,    99] loss: 0.069664\n",
      "[35,   199] loss: 0.094906\n",
      "[35,   299] loss: 0.064079\n",
      "[35,   399] loss: 0.026505\n",
      "[35,   499] loss: 0.043292\n",
      "[35,   599] loss: 0.013983\n",
      "[35,   699] loss: 0.013964\n",
      "[36,    99] loss: 0.033547\n",
      "[36,   199] loss: 0.025781\n",
      "[36,   299] loss: 0.007111\n",
      "[36,   399] loss: 0.007037\n",
      "[36,   499] loss: 0.059476\n",
      "[36,   599] loss: 0.007663\n",
      "[36,   699] loss: 0.015403\n",
      "[37,    99] loss: 0.039364\n",
      "[37,   199] loss: 0.019161\n",
      "[37,   299] loss: 0.008897\n",
      "[37,   399] loss: 0.004497\n",
      "[37,   499] loss: 0.049661\n",
      "[37,   599] loss: 0.007575\n",
      "[37,   699] loss: 0.020774\n",
      "[38,    99] loss: 0.040941\n",
      "[38,   199] loss: 0.012978\n",
      "[38,   299] loss: 0.004890\n",
      "[38,   399] loss: 0.006072\n",
      "[38,   499] loss: 0.065228\n",
      "[38,   599] loss: 0.007069\n",
      "[38,   699] loss: 0.018544\n",
      "[39,    99] loss: 0.028887\n",
      "[39,   199] loss: 0.006410\n",
      "[39,   299] loss: 0.005263\n",
      "[39,   399] loss: 0.019584\n",
      "[39,   499] loss: 0.080694\n",
      "[39,   599] loss: 0.216300\n",
      "[39,   699] loss: 0.330456\n",
      "[40,    99] loss: 0.023744\n",
      "[40,   199] loss: 0.132855\n",
      "[40,   299] loss: 0.030383\n",
      "[40,   399] loss: 0.031597\n",
      "[40,   499] loss: 0.056126\n",
      "[40,   599] loss: 0.029857\n",
      "[40,   699] loss: 0.050366\n",
      "[41,    99] loss: 0.005151\n",
      "[41,   199] loss: 0.033848\n",
      "[41,   299] loss: 0.016302\n",
      "[41,   399] loss: 0.005146\n",
      "[41,   499] loss: 0.008212\n",
      "[41,   599] loss: 0.036549\n",
      "[41,   699] loss: 0.016958\n",
      "[42,    99] loss: 0.005963\n",
      "[42,   199] loss: 0.014954\n",
      "[42,   299] loss: 0.006677\n",
      "[42,   399] loss: 0.006840\n",
      "[42,   499] loss: 0.003507\n",
      "[42,   599] loss: 0.017304\n",
      "[42,   699] loss: 0.028079\n",
      "[43,    99] loss: 0.028295\n",
      "[43,   199] loss: 0.138553\n",
      "[43,   299] loss: 0.393740\n",
      "[43,   399] loss: 0.054058\n",
      "[43,   499] loss: 0.034803\n",
      "[43,   599] loss: 0.024876\n",
      "[43,   699] loss: 0.071041\n",
      "[44,    99] loss: 0.012895\n",
      "[44,   199] loss: 0.038196\n",
      "[44,   299] loss: 0.027845\n",
      "[44,   399] loss: 0.045281\n",
      "[44,   499] loss: 0.036822\n",
      "[44,   599] loss: 0.010111\n",
      "[44,   699] loss: 0.014264\n",
      "[45,    99] loss: 0.042748\n",
      "[45,   199] loss: 0.020024\n",
      "[45,   299] loss: 0.007404\n",
      "[45,   399] loss: 0.007149\n",
      "[45,   499] loss: 0.029769\n",
      "[45,   599] loss: 0.004544\n",
      "[45,   699] loss: 0.007444\n",
      "[46,    99] loss: 0.041941\n",
      "[46,   199] loss: 0.009591\n",
      "[46,   299] loss: 0.021377\n",
      "[46,   399] loss: 0.007823\n",
      "[46,   499] loss: 0.037753\n",
      "[46,   599] loss: 0.011532\n",
      "[46,   699] loss: 0.045030\n",
      "[47,    99] loss: 0.053151\n",
      "[47,   199] loss: 0.058535\n",
      "[47,   299] loss: 0.087170\n",
      "[47,   399] loss: 0.036088\n",
      "[47,   499] loss: 0.133475\n",
      "[47,   599] loss: 0.076494\n",
      "[47,   699] loss: 0.053267\n",
      "[48,    99] loss: 0.090975\n",
      "[48,   199] loss: 0.039607\n",
      "[48,   299] loss: 0.015974\n",
      "[48,   399] loss: 0.012491\n",
      "[48,   499] loss: 0.045180\n",
      "[48,   599] loss: 0.011601\n",
      "[48,   699] loss: 0.007490\n",
      "[49,    99] loss: 0.007691\n",
      "[49,   199] loss: 0.008479\n",
      "[49,   299] loss: 0.007867\n",
      "[49,   399] loss: 0.006184\n",
      "[49,   499] loss: 0.008062\n",
      "[49,   599] loss: 0.007108\n",
      "[49,   699] loss: 0.003244\n",
      "[50,    99] loss: 0.025391\n",
      "[50,   199] loss: 0.005147\n",
      "[50,   299] loss: 0.009957\n",
      "[50,   399] loss: 0.003932\n",
      "[50,   499] loss: 0.069792\n",
      "[50,   599] loss: 0.007250\n",
      "[50,   699] loss: 0.049891\n",
      "[51,    99] loss: 0.040017\n",
      "[51,   199] loss: 0.037377\n",
      "[51,   299] loss: 0.059089\n",
      "[51,   399] loss: 0.045983\n",
      "[51,   499] loss: 0.183422\n",
      "[51,   599] loss: 0.072375\n",
      "[51,   699] loss: 0.023286\n",
      "[52,    99] loss: 0.020382\n",
      "[52,   199] loss: 0.010437\n",
      "[52,   299] loss: 0.004727\n",
      "[52,   399] loss: 0.003487\n",
      "[52,   499] loss: 0.031692\n",
      "[52,   599] loss: 0.009144\n",
      "[52,   699] loss: 0.011180\n",
      "[53,    99] loss: 0.036439\n",
      "[53,   199] loss: 0.025435\n",
      "[53,   299] loss: 0.004435\n",
      "[53,   399] loss: 0.015586\n",
      "[53,   499] loss: 0.037610\n",
      "[53,   599] loss: 0.003568\n",
      "[53,   699] loss: 0.109768\n",
      "[54,    99] loss: 0.035272\n",
      "[54,   199] loss: 0.013771\n",
      "[54,   299] loss: 0.178376\n",
      "[54,   399] loss: 0.058745\n",
      "[54,   499] loss: 0.008823\n",
      "[54,   599] loss: 0.005071\n",
      "[54,   699] loss: 0.013504\n",
      "[55,    99] loss: 0.011922\n",
      "[55,   199] loss: 0.093600\n",
      "[55,   299] loss: 0.004125\n",
      "[55,   399] loss: 0.018648\n",
      "[55,   499] loss: 0.013852\n",
      "[55,   599] loss: 0.022642\n",
      "[55,   699] loss: 0.013141\n",
      "[56,    99] loss: 0.013118\n",
      "[56,   199] loss: 0.008706\n",
      "[56,   299] loss: 0.016357\n",
      "[56,   399] loss: 0.022567\n",
      "[56,   499] loss: 0.014147\n",
      "[56,   599] loss: 0.012404\n",
      "[56,   699] loss: 0.040269\n",
      "[57,    99] loss: 0.022935\n",
      "[57,   199] loss: 0.047371\n",
      "[57,   299] loss: 0.073904\n",
      "[57,   399] loss: 0.083007\n",
      "[57,   499] loss: 0.053603\n",
      "[57,   599] loss: 0.035626\n",
      "[57,   699] loss: 0.024873\n",
      "[58,    99] loss: 0.029820\n",
      "[58,   199] loss: 0.020474\n",
      "[58,   299] loss: 0.003155\n",
      "[58,   399] loss: 0.006286\n",
      "[58,   499] loss: 0.003891\n",
      "[58,   599] loss: 0.011586\n",
      "[58,   699] loss: 0.014795\n",
      "[59,    99] loss: 0.002820\n",
      "[59,   199] loss: 0.015404\n",
      "[59,   299] loss: 0.004719\n",
      "[59,   399] loss: 0.001418\n",
      "[59,   499] loss: 0.002481\n",
      "[59,   599] loss: 0.012995\n",
      "[59,   699] loss: 0.008261\n",
      "[60,    99] loss: 0.007322\n",
      "[60,   199] loss: 0.015644\n",
      "[60,   299] loss: 0.097593\n",
      "[60,   399] loss: 0.105249\n",
      "[60,   499] loss: 0.075448\n",
      "[60,   599] loss: 0.040519\n",
      "[60,   699] loss: 0.111001\n",
      "[61,    99] loss: 0.134748\n",
      "[61,   199] loss: 0.148832\n",
      "[61,   299] loss: 0.056192\n",
      "[61,   399] loss: 0.093192\n",
      "[61,   499] loss: 0.039282\n",
      "[61,   599] loss: 0.009773\n",
      "[61,   699] loss: 0.005618\n",
      "[62,    99] loss: 0.017323\n",
      "[62,   199] loss: 0.019540\n",
      "[62,   299] loss: 0.003833\n",
      "[62,   399] loss: 0.010820\n",
      "[62,   499] loss: 0.006983\n",
      "[62,   599] loss: 0.003469\n",
      "[62,   699] loss: 0.026900\n",
      "[63,    99] loss: 0.005580\n",
      "[63,   199] loss: 0.030211\n",
      "[63,   299] loss: 0.002432\n",
      "[63,   399] loss: 0.059620\n",
      "[63,   499] loss: 0.059317\n",
      "[63,   599] loss: 0.071220\n",
      "[63,   699] loss: 0.018849\n",
      "[64,    99] loss: 0.019231\n",
      "[64,   199] loss: 0.007534\n",
      "[64,   299] loss: 0.004541\n",
      "[64,   399] loss: 0.001845\n",
      "[64,   499] loss: 0.032897\n",
      "[64,   599] loss: 0.011284\n",
      "[64,   699] loss: 0.023133\n",
      "[65,    99] loss: 0.043872\n",
      "[65,   199] loss: 0.008502\n",
      "[65,   299] loss: 0.003163\n",
      "[65,   399] loss: 0.012197\n",
      "[65,   499] loss: 0.021499\n",
      "[65,   599] loss: 0.002296\n",
      "[65,   699] loss: 0.042556\n",
      "[66,    99] loss: 0.024431\n",
      "[66,   199] loss: 0.022191\n",
      "[66,   299] loss: 0.006500\n",
      "[66,   399] loss: 0.006962\n",
      "[66,   499] loss: 0.043773\n",
      "[66,   599] loss: 0.020991\n",
      "[66,   699] loss: 0.077170\n",
      "[67,    99] loss: 0.027230\n",
      "[67,   199] loss: 0.028042\n",
      "[67,   299] loss: 0.001526\n",
      "[67,   399] loss: 0.058572\n",
      "[67,   499] loss: 0.016051\n",
      "[67,   599] loss: 0.007872\n",
      "[67,   699] loss: 0.145020\n",
      "[68,    99] loss: 0.004669\n",
      "[68,   199] loss: 0.008981\n",
      "[68,   299] loss: 0.006191\n",
      "[68,   399] loss: 0.007090\n",
      "[68,   499] loss: 0.004705\n",
      "[68,   599] loss: 0.011005\n",
      "[68,   699] loss: 0.001670\n",
      "[69,    99] loss: 0.010773\n",
      "[69,   199] loss: 0.023473\n",
      "[69,   299] loss: 0.006295\n",
      "[69,   399] loss: 0.001870\n",
      "[69,   499] loss: 0.050328\n",
      "[69,   599] loss: 0.022874\n",
      "[69,   699] loss: 0.066515\n",
      "[70,    99] loss: 0.260577\n",
      "[70,   199] loss: 0.066597\n",
      "[70,   299] loss: 0.200212\n",
      "[70,   399] loss: 0.028776\n",
      "[70,   499] loss: 0.019301\n",
      "[70,   599] loss: 0.015933\n",
      "[70,   699] loss: 0.022121\n",
      "[71,    99] loss: 0.006851\n",
      "[71,   199] loss: 0.014469\n",
      "[71,   299] loss: 0.005159\n",
      "[71,   399] loss: 0.003594\n",
      "[71,   499] loss: 0.004973\n",
      "[71,   599] loss: 0.002612\n",
      "[71,   699] loss: 0.001777\n",
      "[72,    99] loss: 0.007661\n",
      "[72,   199] loss: 0.002230\n",
      "[72,   299] loss: 0.001015\n",
      "[72,   399] loss: 0.001473\n",
      "[72,   499] loss: 0.016632\n",
      "[72,   599] loss: 0.001852\n",
      "[72,   699] loss: 0.002573\n",
      "[73,    99] loss: 0.057700\n",
      "[73,   199] loss: 0.002840\n",
      "[73,   299] loss: 0.001312\n",
      "[73,   399] loss: 0.002177\n",
      "[73,   499] loss: 0.035041\n",
      "[73,   599] loss: 0.001572\n",
      "[73,   699] loss: 0.001854\n",
      "[74,    99] loss: 0.022025\n",
      "[74,   199] loss: 0.001772\n",
      "[74,   299] loss: 0.001101\n",
      "[74,   399] loss: 0.000836\n",
      "[74,   499] loss: 0.024611\n",
      "[74,   599] loss: 0.001296\n",
      "[74,   699] loss: 0.003804\n",
      "[75,    99] loss: 0.053380\n",
      "[75,   199] loss: 0.004834\n",
      "[75,   299] loss: 0.004694\n",
      "[75,   399] loss: 0.001273\n",
      "[75,   499] loss: 0.034304\n",
      "[75,   599] loss: 0.001196\n",
      "[75,   699] loss: 0.069923\n",
      "[76,    99] loss: 0.033707\n",
      "[76,   199] loss: 0.086902\n",
      "[76,   299] loss: 0.310113\n",
      "[76,   399] loss: 0.124475\n",
      "[76,   499] loss: 0.075801\n",
      "[76,   599] loss: 0.073737\n",
      "[76,   699] loss: 0.027108\n",
      "[77,    99] loss: 0.024674\n",
      "[77,   199] loss: 0.020593\n",
      "[77,   299] loss: 0.014870\n",
      "[77,   399] loss: 0.003903\n",
      "[77,   499] loss: 0.004128\n",
      "[77,   599] loss: 0.002239\n",
      "[77,   699] loss: 0.003236\n",
      "[78,    99] loss: 0.001095\n",
      "[78,   199] loss: 0.002788\n",
      "[78,   299] loss: 0.000933\n",
      "[78,   399] loss: 0.001318\n",
      "[78,   499] loss: 0.002306\n",
      "[78,   599] loss: 0.000746\n",
      "[78,   699] loss: 0.001489\n",
      "[79,    99] loss: 0.001030\n",
      "[79,   199] loss: 0.001530\n",
      "[79,   299] loss: 0.000749\n",
      "[79,   399] loss: 0.000993\n",
      "[79,   499] loss: 0.001646\n",
      "[79,   599] loss: 0.000574\n",
      "[79,   699] loss: 0.001047\n",
      "[80,    99] loss: 0.001104\n",
      "[80,   199] loss: 0.001057\n",
      "[80,   299] loss: 0.000618\n",
      "[80,   399] loss: 0.000729\n",
      "[80,   499] loss: 0.001441\n",
      "[80,   599] loss: 0.000466\n",
      "[80,   699] loss: 0.000754\n",
      "[81,    99] loss: 0.001413\n",
      "[81,   199] loss: 0.000743\n",
      "[81,   299] loss: 0.000502\n",
      "[81,   399] loss: 0.000565\n",
      "[81,   499] loss: 0.002387\n",
      "[81,   599] loss: 0.000708\n",
      "[81,   699] loss: 0.000640\n",
      "[82,    99] loss: 0.020583\n",
      "[82,   199] loss: 0.036858\n",
      "[82,   299] loss: 0.059727\n",
      "[82,   399] loss: 0.227081\n",
      "[82,   499] loss: 0.195320\n",
      "[82,   599] loss: 0.168845\n",
      "[82,   699] loss: 0.230995\n",
      "[83,    99] loss: 0.018906\n",
      "[83,   199] loss: 0.025691\n",
      "[83,   299] loss: 0.013379\n",
      "[83,   399] loss: 0.016034\n",
      "[83,   499] loss: 0.009276\n",
      "[83,   599] loss: 0.005643\n",
      "[83,   699] loss: 0.030216\n",
      "[84,    99] loss: 0.003811\n",
      "[84,   199] loss: 0.007894\n",
      "[84,   299] loss: 0.002808\n",
      "[84,   399] loss: 0.004524\n",
      "[84,   499] loss: 0.005605\n",
      "[84,   599] loss: 0.001472\n",
      "[84,   699] loss: 0.002415\n",
      "[85,    99] loss: 0.001668\n",
      "[85,   199] loss: 0.001847\n",
      "[85,   299] loss: 0.001134\n",
      "[85,   399] loss: 0.001572\n",
      "[85,   499] loss: 0.001886\n",
      "[85,   599] loss: 0.001012\n",
      "[85,   699] loss: 0.001479\n",
      "[86,    99] loss: 0.001376\n",
      "[86,   199] loss: 0.001297\n",
      "[86,   299] loss: 0.000844\n",
      "[86,   399] loss: 0.000891\n",
      "[86,   499] loss: 0.001306\n",
      "[86,   599] loss: 0.000660\n",
      "[86,   699] loss: 0.000993\n",
      "[87,    99] loss: 0.001024\n",
      "[87,   199] loss: 0.000974\n",
      "[87,   299] loss: 0.000653\n",
      "[87,   399] loss: 0.000596\n",
      "[87,   499] loss: 0.001010\n",
      "[87,   599] loss: 0.000463\n",
      "[87,   699] loss: 0.000840\n",
      "[88,    99] loss: 0.001211\n",
      "[88,   199] loss: 0.000967\n",
      "[88,   299] loss: 0.000601\n",
      "[88,   399] loss: 0.000444\n",
      "[88,   499] loss: 0.006389\n",
      "[88,   599] loss: 0.003723\n",
      "[88,   699] loss: 0.001183\n",
      "[89,    99] loss: 0.035399\n",
      "[89,   199] loss: 0.076421\n",
      "[89,   299] loss: 0.059601\n",
      "[89,   399] loss: 0.388456\n",
      "[89,   499] loss: 0.228107\n",
      "[89,   599] loss: 0.290500\n",
      "[89,   699] loss: 0.100170\n",
      "[90,    99] loss: 0.158221\n",
      "[90,   199] loss: 0.061882\n",
      "[90,   299] loss: 0.117593\n",
      "[90,   399] loss: 0.004587\n",
      "[90,   499] loss: 0.008234\n",
      "[90,   599] loss: 0.004085\n",
      "[90,   699] loss: 0.003576\n",
      "[91,    99] loss: 0.014801\n",
      "[91,   199] loss: 0.034532\n",
      "[91,   299] loss: 0.002203\n",
      "[91,   399] loss: 0.002550\n",
      "[91,   499] loss: 0.005787\n",
      "[91,   599] loss: 0.001804\n",
      "[91,   699] loss: 0.004030\n",
      "[92,    99] loss: 0.004023\n",
      "[92,   199] loss: 0.001522\n",
      "[92,   299] loss: 0.001050\n",
      "[92,   399] loss: 0.001697\n",
      "[92,   499] loss: 0.001763\n",
      "[92,   599] loss: 0.000977\n",
      "[92,   699] loss: 0.001639\n",
      "[93,    99] loss: 0.001138\n",
      "[93,   199] loss: 0.001152\n",
      "[93,   299] loss: 0.000890\n",
      "[93,   399] loss: 0.001282\n",
      "[93,   499] loss: 0.001419\n",
      "[93,   599] loss: 0.000727\n",
      "[93,   699] loss: 0.001193\n",
      "[94,    99] loss: 0.001375\n",
      "[94,   199] loss: 0.000824\n",
      "[94,   299] loss: 0.000757\n",
      "[94,   399] loss: 0.000840\n",
      "[94,   499] loss: 0.001828\n",
      "[94,   599] loss: 0.000622\n",
      "[94,   699] loss: 0.000936\n",
      "[95,    99] loss: 0.004956\n",
      "[95,   199] loss: 0.000828\n",
      "[95,   299] loss: 0.000899\n",
      "[95,   399] loss: 0.000848\n",
      "[95,   499] loss: 0.044409\n",
      "[95,   599] loss: 0.002238\n",
      "[95,   699] loss: 0.007481\n",
      "[96,    99] loss: 0.035158\n",
      "[96,   199] loss: 0.023295\n",
      "[96,   299] loss: 0.101611\n",
      "[96,   399] loss: 0.282422\n",
      "[96,   499] loss: 0.233923\n",
      "[96,   599] loss: 0.158032\n",
      "[96,   699] loss: 0.035414\n",
      "[97,    99] loss: 0.042381\n",
      "[97,   199] loss: 0.041100\n",
      "[97,   299] loss: 0.041207\n",
      "[97,   399] loss: 0.019649\n",
      "[97,   499] loss: 0.024766\n",
      "[97,   599] loss: 0.009607\n",
      "[97,   699] loss: 0.002513\n",
      "[98,    99] loss: 0.002040\n",
      "[98,   199] loss: 0.009526\n",
      "[98,   299] loss: 0.003292\n",
      "[98,   399] loss: 0.002065\n",
      "[98,   499] loss: 0.001154\n",
      "[98,   599] loss: 0.000947\n",
      "[98,   699] loss: 0.001312\n",
      "[99,    99] loss: 0.001392\n",
      "[99,   199] loss: 0.002035\n",
      "[99,   299] loss: 0.000950\n",
      "[99,   399] loss: 0.001023\n",
      "[99,   499] loss: 0.000728\n",
      "[99,   599] loss: 0.000478\n",
      "[99,   699] loss: 0.000785\n",
      "[100,    99] loss: 0.000903\n",
      "[100,   199] loss: 0.001268\n",
      "[100,   299] loss: 0.000615\n",
      "[100,   399] loss: 0.000843\n",
      "[100,   499] loss: 0.000573\n",
      "[100,   599] loss: 0.000350\n",
      "[100,   699] loss: 0.000560\n",
      "Finished Training\n",
      "[1,    99] loss: 0.704209\n",
      "[1,   199] loss: 0.673867\n",
      "[1,   299] loss: 0.657853\n",
      "[1,   399] loss: 0.648299\n",
      "[1,   499] loss: 0.605344\n",
      "[1,   599] loss: 0.633854\n",
      "[1,   699] loss: 0.628391\n",
      "[2,    99] loss: 0.598537\n",
      "[2,   199] loss: 0.533657\n",
      "[2,   299] loss: 0.530032\n",
      "[2,   399] loss: 0.539649\n",
      "[2,   499] loss: 0.449494\n",
      "[2,   599] loss: 0.503671\n",
      "[2,   699] loss: 0.472896\n",
      "[3,    99] loss: 0.453981\n",
      "[3,   199] loss: 0.430227\n",
      "[3,   299] loss: 0.412830\n",
      "[3,   399] loss: 0.434114\n",
      "[3,   499] loss: 0.319636\n",
      "[3,   599] loss: 0.387712\n",
      "[3,   699] loss: 0.353525\n",
      "[4,    99] loss: 0.343581\n",
      "[4,   199] loss: 0.332943\n",
      "[4,   299] loss: 0.312483\n",
      "[4,   399] loss: 0.368465\n",
      "[4,   499] loss: 0.228815\n",
      "[4,   599] loss: 0.301058\n",
      "[4,   699] loss: 0.259035\n",
      "[5,    99] loss: 0.254379\n",
      "[5,   199] loss: 0.273761\n",
      "[5,   299] loss: 0.249011\n",
      "[5,   399] loss: 0.319058\n",
      "[5,   499] loss: 0.183619\n",
      "[5,   599] loss: 0.239781\n",
      "[5,   699] loss: 0.262391\n",
      "[6,    99] loss: 0.213673\n",
      "[6,   199] loss: 0.224516\n",
      "[6,   299] loss: 0.198870\n",
      "[6,   399] loss: 0.276071\n",
      "[6,   499] loss: 0.155361\n",
      "[6,   599] loss: 0.205561\n",
      "[6,   699] loss: 0.182400\n",
      "[7,    99] loss: 0.164340\n",
      "[7,   199] loss: 0.188490\n",
      "[7,   299] loss: 0.197040\n",
      "[7,   399] loss: 0.245959\n",
      "[7,   499] loss: 0.132035\n",
      "[7,   599] loss: 0.183205\n",
      "[7,   699] loss: 0.175563\n",
      "[8,    99] loss: 0.146474\n",
      "[8,   199] loss: 0.165657\n",
      "[8,   299] loss: 0.151384\n",
      "[8,   399] loss: 0.213683\n",
      "[8,   499] loss: 0.134507\n",
      "[8,   599] loss: 0.209728\n",
      "[8,   699] loss: 0.121562\n",
      "[9,    99] loss: 0.109140\n",
      "[9,   199] loss: 0.157354\n",
      "[9,   299] loss: 0.108820\n",
      "[9,   399] loss: 0.196677\n",
      "[9,   499] loss: 0.094826\n",
      "[9,   599] loss: 0.148790\n",
      "[9,   699] loss: 0.107219\n",
      "[10,    99] loss: 0.094989\n",
      "[10,   199] loss: 0.117922\n",
      "[10,   299] loss: 0.099884\n",
      "[10,   399] loss: 0.176545\n",
      "[10,   499] loss: 0.083567\n",
      "[10,   599] loss: 0.174161\n",
      "[10,   699] loss: 0.227872\n",
      "[11,    99] loss: 0.096810\n",
      "[11,   199] loss: 0.120937\n",
      "[11,   299] loss: 0.115503\n",
      "[11,   399] loss: 0.111996\n",
      "[11,   499] loss: 0.057733\n",
      "[11,   599] loss: 0.101192\n",
      "[11,   699] loss: 0.099960\n",
      "[12,    99] loss: 0.084130\n",
      "[12,   199] loss: 0.075364\n",
      "[12,   299] loss: 0.088505\n",
      "[12,   399] loss: 0.159509\n",
      "[12,   499] loss: 0.061921\n",
      "[12,   599] loss: 0.121424\n",
      "[12,   699] loss: 0.145566\n",
      "[13,    99] loss: 0.205439\n",
      "[13,   199] loss: 0.131065\n",
      "[13,   299] loss: 0.173337\n",
      "[13,   399] loss: 0.186463\n",
      "[13,   499] loss: 0.049409\n",
      "[13,   599] loss: 0.085775\n",
      "[13,   699] loss: 0.078506\n",
      "[14,    99] loss: 0.062033\n",
      "[14,   199] loss: 0.097688\n",
      "[14,   299] loss: 0.109396\n",
      "[14,   399] loss: 0.133023\n",
      "[14,   499] loss: 0.052215\n",
      "[14,   599] loss: 0.092193\n",
      "[14,   699] loss: 0.071828\n",
      "[15,    99] loss: 0.065809\n",
      "[15,   199] loss: 0.093193\n",
      "[15,   299] loss: 0.083879\n",
      "[15,   399] loss: 0.091476\n",
      "[15,   499] loss: 0.052563\n",
      "[15,   599] loss: 0.095990\n",
      "[15,   699] loss: 0.195357\n",
      "[16,    99] loss: 0.124920\n",
      "[16,   199] loss: 0.096692\n",
      "[16,   299] loss: 0.135241\n",
      "[16,   399] loss: 0.079114\n",
      "[16,   499] loss: 0.055766\n",
      "[16,   599] loss: 0.068071\n",
      "[16,   699] loss: 0.056199\n",
      "[17,    99] loss: 0.065559\n",
      "[17,   199] loss: 0.081562\n",
      "[17,   299] loss: 0.068941\n",
      "[17,   399] loss: 0.050317\n",
      "[17,   499] loss: 0.030064\n",
      "[17,   599] loss: 0.062711\n",
      "[17,   699] loss: 0.081671\n",
      "[18,    99] loss: 0.054739\n",
      "[18,   199] loss: 0.103471\n",
      "[18,   299] loss: 0.086206\n",
      "[18,   399] loss: 0.059528\n",
      "[18,   499] loss: 0.036915\n",
      "[18,   599] loss: 0.060266\n",
      "[18,   699] loss: 0.087725\n",
      "[19,    99] loss: 0.049416\n",
      "[19,   199] loss: 0.111677\n",
      "[19,   299] loss: 0.073221\n",
      "[19,   399] loss: 0.137052\n",
      "[19,   499] loss: 0.025541\n",
      "[19,   599] loss: 0.055807\n",
      "[19,   699] loss: 0.093325\n",
      "[20,    99] loss: 0.039622\n",
      "[20,   199] loss: 0.054663\n",
      "[20,   299] loss: 0.072506\n",
      "[20,   399] loss: 0.082707\n",
      "[20,   499] loss: 0.041188\n",
      "[20,   599] loss: 0.173059\n",
      "[20,   699] loss: 0.135327\n",
      "[21,    99] loss: 0.105317\n",
      "[21,   199] loss: 0.057095\n",
      "[21,   299] loss: 0.060443\n",
      "[21,   399] loss: 0.052473\n",
      "[21,   499] loss: 0.037030\n",
      "[21,   599] loss: 0.048400\n",
      "[21,   699] loss: 0.040378\n",
      "[22,    99] loss: 0.031607\n",
      "[22,   199] loss: 0.058494\n",
      "[22,   299] loss: 0.063864\n",
      "[22,   399] loss: 0.088402\n",
      "[22,   499] loss: 0.018149\n",
      "[22,   599] loss: 0.033400\n",
      "[22,   699] loss: 0.081794\n",
      "[23,    99] loss: 0.038464\n",
      "[23,   199] loss: 0.076439\n",
      "[23,   299] loss: 0.087937\n",
      "[23,   399] loss: 0.057735\n",
      "[23,   499] loss: 0.035683\n",
      "[23,   599] loss: 0.071743\n",
      "[23,   699] loss: 0.244806\n",
      "[24,    99] loss: 0.104396\n",
      "[24,   199] loss: 0.055737\n",
      "[24,   299] loss: 0.046771\n",
      "[24,   399] loss: 0.060101\n",
      "[24,   499] loss: 0.041311\n",
      "[24,   599] loss: 0.037011\n",
      "[24,   699] loss: 0.059326\n",
      "[25,    99] loss: 0.030719\n",
      "[25,   199] loss: 0.037784\n",
      "[25,   299] loss: 0.048021\n",
      "[25,   399] loss: 0.039005\n",
      "[25,   499] loss: 0.028778\n",
      "[25,   599] loss: 0.022351\n",
      "[25,   699] loss: 0.047337\n",
      "[26,    99] loss: 0.026513\n",
      "[26,   199] loss: 0.056865\n",
      "[26,   299] loss: 0.042707\n",
      "[26,   399] loss: 0.027522\n",
      "[26,   499] loss: 0.028087\n",
      "[26,   599] loss: 0.022977\n",
      "[26,   699] loss: 0.052272\n",
      "[27,    99] loss: 0.024298\n",
      "[27,   199] loss: 0.055555\n",
      "[27,   299] loss: 0.028070\n",
      "[27,   399] loss: 0.031390\n",
      "[27,   499] loss: 0.017724\n",
      "[27,   599] loss: 0.024038\n",
      "[27,   699] loss: 0.036769\n",
      "[28,    99] loss: 0.019879\n",
      "[28,   199] loss: 0.073201\n",
      "[28,   299] loss: 0.119912\n",
      "[28,   399] loss: 0.159265\n",
      "[28,   499] loss: 0.019896\n",
      "[28,   599] loss: 0.036626\n",
      "[28,   699] loss: 0.102348\n",
      "[29,    99] loss: 0.047731\n",
      "[29,   199] loss: 0.156560\n",
      "[29,   299] loss: 0.076757\n",
      "[29,   399] loss: 0.121402\n",
      "[29,   499] loss: 0.368917\n",
      "[29,   599] loss: 0.044113\n",
      "[29,   699] loss: 0.057096\n",
      "[30,    99] loss: 0.014984\n",
      "[30,   199] loss: 0.024542\n",
      "[30,   299] loss: 0.018391\n",
      "[30,   399] loss: 0.026109\n",
      "[30,   499] loss: 0.013135\n",
      "[30,   599] loss: 0.013270\n",
      "[30,   699] loss: 0.018425\n",
      "[31,    99] loss: 0.009991\n",
      "[31,   199] loss: 0.017587\n",
      "[31,   299] loss: 0.008360\n",
      "[31,   399] loss: 0.017517\n",
      "[31,   499] loss: 0.014204\n",
      "[31,   599] loss: 0.009208\n",
      "[31,   699] loss: 0.040049\n",
      "[32,    99] loss: 0.022262\n",
      "[32,   199] loss: 0.040995\n",
      "[32,   299] loss: 0.019505\n",
      "[32,   399] loss: 0.022542\n",
      "[32,   499] loss: 0.012343\n",
      "[32,   599] loss: 0.026208\n",
      "[32,   699] loss: 0.083022\n",
      "[33,    99] loss: 0.058457\n",
      "[33,   199] loss: 0.039947\n",
      "[33,   299] loss: 0.088358\n",
      "[33,   399] loss: 0.277766\n",
      "[33,   499] loss: 0.137523\n",
      "[33,   599] loss: 0.090136\n",
      "[33,   699] loss: 0.092320\n",
      "[34,    99] loss: 0.024939\n",
      "[34,   199] loss: 0.090207\n",
      "[34,   299] loss: 0.042310\n",
      "[34,   399] loss: 0.047951\n",
      "[34,   499] loss: 0.020161\n",
      "[34,   599] loss: 0.015999\n",
      "[34,   699] loss: 0.023527\n",
      "[35,    99] loss: 0.008426\n",
      "[35,   199] loss: 0.030012\n",
      "[35,   299] loss: 0.017681\n",
      "[35,   399] loss: 0.021625\n",
      "[35,   499] loss: 0.016937\n",
      "[35,   599] loss: 0.025888\n",
      "[35,   699] loss: 0.050774\n",
      "[36,    99] loss: 0.043524\n",
      "[36,   199] loss: 0.159403\n",
      "[36,   299] loss: 0.009003\n",
      "[36,   399] loss: 0.030942\n",
      "[36,   499] loss: 0.011681\n",
      "[36,   599] loss: 0.014035\n",
      "[36,   699] loss: 0.050423\n",
      "[37,    99] loss: 0.005698\n",
      "[37,   199] loss: 0.025535\n",
      "[37,   299] loss: 0.005080\n",
      "[37,   399] loss: 0.032858\n",
      "[37,   499] loss: 0.027960\n",
      "[37,   599] loss: 0.032663\n",
      "[37,   699] loss: 0.030008\n",
      "[38,    99] loss: 0.042206\n",
      "[38,   199] loss: 0.056745\n",
      "[38,   299] loss: 0.042300\n",
      "[38,   399] loss: 0.031452\n",
      "[38,   499] loss: 0.015188\n",
      "[38,   599] loss: 0.010140\n",
      "[38,   699] loss: 0.031715\n",
      "[39,    99] loss: 0.008825\n",
      "[39,   199] loss: 0.019248\n",
      "[39,   299] loss: 0.007213\n",
      "[39,   399] loss: 0.016780\n",
      "[39,   499] loss: 0.004178\n",
      "[39,   599] loss: 0.039803\n",
      "[39,   699] loss: 0.043032\n",
      "[40,    99] loss: 0.136868\n",
      "[40,   199] loss: 0.346915\n",
      "[40,   299] loss: 0.021543\n",
      "[40,   399] loss: 0.177347\n",
      "[40,   499] loss: 0.032154\n",
      "[40,   599] loss: 0.036175\n",
      "[40,   699] loss: 0.046543\n",
      "[41,    99] loss: 0.044601\n",
      "[41,   199] loss: 0.023259\n",
      "[41,   299] loss: 0.037795\n",
      "[41,   399] loss: 0.034453\n",
      "[41,   499] loss: 0.267667\n",
      "[41,   599] loss: 0.026953\n",
      "[41,   699] loss: 0.049692\n",
      "[42,    99] loss: 0.015992\n",
      "[42,   199] loss: 0.011747\n",
      "[42,   299] loss: 0.022645\n",
      "[42,   399] loss: 0.026158\n",
      "[42,   499] loss: 0.041938\n",
      "[42,   599] loss: 0.028007\n",
      "[42,   699] loss: 0.082435\n",
      "[43,    99] loss: 0.011014\n",
      "[43,   199] loss: 0.027365\n",
      "[43,   299] loss: 0.004458\n",
      "[43,   399] loss: 0.042085\n",
      "[43,   499] loss: 0.048509\n",
      "[43,   599] loss: 0.035206\n",
      "[43,   699] loss: 0.023221\n",
      "[44,    99] loss: 0.020258\n",
      "[44,   199] loss: 0.010049\n",
      "[44,   299] loss: 0.004356\n",
      "[44,   399] loss: 0.023843\n",
      "[44,   499] loss: 0.016723\n",
      "[44,   599] loss: 0.013006\n",
      "[44,   699] loss: 0.027260\n",
      "[45,    99] loss: 0.017018\n",
      "[45,   199] loss: 0.027174\n",
      "[45,   299] loss: 0.020673\n",
      "[45,   399] loss: 0.011942\n",
      "[45,   499] loss: 0.005888\n",
      "[45,   599] loss: 0.010779\n",
      "[45,   699] loss: 0.044842\n",
      "[46,    99] loss: 0.132695\n",
      "[46,   199] loss: 0.018253\n",
      "[46,   299] loss: 0.006612\n",
      "[46,   399] loss: 0.015763\n",
      "[46,   499] loss: 0.003566\n",
      "[46,   599] loss: 0.005723\n",
      "[46,   699] loss: 0.026588\n",
      "[47,    99] loss: 0.002272\n",
      "[47,   199] loss: 0.024576\n",
      "[47,   299] loss: 0.016940\n",
      "[47,   399] loss: 0.055379\n",
      "[47,   499] loss: 0.029127\n",
      "[47,   599] loss: 0.064158\n",
      "[47,   699] loss: 0.061421\n",
      "[48,    99] loss: 0.010785\n",
      "[48,   199] loss: 0.004137\n",
      "[48,   299] loss: 0.004640\n",
      "[48,   399] loss: 0.050957\n",
      "[48,   499] loss: 0.006242\n",
      "[48,   599] loss: 0.003860\n",
      "[48,   699] loss: 0.027270\n",
      "[49,    99] loss: 0.004707\n",
      "[49,   199] loss: 0.006437\n",
      "[49,   299] loss: 0.062585\n",
      "[49,   399] loss: 0.028079\n",
      "[49,   499] loss: 0.015615\n",
      "[49,   599] loss: 0.013789\n",
      "[49,   699] loss: 0.047885\n",
      "[50,    99] loss: 0.045263\n",
      "[50,   199] loss: 0.182906\n",
      "[50,   299] loss: 0.038822\n",
      "[50,   399] loss: 0.082728\n",
      "[50,   499] loss: 0.010227\n",
      "[50,   599] loss: 0.009792\n",
      "[50,   699] loss: 0.032032\n",
      "[51,    99] loss: 0.023601\n",
      "[51,   199] loss: 0.007144\n",
      "[51,   299] loss: 0.006070\n",
      "[51,   399] loss: 0.125225\n",
      "[51,   499] loss: 0.470836\n",
      "[51,   599] loss: 0.088959\n",
      "[51,   699] loss: 0.185910\n",
      "[52,    99] loss: 0.076563\n",
      "[52,   199] loss: 0.021068\n",
      "[52,   299] loss: 0.032205\n",
      "[52,   399] loss: 0.041342\n",
      "[52,   499] loss: 0.006197\n",
      "[52,   599] loss: 0.045103\n",
      "[52,   699] loss: 0.025201\n",
      "[53,    99] loss: 0.009985\n",
      "[53,   199] loss: 0.015782\n",
      "[53,   299] loss: 0.009497\n",
      "[53,   399] loss: 0.028180\n",
      "[53,   499] loss: 0.176384\n",
      "[53,   599] loss: 0.010875\n",
      "[53,   699] loss: 0.010909\n",
      "[54,    99] loss: 0.006824\n",
      "[54,   199] loss: 0.053157\n",
      "[54,   299] loss: 0.020659\n",
      "[54,   399] loss: 0.093847\n",
      "[54,   499] loss: 0.016743\n",
      "[54,   599] loss: 0.003667\n",
      "[54,   699] loss: 0.014105\n",
      "[55,    99] loss: 0.002368\n",
      "[55,   199] loss: 0.001571\n",
      "[55,   299] loss: 0.005737\n",
      "[55,   399] loss: 0.011850\n",
      "[55,   499] loss: 0.001430\n",
      "[55,   599] loss: 0.003184\n",
      "[55,   699] loss: 0.018002\n",
      "[56,    99] loss: 0.004853\n",
      "[56,   199] loss: 0.014396\n",
      "[56,   299] loss: 0.009787\n",
      "[56,   399] loss: 0.037384\n",
      "[56,   499] loss: 0.044689\n",
      "[56,   599] loss: 0.039517\n",
      "[56,   699] loss: 0.059787\n",
      "[57,    99] loss: 0.035327\n",
      "[57,   199] loss: 0.050116\n",
      "[57,   299] loss: 0.260055\n",
      "[57,   399] loss: 0.187521\n",
      "[57,   499] loss: 0.007249\n",
      "[57,   599] loss: 0.038512\n",
      "[57,   699] loss: 0.032722\n",
      "[58,    99] loss: 0.007678\n",
      "[58,   199] loss: 0.039759\n",
      "[58,   299] loss: 0.016962\n",
      "[58,   399] loss: 0.067167\n",
      "[58,   499] loss: 0.004352\n",
      "[58,   599] loss: 0.024751\n",
      "[58,   699] loss: 0.012768\n",
      "[59,    99] loss: 0.004714\n",
      "[59,   199] loss: 0.005291\n",
      "[59,   299] loss: 0.003640\n",
      "[59,   399] loss: 0.007194\n",
      "[59,   499] loss: 0.001799\n",
      "[59,   599] loss: 0.002532\n",
      "[59,   699] loss: 0.026981\n",
      "[60,    99] loss: 0.005213\n",
      "[60,   199] loss: 0.008694\n",
      "[60,   299] loss: 0.002590\n",
      "[60,   399] loss: 0.056100\n",
      "[60,   499] loss: 0.022928\n",
      "[60,   599] loss: 0.058982\n",
      "[60,   699] loss: 0.039518\n",
      "[61,    99] loss: 0.015175\n",
      "[61,   199] loss: 0.017926\n",
      "[61,   299] loss: 0.002895\n",
      "[61,   399] loss: 0.009553\n",
      "[61,   499] loss: 0.002394\n",
      "[61,   599] loss: 0.006603\n",
      "[61,   699] loss: 0.013930\n",
      "[62,    99] loss: 0.073443\n",
      "[62,   199] loss: 0.003475\n",
      "[62,   299] loss: 0.002991\n",
      "[62,   399] loss: 0.004893\n",
      "[62,   499] loss: 0.033780\n",
      "[62,   599] loss: 0.006838\n",
      "[62,   699] loss: 0.012029\n",
      "[63,    99] loss: 0.006846\n",
      "[63,   199] loss: 0.136822\n",
      "[63,   299] loss: 0.093498\n",
      "[63,   399] loss: 0.042909\n",
      "[63,   499] loss: 0.106001\n",
      "[63,   599] loss: 0.005364\n",
      "[63,   699] loss: 0.041775\n",
      "[64,    99] loss: 0.029997\n",
      "[64,   199] loss: 0.120442\n",
      "[64,   299] loss: 0.004053\n",
      "[64,   399] loss: 0.012503\n",
      "[64,   499] loss: 0.041257\n",
      "[64,   599] loss: 0.060924\n",
      "[64,   699] loss: 0.022440\n",
      "[65,    99] loss: 0.017348\n",
      "[65,   199] loss: 0.039903\n",
      "[65,   299] loss: 0.014638\n",
      "[65,   399] loss: 0.011649\n",
      "[65,   499] loss: 0.047555\n",
      "[65,   599] loss: 0.018241\n",
      "[65,   699] loss: 0.006121\n",
      "[66,    99] loss: 0.005255\n",
      "[66,   199] loss: 0.009493\n",
      "[66,   299] loss: 0.017989\n",
      "[66,   399] loss: 0.038065\n",
      "[66,   499] loss: 0.004433\n",
      "[66,   599] loss: 0.002583\n",
      "[66,   699] loss: 0.046193\n",
      "[67,    99] loss: 0.004111\n",
      "[67,   199] loss: 0.003809\n",
      "[67,   299] loss: 0.001601\n",
      "[67,   399] loss: 0.002937\n",
      "[67,   499] loss: 0.008187\n",
      "[67,   599] loss: 0.001205\n",
      "[67,   699] loss: 0.004760\n",
      "[68,    99] loss: 0.000937\n",
      "[68,   199] loss: 0.004551\n",
      "[68,   299] loss: 0.001303\n",
      "[68,   399] loss: 0.007156\n",
      "[68,   499] loss: 0.003316\n",
      "[68,   599] loss: 0.071358\n",
      "[68,   699] loss: 0.075623\n",
      "[69,    99] loss: 0.011599\n",
      "[69,   199] loss: 0.011281\n",
      "[69,   299] loss: 0.004014\n",
      "[69,   399] loss: 0.035250\n",
      "[69,   499] loss: 0.021582\n",
      "[69,   599] loss: 0.183077\n",
      "[69,   699] loss: 0.055408\n",
      "[70,    99] loss: 0.020869\n",
      "[70,   199] loss: 0.013330\n",
      "[70,   299] loss: 0.008449\n",
      "[70,   399] loss: 0.018726\n",
      "[70,   499] loss: 0.017153\n",
      "[70,   599] loss: 0.004415\n",
      "[70,   699] loss: 0.032086\n",
      "[71,    99] loss: 0.001557\n",
      "[71,   199] loss: 0.152298\n",
      "[71,   299] loss: 0.007104\n",
      "[71,   399] loss: 0.020850\n",
      "[71,   499] loss: 0.005013\n",
      "[71,   599] loss: 0.008168\n",
      "[71,   699] loss: 0.007468\n",
      "[72,    99] loss: 0.005026\n",
      "[72,   199] loss: 0.007442\n",
      "[72,   299] loss: 0.002489\n",
      "[72,   399] loss: 0.003655\n",
      "[72,   499] loss: 0.000794\n",
      "[72,   599] loss: 0.001685\n",
      "[72,   699] loss: 0.005653\n",
      "[73,    99] loss: 0.001917\n",
      "[73,   199] loss: 0.005553\n",
      "[73,   299] loss: 0.003328\n",
      "[73,   399] loss: 0.001779\n",
      "[73,   499] loss: 0.000714\n",
      "[73,   599] loss: 0.000966\n",
      "[73,   699] loss: 0.015240\n",
      "[74,    99] loss: 0.001504\n",
      "[74,   199] loss: 0.004414\n",
      "[74,   299] loss: 0.002438\n",
      "[74,   399] loss: 0.002782\n",
      "[74,   499] loss: 0.000530\n",
      "[74,   599] loss: 0.001761\n",
      "[74,   699] loss: 0.049045\n",
      "[75,    99] loss: 0.107222\n",
      "[75,   199] loss: 0.101464\n",
      "[75,   299] loss: 0.155208\n",
      "[75,   399] loss: 0.014830\n",
      "[75,   499] loss: 0.008605\n",
      "[75,   599] loss: 0.043262\n",
      "[75,   699] loss: 0.106898\n",
      "[76,    99] loss: 0.224590\n",
      "[76,   199] loss: 0.059685\n",
      "[76,   299] loss: 0.002215\n",
      "[76,   399] loss: 0.068781\n",
      "[76,   499] loss: 0.014111\n",
      "[76,   599] loss: 0.008788\n",
      "[76,   699] loss: 0.042176\n",
      "[77,    99] loss: 0.005902\n",
      "[77,   199] loss: 0.016492\n",
      "[77,   299] loss: 0.025450\n",
      "[77,   399] loss: 0.012706\n",
      "[77,   499] loss: 0.001962\n",
      "[77,   599] loss: 0.002368\n",
      "[77,   699] loss: 0.032098\n",
      "[78,    99] loss: 0.008172\n",
      "[78,   199] loss: 0.004299\n",
      "[78,   299] loss: 0.000848\n",
      "[78,   399] loss: 0.012097\n",
      "[78,   499] loss: 0.001157\n",
      "[78,   599] loss: 0.001258\n",
      "[78,   699] loss: 0.018072\n",
      "[79,    99] loss: 0.014821\n",
      "[79,   199] loss: 0.003083\n",
      "[79,   299] loss: 0.000697\n",
      "[79,   399] loss: 0.026864\n",
      "[79,   499] loss: 0.009396\n",
      "[79,   599] loss: 0.014327\n",
      "[79,   699] loss: 0.026072\n",
      "[80,    99] loss: 0.036479\n",
      "[80,   199] loss: 0.002535\n",
      "[80,   299] loss: 0.001253\n",
      "[80,   399] loss: 0.013410\n",
      "[80,   499] loss: 0.003778\n",
      "[80,   599] loss: 0.001400\n",
      "[80,   699] loss: 0.006458\n",
      "[81,    99] loss: 0.005742\n",
      "[81,   199] loss: 0.029283\n",
      "[81,   299] loss: 0.059528\n",
      "[81,   399] loss: 0.003275\n",
      "[81,   499] loss: 0.000730\n",
      "[81,   599] loss: 0.010944\n",
      "[81,   699] loss: 0.006921\n",
      "[82,    99] loss: 0.002114\n",
      "[82,   199] loss: 0.003495\n",
      "[82,   299] loss: 0.000544\n",
      "[82,   399] loss: 0.001627\n",
      "[82,   499] loss: 0.000611\n",
      "[82,   599] loss: 0.000524\n",
      "[82,   699] loss: 0.005222\n",
      "[83,    99] loss: 0.001562\n",
      "[83,   199] loss: 0.003423\n",
      "[83,   299] loss: 0.000463\n",
      "[83,   399] loss: 0.001204\n",
      "[83,   499] loss: 0.000266\n",
      "[83,   599] loss: 0.000427\n",
      "[83,   699] loss: 0.011179\n",
      "[84,    99] loss: 0.002635\n",
      "[84,   199] loss: 0.026260\n",
      "[84,   299] loss: 0.002288\n",
      "[84,   399] loss: 0.046983\n",
      "[84,   499] loss: 0.007747\n",
      "[84,   599] loss: 0.013358\n",
      "[84,   699] loss: 0.107030\n",
      "[85,    99] loss: 0.014373\n",
      "[85,   199] loss: 0.013943\n",
      "[85,   299] loss: 0.002735\n",
      "[85,   399] loss: 0.003992\n",
      "[85,   499] loss: 0.000361\n",
      "[85,   599] loss: 0.004543\n",
      "[85,   699] loss: 0.005248\n",
      "[86,    99] loss: 0.008074\n",
      "[86,   199] loss: 0.009650\n",
      "[86,   299] loss: 0.005503\n",
      "[86,   399] loss: 0.043679\n",
      "[86,   499] loss: 0.181247\n",
      "[86,   599] loss: 0.009443\n",
      "[86,   699] loss: 0.022225\n",
      "[87,    99] loss: 0.054549\n",
      "[87,   199] loss: 0.009373\n",
      "[87,   299] loss: 0.014477\n",
      "[87,   399] loss: 0.059030\n",
      "[87,   499] loss: 0.012918\n",
      "[87,   599] loss: 0.002729\n",
      "[87,   699] loss: 0.027513\n",
      "[88,    99] loss: 0.004062\n",
      "[88,   199] loss: 0.045463\n",
      "[88,   299] loss: 0.029832\n",
      "[88,   399] loss: 0.014958\n",
      "[88,   499] loss: 0.000823\n",
      "[88,   599] loss: 0.000549\n",
      "[88,   699] loss: 0.003188\n",
      "[89,    99] loss: 0.001758\n",
      "[89,   199] loss: 0.001646\n",
      "[89,   299] loss: 0.000406\n",
      "[89,   399] loss: 0.001632\n",
      "[89,   499] loss: 0.000491\n",
      "[89,   599] loss: 0.000387\n",
      "[89,   699] loss: 0.001254\n",
      "[90,    99] loss: 0.000705\n",
      "[90,   199] loss: 0.000760\n",
      "[90,   299] loss: 0.000352\n",
      "[90,   399] loss: 0.001067\n",
      "[90,   499] loss: 0.000365\n",
      "[90,   599] loss: 0.000314\n",
      "[90,   699] loss: 0.000776\n",
      "[91,    99] loss: 0.000447\n",
      "[91,   199] loss: 0.000600\n",
      "[91,   299] loss: 0.000288\n",
      "[91,   399] loss: 0.000814\n",
      "[91,   499] loss: 0.000266\n",
      "[91,   599] loss: 0.000250\n",
      "[91,   699] loss: 0.000745\n",
      "[92,    99] loss: 0.000374\n",
      "[92,   199] loss: 0.000934\n",
      "[92,   299] loss: 0.000323\n",
      "[92,   399] loss: 0.000609\n",
      "[92,   499] loss: 0.000189\n",
      "[92,   599] loss: 0.000208\n",
      "[92,   699] loss: 0.001144\n",
      "[93,    99] loss: 0.000662\n",
      "[93,   199] loss: 0.049296\n",
      "[93,   299] loss: 0.101265\n",
      "[93,   399] loss: 0.186819\n",
      "[93,   499] loss: 0.063913\n",
      "[93,   599] loss: 0.114090\n",
      "[93,   699] loss: 0.140392\n",
      "[94,    99] loss: 0.131836\n",
      "[94,   199] loss: 0.065118\n",
      "[94,   299] loss: 0.061576\n",
      "[94,   399] loss: 0.106484\n",
      "[94,   499] loss: 0.014737\n",
      "[94,   599] loss: 0.012131\n",
      "[94,   699] loss: 0.011956\n",
      "[95,    99] loss: 0.004117\n",
      "[95,   199] loss: 0.000898\n",
      "[95,   299] loss: 0.001295\n",
      "[95,   399] loss: 0.003713\n",
      "[95,   499] loss: 0.002038\n",
      "[95,   599] loss: 0.001754\n",
      "[95,   699] loss: 0.002075\n",
      "[96,    99] loss: 0.000970\n",
      "[96,   199] loss: 0.000587\n",
      "[96,   299] loss: 0.000969\n",
      "[96,   399] loss: 0.001717\n",
      "[96,   499] loss: 0.000609\n",
      "[96,   599] loss: 0.000721\n",
      "[96,   699] loss: 0.001543\n",
      "[97,    99] loss: 0.000643\n",
      "[97,   199] loss: 0.000452\n",
      "[97,   299] loss: 0.000746\n",
      "[97,   399] loss: 0.001289\n",
      "[97,   499] loss: 0.000387\n",
      "[97,   599] loss: 0.000520\n",
      "[97,   699] loss: 0.001191\n",
      "[98,    99] loss: 0.000444\n",
      "[98,   199] loss: 0.000364\n",
      "[98,   299] loss: 0.000563\n",
      "[98,   399] loss: 0.000896\n",
      "[98,   499] loss: 0.000280\n",
      "[98,   599] loss: 0.000381\n",
      "[98,   699] loss: 0.000942\n",
      "[99,    99] loss: 0.000378\n",
      "[99,   199] loss: 0.000303\n",
      "[99,   299] loss: 0.000414\n",
      "[99,   399] loss: 0.000738\n",
      "[99,   499] loss: 0.000201\n",
      "[99,   599] loss: 0.000285\n",
      "[99,   699] loss: 0.000740\n",
      "[100,    99] loss: 0.000244\n",
      "[100,   199] loss: 0.000272\n",
      "[100,   299] loss: 0.000312\n",
      "[100,   399] loss: 0.000519\n",
      "[100,   499] loss: 0.000153\n",
      "[100,   599] loss: 0.000215\n",
      "[100,   699] loss: 0.000583\n",
      "Finished Training\n",
      "[1,    99] loss: 0.696190\n",
      "[1,   199] loss: 0.678650\n",
      "[1,   299] loss: 0.670418\n",
      "[1,   399] loss: 0.653793\n",
      "[1,   499] loss: 0.674302\n",
      "[1,   599] loss: 0.642099\n",
      "[1,   699] loss: 0.625873\n",
      "[2,    99] loss: 0.648029\n",
      "[2,   199] loss: 0.583136\n",
      "[2,   299] loss: 0.533591\n",
      "[2,   399] loss: 0.566462\n",
      "[2,   499] loss: 0.614532\n",
      "[2,   599] loss: 0.565800\n",
      "[2,   699] loss: 0.521770\n",
      "[3,    99] loss: 0.562027\n",
      "[3,   199] loss: 0.479176\n",
      "[3,   299] loss: 0.464313\n",
      "[3,   399] loss: 0.465547\n",
      "[3,   499] loss: 0.504390\n",
      "[3,   599] loss: 0.498070\n",
      "[3,   699] loss: 0.430664\n",
      "[4,    99] loss: 0.451482\n",
      "[4,   199] loss: 0.367095\n",
      "[4,   299] loss: 0.375758\n",
      "[4,   399] loss: 0.394097\n",
      "[4,   499] loss: 0.411292\n",
      "[4,   599] loss: 0.450398\n",
      "[4,   699] loss: 0.366977\n",
      "[5,    99] loss: 0.348860\n",
      "[5,   199] loss: 0.285492\n",
      "[5,   299] loss: 0.333260\n",
      "[5,   399] loss: 0.325846\n",
      "[5,   499] loss: 0.351138\n",
      "[5,   599] loss: 0.410687\n",
      "[5,   699] loss: 0.298713\n",
      "[6,    99] loss: 0.283998\n",
      "[6,   199] loss: 0.223622\n",
      "[6,   299] loss: 0.285813\n",
      "[6,   399] loss: 0.286848\n",
      "[6,   499] loss: 0.292144\n",
      "[6,   599] loss: 0.355448\n",
      "[6,   699] loss: 0.258984\n",
      "[7,    99] loss: 0.253894\n",
      "[7,   199] loss: 0.183346\n",
      "[7,   299] loss: 0.231595\n",
      "[7,   399] loss: 0.238487\n",
      "[7,   499] loss: 0.250358\n",
      "[7,   599] loss: 0.336043\n",
      "[7,   699] loss: 0.211909\n",
      "[8,    99] loss: 0.204820\n",
      "[8,   199] loss: 0.150126\n",
      "[8,   299] loss: 0.186571\n",
      "[8,   399] loss: 0.206311\n",
      "[8,   499] loss: 0.216438\n",
      "[8,   599] loss: 0.287182\n",
      "[8,   699] loss: 0.166638\n",
      "[9,    99] loss: 0.170857\n",
      "[9,   199] loss: 0.143425\n",
      "[9,   299] loss: 0.162695\n",
      "[9,   399] loss: 0.166362\n",
      "[9,   499] loss: 0.194804\n",
      "[9,   599] loss: 0.266388\n",
      "[9,   699] loss: 0.132231\n",
      "[10,    99] loss: 0.156082\n",
      "[10,   199] loss: 0.117288\n",
      "[10,   299] loss: 0.158955\n",
      "[10,   399] loss: 0.165021\n",
      "[10,   499] loss: 0.179899\n",
      "[10,   599] loss: 0.214806\n",
      "[10,   699] loss: 0.104640\n",
      "[11,    99] loss: 0.106491\n",
      "[11,   199] loss: 0.104781\n",
      "[11,   299] loss: 0.147024\n",
      "[11,   399] loss: 0.128670\n",
      "[11,   499] loss: 0.228986\n",
      "[11,   599] loss: 0.257276\n",
      "[11,   699] loss: 0.087148\n",
      "[12,    99] loss: 0.093458\n",
      "[12,   199] loss: 0.092540\n",
      "[12,   299] loss: 0.118094\n",
      "[12,   399] loss: 0.133538\n",
      "[12,   499] loss: 0.151942\n",
      "[12,   599] loss: 0.190373\n",
      "[12,   699] loss: 0.075623\n",
      "[13,    99] loss: 0.084654\n",
      "[13,   199] loss: 0.103652\n",
      "[13,   299] loss: 0.158449\n",
      "[13,   399] loss: 0.104170\n",
      "[13,   499] loss: 0.163129\n",
      "[13,   599] loss: 0.163772\n",
      "[13,   699] loss: 0.059524\n",
      "[14,    99] loss: 0.086817\n",
      "[14,   199] loss: 0.059200\n",
      "[14,   299] loss: 0.107964\n",
      "[14,   399] loss: 0.105199\n",
      "[14,   499] loss: 0.222427\n",
      "[14,   599] loss: 0.234606\n",
      "[14,   699] loss: 0.050165\n",
      "[15,    99] loss: 0.063072\n",
      "[15,   199] loss: 0.076034\n",
      "[15,   299] loss: 0.085059\n",
      "[15,   399] loss: 0.078616\n",
      "[15,   499] loss: 0.193146\n",
      "[15,   599] loss: 0.168934\n",
      "[15,   699] loss: 0.067666\n",
      "[16,    99] loss: 0.060137\n",
      "[16,   199] loss: 0.066081\n",
      "[16,   299] loss: 0.128182\n",
      "[16,   399] loss: 0.085023\n",
      "[16,   499] loss: 0.141473\n",
      "[16,   599] loss: 0.138513\n",
      "[16,   699] loss: 0.038727\n",
      "[17,    99] loss: 0.054826\n",
      "[17,   199] loss: 0.056470\n",
      "[17,   299] loss: 0.145645\n",
      "[17,   399] loss: 0.086131\n",
      "[17,   499] loss: 0.161413\n",
      "[17,   599] loss: 0.142761\n",
      "[17,   699] loss: 0.036749\n",
      "[18,    99] loss: 0.049715\n",
      "[18,   199] loss: 0.044838\n",
      "[18,   299] loss: 0.066391\n",
      "[18,   399] loss: 0.071277\n",
      "[18,   499] loss: 0.144515\n",
      "[18,   599] loss: 0.148168\n",
      "[18,   699] loss: 0.076074\n",
      "[19,    99] loss: 0.073981\n",
      "[19,   199] loss: 0.033978\n",
      "[19,   299] loss: 0.073271\n",
      "[19,   399] loss: 0.076815\n",
      "[19,   499] loss: 0.164063\n",
      "[19,   599] loss: 0.105397\n",
      "[19,   699] loss: 0.027566\n",
      "[20,    99] loss: 0.051949\n",
      "[20,   199] loss: 0.029379\n",
      "[20,   299] loss: 0.046787\n",
      "[20,   399] loss: 0.078339\n",
      "[20,   499] loss: 0.136630\n",
      "[20,   599] loss: 0.113077\n",
      "[20,   699] loss: 0.021444\n",
      "[21,    99] loss: 0.032179\n",
      "[21,   199] loss: 0.033846\n",
      "[21,   299] loss: 0.062832\n",
      "[21,   399] loss: 0.064398\n",
      "[21,   499] loss: 0.121712\n",
      "[21,   599] loss: 0.122529\n",
      "[21,   699] loss: 0.032239\n",
      "[22,    99] loss: 0.039216\n",
      "[22,   199] loss: 0.036679\n",
      "[22,   299] loss: 0.049008\n",
      "[22,   399] loss: 0.066323\n",
      "[22,   499] loss: 0.091527\n",
      "[22,   599] loss: 0.160569\n",
      "[22,   699] loss: 0.052921\n",
      "[23,    99] loss: 0.047421\n",
      "[23,   199] loss: 0.039122\n",
      "[23,   299] loss: 0.027668\n",
      "[23,   399] loss: 0.069498\n",
      "[23,   499] loss: 0.116607\n",
      "[23,   599] loss: 0.134986\n",
      "[23,   699] loss: 0.029596\n",
      "[24,    99] loss: 0.045110\n",
      "[24,   199] loss: 0.021435\n",
      "[24,   299] loss: 0.044190\n",
      "[24,   399] loss: 0.042475\n",
      "[24,   499] loss: 0.118358\n",
      "[24,   599] loss: 0.097528\n",
      "[24,   699] loss: 0.013971\n",
      "[25,    99] loss: 0.028232\n",
      "[25,   199] loss: 0.024810\n",
      "[25,   299] loss: 0.080687\n",
      "[25,   399] loss: 0.072743\n",
      "[25,   499] loss: 0.068883\n",
      "[25,   599] loss: 0.096625\n",
      "[25,   699] loss: 0.020386\n",
      "[26,    99] loss: 0.021803\n",
      "[26,   199] loss: 0.025700\n",
      "[26,   299] loss: 0.035280\n",
      "[26,   399] loss: 0.065212\n",
      "[26,   499] loss: 0.128418\n",
      "[26,   599] loss: 0.173392\n",
      "[26,   699] loss: 0.014644\n",
      "[27,    99] loss: 0.016341\n",
      "[27,   199] loss: 0.020616\n",
      "[27,   299] loss: 0.033460\n",
      "[27,   399] loss: 0.054214\n",
      "[27,   499] loss: 0.097671\n",
      "[27,   599] loss: 0.064304\n",
      "[27,   699] loss: 0.122454\n",
      "[28,    99] loss: 0.096319\n",
      "[28,   199] loss: 0.042092\n",
      "[28,   299] loss: 0.059626\n",
      "[28,   399] loss: 0.053644\n",
      "[28,   499] loss: 0.068202\n",
      "[28,   599] loss: 0.039469\n",
      "[28,   699] loss: 0.063830\n",
      "[29,    99] loss: 0.038595\n",
      "[29,   199] loss: 0.028213\n",
      "[29,   299] loss: 0.069322\n",
      "[29,   399] loss: 0.023233\n",
      "[29,   499] loss: 0.077543\n",
      "[29,   599] loss: 0.136982\n",
      "[29,   699] loss: 0.039903\n",
      "[30,    99] loss: 0.092929\n",
      "[30,   199] loss: 0.070316\n",
      "[30,   299] loss: 0.096984\n",
      "[30,   399] loss: 0.056993\n",
      "[30,   499] loss: 0.063702\n",
      "[30,   599] loss: 0.097578\n",
      "[30,   699] loss: 0.028255\n",
      "[31,    99] loss: 0.036312\n",
      "[31,   199] loss: 0.024985\n",
      "[31,   299] loss: 0.023668\n",
      "[31,   399] loss: 0.022795\n",
      "[31,   499] loss: 0.056266\n",
      "[31,   599] loss: 0.084916\n",
      "[31,   699] loss: 0.007897\n",
      "[32,    99] loss: 0.012478\n",
      "[32,   199] loss: 0.013995\n",
      "[32,   299] loss: 0.018045\n",
      "[32,   399] loss: 0.011137\n",
      "[32,   499] loss: 0.045893\n",
      "[32,   599] loss: 0.091112\n",
      "[32,   699] loss: 0.022447\n",
      "[33,    99] loss: 0.029812\n",
      "[33,   199] loss: 0.027415\n",
      "[33,   299] loss: 0.082335\n",
      "[33,   399] loss: 0.039010\n",
      "[33,   499] loss: 0.075366\n",
      "[33,   599] loss: 0.053043\n",
      "[33,   699] loss: 0.008625\n",
      "[34,    99] loss: 0.014175\n",
      "[34,   199] loss: 0.021056\n",
      "[34,   299] loss: 0.025618\n",
      "[34,   399] loss: 0.037705\n",
      "[34,   499] loss: 0.117460\n",
      "[34,   599] loss: 0.106637\n",
      "[34,   699] loss: 0.015618\n",
      "[35,    99] loss: 0.019423\n",
      "[35,   199] loss: 0.023224\n",
      "[35,   299] loss: 0.014216\n",
      "[35,   399] loss: 0.011885\n",
      "[35,   499] loss: 0.058157\n",
      "[35,   599] loss: 0.178792\n",
      "[35,   699] loss: 0.007855\n",
      "[36,    99] loss: 0.012546\n",
      "[36,   199] loss: 0.017083\n",
      "[36,   299] loss: 0.022771\n",
      "[36,   399] loss: 0.015841\n",
      "[36,   499] loss: 0.043597\n",
      "[36,   599] loss: 0.051696\n",
      "[36,   699] loss: 0.115168\n",
      "[37,    99] loss: 0.011545\n",
      "[37,   199] loss: 0.082577\n",
      "[37,   299] loss: 0.031259\n",
      "[37,   399] loss: 0.010037\n",
      "[37,   499] loss: 0.029127\n",
      "[37,   599] loss: 0.072524\n",
      "[37,   699] loss: 0.011995\n",
      "[38,    99] loss: 0.014223\n",
      "[38,   199] loss: 0.012697\n",
      "[38,   299] loss: 0.022160\n",
      "[38,   399] loss: 0.010505\n",
      "[38,   499] loss: 0.032338\n",
      "[38,   599] loss: 0.046968\n",
      "[38,   699] loss: 0.005865\n",
      "[39,    99] loss: 0.039507\n",
      "[39,   199] loss: 0.075635\n",
      "[39,   299] loss: 0.282512\n",
      "[39,   399] loss: 0.377105\n",
      "[39,   499] loss: 0.059646\n",
      "[39,   599] loss: 0.041260\n",
      "[39,   699] loss: 0.010300\n",
      "[40,    99] loss: 0.009497\n",
      "[40,   199] loss: 0.025425\n",
      "[40,   299] loss: 0.046349\n",
      "[40,   399] loss: 0.012024\n",
      "[40,   499] loss: 0.036311\n",
      "[40,   599] loss: 0.039544\n",
      "[40,   699] loss: 0.005481\n",
      "[41,    99] loss: 0.011526\n",
      "[41,   199] loss: 0.128662\n",
      "[41,   299] loss: 0.081956\n",
      "[41,   399] loss: 0.019389\n",
      "[41,   499] loss: 0.053747\n",
      "[41,   599] loss: 0.191156\n",
      "[41,   699] loss: 0.008734\n",
      "[42,    99] loss: 0.027503\n",
      "[42,   199] loss: 0.014928\n",
      "[42,   299] loss: 0.016304\n",
      "[42,   399] loss: 0.046049\n",
      "[42,   499] loss: 0.017588\n",
      "[42,   599] loss: 0.119439\n",
      "[42,   699] loss: 0.008872\n",
      "[43,    99] loss: 0.010581\n",
      "[43,   199] loss: 0.008816\n",
      "[43,   299] loss: 0.010238\n",
      "[43,   399] loss: 0.012136\n",
      "[43,   499] loss: 0.039327\n",
      "[43,   599] loss: 0.089308\n",
      "[43,   699] loss: 0.007913\n",
      "[44,    99] loss: 0.009232\n",
      "[44,   199] loss: 0.037128\n",
      "[44,   299] loss: 0.052387\n",
      "[44,   399] loss: 0.013129\n",
      "[44,   499] loss: 0.056499\n",
      "[44,   599] loss: 0.059795\n",
      "[44,   699] loss: 0.002628\n",
      "[45,    99] loss: 0.008947\n",
      "[45,   199] loss: 0.009710\n",
      "[45,   299] loss: 0.008917\n",
      "[45,   399] loss: 0.012161\n",
      "[45,   499] loss: 0.027788\n",
      "[45,   599] loss: 0.051463\n",
      "[45,   699] loss: 0.002101\n",
      "[46,    99] loss: 0.007670\n",
      "[46,   199] loss: 0.006157\n",
      "[46,   299] loss: 0.009571\n",
      "[46,   399] loss: 0.015927\n",
      "[46,   499] loss: 0.023436\n",
      "[46,   599] loss: 0.087378\n",
      "[46,   699] loss: 0.053918\n",
      "[47,    99] loss: 0.035895\n",
      "[47,   199] loss: 0.075520\n",
      "[47,   299] loss: 0.079221\n",
      "[47,   399] loss: 0.027530\n",
      "[47,   499] loss: 0.051946\n",
      "[47,   599] loss: 0.138822\n",
      "[47,   699] loss: 0.006342\n",
      "[48,    99] loss: 0.021665\n",
      "[48,   199] loss: 0.021856\n",
      "[48,   299] loss: 0.048452\n",
      "[48,   399] loss: 0.018194\n",
      "[48,   499] loss: 0.057971\n",
      "[48,   599] loss: 0.070715\n",
      "[48,   699] loss: 0.022077\n",
      "[49,    99] loss: 0.066149\n",
      "[49,   199] loss: 0.121743\n",
      "[49,   299] loss: 0.019426\n",
      "[49,   399] loss: 0.052771\n",
      "[49,   499] loss: 0.141687\n",
      "[49,   599] loss: 0.061644\n",
      "[49,   699] loss: 0.029951\n",
      "[50,    99] loss: 0.024786\n",
      "[50,   199] loss: 0.091667\n",
      "[50,   299] loss: 0.041860\n",
      "[50,   399] loss: 0.012008\n",
      "[50,   499] loss: 0.015262\n",
      "[50,   599] loss: 0.025429\n",
      "[50,   699] loss: 0.018015\n",
      "[51,    99] loss: 0.029397\n",
      "[51,   199] loss: 0.008614\n",
      "[51,   299] loss: 0.004494\n",
      "[51,   399] loss: 0.005536\n",
      "[51,   499] loss: 0.013102\n",
      "[51,   599] loss: 0.011834\n",
      "[51,   699] loss: 0.002591\n",
      "[52,    99] loss: 0.002379\n",
      "[52,   199] loss: 0.002431\n",
      "[52,   299] loss: 0.002906\n",
      "[52,   399] loss: 0.002937\n",
      "[52,   499] loss: 0.025242\n",
      "[52,   599] loss: 0.059276\n",
      "[52,   699] loss: 0.002304\n",
      "[53,    99] loss: 0.003191\n",
      "[53,   199] loss: 0.003704\n",
      "[53,   299] loss: 0.004119\n",
      "[53,   399] loss: 0.018529\n",
      "[53,   499] loss: 0.067370\n",
      "[53,   599] loss: 0.111766\n",
      "[53,   699] loss: 0.023678\n",
      "[54,    99] loss: 0.017436\n",
      "[54,   199] loss: 0.031000\n",
      "[54,   299] loss: 0.039058\n",
      "[54,   399] loss: 0.025772\n",
      "[54,   499] loss: 0.180749\n",
      "[54,   599] loss: 0.018689\n",
      "[54,   699] loss: 0.048067\n",
      "[55,    99] loss: 0.008949\n",
      "[55,   199] loss: 0.058926\n",
      "[55,   299] loss: 0.078953\n",
      "[55,   399] loss: 0.028903\n",
      "[55,   499] loss: 0.053835\n",
      "[55,   599] loss: 0.025786\n",
      "[55,   699] loss: 0.005999\n",
      "[56,    99] loss: 0.014368\n",
      "[56,   199] loss: 0.012558\n",
      "[56,   299] loss: 0.017208\n",
      "[56,   399] loss: 0.015175\n",
      "[56,   499] loss: 0.053391\n",
      "[56,   599] loss: 0.080017\n",
      "[56,   699] loss: 0.002774\n",
      "[57,    99] loss: 0.012645\n",
      "[57,   199] loss: 0.055169\n",
      "[57,   299] loss: 0.006978\n",
      "[57,   399] loss: 0.054823\n",
      "[57,   499] loss: 0.023469\n",
      "[57,   599] loss: 0.010266\n",
      "[57,   699] loss: 0.011129\n",
      "[58,    99] loss: 0.029504\n",
      "[58,   199] loss: 0.010444\n",
      "[58,   299] loss: 0.010343\n",
      "[58,   399] loss: 0.015904\n",
      "[58,   499] loss: 0.036147\n",
      "[58,   599] loss: 0.034026\n",
      "[58,   699] loss: 0.014340\n",
      "[59,    99] loss: 0.029031\n",
      "[59,   199] loss: 0.010987\n",
      "[59,   299] loss: 0.015998\n",
      "[59,   399] loss: 0.081074\n",
      "[59,   499] loss: 0.149462\n",
      "[59,   599] loss: 0.159516\n",
      "[59,   699] loss: 0.004424\n",
      "[60,    99] loss: 0.007903\n",
      "[60,   199] loss: 0.007019\n",
      "[60,   299] loss: 0.028567\n",
      "[60,   399] loss: 0.018375\n",
      "[60,   499] loss: 0.043925\n",
      "[60,   599] loss: 0.148379\n",
      "[60,   699] loss: 0.016085\n",
      "[61,    99] loss: 0.019066\n",
      "[61,   199] loss: 0.053186\n",
      "[61,   299] loss: 0.009428\n",
      "[61,   399] loss: 0.007215\n",
      "[61,   499] loss: 0.008914\n",
      "[61,   599] loss: 0.005710\n",
      "[61,   699] loss: 0.002846\n",
      "[62,    99] loss: 0.001782\n",
      "[62,   199] loss: 0.003428\n",
      "[62,   299] loss: 0.004824\n",
      "[62,   399] loss: 0.002581\n",
      "[62,   499] loss: 0.002587\n",
      "[62,   599] loss: 0.003302\n",
      "[62,   699] loss: 0.001096\n",
      "[63,    99] loss: 0.001299\n",
      "[63,   199] loss: 0.001371\n",
      "[63,   299] loss: 0.001835\n",
      "[63,   399] loss: 0.001300\n",
      "[63,   499] loss: 0.002065\n",
      "[63,   599] loss: 0.003382\n",
      "[63,   699] loss: 0.000690\n",
      "[64,    99] loss: 0.001006\n",
      "[64,   199] loss: 0.000858\n",
      "[64,   299] loss: 0.001314\n",
      "[64,   399] loss: 0.000802\n",
      "[64,   499] loss: 0.002653\n",
      "[64,   599] loss: 0.060743\n",
      "[64,   699] loss: 0.085073\n",
      "[65,    99] loss: 0.278409\n",
      "[65,   199] loss: 0.019543\n",
      "[65,   299] loss: 0.007834\n",
      "[65,   399] loss: 0.002242\n",
      "[65,   499] loss: 0.042597\n",
      "[65,   599] loss: 0.206071\n",
      "[65,   699] loss: 0.015268\n",
      "[66,    99] loss: 0.016916\n",
      "[66,   199] loss: 0.006538\n",
      "[66,   299] loss: 0.009468\n",
      "[66,   399] loss: 0.006659\n",
      "[66,   499] loss: 0.022736\n",
      "[66,   599] loss: 0.028349\n",
      "[66,   699] loss: 0.001400\n",
      "[67,    99] loss: 0.003206\n",
      "[67,   199] loss: 0.002613\n",
      "[67,   299] loss: 0.004057\n",
      "[67,   399] loss: 0.003060\n",
      "[67,   499] loss: 0.011034\n",
      "[67,   599] loss: 0.012686\n",
      "[67,   699] loss: 0.000431\n",
      "[68,    99] loss: 0.001001\n",
      "[68,   199] loss: 0.001414\n",
      "[68,   299] loss: 0.001663\n",
      "[68,   399] loss: 0.003493\n",
      "[68,   499] loss: 0.015343\n",
      "[68,   599] loss: 0.022550\n",
      "[68,   699] loss: 0.000949\n",
      "[69,    99] loss: 0.028326\n",
      "[69,   199] loss: 0.103507\n",
      "[69,   299] loss: 0.012230\n",
      "[69,   399] loss: 0.006787\n",
      "[69,   499] loss: 0.031553\n",
      "[69,   599] loss: 0.071105\n",
      "[69,   699] loss: 0.001512\n",
      "[70,    99] loss: 0.132305\n",
      "[70,   199] loss: 0.007153\n",
      "[70,   299] loss: 0.009450\n",
      "[70,   399] loss: 0.057705\n",
      "[70,   499] loss: 0.039058\n",
      "[70,   599] loss: 0.037626\n",
      "[70,   699] loss: 0.001148\n",
      "[71,    99] loss: 0.002042\n",
      "[71,   199] loss: 0.015004\n",
      "[71,   299] loss: 0.089084\n",
      "[71,   399] loss: 0.014524\n",
      "[71,   499] loss: 0.006073\n",
      "[71,   599] loss: 0.011970\n",
      "[71,   699] loss: 0.000965\n",
      "[72,    99] loss: 0.002163\n",
      "[72,   199] loss: 0.007803\n",
      "[72,   299] loss: 0.004335\n",
      "[72,   399] loss: 0.001677\n",
      "[72,   499] loss: 0.001538\n",
      "[72,   599] loss: 0.002953\n",
      "[72,   699] loss: 0.000547\n",
      "[73,    99] loss: 0.000735\n",
      "[73,   199] loss: 0.001005\n",
      "[73,   299] loss: 0.001066\n",
      "[73,   399] loss: 0.000942\n",
      "[73,   499] loss: 0.000750\n",
      "[73,   599] loss: 0.001893\n",
      "[73,   699] loss: 0.000322\n",
      "[74,    99] loss: 0.000570\n",
      "[74,   199] loss: 0.000619\n",
      "[74,   299] loss: 0.001618\n",
      "[74,   399] loss: 0.016520\n",
      "[74,   499] loss: 0.087974\n",
      "[74,   599] loss: 0.668697\n",
      "[74,   699] loss: 0.066997\n",
      "[75,    99] loss: 0.022038\n",
      "[75,   199] loss: 0.185545\n",
      "[75,   299] loss: 0.108858\n",
      "[75,   399] loss: 0.024203\n",
      "[75,   499] loss: 0.025268\n",
      "[75,   599] loss: 0.007317\n",
      "[75,   699] loss: 0.003930\n",
      "[76,    99] loss: 0.003898\n",
      "[76,   199] loss: 0.003591\n",
      "[76,   299] loss: 0.003066\n",
      "[76,   399] loss: 0.002188\n",
      "[76,   499] loss: 0.007252\n",
      "[76,   599] loss: 0.004653\n",
      "[76,   699] loss: 0.000964\n",
      "[77,    99] loss: 0.001177\n",
      "[77,   199] loss: 0.001197\n",
      "[77,   299] loss: 0.001264\n",
      "[77,   399] loss: 0.000794\n",
      "[77,   499] loss: 0.005548\n",
      "[77,   599] loss: 0.012050\n",
      "[77,   699] loss: 0.000638\n",
      "[78,    99] loss: 0.001926\n",
      "[78,   199] loss: 0.000791\n",
      "[78,   299] loss: 0.001091\n",
      "[78,   399] loss: 0.000635\n",
      "[78,   499] loss: 0.010230\n",
      "[78,   599] loss: 0.025770\n",
      "[78,   699] loss: 0.013000\n",
      "[79,    99] loss: 0.003709\n",
      "[79,   199] loss: 0.003419\n",
      "[79,   299] loss: 0.002371\n",
      "[79,   399] loss: 0.001846\n",
      "[79,   499] loss: 0.008824\n",
      "[79,   599] loss: 0.029125\n",
      "[79,   699] loss: 0.043104\n",
      "[80,    99] loss: 0.123648\n",
      "[80,   199] loss: 0.048600\n",
      "[80,   299] loss: 0.082928\n",
      "[80,   399] loss: 0.140126\n",
      "[80,   499] loss: 0.124386\n",
      "[80,   599] loss: 0.161859\n",
      "[80,   699] loss: 0.002698\n",
      "[81,    99] loss: 0.012788\n",
      "[81,   199] loss: 0.020072\n",
      "[81,   299] loss: 0.010443\n",
      "[81,   399] loss: 0.061959\n",
      "[81,   499] loss: 0.076206\n",
      "[81,   599] loss: 0.030985\n",
      "[81,   699] loss: 0.001555\n",
      "[82,    99] loss: 0.001705\n",
      "[82,   199] loss: 0.006053\n",
      "[82,   299] loss: 0.003727\n",
      "[82,   399] loss: 0.007130\n",
      "[82,   499] loss: 0.005549\n",
      "[82,   599] loss: 0.075723\n",
      "[82,   699] loss: 0.000822\n",
      "[83,    99] loss: 0.000633\n",
      "[83,   199] loss: 0.001038\n",
      "[83,   299] loss: 0.001088\n",
      "[83,   399] loss: 0.000736\n",
      "[83,   499] loss: 0.001521\n",
      "[83,   599] loss: 0.065127\n",
      "[83,   699] loss: 0.001135\n",
      "[84,    99] loss: 0.000592\n",
      "[84,   199] loss: 0.000567\n",
      "[84,   299] loss: 0.000588\n",
      "[84,   399] loss: 0.000884\n",
      "[84,   499] loss: 0.000960\n",
      "[84,   599] loss: 0.070434\n",
      "[84,   699] loss: 0.000455\n",
      "[85,    99] loss: 0.000444\n",
      "[85,   199] loss: 0.000622\n",
      "[85,   299] loss: 0.000545\n",
      "[85,   399] loss: 0.000369\n",
      "[85,   499] loss: 0.000469\n",
      "[85,   599] loss: 0.007151\n",
      "[85,   699] loss: 0.000311\n",
      "[86,    99] loss: 0.004387\n",
      "[86,   199] loss: 0.097496\n",
      "[86,   299] loss: 0.029252\n",
      "[86,   399] loss: 0.095422\n",
      "[86,   499] loss: 0.208360\n",
      "[86,   599] loss: 0.057664\n",
      "[86,   699] loss: 0.132417\n",
      "[87,    99] loss: 0.146088\n",
      "[87,   199] loss: 0.007945\n",
      "[87,   299] loss: 0.009637\n",
      "[87,   399] loss: 0.001466\n",
      "[87,   499] loss: 0.007420\n",
      "[87,   599] loss: 0.008119\n",
      "[87,   699] loss: 0.002293\n",
      "[88,    99] loss: 0.001053\n",
      "[88,   199] loss: 0.001043\n",
      "[88,   299] loss: 0.002209\n",
      "[88,   399] loss: 0.001667\n",
      "[88,   499] loss: 0.002115\n",
      "[88,   599] loss: 0.002007\n",
      "[88,   699] loss: 0.001061\n",
      "[89,    99] loss: 0.000864\n",
      "[89,   199] loss: 0.000749\n",
      "[89,   299] loss: 0.001084\n",
      "[89,   399] loss: 0.001229\n",
      "[89,   499] loss: 0.001049\n",
      "[89,   599] loss: 0.001055\n",
      "[89,   699] loss: 0.000642\n",
      "[90,    99] loss: 0.000685\n",
      "[90,   199] loss: 0.000549\n",
      "[90,   299] loss: 0.000703\n",
      "[90,   399] loss: 0.000958\n",
      "[90,   499] loss: 0.000923\n",
      "[90,   599] loss: 0.000697\n",
      "[90,   699] loss: 0.000414\n",
      "[91,    99] loss: 0.000521\n",
      "[91,   199] loss: 0.000405\n",
      "[91,   299] loss: 0.000474\n",
      "[91,   399] loss: 0.000547\n",
      "[91,   499] loss: 0.000454\n",
      "[91,   599] loss: 0.000554\n",
      "[91,   699] loss: 0.000337\n",
      "[92,    99] loss: 0.000386\n",
      "[92,   199] loss: 0.000298\n",
      "[92,   299] loss: 0.000351\n",
      "[92,   399] loss: 0.000300\n",
      "[92,   499] loss: 0.000306\n",
      "[92,   599] loss: 0.000376\n",
      "[92,   699] loss: 0.000211\n",
      "[93,    99] loss: 0.000286\n",
      "[93,   199] loss: 0.000232\n",
      "[93,   299] loss: 0.000285\n",
      "[93,   399] loss: 0.000218\n",
      "[93,   499] loss: 0.000227\n",
      "[93,   599] loss: 0.000288\n",
      "[93,   699] loss: 0.000159\n",
      "[94,    99] loss: 0.000192\n",
      "[94,   199] loss: 0.000188\n",
      "[94,   299] loss: 0.000269\n",
      "[94,   399] loss: 0.000159\n",
      "[94,   499] loss: 0.000166\n",
      "[94,   599] loss: 0.000222\n",
      "[94,   699] loss: 0.000120\n",
      "[95,    99] loss: 0.000136\n",
      "[95,   199] loss: 0.000191\n",
      "[95,   299] loss: 0.070360\n",
      "[95,   399] loss: 0.180158\n",
      "[95,   499] loss: 0.244136\n",
      "[95,   599] loss: 0.281898\n",
      "[95,   699] loss: 0.147973\n",
      "[96,    99] loss: 0.047396\n",
      "[96,   199] loss: 0.045713\n",
      "[96,   299] loss: 0.019280\n",
      "[96,   399] loss: 0.013023\n",
      "[96,   499] loss: 0.026880\n",
      "[96,   599] loss: 0.072582\n",
      "[96,   699] loss: 0.007836\n",
      "[97,    99] loss: 0.001627\n",
      "[97,   199] loss: 0.043913\n",
      "[97,   299] loss: 0.015629\n",
      "[97,   399] loss: 0.005747\n",
      "[97,   499] loss: 0.002725\n",
      "[97,   599] loss: 0.007686\n",
      "[97,   699] loss: 0.001890\n",
      "[98,    99] loss: 0.001501\n",
      "[98,   199] loss: 0.005851\n",
      "[98,   299] loss: 0.002151\n",
      "[98,   399] loss: 0.001388\n",
      "[98,   499] loss: 0.000562\n",
      "[98,   599] loss: 0.000764\n",
      "[98,   699] loss: 0.000779\n",
      "[99,    99] loss: 0.000843\n",
      "[99,   199] loss: 0.000513\n",
      "[99,   299] loss: 0.000752\n",
      "[99,   399] loss: 0.000777\n",
      "[99,   499] loss: 0.000398\n",
      "[99,   599] loss: 0.000635\n",
      "[99,   699] loss: 0.000517\n",
      "[100,    99] loss: 0.000562\n",
      "[100,   199] loss: 0.000387\n",
      "[100,   299] loss: 0.000559\n",
      "[100,   399] loss: 0.000534\n",
      "[100,   499] loss: 0.000321\n",
      "[100,   599] loss: 0.000542\n",
      "[100,   699] loss: 0.000370\n",
      "Finished Training\n",
      "[1,    99] loss: 0.709066\n",
      "[1,   199] loss: 0.698038\n",
      "[1,   299] loss: 0.693814\n",
      "[1,   399] loss: 0.689274\n",
      "[1,   499] loss: 0.685005\n",
      "[1,   599] loss: 0.687269\n",
      "[1,   699] loss: 0.685235\n",
      "[2,    99] loss: 0.667853\n",
      "[2,   199] loss: 0.658460\n",
      "[2,   299] loss: 0.663176\n",
      "[2,   399] loss: 0.658314\n",
      "[2,   499] loss: 0.656252\n",
      "[2,   599] loss: 0.673884\n",
      "[2,   699] loss: 0.648689\n",
      "[3,    99] loss: 0.634507\n",
      "[3,   199] loss: 0.629411\n",
      "[3,   299] loss: 0.640156\n",
      "[3,   399] loss: 0.629945\n",
      "[3,   499] loss: 0.625508\n",
      "[3,   599] loss: 0.663623\n",
      "[3,   699] loss: 0.621245\n",
      "[4,    99] loss: 0.602708\n",
      "[4,   199] loss: 0.606746\n",
      "[4,   299] loss: 0.620431\n",
      "[4,   399] loss: 0.602528\n",
      "[4,   499] loss: 0.596046\n",
      "[4,   599] loss: 0.655758\n",
      "[4,   699] loss: 0.600957\n",
      "[5,    99] loss: 0.574582\n",
      "[5,   199] loss: 0.587306\n",
      "[5,   299] loss: 0.603665\n",
      "[5,   399] loss: 0.577254\n",
      "[5,   499] loss: 0.568199\n",
      "[5,   599] loss: 0.646650\n",
      "[5,   699] loss: 0.583777\n",
      "[6,    99] loss: 0.548829\n",
      "[6,   199] loss: 0.569897\n",
      "[6,   299] loss: 0.588652\n",
      "[6,   399] loss: 0.553861\n",
      "[6,   499] loss: 0.541741\n",
      "[6,   599] loss: 0.636782\n",
      "[6,   699] loss: 0.568214\n",
      "[7,    99] loss: 0.523763\n",
      "[7,   199] loss: 0.552235\n",
      "[7,   299] loss: 0.574369\n",
      "[7,   399] loss: 0.532258\n",
      "[7,   499] loss: 0.518311\n",
      "[7,   599] loss: 0.627035\n",
      "[7,   699] loss: 0.552873\n",
      "[8,    99] loss: 0.499534\n",
      "[8,   199] loss: 0.535152\n",
      "[8,   299] loss: 0.560941\n",
      "[8,   399] loss: 0.512668\n",
      "[8,   499] loss: 0.496538\n",
      "[8,   599] loss: 0.615451\n",
      "[8,   699] loss: 0.537940\n",
      "[9,    99] loss: 0.476434\n",
      "[9,   199] loss: 0.518749\n",
      "[9,   299] loss: 0.547606\n",
      "[9,   399] loss: 0.492915\n",
      "[9,   499] loss: 0.474982\n",
      "[9,   599] loss: 0.602410\n",
      "[9,   699] loss: 0.524496\n",
      "[10,    99] loss: 0.454786\n",
      "[10,   199] loss: 0.502581\n",
      "[10,   299] loss: 0.532764\n",
      "[10,   399] loss: 0.473723\n",
      "[10,   499] loss: 0.454208\n",
      "[10,   599] loss: 0.587972\n",
      "[10,   699] loss: 0.510380\n",
      "[11,    99] loss: 0.433400\n",
      "[11,   199] loss: 0.486698\n",
      "[11,   299] loss: 0.517964\n",
      "[11,   399] loss: 0.455841\n",
      "[11,   499] loss: 0.434076\n",
      "[11,   599] loss: 0.572102\n",
      "[11,   699] loss: 0.494700\n",
      "[12,    99] loss: 0.412703\n",
      "[12,   199] loss: 0.471569\n",
      "[12,   299] loss: 0.503148\n",
      "[12,   399] loss: 0.437639\n",
      "[12,   499] loss: 0.414756\n",
      "[12,   599] loss: 0.556055\n",
      "[12,   699] loss: 0.480337\n",
      "[13,    99] loss: 0.393171\n",
      "[13,   199] loss: 0.456472\n",
      "[13,   299] loss: 0.488373\n",
      "[13,   399] loss: 0.419584\n",
      "[13,   499] loss: 0.396085\n",
      "[13,   599] loss: 0.540139\n",
      "[13,   699] loss: 0.466313\n",
      "[14,    99] loss: 0.374211\n",
      "[14,   199] loss: 0.441193\n",
      "[14,   299] loss: 0.473221\n",
      "[14,   399] loss: 0.402277\n",
      "[14,   499] loss: 0.379337\n",
      "[14,   599] loss: 0.525038\n",
      "[14,   699] loss: 0.452185\n",
      "[15,    99] loss: 0.355293\n",
      "[15,   199] loss: 0.425748\n",
      "[15,   299] loss: 0.459244\n",
      "[15,   399] loss: 0.385375\n",
      "[15,   499] loss: 0.363278\n",
      "[15,   599] loss: 0.509495\n",
      "[15,   699] loss: 0.438684\n",
      "[16,    99] loss: 0.337301\n",
      "[16,   199] loss: 0.410497\n",
      "[16,   299] loss: 0.445327\n",
      "[16,   399] loss: 0.369237\n",
      "[16,   499] loss: 0.347901\n",
      "[16,   599] loss: 0.494200\n",
      "[16,   699] loss: 0.424918\n",
      "[17,    99] loss: 0.320841\n",
      "[17,   199] loss: 0.395926\n",
      "[17,   299] loss: 0.430812\n",
      "[17,   399] loss: 0.352636\n",
      "[17,   499] loss: 0.332532\n",
      "[17,   599] loss: 0.479361\n",
      "[17,   699] loss: 0.410930\n",
      "[18,    99] loss: 0.304632\n",
      "[18,   199] loss: 0.381225\n",
      "[18,   299] loss: 0.416896\n",
      "[18,   399] loss: 0.337039\n",
      "[18,   499] loss: 0.317970\n",
      "[18,   599] loss: 0.464436\n",
      "[18,   699] loss: 0.395675\n",
      "[19,    99] loss: 0.290067\n",
      "[19,   199] loss: 0.366263\n",
      "[19,   299] loss: 0.402682\n",
      "[19,   399] loss: 0.322334\n",
      "[19,   499] loss: 0.305049\n",
      "[19,   599] loss: 0.450950\n",
      "[19,   699] loss: 0.382910\n",
      "[20,    99] loss: 0.275455\n",
      "[20,   199] loss: 0.352377\n",
      "[20,   299] loss: 0.388229\n",
      "[20,   399] loss: 0.306114\n",
      "[20,   499] loss: 0.292858\n",
      "[20,   599] loss: 0.436970\n",
      "[20,   699] loss: 0.367487\n",
      "[21,    99] loss: 0.261673\n",
      "[21,   199] loss: 0.338645\n",
      "[21,   299] loss: 0.374271\n",
      "[21,   399] loss: 0.291094\n",
      "[21,   499] loss: 0.280927\n",
      "[21,   599] loss: 0.423947\n",
      "[21,   699] loss: 0.354020\n",
      "[22,    99] loss: 0.248360\n",
      "[22,   199] loss: 0.325355\n",
      "[22,   299] loss: 0.360077\n",
      "[22,   399] loss: 0.275922\n",
      "[22,   499] loss: 0.269618\n",
      "[22,   599] loss: 0.411600\n",
      "[22,   699] loss: 0.340250\n",
      "[23,    99] loss: 0.236101\n",
      "[23,   199] loss: 0.312554\n",
      "[23,   299] loss: 0.346365\n",
      "[23,   399] loss: 0.261390\n",
      "[23,   499] loss: 0.259549\n",
      "[23,   599] loss: 0.399951\n",
      "[23,   699] loss: 0.327093\n",
      "[24,    99] loss: 0.223717\n",
      "[24,   199] loss: 0.300320\n",
      "[24,   299] loss: 0.333523\n",
      "[24,   399] loss: 0.247074\n",
      "[24,   499] loss: 0.249239\n",
      "[24,   599] loss: 0.387105\n",
      "[24,   699] loss: 0.313157\n",
      "[25,    99] loss: 0.212741\n",
      "[25,   199] loss: 0.288482\n",
      "[25,   299] loss: 0.320489\n",
      "[25,   399] loss: 0.234820\n",
      "[25,   499] loss: 0.239895\n",
      "[25,   599] loss: 0.375943\n",
      "[25,   699] loss: 0.300919\n",
      "[26,    99] loss: 0.201276\n",
      "[26,   199] loss: 0.277332\n",
      "[26,   299] loss: 0.308981\n",
      "[26,   399] loss: 0.222667\n",
      "[26,   499] loss: 0.230500\n",
      "[26,   599] loss: 0.363159\n",
      "[26,   699] loss: 0.288336\n",
      "[27,    99] loss: 0.191324\n",
      "[27,   199] loss: 0.266337\n",
      "[27,   299] loss: 0.297356\n",
      "[27,   399] loss: 0.211218\n",
      "[27,   499] loss: 0.221256\n",
      "[27,   599] loss: 0.351147\n",
      "[27,   699] loss: 0.276144\n",
      "[28,    99] loss: 0.182154\n",
      "[28,   199] loss: 0.256117\n",
      "[28,   299] loss: 0.285793\n",
      "[28,   399] loss: 0.200637\n",
      "[28,   499] loss: 0.212498\n",
      "[28,   599] loss: 0.338978\n",
      "[28,   699] loss: 0.264092\n",
      "[29,    99] loss: 0.172920\n",
      "[29,   199] loss: 0.246245\n",
      "[29,   299] loss: 0.274444\n",
      "[29,   399] loss: 0.190149\n",
      "[29,   499] loss: 0.204277\n",
      "[29,   599] loss: 0.327497\n",
      "[29,   699] loss: 0.252050\n",
      "[30,    99] loss: 0.164659\n",
      "[30,   199] loss: 0.237137\n",
      "[30,   299] loss: 0.263243\n",
      "[30,   399] loss: 0.181248\n",
      "[30,   499] loss: 0.196829\n",
      "[30,   599] loss: 0.315702\n",
      "[30,   699] loss: 0.240341\n",
      "[31,    99] loss: 0.156670\n",
      "[31,   199] loss: 0.228353\n",
      "[31,   299] loss: 0.252808\n",
      "[31,   399] loss: 0.171900\n",
      "[31,   499] loss: 0.188785\n",
      "[31,   599] loss: 0.303325\n",
      "[31,   699] loss: 0.229448\n",
      "[32,    99] loss: 0.149333\n",
      "[32,   199] loss: 0.220233\n",
      "[32,   299] loss: 0.242019\n",
      "[32,   399] loss: 0.163721\n",
      "[32,   499] loss: 0.181643\n",
      "[32,   599] loss: 0.292718\n",
      "[32,   699] loss: 0.219046\n",
      "[33,    99] loss: 0.141904\n",
      "[33,   199] loss: 0.212342\n",
      "[33,   299] loss: 0.232453\n",
      "[33,   399] loss: 0.155766\n",
      "[33,   499] loss: 0.175095\n",
      "[33,   599] loss: 0.280724\n",
      "[33,   699] loss: 0.208844\n",
      "[34,    99] loss: 0.134984\n",
      "[34,   199] loss: 0.205095\n",
      "[34,   299] loss: 0.222580\n",
      "[34,   399] loss: 0.148929\n",
      "[34,   499] loss: 0.168675\n",
      "[34,   599] loss: 0.269886\n",
      "[34,   699] loss: 0.198293\n",
      "[35,    99] loss: 0.128508\n",
      "[35,   199] loss: 0.197269\n",
      "[35,   299] loss: 0.213549\n",
      "[35,   399] loss: 0.140329\n",
      "[35,   499] loss: 0.161931\n",
      "[35,   599] loss: 0.258006\n",
      "[35,   699] loss: 0.189630\n",
      "[36,    99] loss: 0.122209\n",
      "[36,   199] loss: 0.190611\n",
      "[36,   299] loss: 0.203972\n",
      "[36,   399] loss: 0.134104\n",
      "[36,   499] loss: 0.156977\n",
      "[36,   599] loss: 0.246904\n",
      "[36,   699] loss: 0.180261\n",
      "[37,    99] loss: 0.116131\n",
      "[37,   199] loss: 0.184504\n",
      "[37,   299] loss: 0.195470\n",
      "[37,   399] loss: 0.127500\n",
      "[37,   499] loss: 0.151139\n",
      "[37,   599] loss: 0.236087\n",
      "[37,   699] loss: 0.171392\n",
      "[38,    99] loss: 0.110333\n",
      "[38,   199] loss: 0.177993\n",
      "[38,   299] loss: 0.187381\n",
      "[38,   399] loss: 0.121696\n",
      "[38,   499] loss: 0.145643\n",
      "[38,   599] loss: 0.226608\n",
      "[38,   699] loss: 0.163354\n",
      "[39,    99] loss: 0.105025\n",
      "[39,   199] loss: 0.172124\n",
      "[39,   299] loss: 0.178765\n",
      "[39,   399] loss: 0.116178\n",
      "[39,   499] loss: 0.140927\n",
      "[39,   599] loss: 0.216569\n",
      "[39,   699] loss: 0.154245\n",
      "[40,    99] loss: 0.100708\n",
      "[40,   199] loss: 0.165457\n",
      "[40,   299] loss: 0.170840\n",
      "[40,   399] loss: 0.110566\n",
      "[40,   499] loss: 0.136245\n",
      "[40,   599] loss: 0.207784\n",
      "[40,   699] loss: 0.147138\n",
      "[41,    99] loss: 0.095648\n",
      "[41,   199] loss: 0.160099\n",
      "[41,   299] loss: 0.163441\n",
      "[41,   399] loss: 0.105153\n",
      "[41,   499] loss: 0.131451\n",
      "[41,   599] loss: 0.198567\n",
      "[41,   699] loss: 0.139155\n",
      "[42,    99] loss: 0.091234\n",
      "[42,   199] loss: 0.154492\n",
      "[42,   299] loss: 0.156014\n",
      "[42,   399] loss: 0.100610\n",
      "[42,   499] loss: 0.127580\n",
      "[42,   599] loss: 0.189524\n",
      "[42,   699] loss: 0.131656\n",
      "[43,    99] loss: 0.087338\n",
      "[43,   199] loss: 0.147702\n",
      "[43,   299] loss: 0.149468\n",
      "[43,   399] loss: 0.095534\n",
      "[43,   499] loss: 0.123310\n",
      "[43,   599] loss: 0.181729\n",
      "[43,   699] loss: 0.125236\n",
      "[44,    99] loss: 0.083114\n",
      "[44,   199] loss: 0.142398\n",
      "[44,   299] loss: 0.142695\n",
      "[44,   399] loss: 0.090912\n",
      "[44,   499] loss: 0.119466\n",
      "[44,   599] loss: 0.174105\n",
      "[44,   699] loss: 0.118762\n",
      "[45,    99] loss: 0.079064\n",
      "[45,   199] loss: 0.137195\n",
      "[45,   299] loss: 0.136247\n",
      "[45,   399] loss: 0.086471\n",
      "[45,   499] loss: 0.115301\n",
      "[45,   599] loss: 0.166339\n",
      "[45,   699] loss: 0.112751\n",
      "[46,    99] loss: 0.075794\n",
      "[46,   199] loss: 0.132930\n",
      "[46,   299] loss: 0.129881\n",
      "[46,   399] loss: 0.082093\n",
      "[46,   499] loss: 0.111674\n",
      "[46,   599] loss: 0.158674\n",
      "[46,   699] loss: 0.106490\n",
      "[47,    99] loss: 0.072150\n",
      "[47,   199] loss: 0.127099\n",
      "[47,   299] loss: 0.124337\n",
      "[47,   399] loss: 0.077860\n",
      "[47,   499] loss: 0.107896\n",
      "[47,   599] loss: 0.152992\n",
      "[47,   699] loss: 0.101594\n",
      "[48,    99] loss: 0.067874\n",
      "[48,   199] loss: 0.124115\n",
      "[48,   299] loss: 0.118646\n",
      "[48,   399] loss: 0.073740\n",
      "[48,   499] loss: 0.104931\n",
      "[48,   599] loss: 0.146169\n",
      "[48,   699] loss: 0.096345\n",
      "[49,    99] loss: 0.064876\n",
      "[49,   199] loss: 0.119566\n",
      "[49,   299] loss: 0.113816\n",
      "[49,   399] loss: 0.069691\n",
      "[49,   499] loss: 0.101367\n",
      "[49,   599] loss: 0.139379\n",
      "[49,   699] loss: 0.091639\n",
      "[50,    99] loss: 0.062077\n",
      "[50,   199] loss: 0.115484\n",
      "[50,   299] loss: 0.108840\n",
      "[50,   399] loss: 0.065925\n",
      "[50,   499] loss: 0.098109\n",
      "[50,   599] loss: 0.133846\n",
      "[50,   699] loss: 0.086978\n",
      "[51,    99] loss: 0.058931\n",
      "[51,   199] loss: 0.112394\n",
      "[51,   299] loss: 0.103832\n",
      "[51,   399] loss: 0.062277\n",
      "[51,   499] loss: 0.095904\n",
      "[51,   599] loss: 0.127003\n",
      "[51,   699] loss: 0.082642\n",
      "[52,    99] loss: 0.056767\n",
      "[52,   199] loss: 0.108078\n",
      "[52,   299] loss: 0.099339\n",
      "[52,   399] loss: 0.059146\n",
      "[52,   499] loss: 0.092500\n",
      "[52,   599] loss: 0.123106\n",
      "[52,   699] loss: 0.078250\n",
      "[53,    99] loss: 0.053610\n",
      "[53,   199] loss: 0.105166\n",
      "[53,   299] loss: 0.095116\n",
      "[53,   399] loss: 0.056202\n",
      "[53,   499] loss: 0.090128\n",
      "[53,   599] loss: 0.117149\n",
      "[53,   699] loss: 0.073363\n",
      "[54,    99] loss: 0.050909\n",
      "[54,   199] loss: 0.101811\n",
      "[54,   299] loss: 0.090771\n",
      "[54,   399] loss: 0.052869\n",
      "[54,   499] loss: 0.087567\n",
      "[54,   599] loss: 0.113220\n",
      "[54,   699] loss: 0.069616\n",
      "[55,    99] loss: 0.048707\n",
      "[55,   199] loss: 0.098907\n",
      "[55,   299] loss: 0.086474\n",
      "[55,   399] loss: 0.050434\n",
      "[55,   499] loss: 0.084762\n",
      "[55,   599] loss: 0.108547\n",
      "[55,   699] loss: 0.065858\n",
      "[56,    99] loss: 0.046328\n",
      "[56,   199] loss: 0.095942\n",
      "[56,   299] loss: 0.082441\n",
      "[56,   399] loss: 0.047769\n",
      "[56,   499] loss: 0.082494\n",
      "[56,   599] loss: 0.104361\n",
      "[56,   699] loss: 0.062393\n",
      "[57,    99] loss: 0.044219\n",
      "[57,   199] loss: 0.093628\n",
      "[57,   299] loss: 0.079318\n",
      "[57,   399] loss: 0.045298\n",
      "[57,   499] loss: 0.080223\n",
      "[57,   599] loss: 0.100242\n",
      "[57,   699] loss: 0.059311\n",
      "[58,    99] loss: 0.041817\n",
      "[58,   199] loss: 0.090553\n",
      "[58,   299] loss: 0.075868\n",
      "[58,   399] loss: 0.042820\n",
      "[58,   499] loss: 0.077648\n",
      "[58,   599] loss: 0.097120\n",
      "[58,   699] loss: 0.055508\n",
      "[59,    99] loss: 0.039758\n",
      "[59,   199] loss: 0.088429\n",
      "[59,   299] loss: 0.071944\n",
      "[59,   399] loss: 0.040668\n",
      "[59,   499] loss: 0.074776\n",
      "[59,   599] loss: 0.092657\n",
      "[59,   699] loss: 0.053261\n",
      "[60,    99] loss: 0.037912\n",
      "[60,   199] loss: 0.086091\n",
      "[60,   299] loss: 0.068625\n",
      "[60,   399] loss: 0.038255\n",
      "[60,   499] loss: 0.072929\n",
      "[60,   599] loss: 0.089393\n",
      "[60,   699] loss: 0.050292\n",
      "[61,    99] loss: 0.035841\n",
      "[61,   199] loss: 0.083795\n",
      "[61,   299] loss: 0.064684\n",
      "[61,   399] loss: 0.036526\n",
      "[61,   499] loss: 0.070603\n",
      "[61,   599] loss: 0.085832\n",
      "[61,   699] loss: 0.047463\n",
      "[62,    99] loss: 0.034355\n",
      "[62,   199] loss: 0.080471\n",
      "[62,   299] loss: 0.062157\n",
      "[62,   399] loss: 0.034465\n",
      "[62,   499] loss: 0.068510\n",
      "[62,   599] loss: 0.083140\n",
      "[62,   699] loss: 0.045003\n",
      "[63,    99] loss: 0.032336\n",
      "[63,   199] loss: 0.078736\n",
      "[63,   299] loss: 0.058804\n",
      "[63,   399] loss: 0.032829\n",
      "[63,   499] loss: 0.066017\n",
      "[63,   599] loss: 0.079601\n",
      "[63,   699] loss: 0.043070\n",
      "[64,    99] loss: 0.030885\n",
      "[64,   199] loss: 0.076523\n",
      "[64,   299] loss: 0.055984\n",
      "[64,   399] loss: 0.031198\n",
      "[64,   499] loss: 0.063724\n",
      "[64,   599] loss: 0.075939\n",
      "[64,   699] loss: 0.041069\n",
      "[65,    99] loss: 0.029231\n",
      "[65,   199] loss: 0.074254\n",
      "[65,   299] loss: 0.053538\n",
      "[65,   399] loss: 0.029615\n",
      "[65,   499] loss: 0.061960\n",
      "[65,   599] loss: 0.074189\n",
      "[65,   699] loss: 0.038973\n",
      "[66,    99] loss: 0.027618\n",
      "[66,   199] loss: 0.071931\n",
      "[66,   299] loss: 0.051782\n",
      "[66,   399] loss: 0.028282\n",
      "[66,   499] loss: 0.059193\n",
      "[66,   599] loss: 0.070418\n",
      "[66,   699] loss: 0.037095\n",
      "[67,    99] loss: 0.026080\n",
      "[67,   199] loss: 0.070034\n",
      "[67,   299] loss: 0.049067\n",
      "[67,   399] loss: 0.026846\n",
      "[67,   499] loss: 0.057773\n",
      "[67,   599] loss: 0.068294\n",
      "[67,   699] loss: 0.035276\n",
      "[68,    99] loss: 0.025082\n",
      "[68,   199] loss: 0.068111\n",
      "[68,   299] loss: 0.046331\n",
      "[68,   399] loss: 0.025648\n",
      "[68,   499] loss: 0.055497\n",
      "[68,   599] loss: 0.065725\n",
      "[68,   699] loss: 0.034030\n",
      "[69,    99] loss: 0.023389\n",
      "[69,   199] loss: 0.065920\n",
      "[69,   299] loss: 0.045084\n",
      "[69,   399] loss: 0.024391\n",
      "[69,   499] loss: 0.053156\n",
      "[69,   599] loss: 0.063022\n",
      "[69,   699] loss: 0.032518\n",
      "[70,    99] loss: 0.022348\n",
      "[70,   199] loss: 0.064578\n",
      "[70,   299] loss: 0.042940\n",
      "[70,   399] loss: 0.023137\n",
      "[70,   499] loss: 0.051423\n",
      "[70,   599] loss: 0.060508\n",
      "[70,   699] loss: 0.030681\n",
      "[71,    99] loss: 0.021058\n",
      "[71,   199] loss: 0.062559\n",
      "[71,   299] loss: 0.041553\n",
      "[71,   399] loss: 0.022067\n",
      "[71,   499] loss: 0.049546\n",
      "[71,   599] loss: 0.058874\n",
      "[71,   699] loss: 0.029226\n",
      "[72,    99] loss: 0.020281\n",
      "[72,   199] loss: 0.060898\n",
      "[72,   299] loss: 0.039202\n",
      "[72,   399] loss: 0.021297\n",
      "[72,   499] loss: 0.047504\n",
      "[72,   599] loss: 0.056206\n",
      "[72,   699] loss: 0.028492\n",
      "[73,    99] loss: 0.018760\n",
      "[73,   199] loss: 0.058761\n",
      "[73,   299] loss: 0.038137\n",
      "[73,   399] loss: 0.020299\n",
      "[73,   499] loss: 0.046289\n",
      "[73,   599] loss: 0.055567\n",
      "[73,   699] loss: 0.027260\n",
      "[74,    99] loss: 0.018160\n",
      "[74,   199] loss: 0.057819\n",
      "[74,   299] loss: 0.036197\n",
      "[74,   399] loss: 0.019372\n",
      "[74,   499] loss: 0.044223\n",
      "[74,   599] loss: 0.052977\n",
      "[74,   699] loss: 0.025652\n",
      "[75,    99] loss: 0.017153\n",
      "[75,   199] loss: 0.056624\n",
      "[75,   299] loss: 0.034582\n",
      "[75,   399] loss: 0.018474\n",
      "[75,   499] loss: 0.042742\n",
      "[75,   599] loss: 0.051467\n",
      "[75,   699] loss: 0.024844\n",
      "[76,    99] loss: 0.016115\n",
      "[76,   199] loss: 0.055234\n",
      "[76,   299] loss: 0.033318\n",
      "[76,   399] loss: 0.018229\n",
      "[76,   499] loss: 0.041037\n",
      "[76,   599] loss: 0.048690\n",
      "[76,   699] loss: 0.023753\n",
      "[77,    99] loss: 0.015702\n",
      "[77,   199] loss: 0.054190\n",
      "[77,   299] loss: 0.031818\n",
      "[77,   399] loss: 0.017308\n",
      "[77,   499] loss: 0.039200\n",
      "[77,   599] loss: 0.047792\n",
      "[77,   699] loss: 0.022568\n",
      "[78,    99] loss: 0.014656\n",
      "[78,   199] loss: 0.053588\n",
      "[78,   299] loss: 0.030324\n",
      "[78,   399] loss: 0.016236\n",
      "[78,   499] loss: 0.037798\n",
      "[78,   599] loss: 0.046757\n",
      "[78,   699] loss: 0.021633\n",
      "[79,    99] loss: 0.014183\n",
      "[79,   199] loss: 0.052412\n",
      "[79,   299] loss: 0.028842\n",
      "[79,   399] loss: 0.016066\n",
      "[79,   499] loss: 0.035934\n",
      "[79,   599] loss: 0.044137\n",
      "[79,   699] loss: 0.020722\n",
      "[80,    99] loss: 0.013566\n",
      "[80,   199] loss: 0.051184\n",
      "[80,   299] loss: 0.028126\n",
      "[80,   399] loss: 0.014850\n",
      "[80,   499] loss: 0.034389\n",
      "[80,   599] loss: 0.043718\n",
      "[80,   699] loss: 0.020255\n",
      "[81,    99] loss: 0.012777\n",
      "[81,   199] loss: 0.050474\n",
      "[81,   299] loss: 0.026914\n",
      "[81,   399] loss: 0.014651\n",
      "[81,   499] loss: 0.033008\n",
      "[81,   599] loss: 0.042285\n",
      "[81,   699] loss: 0.019274\n",
      "[82,    99] loss: 0.012215\n",
      "[82,   199] loss: 0.049492\n",
      "[82,   299] loss: 0.025371\n",
      "[82,   399] loss: 0.013756\n",
      "[82,   499] loss: 0.031466\n",
      "[82,   599] loss: 0.040699\n",
      "[82,   699] loss: 0.018332\n",
      "[83,    99] loss: 0.011324\n",
      "[83,   199] loss: 0.048247\n",
      "[83,   299] loss: 0.024573\n",
      "[83,   399] loss: 0.013463\n",
      "[83,   499] loss: 0.030060\n",
      "[83,   599] loss: 0.039403\n",
      "[83,   699] loss: 0.017665\n",
      "[84,    99] loss: 0.010976\n",
      "[84,   199] loss: 0.047296\n",
      "[84,   299] loss: 0.023256\n",
      "[84,   399] loss: 0.012616\n",
      "[84,   499] loss: 0.028775\n",
      "[84,   599] loss: 0.039375\n",
      "[84,   699] loss: 0.016773\n",
      "[85,    99] loss: 0.010708\n",
      "[85,   199] loss: 0.047088\n",
      "[85,   299] loss: 0.022439\n",
      "[85,   399] loss: 0.012337\n",
      "[85,   499] loss: 0.027803\n",
      "[85,   599] loss: 0.036947\n",
      "[85,   699] loss: 0.016464\n",
      "[86,    99] loss: 0.010155\n",
      "[86,   199] loss: 0.046128\n",
      "[86,   299] loss: 0.021561\n",
      "[86,   399] loss: 0.012022\n",
      "[86,   499] loss: 0.025903\n",
      "[86,   599] loss: 0.036292\n",
      "[86,   699] loss: 0.015771\n",
      "[87,    99] loss: 0.009646\n",
      "[87,   199] loss: 0.043640\n",
      "[87,   299] loss: 0.020144\n",
      "[87,   399] loss: 0.011271\n",
      "[87,   499] loss: 0.024515\n",
      "[87,   599] loss: 0.035631\n",
      "[87,   699] loss: 0.014967\n",
      "[88,    99] loss: 0.009246\n",
      "[88,   199] loss: 0.043104\n",
      "[88,   299] loss: 0.019828\n",
      "[88,   399] loss: 0.011170\n",
      "[88,   499] loss: 0.023650\n",
      "[88,   599] loss: 0.034436\n",
      "[88,   699] loss: 0.014339\n",
      "[89,    99] loss: 0.008886\n",
      "[89,   199] loss: 0.043389\n",
      "[89,   299] loss: 0.019214\n",
      "[89,   399] loss: 0.010631\n",
      "[89,   499] loss: 0.023037\n",
      "[89,   599] loss: 0.033439\n",
      "[89,   699] loss: 0.013937\n",
      "[90,    99] loss: 0.008356\n",
      "[90,   199] loss: 0.041640\n",
      "[90,   299] loss: 0.018166\n",
      "[90,   399] loss: 0.010115\n",
      "[90,   499] loss: 0.021517\n",
      "[90,   599] loss: 0.032827\n",
      "[90,   699] loss: 0.013278\n",
      "[91,    99] loss: 0.008287\n",
      "[91,   199] loss: 0.039637\n",
      "[91,   299] loss: 0.017272\n",
      "[91,   399] loss: 0.009965\n",
      "[91,   499] loss: 0.021104\n",
      "[91,   599] loss: 0.032210\n",
      "[91,   699] loss: 0.013110\n",
      "[92,    99] loss: 0.007896\n",
      "[92,   199] loss: 0.039430\n",
      "[92,   299] loss: 0.016501\n",
      "[92,   399] loss: 0.009480\n",
      "[92,   499] loss: 0.019743\n",
      "[92,   599] loss: 0.031267\n",
      "[92,   699] loss: 0.012289\n",
      "[93,    99] loss: 0.007453\n",
      "[93,   199] loss: 0.038140\n",
      "[93,   299] loss: 0.015839\n",
      "[93,   399] loss: 0.009322\n",
      "[93,   499] loss: 0.018940\n",
      "[93,   599] loss: 0.030872\n",
      "[93,   699] loss: 0.011886\n",
      "[94,    99] loss: 0.006998\n",
      "[94,   199] loss: 0.038745\n",
      "[94,   299] loss: 0.015392\n",
      "[94,   399] loss: 0.008803\n",
      "[94,   499] loss: 0.018544\n",
      "[94,   599] loss: 0.030171\n",
      "[94,   699] loss: 0.011446\n",
      "[95,    99] loss: 0.006929\n",
      "[95,   199] loss: 0.037563\n",
      "[95,   299] loss: 0.014661\n",
      "[95,   399] loss: 0.008580\n",
      "[95,   499] loss: 0.017816\n",
      "[95,   599] loss: 0.028757\n",
      "[95,   699] loss: 0.010973\n",
      "[96,    99] loss: 0.006680\n",
      "[96,   199] loss: 0.036819\n",
      "[96,   299] loss: 0.013708\n",
      "[96,   399] loss: 0.008407\n",
      "[96,   499] loss: 0.016647\n",
      "[96,   599] loss: 0.027948\n",
      "[96,   699] loss: 0.010902\n",
      "[97,    99] loss: 0.006182\n",
      "[97,   199] loss: 0.035924\n",
      "[97,   299] loss: 0.013504\n",
      "[97,   399] loss: 0.008066\n",
      "[97,   499] loss: 0.016048\n",
      "[97,   599] loss: 0.027878\n",
      "[97,   699] loss: 0.010251\n",
      "[98,    99] loss: 0.005901\n",
      "[98,   199] loss: 0.033791\n",
      "[98,   299] loss: 0.012767\n",
      "[98,   399] loss: 0.007699\n",
      "[98,   499] loss: 0.014830\n",
      "[98,   599] loss: 0.027769\n",
      "[98,   699] loss: 0.009705\n",
      "[99,    99] loss: 0.005908\n",
      "[99,   199] loss: 0.033984\n",
      "[99,   299] loss: 0.012578\n",
      "[99,   399] loss: 0.007358\n",
      "[99,   499] loss: 0.014944\n",
      "[99,   599] loss: 0.026804\n",
      "[99,   699] loss: 0.009456\n",
      "[100,    99] loss: 0.005520\n",
      "[100,   199] loss: 0.034072\n",
      "[100,   299] loss: 0.012007\n",
      "[100,   399] loss: 0.007401\n",
      "[100,   499] loss: 0.013369\n",
      "[100,   599] loss: 0.025492\n",
      "[100,   699] loss: 0.009147\n",
      "Finished Training\n",
      "[1,    99] loss: 0.692281\n",
      "[1,   199] loss: 0.686273\n",
      "[1,   299] loss: 0.683727\n",
      "[1,   399] loss: 0.678332\n",
      "[1,   499] loss: 0.675579\n",
      "[1,   599] loss: 0.685537\n",
      "[1,   699] loss: 0.687831\n",
      "[2,    99] loss: 0.677317\n",
      "[2,   199] loss: 0.668749\n",
      "[2,   299] loss: 0.667248\n",
      "[2,   399] loss: 0.660348\n",
      "[2,   499] loss: 0.658509\n",
      "[2,   599] loss: 0.666384\n",
      "[2,   699] loss: 0.674426\n",
      "[3,    99] loss: 0.664847\n",
      "[3,   199] loss: 0.653103\n",
      "[3,   299] loss: 0.653502\n",
      "[3,   399] loss: 0.643294\n",
      "[3,   499] loss: 0.642002\n",
      "[3,   599] loss: 0.648298\n",
      "[3,   699] loss: 0.659275\n",
      "[4,    99] loss: 0.650754\n",
      "[4,   199] loss: 0.638696\n",
      "[4,   299] loss: 0.639173\n",
      "[4,   399] loss: 0.625547\n",
      "[4,   499] loss: 0.626867\n",
      "[4,   599] loss: 0.631670\n",
      "[4,   699] loss: 0.642663\n",
      "[5,    99] loss: 0.636209\n",
      "[5,   199] loss: 0.624528\n",
      "[5,   299] loss: 0.623564\n",
      "[5,   399] loss: 0.607700\n",
      "[5,   499] loss: 0.612978\n",
      "[5,   599] loss: 0.617065\n",
      "[5,   699] loss: 0.624022\n",
      "[6,    99] loss: 0.620641\n",
      "[6,   199] loss: 0.610365\n",
      "[6,   299] loss: 0.607381\n",
      "[6,   399] loss: 0.588837\n",
      "[6,   499] loss: 0.599621\n",
      "[6,   599] loss: 0.603040\n",
      "[6,   699] loss: 0.604494\n",
      "[7,    99] loss: 0.604274\n",
      "[7,   199] loss: 0.595931\n",
      "[7,   299] loss: 0.589846\n",
      "[7,   399] loss: 0.570126\n",
      "[7,   499] loss: 0.586119\n",
      "[7,   599] loss: 0.589330\n",
      "[7,   699] loss: 0.582952\n",
      "[8,    99] loss: 0.586031\n",
      "[8,   199] loss: 0.580663\n",
      "[8,   299] loss: 0.572573\n",
      "[8,   399] loss: 0.551566\n",
      "[8,   499] loss: 0.571475\n",
      "[8,   599] loss: 0.576539\n",
      "[8,   699] loss: 0.563341\n",
      "[9,    99] loss: 0.568116\n",
      "[9,   199] loss: 0.564586\n",
      "[9,   299] loss: 0.555232\n",
      "[9,   399] loss: 0.533318\n",
      "[9,   499] loss: 0.556941\n",
      "[9,   599] loss: 0.564799\n",
      "[9,   699] loss: 0.543593\n",
      "[10,    99] loss: 0.550011\n",
      "[10,   199] loss: 0.548133\n",
      "[10,   299] loss: 0.539744\n",
      "[10,   399] loss: 0.516164\n",
      "[10,   499] loss: 0.542659\n",
      "[10,   599] loss: 0.553130\n",
      "[10,   699] loss: 0.524161\n",
      "[11,    99] loss: 0.531518\n",
      "[11,   199] loss: 0.531524\n",
      "[11,   299] loss: 0.523357\n",
      "[11,   399] loss: 0.499144\n",
      "[11,   499] loss: 0.526775\n",
      "[11,   599] loss: 0.542275\n",
      "[11,   699] loss: 0.505195\n",
      "[12,    99] loss: 0.512894\n",
      "[12,   199] loss: 0.515629\n",
      "[12,   299] loss: 0.507532\n",
      "[12,   399] loss: 0.482176\n",
      "[12,   499] loss: 0.510611\n",
      "[12,   599] loss: 0.531426\n",
      "[12,   699] loss: 0.487223\n",
      "[13,    99] loss: 0.494991\n",
      "[13,   199] loss: 0.499760\n",
      "[13,   299] loss: 0.490396\n",
      "[13,   399] loss: 0.465737\n",
      "[13,   499] loss: 0.494428\n",
      "[13,   599] loss: 0.520684\n",
      "[13,   699] loss: 0.469928\n",
      "[14,    99] loss: 0.477165\n",
      "[14,   199] loss: 0.483768\n",
      "[14,   299] loss: 0.474521\n",
      "[14,   399] loss: 0.449704\n",
      "[14,   499] loss: 0.478177\n",
      "[14,   599] loss: 0.510178\n",
      "[14,   699] loss: 0.453199\n",
      "[15,    99] loss: 0.459812\n",
      "[15,   199] loss: 0.467671\n",
      "[15,   299] loss: 0.459025\n",
      "[15,   399] loss: 0.434461\n",
      "[15,   499] loss: 0.461459\n",
      "[15,   599] loss: 0.499127\n",
      "[15,   699] loss: 0.436765\n",
      "[16,    99] loss: 0.443544\n",
      "[16,   199] loss: 0.451843\n",
      "[16,   299] loss: 0.442452\n",
      "[16,   399] loss: 0.419331\n",
      "[16,   499] loss: 0.444576\n",
      "[16,   599] loss: 0.487887\n",
      "[16,   699] loss: 0.421305\n",
      "[17,    99] loss: 0.427324\n",
      "[17,   199] loss: 0.435947\n",
      "[17,   299] loss: 0.426379\n",
      "[17,   399] loss: 0.403963\n",
      "[17,   499] loss: 0.427378\n",
      "[17,   599] loss: 0.477135\n",
      "[17,   699] loss: 0.406332\n",
      "[18,    99] loss: 0.410822\n",
      "[18,   199] loss: 0.420465\n",
      "[18,   299] loss: 0.412053\n",
      "[18,   399] loss: 0.390022\n",
      "[18,   499] loss: 0.409573\n",
      "[18,   599] loss: 0.465200\n",
      "[18,   699] loss: 0.391785\n",
      "[19,    99] loss: 0.395097\n",
      "[19,   199] loss: 0.404503\n",
      "[19,   299] loss: 0.396383\n",
      "[19,   399] loss: 0.375583\n",
      "[19,   499] loss: 0.391910\n",
      "[19,   599] loss: 0.452836\n",
      "[19,   699] loss: 0.377700\n",
      "[20,    99] loss: 0.379624\n",
      "[20,   199] loss: 0.389383\n",
      "[20,   299] loss: 0.381252\n",
      "[20,   399] loss: 0.361184\n",
      "[20,   499] loss: 0.374705\n",
      "[20,   599] loss: 0.440895\n",
      "[20,   699] loss: 0.363491\n",
      "[21,    99] loss: 0.365418\n",
      "[21,   199] loss: 0.374656\n",
      "[21,   299] loss: 0.366770\n",
      "[21,   399] loss: 0.347663\n",
      "[21,   499] loss: 0.357992\n",
      "[21,   599] loss: 0.428755\n",
      "[21,   699] loss: 0.349761\n",
      "[22,    99] loss: 0.351660\n",
      "[22,   199] loss: 0.360445\n",
      "[22,   299] loss: 0.352179\n",
      "[22,   399] loss: 0.333695\n",
      "[22,   499] loss: 0.341308\n",
      "[22,   599] loss: 0.416306\n",
      "[22,   699] loss: 0.336452\n",
      "[23,    99] loss: 0.338255\n",
      "[23,   199] loss: 0.345698\n",
      "[23,   299] loss: 0.338381\n",
      "[23,   399] loss: 0.320635\n",
      "[23,   499] loss: 0.325205\n",
      "[23,   599] loss: 0.404533\n",
      "[23,   699] loss: 0.323340\n",
      "[24,    99] loss: 0.325162\n",
      "[24,   199] loss: 0.330955\n",
      "[24,   299] loss: 0.325539\n",
      "[24,   399] loss: 0.307895\n",
      "[24,   499] loss: 0.309748\n",
      "[24,   599] loss: 0.392328\n",
      "[24,   699] loss: 0.311268\n",
      "[25,    99] loss: 0.312261\n",
      "[25,   199] loss: 0.317363\n",
      "[25,   299] loss: 0.313100\n",
      "[25,   399] loss: 0.295907\n",
      "[25,   499] loss: 0.294904\n",
      "[25,   599] loss: 0.380729\n",
      "[25,   699] loss: 0.299608\n",
      "[26,    99] loss: 0.300545\n",
      "[26,   199] loss: 0.303992\n",
      "[26,   299] loss: 0.301125\n",
      "[26,   399] loss: 0.283775\n",
      "[26,   499] loss: 0.280530\n",
      "[26,   599] loss: 0.369531\n",
      "[26,   699] loss: 0.288828\n",
      "[27,    99] loss: 0.288713\n",
      "[27,   199] loss: 0.292014\n",
      "[27,   299] loss: 0.289655\n",
      "[27,   399] loss: 0.271614\n",
      "[27,   499] loss: 0.267079\n",
      "[27,   599] loss: 0.357734\n",
      "[27,   699] loss: 0.278155\n",
      "[28,    99] loss: 0.277505\n",
      "[28,   199] loss: 0.280415\n",
      "[28,   299] loss: 0.278751\n",
      "[28,   399] loss: 0.260955\n",
      "[28,   499] loss: 0.253884\n",
      "[28,   599] loss: 0.347242\n",
      "[28,   699] loss: 0.269476\n",
      "[29,    99] loss: 0.266033\n",
      "[29,   199] loss: 0.268738\n",
      "[29,   299] loss: 0.268735\n",
      "[29,   399] loss: 0.250480\n",
      "[29,   499] loss: 0.241462\n",
      "[29,   599] loss: 0.335985\n",
      "[29,   699] loss: 0.260616\n",
      "[30,    99] loss: 0.255632\n",
      "[30,   199] loss: 0.257528\n",
      "[30,   299] loss: 0.258545\n",
      "[30,   399] loss: 0.240067\n",
      "[30,   499] loss: 0.230123\n",
      "[30,   599] loss: 0.324782\n",
      "[30,   699] loss: 0.251963\n",
      "[31,    99] loss: 0.244851\n",
      "[31,   199] loss: 0.247100\n",
      "[31,   299] loss: 0.249633\n",
      "[31,   399] loss: 0.230381\n",
      "[31,   499] loss: 0.218882\n",
      "[31,   599] loss: 0.313666\n",
      "[31,   699] loss: 0.244014\n",
      "[32,    99] loss: 0.235305\n",
      "[32,   199] loss: 0.236891\n",
      "[32,   299] loss: 0.240367\n",
      "[32,   399] loss: 0.221661\n",
      "[32,   499] loss: 0.208207\n",
      "[32,   599] loss: 0.303426\n",
      "[32,   699] loss: 0.236598\n",
      "[33,    99] loss: 0.225129\n",
      "[33,   199] loss: 0.227116\n",
      "[33,   299] loss: 0.232377\n",
      "[33,   399] loss: 0.212859\n",
      "[33,   499] loss: 0.198098\n",
      "[33,   599] loss: 0.293428\n",
      "[33,   699] loss: 0.228502\n",
      "[34,    99] loss: 0.216309\n",
      "[34,   199] loss: 0.218279\n",
      "[34,   299] loss: 0.224062\n",
      "[34,   399] loss: 0.203449\n",
      "[34,   499] loss: 0.188896\n",
      "[34,   599] loss: 0.283009\n",
      "[34,   699] loss: 0.222216\n",
      "[35,    99] loss: 0.207677\n",
      "[35,   199] loss: 0.209297\n",
      "[35,   299] loss: 0.216250\n",
      "[35,   399] loss: 0.196107\n",
      "[35,   499] loss: 0.179928\n",
      "[35,   599] loss: 0.273774\n",
      "[35,   699] loss: 0.215418\n",
      "[36,    99] loss: 0.199220\n",
      "[36,   199] loss: 0.201129\n",
      "[36,   299] loss: 0.209671\n",
      "[36,   399] loss: 0.187538\n",
      "[36,   499] loss: 0.171309\n",
      "[36,   599] loss: 0.264589\n",
      "[36,   699] loss: 0.209254\n",
      "[37,    99] loss: 0.191968\n",
      "[37,   199] loss: 0.193322\n",
      "[37,   299] loss: 0.202461\n",
      "[37,   399] loss: 0.179997\n",
      "[37,   499] loss: 0.163327\n",
      "[37,   599] loss: 0.255573\n",
      "[37,   699] loss: 0.203620\n",
      "[38,    99] loss: 0.183859\n",
      "[38,   199] loss: 0.186141\n",
      "[38,   299] loss: 0.195999\n",
      "[38,   399] loss: 0.172402\n",
      "[38,   499] loss: 0.155340\n",
      "[38,   599] loss: 0.246926\n",
      "[38,   699] loss: 0.197720\n",
      "[39,    99] loss: 0.176542\n",
      "[39,   199] loss: 0.178858\n",
      "[39,   299] loss: 0.189516\n",
      "[39,   399] loss: 0.165939\n",
      "[39,   499] loss: 0.148006\n",
      "[39,   599] loss: 0.237795\n",
      "[39,   699] loss: 0.191597\n",
      "[40,    99] loss: 0.169599\n",
      "[40,   199] loss: 0.172612\n",
      "[40,   299] loss: 0.183526\n",
      "[40,   399] loss: 0.159033\n",
      "[40,   499] loss: 0.141015\n",
      "[40,   599] loss: 0.230671\n",
      "[40,   699] loss: 0.186848\n",
      "[41,    99] loss: 0.163509\n",
      "[41,   199] loss: 0.165249\n",
      "[41,   299] loss: 0.178339\n",
      "[41,   399] loss: 0.152875\n",
      "[41,   499] loss: 0.134329\n",
      "[41,   599] loss: 0.221555\n",
      "[41,   699] loss: 0.181747\n",
      "[42,    99] loss: 0.157654\n",
      "[42,   199] loss: 0.159285\n",
      "[42,   299] loss: 0.173080\n",
      "[42,   399] loss: 0.147130\n",
      "[42,   499] loss: 0.127704\n",
      "[42,   599] loss: 0.213789\n",
      "[42,   699] loss: 0.176637\n",
      "[43,    99] loss: 0.151563\n",
      "[43,   199] loss: 0.154108\n",
      "[43,   299] loss: 0.167195\n",
      "[43,   399] loss: 0.141864\n",
      "[43,   499] loss: 0.121617\n",
      "[43,   599] loss: 0.206038\n",
      "[43,   699] loss: 0.171907\n",
      "[44,    99] loss: 0.146023\n",
      "[44,   199] loss: 0.148321\n",
      "[44,   299] loss: 0.162643\n",
      "[44,   399] loss: 0.136188\n",
      "[44,   499] loss: 0.116156\n",
      "[44,   599] loss: 0.197931\n",
      "[44,   699] loss: 0.167645\n",
      "[45,    99] loss: 0.140542\n",
      "[45,   199] loss: 0.143828\n",
      "[45,   299] loss: 0.157758\n",
      "[45,   399] loss: 0.130846\n",
      "[45,   499] loss: 0.111020\n",
      "[45,   599] loss: 0.191397\n",
      "[45,   699] loss: 0.162487\n",
      "[46,    99] loss: 0.135641\n",
      "[46,   199] loss: 0.139001\n",
      "[46,   299] loss: 0.152910\n",
      "[46,   399] loss: 0.126415\n",
      "[46,   499] loss: 0.105520\n",
      "[46,   599] loss: 0.183681\n",
      "[46,   699] loss: 0.158558\n",
      "[47,    99] loss: 0.130582\n",
      "[47,   199] loss: 0.134876\n",
      "[47,   299] loss: 0.147741\n",
      "[47,   399] loss: 0.121824\n",
      "[47,   499] loss: 0.101434\n",
      "[47,   599] loss: 0.176713\n",
      "[47,   699] loss: 0.154023\n",
      "[48,    99] loss: 0.126270\n",
      "[48,   199] loss: 0.129639\n",
      "[48,   299] loss: 0.143394\n",
      "[48,   399] loss: 0.117436\n",
      "[48,   499] loss: 0.096766\n",
      "[48,   599] loss: 0.170079\n",
      "[48,   699] loss: 0.150273\n",
      "[49,    99] loss: 0.121604\n",
      "[49,   199] loss: 0.125685\n",
      "[49,   299] loss: 0.139063\n",
      "[49,   399] loss: 0.113497\n",
      "[49,   499] loss: 0.092545\n",
      "[49,   599] loss: 0.163263\n",
      "[49,   699] loss: 0.145652\n",
      "[50,    99] loss: 0.117934\n",
      "[50,   199] loss: 0.120711\n",
      "[50,   299] loss: 0.134254\n",
      "[50,   399] loss: 0.110011\n",
      "[50,   499] loss: 0.088319\n",
      "[50,   599] loss: 0.157979\n",
      "[50,   699] loss: 0.142176\n",
      "[51,    99] loss: 0.113757\n",
      "[51,   199] loss: 0.117511\n",
      "[51,   299] loss: 0.129668\n",
      "[51,   399] loss: 0.105418\n",
      "[51,   499] loss: 0.084239\n",
      "[51,   599] loss: 0.151135\n",
      "[51,   699] loss: 0.138408\n",
      "[52,    99] loss: 0.109516\n",
      "[52,   199] loss: 0.113230\n",
      "[52,   299] loss: 0.124880\n",
      "[52,   399] loss: 0.102654\n",
      "[52,   499] loss: 0.080605\n",
      "[52,   599] loss: 0.144425\n",
      "[52,   699] loss: 0.134143\n",
      "[53,    99] loss: 0.105870\n",
      "[53,   199] loss: 0.108975\n",
      "[53,   299] loss: 0.120715\n",
      "[53,   399] loss: 0.099103\n",
      "[53,   499] loss: 0.076812\n",
      "[53,   599] loss: 0.139171\n",
      "[53,   699] loss: 0.130785\n",
      "[54,    99] loss: 0.102226\n",
      "[54,   199] loss: 0.105914\n",
      "[54,   299] loss: 0.116049\n",
      "[54,   399] loss: 0.095530\n",
      "[54,   499] loss: 0.073661\n",
      "[54,   599] loss: 0.133585\n",
      "[54,   699] loss: 0.126353\n",
      "[55,    99] loss: 0.097679\n",
      "[55,   199] loss: 0.101802\n",
      "[55,   299] loss: 0.112141\n",
      "[55,   399] loss: 0.092647\n",
      "[55,   499] loss: 0.070605\n",
      "[55,   599] loss: 0.128168\n",
      "[55,   699] loss: 0.123705\n",
      "[56,    99] loss: 0.093524\n",
      "[56,   199] loss: 0.097981\n",
      "[56,   299] loss: 0.107849\n",
      "[56,   399] loss: 0.089319\n",
      "[56,   499] loss: 0.067606\n",
      "[56,   599] loss: 0.122866\n",
      "[56,   699] loss: 0.119146\n",
      "[57,    99] loss: 0.089895\n",
      "[57,   199] loss: 0.094135\n",
      "[57,   299] loss: 0.104187\n",
      "[57,   399] loss: 0.086966\n",
      "[57,   499] loss: 0.064234\n",
      "[57,   599] loss: 0.117481\n",
      "[57,   699] loss: 0.116188\n",
      "[58,    99] loss: 0.085859\n",
      "[58,   199] loss: 0.090572\n",
      "[58,   299] loss: 0.100343\n",
      "[58,   399] loss: 0.084091\n",
      "[58,   499] loss: 0.061408\n",
      "[58,   599] loss: 0.113240\n",
      "[58,   699] loss: 0.111834\n",
      "[59,    99] loss: 0.082850\n",
      "[59,   199] loss: 0.087319\n",
      "[59,   299] loss: 0.096855\n",
      "[59,   399] loss: 0.081571\n",
      "[59,   499] loss: 0.058513\n",
      "[59,   599] loss: 0.108598\n",
      "[59,   699] loss: 0.109534\n",
      "[60,    99] loss: 0.079579\n",
      "[60,   199] loss: 0.084307\n",
      "[60,   299] loss: 0.092975\n",
      "[60,   399] loss: 0.078704\n",
      "[60,   499] loss: 0.055707\n",
      "[60,   599] loss: 0.102474\n",
      "[60,   699] loss: 0.106118\n",
      "[61,    99] loss: 0.076359\n",
      "[61,   199] loss: 0.080902\n",
      "[61,   299] loss: 0.089942\n",
      "[61,   399] loss: 0.076203\n",
      "[61,   499] loss: 0.053159\n",
      "[61,   599] loss: 0.100617\n",
      "[61,   699] loss: 0.103514\n",
      "[62,    99] loss: 0.072900\n",
      "[62,   199] loss: 0.077756\n",
      "[62,   299] loss: 0.085668\n",
      "[62,   399] loss: 0.073525\n",
      "[62,   499] loss: 0.050833\n",
      "[62,   599] loss: 0.095141\n",
      "[62,   699] loss: 0.099635\n",
      "[63,    99] loss: 0.070712\n",
      "[63,   199] loss: 0.075234\n",
      "[63,   299] loss: 0.082759\n",
      "[63,   399] loss: 0.071120\n",
      "[63,   499] loss: 0.048148\n",
      "[63,   599] loss: 0.091134\n",
      "[63,   699] loss: 0.096208\n",
      "[64,    99] loss: 0.067424\n",
      "[64,   199] loss: 0.072103\n",
      "[64,   299] loss: 0.079613\n",
      "[64,   399] loss: 0.069104\n",
      "[64,   499] loss: 0.046582\n",
      "[64,   599] loss: 0.086823\n",
      "[64,   699] loss: 0.093715\n",
      "[65,    99] loss: 0.064729\n",
      "[65,   199] loss: 0.069284\n",
      "[65,   299] loss: 0.077121\n",
      "[65,   399] loss: 0.066575\n",
      "[65,   499] loss: 0.044683\n",
      "[65,   599] loss: 0.084679\n",
      "[65,   699] loss: 0.092046\n",
      "[66,    99] loss: 0.062020\n",
      "[66,   199] loss: 0.066617\n",
      "[66,   299] loss: 0.073439\n",
      "[66,   399] loss: 0.064513\n",
      "[66,   499] loss: 0.042261\n",
      "[66,   599] loss: 0.080691\n",
      "[66,   699] loss: 0.088259\n",
      "[67,    99] loss: 0.060376\n",
      "[67,   199] loss: 0.064795\n",
      "[67,   299] loss: 0.070494\n",
      "[67,   399] loss: 0.062401\n",
      "[67,   499] loss: 0.040023\n",
      "[67,   599] loss: 0.077097\n",
      "[67,   699] loss: 0.084955\n",
      "[68,    99] loss: 0.057691\n",
      "[68,   199] loss: 0.062133\n",
      "[68,   299] loss: 0.068304\n",
      "[68,   399] loss: 0.061006\n",
      "[68,   499] loss: 0.038538\n",
      "[68,   599] loss: 0.074509\n",
      "[68,   699] loss: 0.083252\n",
      "[69,    99] loss: 0.055408\n",
      "[69,   199] loss: 0.058856\n",
      "[69,   299] loss: 0.065118\n",
      "[69,   399] loss: 0.058566\n",
      "[69,   499] loss: 0.036959\n",
      "[69,   599] loss: 0.071080\n",
      "[69,   699] loss: 0.080237\n",
      "[70,    99] loss: 0.053325\n",
      "[70,   199] loss: 0.057389\n",
      "[70,   299] loss: 0.062246\n",
      "[70,   399] loss: 0.056734\n",
      "[70,   499] loss: 0.034976\n",
      "[70,   599] loss: 0.068683\n",
      "[70,   699] loss: 0.078282\n",
      "[71,    99] loss: 0.051418\n",
      "[71,   199] loss: 0.055852\n",
      "[71,   299] loss: 0.059376\n",
      "[71,   399] loss: 0.054597\n",
      "[71,   499] loss: 0.033135\n",
      "[71,   599] loss: 0.066242\n",
      "[71,   699] loss: 0.075837\n",
      "[72,    99] loss: 0.049176\n",
      "[72,   199] loss: 0.053282\n",
      "[72,   299] loss: 0.056677\n",
      "[72,   399] loss: 0.052611\n",
      "[72,   499] loss: 0.031230\n",
      "[72,   599] loss: 0.063784\n",
      "[72,   699] loss: 0.073856\n",
      "[73,    99] loss: 0.047142\n",
      "[73,   199] loss: 0.051304\n",
      "[73,   299] loss: 0.054497\n",
      "[73,   399] loss: 0.050898\n",
      "[73,   499] loss: 0.030392\n",
      "[73,   599] loss: 0.061742\n",
      "[73,   699] loss: 0.071985\n",
      "[74,    99] loss: 0.045753\n",
      "[74,   199] loss: 0.049582\n",
      "[74,   299] loss: 0.051616\n",
      "[74,   399] loss: 0.049243\n",
      "[74,   499] loss: 0.028956\n",
      "[74,   599] loss: 0.059230\n",
      "[74,   699] loss: 0.069709\n",
      "[75,    99] loss: 0.043953\n",
      "[75,   199] loss: 0.047680\n",
      "[75,   299] loss: 0.049827\n",
      "[75,   399] loss: 0.047166\n",
      "[75,   499] loss: 0.027483\n",
      "[75,   599] loss: 0.057524\n",
      "[75,   699] loss: 0.067817\n",
      "[76,    99] loss: 0.042024\n",
      "[76,   199] loss: 0.045817\n",
      "[76,   299] loss: 0.046672\n",
      "[76,   399] loss: 0.045745\n",
      "[76,   499] loss: 0.026307\n",
      "[76,   599] loss: 0.055469\n",
      "[76,   699] loss: 0.065904\n",
      "[77,    99] loss: 0.040529\n",
      "[77,   199] loss: 0.043983\n",
      "[77,   299] loss: 0.045285\n",
      "[77,   399] loss: 0.044118\n",
      "[77,   499] loss: 0.025963\n",
      "[77,   599] loss: 0.053884\n",
      "[77,   699] loss: 0.064771\n",
      "[78,    99] loss: 0.038872\n",
      "[78,   199] loss: 0.042705\n",
      "[78,   299] loss: 0.042227\n",
      "[78,   399] loss: 0.042117\n",
      "[78,   499] loss: 0.024151\n",
      "[78,   599] loss: 0.052031\n",
      "[78,   699] loss: 0.062581\n",
      "[79,    99] loss: 0.037578\n",
      "[79,   199] loss: 0.041530\n",
      "[79,   299] loss: 0.041595\n",
      "[79,   399] loss: 0.041117\n",
      "[79,   499] loss: 0.023471\n",
      "[79,   599] loss: 0.049482\n",
      "[79,   699] loss: 0.060929\n",
      "[80,    99] loss: 0.035946\n",
      "[80,   199] loss: 0.040195\n",
      "[80,   299] loss: 0.038988\n",
      "[80,   399] loss: 0.039233\n",
      "[80,   499] loss: 0.021503\n",
      "[80,   599] loss: 0.047615\n",
      "[80,   699] loss: 0.059239\n",
      "[81,    99] loss: 0.034188\n",
      "[81,   199] loss: 0.038400\n",
      "[81,   299] loss: 0.037801\n",
      "[81,   399] loss: 0.038565\n",
      "[81,   499] loss: 0.021322\n",
      "[81,   599] loss: 0.046336\n",
      "[81,   699] loss: 0.057603\n",
      "[82,    99] loss: 0.033504\n",
      "[82,   199] loss: 0.037706\n",
      "[82,   299] loss: 0.036224\n",
      "[82,   399] loss: 0.037072\n",
      "[82,   499] loss: 0.020699\n",
      "[82,   599] loss: 0.045401\n",
      "[82,   699] loss: 0.056608\n",
      "[83,    99] loss: 0.031735\n",
      "[83,   199] loss: 0.036036\n",
      "[83,   299] loss: 0.034234\n",
      "[83,   399] loss: 0.035688\n",
      "[83,   499] loss: 0.019642\n",
      "[83,   599] loss: 0.043492\n",
      "[83,   699] loss: 0.054851\n",
      "[84,    99] loss: 0.030662\n",
      "[84,   199] loss: 0.034498\n",
      "[84,   299] loss: 0.032933\n",
      "[84,   399] loss: 0.034467\n",
      "[84,   499] loss: 0.019431\n",
      "[84,   599] loss: 0.040864\n",
      "[84,   699] loss: 0.051749\n",
      "[85,    99] loss: 0.029398\n",
      "[85,   199] loss: 0.032943\n",
      "[85,   299] loss: 0.031075\n",
      "[85,   399] loss: 0.032610\n",
      "[85,   499] loss: 0.017524\n",
      "[85,   599] loss: 0.039299\n",
      "[85,   699] loss: 0.050380\n",
      "[86,    99] loss: 0.028150\n",
      "[86,   199] loss: 0.032767\n",
      "[86,   299] loss: 0.029440\n",
      "[86,   399] loss: 0.031849\n",
      "[86,   499] loss: 0.016660\n",
      "[86,   599] loss: 0.037358\n",
      "[86,   699] loss: 0.047692\n",
      "[87,    99] loss: 0.026763\n",
      "[87,   199] loss: 0.030404\n",
      "[87,   299] loss: 0.028654\n",
      "[87,   399] loss: 0.031376\n",
      "[87,   499] loss: 0.016547\n",
      "[87,   599] loss: 0.035941\n",
      "[87,   699] loss: 0.046563\n",
      "[88,    99] loss: 0.025885\n",
      "[88,   199] loss: 0.029549\n",
      "[88,   299] loss: 0.028388\n",
      "[88,   399] loss: 0.031495\n",
      "[88,   499] loss: 0.016476\n",
      "[88,   599] loss: 0.034289\n",
      "[88,   699] loss: 0.043961\n",
      "[89,    99] loss: 0.024971\n",
      "[89,   199] loss: 0.028938\n",
      "[89,   299] loss: 0.025275\n",
      "[89,   399] loss: 0.028354\n",
      "[89,   499] loss: 0.014552\n",
      "[89,   599] loss: 0.032967\n",
      "[89,   699] loss: 0.043205\n",
      "[90,    99] loss: 0.024044\n",
      "[90,   199] loss: 0.027216\n",
      "[90,   299] loss: 0.026254\n",
      "[90,   399] loss: 0.029496\n",
      "[90,   499] loss: 0.015368\n",
      "[90,   599] loss: 0.032095\n",
      "[90,   699] loss: 0.042487\n",
      "[91,    99] loss: 0.022732\n",
      "[91,   199] loss: 0.026559\n",
      "[91,   299] loss: 0.024466\n",
      "[91,   399] loss: 0.027731\n",
      "[91,   499] loss: 0.014869\n",
      "[91,   599] loss: 0.030747\n",
      "[91,   699] loss: 0.040670\n",
      "[92,    99] loss: 0.022600\n",
      "[92,   199] loss: 0.025834\n",
      "[92,   299] loss: 0.023493\n",
      "[92,   399] loss: 0.026108\n",
      "[92,   499] loss: 0.014638\n",
      "[92,   599] loss: 0.030641\n",
      "[92,   699] loss: 0.041277\n",
      "[93,    99] loss: 0.021088\n",
      "[93,   199] loss: 0.024367\n",
      "[93,   299] loss: 0.022912\n",
      "[93,   399] loss: 0.025831\n",
      "[93,   499] loss: 0.014390\n",
      "[93,   599] loss: 0.029467\n",
      "[93,   699] loss: 0.039608\n",
      "[94,    99] loss: 0.020089\n",
      "[94,   199] loss: 0.023709\n",
      "[94,   299] loss: 0.020591\n",
      "[94,   399] loss: 0.023354\n",
      "[94,   499] loss: 0.011366\n",
      "[94,   599] loss: 0.027813\n",
      "[94,   699] loss: 0.038074\n",
      "[95,    99] loss: 0.019481\n",
      "[95,   199] loss: 0.022663\n",
      "[95,   299] loss: 0.022010\n",
      "[95,   399] loss: 0.025830\n",
      "[95,   499] loss: 0.013800\n",
      "[95,   599] loss: 0.026591\n",
      "[95,   699] loss: 0.036359\n",
      "[96,    99] loss: 0.021657\n",
      "[96,   199] loss: 0.021481\n",
      "[96,   299] loss: 0.020498\n",
      "[96,   399] loss: 0.023241\n",
      "[96,   499] loss: 0.012210\n",
      "[96,   599] loss: 0.025516\n",
      "[96,   699] loss: 0.035464\n",
      "[97,    99] loss: 0.018495\n",
      "[97,   199] loss: 0.020477\n",
      "[97,   299] loss: 0.019836\n",
      "[97,   399] loss: 0.022494\n",
      "[97,   499] loss: 0.012333\n",
      "[97,   599] loss: 0.024611\n",
      "[97,   699] loss: 0.033169\n",
      "[98,    99] loss: 0.017772\n",
      "[98,   199] loss: 0.020367\n",
      "[98,   299] loss: 0.018275\n",
      "[98,   399] loss: 0.021430\n",
      "[98,   499] loss: 0.011341\n",
      "[98,   599] loss: 0.023719\n",
      "[98,   699] loss: 0.032037\n",
      "[99,    99] loss: 0.017449\n",
      "[99,   199] loss: 0.019790\n",
      "[99,   299] loss: 0.018183\n",
      "[99,   399] loss: 0.021327\n",
      "[99,   499] loss: 0.011575\n",
      "[99,   599] loss: 0.022789\n",
      "[99,   699] loss: 0.031445\n",
      "[100,    99] loss: 0.016229\n",
      "[100,   199] loss: 0.019460\n",
      "[100,   299] loss: 0.016584\n",
      "[100,   399] loss: 0.019812\n",
      "[100,   499] loss: 0.009704\n",
      "[100,   599] loss: 0.021800\n",
      "[100,   699] loss: 0.030477\n",
      "Finished Training\n",
      "[1,    99] loss: 0.679990\n",
      "[1,   199] loss: 0.710746\n",
      "[1,   299] loss: 0.691508\n",
      "[1,   399] loss: 0.688840\n",
      "[1,   499] loss: 0.682152\n",
      "[1,   599] loss: 0.693731\n",
      "[1,   699] loss: 0.681684\n",
      "[2,    99] loss: 0.665752"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2,   199] loss: 0.688581\n",
      "[2,   299] loss: 0.672579\n",
      "[2,   399] loss: 0.674574\n",
      "[2,   499] loss: 0.668372\n",
      "[2,   599] loss: 0.681138\n",
      "[2,   699] loss: 0.667756\n",
      "[3,    99] loss: 0.648697\n",
      "[3,   199] loss: 0.666738\n",
      "[3,   299] loss: 0.652342\n",
      "[3,   399] loss: 0.658120\n",
      "[3,   499] loss: 0.651307\n",
      "[3,   599] loss: 0.666138\n",
      "[3,   699] loss: 0.650917\n",
      "[4,    99] loss: 0.627235\n",
      "[4,   199] loss: 0.639583\n",
      "[4,   299] loss: 0.628694\n",
      "[4,   399] loss: 0.638854\n",
      "[4,   499] loss: 0.631063\n",
      "[4,   599] loss: 0.649389\n",
      "[4,   699] loss: 0.633737\n",
      "[5,    99] loss: 0.605665\n",
      "[5,   199] loss: 0.608733\n",
      "[5,   299] loss: 0.603773\n",
      "[5,   399] loss: 0.618379\n",
      "[5,   499] loss: 0.610253\n",
      "[5,   599] loss: 0.632346\n",
      "[5,   699] loss: 0.617666\n",
      "[6,    99] loss: 0.587689\n",
      "[6,   199] loss: 0.578947\n",
      "[6,   299] loss: 0.579889\n",
      "[6,   399] loss: 0.598238\n",
      "[6,   499] loss: 0.590495\n",
      "[6,   599] loss: 0.617033\n",
      "[6,   699] loss: 0.602555\n",
      "[7,    99] loss: 0.572984\n",
      "[7,   199] loss: 0.551055\n",
      "[7,   299] loss: 0.558313\n",
      "[7,   399] loss: 0.579551\n",
      "[7,   499] loss: 0.571223\n",
      "[7,   599] loss: 0.603089\n",
      "[7,   699] loss: 0.587803\n",
      "[8,    99] loss: 0.559494\n",
      "[8,   199] loss: 0.526309\n",
      "[8,   299] loss: 0.538280\n",
      "[8,   399] loss: 0.561942\n",
      "[8,   499] loss: 0.552287\n",
      "[8,   599] loss: 0.589119\n",
      "[8,   699] loss: 0.573481\n",
      "[9,    99] loss: 0.547998\n",
      "[9,   199] loss: 0.503380\n",
      "[9,   299] loss: 0.518917\n",
      "[9,   399] loss: 0.545569\n",
      "[9,   499] loss: 0.533444\n",
      "[9,   599] loss: 0.574541\n",
      "[9,   699] loss: 0.558185\n",
      "[10,    99] loss: 0.536292\n",
      "[10,   199] loss: 0.481414\n",
      "[10,   299] loss: 0.499854\n",
      "[10,   399] loss: 0.529581\n",
      "[10,   499] loss: 0.514172\n",
      "[10,   599] loss: 0.559492\n",
      "[10,   699] loss: 0.541950\n",
      "[11,    99] loss: 0.524728\n",
      "[11,   199] loss: 0.460061\n",
      "[11,   299] loss: 0.481301\n",
      "[11,   399] loss: 0.514428\n",
      "[11,   499] loss: 0.494919\n",
      "[11,   599] loss: 0.544179\n",
      "[11,   699] loss: 0.524438\n",
      "[12,    99] loss: 0.512459\n",
      "[12,   199] loss: 0.438689\n",
      "[12,   299] loss: 0.462522\n",
      "[12,   399] loss: 0.499536\n",
      "[12,   499] loss: 0.475752\n",
      "[12,   599] loss: 0.528199\n",
      "[12,   699] loss: 0.506205\n",
      "[13,    99] loss: 0.499398\n",
      "[13,   199] loss: 0.417135\n",
      "[13,   299] loss: 0.443233\n",
      "[13,   399] loss: 0.484799\n",
      "[13,   499] loss: 0.457116\n",
      "[13,   599] loss: 0.511592\n",
      "[13,   699] loss: 0.487839\n",
      "[14,    99] loss: 0.486883\n",
      "[14,   199] loss: 0.396038\n",
      "[14,   299] loss: 0.423410\n",
      "[14,   399] loss: 0.470316\n",
      "[14,   499] loss: 0.438129\n",
      "[14,   599] loss: 0.494251\n",
      "[14,   699] loss: 0.469577\n",
      "[15,    99] loss: 0.473752\n",
      "[15,   199] loss: 0.374683\n",
      "[15,   299] loss: 0.403592\n",
      "[15,   399] loss: 0.456284\n",
      "[15,   499] loss: 0.420643\n",
      "[15,   599] loss: 0.476734\n",
      "[15,   699] loss: 0.451507\n",
      "[16,    99] loss: 0.460305\n",
      "[16,   199] loss: 0.354320\n",
      "[16,   299] loss: 0.383390\n",
      "[16,   399] loss: 0.442749\n",
      "[16,   499] loss: 0.402983\n",
      "[16,   599] loss: 0.459120\n",
      "[16,   699] loss: 0.432856\n",
      "[17,    99] loss: 0.445862\n",
      "[17,   199] loss: 0.334799\n",
      "[17,   299] loss: 0.363759\n",
      "[17,   399] loss: 0.429352\n",
      "[17,   499] loss: 0.385906\n",
      "[17,   599] loss: 0.440981\n",
      "[17,   699] loss: 0.414371\n",
      "[18,    99] loss: 0.431496\n",
      "[18,   199] loss: 0.315455\n",
      "[18,   299] loss: 0.344408\n",
      "[18,   399] loss: 0.416307\n",
      "[18,   499] loss: 0.369217\n",
      "[18,   599] loss: 0.422654\n",
      "[18,   699] loss: 0.395480\n",
      "[19,    99] loss: 0.420185\n",
      "[19,   199] loss: 0.297872\n",
      "[19,   299] loss: 0.325484\n",
      "[19,   399] loss: 0.403965\n",
      "[19,   499] loss: 0.352954\n",
      "[19,   599] loss: 0.404363\n",
      "[19,   699] loss: 0.378257\n",
      "[20,    99] loss: 0.405965\n",
      "[20,   199] loss: 0.280995\n",
      "[20,   299] loss: 0.308101\n",
      "[20,   399] loss: 0.391947\n",
      "[20,   499] loss: 0.337798\n",
      "[20,   599] loss: 0.387198\n",
      "[20,   699] loss: 0.359831\n",
      "[21,    99] loss: 0.391975\n",
      "[21,   199] loss: 0.265646\n",
      "[21,   299] loss: 0.290849\n",
      "[21,   399] loss: 0.380009\n",
      "[21,   499] loss: 0.324223\n",
      "[21,   599] loss: 0.370067\n",
      "[21,   699] loss: 0.343611\n",
      "[22,    99] loss: 0.378808\n",
      "[22,   199] loss: 0.251383\n",
      "[22,   299] loss: 0.275139\n",
      "[22,   399] loss: 0.368958\n",
      "[22,   499] loss: 0.311033\n",
      "[22,   599] loss: 0.354383\n",
      "[22,   699] loss: 0.327562\n",
      "[23,    99] loss: 0.365004\n",
      "[23,   199] loss: 0.237394\n",
      "[23,   299] loss: 0.260718\n",
      "[23,   399] loss: 0.358227\n",
      "[23,   499] loss: 0.299048\n",
      "[23,   599] loss: 0.339058\n",
      "[23,   699] loss: 0.313062\n",
      "[24,    99] loss: 0.352631\n",
      "[24,   199] loss: 0.224529\n",
      "[24,   299] loss: 0.246794\n",
      "[24,   399] loss: 0.347091\n",
      "[24,   499] loss: 0.287916\n",
      "[24,   599] loss: 0.324541\n",
      "[24,   699] loss: 0.297641\n",
      "[25,    99] loss: 0.340333\n",
      "[25,   199] loss: 0.214362\n",
      "[25,   299] loss: 0.233588\n",
      "[25,   399] loss: 0.336155\n",
      "[25,   499] loss: 0.277351\n",
      "[25,   599] loss: 0.309936\n",
      "[25,   699] loss: 0.283490\n",
      "[26,    99] loss: 0.326611\n",
      "[26,   199] loss: 0.203052\n",
      "[26,   299] loss: 0.221017\n",
      "[26,   399] loss: 0.325695\n",
      "[26,   499] loss: 0.267423\n",
      "[26,   599] loss: 0.296205\n",
      "[26,   699] loss: 0.269154\n",
      "[27,    99] loss: 0.313552\n",
      "[27,   199] loss: 0.192604\n",
      "[27,   299] loss: 0.210123\n",
      "[27,   399] loss: 0.315420\n",
      "[27,   499] loss: 0.257451\n",
      "[27,   599] loss: 0.283960\n",
      "[27,   699] loss: 0.256399\n",
      "[28,    99] loss: 0.299695\n",
      "[28,   199] loss: 0.182583\n",
      "[28,   299] loss: 0.199604\n",
      "[28,   399] loss: 0.305788\n",
      "[28,   499] loss: 0.248168\n",
      "[28,   599] loss: 0.271819\n",
      "[28,   699] loss: 0.243779\n",
      "[29,    99] loss: 0.288729\n",
      "[29,   199] loss: 0.173561\n",
      "[29,   299] loss: 0.189928\n",
      "[29,   399] loss: 0.296838\n",
      "[29,   499] loss: 0.239300\n",
      "[29,   599] loss: 0.260851\n",
      "[29,   699] loss: 0.231485\n",
      "[30,    99] loss: 0.278666\n",
      "[30,   199] loss: 0.165658\n",
      "[30,   299] loss: 0.181094\n",
      "[30,   399] loss: 0.287406\n",
      "[30,   499] loss: 0.230995\n",
      "[30,   599] loss: 0.250299\n",
      "[30,   699] loss: 0.220874\n",
      "[31,    99] loss: 0.268199\n",
      "[31,   199] loss: 0.156705\n",
      "[31,   299] loss: 0.172930\n",
      "[31,   399] loss: 0.279236\n",
      "[31,   499] loss: 0.222784\n",
      "[31,   599] loss: 0.239999\n",
      "[31,   699] loss: 0.210419\n",
      "[32,    99] loss: 0.258540\n",
      "[32,   199] loss: 0.148405\n",
      "[32,   299] loss: 0.165044\n",
      "[32,   399] loss: 0.270609\n",
      "[32,   499] loss: 0.215681\n",
      "[32,   599] loss: 0.230935\n",
      "[32,   699] loss: 0.199954\n",
      "[33,    99] loss: 0.248841\n",
      "[33,   199] loss: 0.141789\n",
      "[33,   299] loss: 0.158178\n",
      "[33,   399] loss: 0.262159\n",
      "[33,   499] loss: 0.208538\n",
      "[33,   599] loss: 0.221723\n",
      "[33,   699] loss: 0.190434\n",
      "[34,    99] loss: 0.240016\n",
      "[34,   199] loss: 0.135488\n",
      "[34,   299] loss: 0.151066\n",
      "[34,   399] loss: 0.253739\n",
      "[34,   499] loss: 0.202223\n",
      "[34,   599] loss: 0.213566\n",
      "[34,   699] loss: 0.181257\n",
      "[35,    99] loss: 0.230600\n",
      "[35,   199] loss: 0.128435\n",
      "[35,   299] loss: 0.144747\n",
      "[35,   399] loss: 0.245435\n",
      "[35,   499] loss: 0.195664\n",
      "[35,   599] loss: 0.205458\n",
      "[35,   699] loss: 0.172439\n",
      "[36,    99] loss: 0.222510\n",
      "[36,   199] loss: 0.123074\n",
      "[36,   299] loss: 0.138504\n",
      "[36,   399] loss: 0.238243\n",
      "[36,   499] loss: 0.189724\n",
      "[36,   599] loss: 0.197792\n",
      "[36,   699] loss: 0.164363\n",
      "[37,    99] loss: 0.214676\n",
      "[37,   199] loss: 0.116097\n",
      "[37,   299] loss: 0.132708\n",
      "[37,   399] loss: 0.230633\n",
      "[37,   499] loss: 0.184026\n",
      "[37,   599] loss: 0.190505\n",
      "[37,   699] loss: 0.157175\n",
      "[38,    99] loss: 0.206603\n",
      "[38,   199] loss: 0.110017\n",
      "[38,   299] loss: 0.127110\n",
      "[38,   399] loss: 0.223018\n",
      "[38,   499] loss: 0.178964\n",
      "[38,   599] loss: 0.183735\n",
      "[38,   699] loss: 0.149681\n",
      "[39,    99] loss: 0.198467\n",
      "[39,   199] loss: 0.105438\n",
      "[39,   299] loss: 0.122118\n",
      "[39,   399] loss: 0.216150\n",
      "[39,   499] loss: 0.174063\n",
      "[39,   599] loss: 0.176801\n",
      "[39,   699] loss: 0.142752\n",
      "[40,    99] loss: 0.192252\n",
      "[40,   199] loss: 0.098543\n",
      "[40,   299] loss: 0.117259\n",
      "[40,   399] loss: 0.209448\n",
      "[40,   499] loss: 0.168549\n",
      "[40,   599] loss: 0.170596\n",
      "[40,   699] loss: 0.136489\n",
      "[41,    99] loss: 0.184727\n",
      "[41,   199] loss: 0.095132\n",
      "[41,   299] loss: 0.113230\n",
      "[41,   399] loss: 0.202759\n",
      "[41,   499] loss: 0.163160\n",
      "[41,   599] loss: 0.164276\n",
      "[41,   699] loss: 0.130498\n",
      "[42,    99] loss: 0.178772\n",
      "[42,   199] loss: 0.090222\n",
      "[42,   299] loss: 0.107984\n",
      "[42,   399] loss: 0.197420\n",
      "[42,   499] loss: 0.158954\n",
      "[42,   599] loss: 0.158312\n",
      "[42,   699] loss: 0.124621\n",
      "[43,    99] loss: 0.171762\n",
      "[43,   199] loss: 0.085384\n",
      "[43,   299] loss: 0.104194\n",
      "[43,   399] loss: 0.190429\n",
      "[43,   499] loss: 0.154646\n",
      "[43,   599] loss: 0.152617\n",
      "[43,   699] loss: 0.118828\n",
      "[44,    99] loss: 0.166563\n",
      "[44,   199] loss: 0.082812\n",
      "[44,   299] loss: 0.100849\n",
      "[44,   399] loss: 0.183862\n",
      "[44,   499] loss: 0.150019\n",
      "[44,   599] loss: 0.147742\n",
      "[44,   699] loss: 0.113802\n",
      "[45,    99] loss: 0.161437\n",
      "[45,   199] loss: 0.077227\n",
      "[45,   299] loss: 0.096692\n",
      "[45,   399] loss: 0.177702\n",
      "[45,   499] loss: 0.146217\n",
      "[45,   599] loss: 0.142222\n",
      "[45,   699] loss: 0.108859\n",
      "[46,    99] loss: 0.156094\n",
      "[46,   199] loss: 0.072398\n",
      "[46,   299] loss: 0.092995\n",
      "[46,   399] loss: 0.171569\n",
      "[46,   499] loss: 0.143165\n",
      "[46,   599] loss: 0.137678\n",
      "[46,   699] loss: 0.103051\n",
      "[47,    99] loss: 0.151689\n",
      "[47,   199] loss: 0.070320\n",
      "[47,   299] loss: 0.090410\n",
      "[47,   399] loss: 0.165512\n",
      "[47,   499] loss: 0.138222\n",
      "[47,   599] loss: 0.132916\n",
      "[47,   699] loss: 0.098645\n",
      "[48,    99] loss: 0.146859\n",
      "[48,   199] loss: 0.065420\n",
      "[48,   299] loss: 0.086381\n",
      "[48,   399] loss: 0.160652\n",
      "[48,   499] loss: 0.134395\n",
      "[48,   599] loss: 0.127919\n",
      "[48,   699] loss: 0.094642\n",
      "[49,    99] loss: 0.142152\n",
      "[49,   199] loss: 0.063713\n",
      "[49,   299] loss: 0.083919\n",
      "[49,   399] loss: 0.153395\n",
      "[49,   499] loss: 0.130549\n",
      "[49,   599] loss: 0.123939\n",
      "[49,   699] loss: 0.090086\n",
      "[50,    99] loss: 0.136808\n",
      "[50,   199] loss: 0.058553\n",
      "[50,   299] loss: 0.080945\n",
      "[50,   399] loss: 0.147869\n",
      "[50,   499] loss: 0.126531\n",
      "[50,   599] loss: 0.119070\n",
      "[50,   699] loss: 0.086287\n",
      "[51,    99] loss: 0.133656\n",
      "[51,   199] loss: 0.056417\n",
      "[51,   299] loss: 0.078152\n",
      "[51,   399] loss: 0.142486\n",
      "[51,   499] loss: 0.123197\n",
      "[51,   599] loss: 0.114240\n",
      "[51,   699] loss: 0.082214\n",
      "[52,    99] loss: 0.129717\n",
      "[52,   199] loss: 0.053044\n",
      "[52,   299] loss: 0.075496\n",
      "[52,   399] loss: 0.136703\n",
      "[52,   499] loss: 0.120703\n",
      "[52,   599] loss: 0.110106\n",
      "[52,   699] loss: 0.078146\n",
      "[53,    99] loss: 0.125964\n",
      "[53,   199] loss: 0.051546\n",
      "[53,   299] loss: 0.072506\n",
      "[53,   399] loss: 0.133072\n",
      "[53,   499] loss: 0.115287\n",
      "[53,   599] loss: 0.106663\n",
      "[53,   699] loss: 0.075210\n",
      "[54,    99] loss: 0.122030\n",
      "[54,   199] loss: 0.048576\n",
      "[54,   299] loss: 0.069902\n",
      "[54,   399] loss: 0.126872\n",
      "[54,   499] loss: 0.112880\n",
      "[54,   599] loss: 0.102363\n",
      "[54,   699] loss: 0.071637\n",
      "[55,    99] loss: 0.118883\n",
      "[55,   199] loss: 0.045688\n",
      "[55,   299] loss: 0.067318\n",
      "[55,   399] loss: 0.121806\n",
      "[55,   499] loss: 0.109964\n",
      "[55,   599] loss: 0.098395\n",
      "[55,   699] loss: 0.068315\n",
      "[56,    99] loss: 0.115617\n",
      "[56,   199] loss: 0.044523\n",
      "[56,   299] loss: 0.065134\n",
      "[56,   399] loss: 0.116996\n",
      "[56,   499] loss: 0.106574\n",
      "[56,   599] loss: 0.095349\n",
      "[56,   699] loss: 0.065819\n",
      "[57,    99] loss: 0.112526\n",
      "[57,   199] loss: 0.039956\n",
      "[57,   299] loss: 0.062088\n",
      "[57,   399] loss: 0.112233\n",
      "[57,   499] loss: 0.102970\n",
      "[57,   599] loss: 0.091817\n",
      "[57,   699] loss: 0.063413\n",
      "[58,    99] loss: 0.110246\n",
      "[58,   199] loss: 0.040677\n",
      "[58,   299] loss: 0.060427\n",
      "[58,   399] loss: 0.109005\n",
      "[58,   499] loss: 0.100369\n",
      "[58,   599] loss: 0.089211\n",
      "[58,   699] loss: 0.060713\n",
      "[59,    99] loss: 0.106488\n",
      "[59,   199] loss: 0.036839\n",
      "[59,   299] loss: 0.057785\n",
      "[59,   399] loss: 0.103517\n",
      "[59,   499] loss: 0.098919\n",
      "[59,   599] loss: 0.085935\n",
      "[59,   699] loss: 0.057775\n",
      "[60,    99] loss: 0.104447\n",
      "[60,   199] loss: 0.037366\n",
      "[60,   299] loss: 0.055905\n",
      "[60,   399] loss: 0.098999\n",
      "[60,   499] loss: 0.094431\n",
      "[60,   599] loss: 0.083130\n",
      "[60,   699] loss: 0.056067\n",
      "[61,    99] loss: 0.101606\n",
      "[61,   199] loss: 0.033059\n",
      "[61,   299] loss: 0.052781\n",
      "[61,   399] loss: 0.095948\n",
      "[61,   499] loss: 0.093189\n",
      "[61,   599] loss: 0.080115\n",
      "[61,   699] loss: 0.053308\n",
      "[62,    99] loss: 0.099273\n",
      "[62,   199] loss: 0.033728\n",
      "[62,   299] loss: 0.051197\n",
      "[62,   399] loss: 0.091274\n",
      "[62,   499] loss: 0.089907\n",
      "[62,   599] loss: 0.078435\n",
      "[62,   699] loss: 0.051444\n",
      "[63,    99] loss: 0.096851\n",
      "[63,   199] loss: 0.029618\n",
      "[63,   299] loss: 0.047943\n",
      "[63,   399] loss: 0.088842\n",
      "[63,   499] loss: 0.087351\n",
      "[63,   599] loss: 0.074843\n",
      "[63,   699] loss: 0.048720\n",
      "[64,    99] loss: 0.095001\n",
      "[64,   199] loss: 0.030040\n",
      "[64,   299] loss: 0.046507\n",
      "[64,   399] loss: 0.084121\n",
      "[64,   499] loss: 0.085319\n",
      "[64,   599] loss: 0.073019\n",
      "[64,   699] loss: 0.047015\n",
      "[65,    99] loss: 0.091816\n",
      "[65,   199] loss: 0.026007\n",
      "[65,   299] loss: 0.044500\n",
      "[65,   399] loss: 0.081442\n",
      "[65,   499] loss: 0.081852\n",
      "[65,   599] loss: 0.070575\n",
      "[65,   699] loss: 0.045092\n",
      "[66,    99] loss: 0.090927\n",
      "[66,   199] loss: 0.030799\n",
      "[66,   299] loss: 0.042601\n",
      "[66,   399] loss: 0.077936\n",
      "[66,   499] loss: 0.079905\n",
      "[66,   599] loss: 0.068340\n",
      "[66,   699] loss: 0.043392\n",
      "[67,    99] loss: 0.087124\n",
      "[67,   199] loss: 0.022972\n",
      "[67,   299] loss: 0.041367\n",
      "[67,   399] loss: 0.074261\n",
      "[67,   499] loss: 0.077277\n",
      "[67,   599] loss: 0.065550\n",
      "[67,   699] loss: 0.041762\n",
      "[68,    99] loss: 0.085977\n",
      "[68,   199] loss: 0.022471\n",
      "[68,   299] loss: 0.038693\n",
      "[68,   399] loss: 0.070799\n",
      "[68,   499] loss: 0.074874\n",
      "[68,   599] loss: 0.063798\n",
      "[68,   699] loss: 0.039640\n",
      "[69,    99] loss: 0.084112\n",
      "[69,   199] loss: 0.024754\n",
      "[69,   299] loss: 0.038004\n",
      "[69,   399] loss: 0.069156\n",
      "[69,   499] loss: 0.071277\n",
      "[69,   599] loss: 0.062042\n",
      "[69,   699] loss: 0.039150\n",
      "[70,    99] loss: 0.081850\n",
      "[70,   199] loss: 0.020288\n",
      "[70,   299] loss: 0.035630\n",
      "[70,   399] loss: 0.066354\n",
      "[70,   499] loss: 0.070584\n",
      "[70,   599] loss: 0.059982\n",
      "[70,   699] loss: 0.036607\n",
      "[71,    99] loss: 0.080087\n",
      "[71,   199] loss: 0.021195\n",
      "[71,   299] loss: 0.034458\n",
      "[71,   399] loss: 0.063157\n",
      "[71,   499] loss: 0.067173\n",
      "[71,   599] loss: 0.058028\n",
      "[71,   699] loss: 0.035758\n",
      "[72,    99] loss: 0.078249\n",
      "[72,   199] loss: 0.019917\n",
      "[72,   299] loss: 0.033190\n",
      "[72,   399] loss: 0.059556\n",
      "[72,   499] loss: 0.065479\n",
      "[72,   599] loss: 0.055860\n",
      "[72,   699] loss: 0.034298\n",
      "[73,    99] loss: 0.076252\n",
      "[73,   199] loss: 0.017807\n",
      "[73,   299] loss: 0.031074\n",
      "[73,   399] loss: 0.058900\n",
      "[73,   499] loss: 0.062887\n",
      "[73,   599] loss: 0.053954\n",
      "[73,   699] loss: 0.032833\n",
      "[74,    99] loss: 0.074982\n",
      "[74,   199] loss: 0.019830\n",
      "[74,   299] loss: 0.030161\n",
      "[74,   399] loss: 0.055032\n",
      "[74,   499] loss: 0.061633\n",
      "[74,   599] loss: 0.052110\n",
      "[74,   699] loss: 0.031648\n",
      "[75,    99] loss: 0.072583\n",
      "[75,   199] loss: 0.015896\n",
      "[75,   299] loss: 0.028359\n",
      "[75,   399] loss: 0.052692\n",
      "[75,   499] loss: 0.059629\n",
      "[75,   599] loss: 0.050965\n",
      "[75,   699] loss: 0.029959\n",
      "[76,    99] loss: 0.070823\n",
      "[76,   199] loss: 0.015741\n",
      "[76,   299] loss: 0.027517\n",
      "[76,   399] loss: 0.051405\n",
      "[76,   499] loss: 0.057486\n",
      "[76,   599] loss: 0.049652\n",
      "[76,   699] loss: 0.029308\n",
      "[77,    99] loss: 0.069491\n",
      "[77,   199] loss: 0.016950\n",
      "[77,   299] loss: 0.026560\n",
      "[77,   399] loss: 0.048591\n",
      "[77,   499] loss: 0.055231\n",
      "[77,   599] loss: 0.047500\n",
      "[77,   699] loss: 0.028293\n",
      "[78,    99] loss: 0.066732\n",
      "[78,   199] loss: 0.014148\n",
      "[78,   299] loss: 0.025223\n",
      "[78,   399] loss: 0.045964\n",
      "[78,   499] loss: 0.054044\n",
      "[78,   599] loss: 0.045947\n",
      "[78,   699] loss: 0.026985\n",
      "[79,    99] loss: 0.065368\n",
      "[79,   199] loss: 0.016295\n",
      "[79,   299] loss: 0.024666\n",
      "[79,   399] loss: 0.044583\n",
      "[79,   499] loss: 0.050917\n",
      "[79,   599] loss: 0.044016\n",
      "[79,   699] loss: 0.026170\n",
      "[80,    99] loss: 0.061910\n",
      "[80,   199] loss: 0.012711\n",
      "[80,   299] loss: 0.023019\n",
      "[80,   399] loss: 0.042863\n",
      "[80,   499] loss: 0.050113\n",
      "[80,   599] loss: 0.042762\n",
      "[80,   699] loss: 0.024262\n",
      "[81,    99] loss: 0.059982\n",
      "[81,   199] loss: 0.011899\n",
      "[81,   299] loss: 0.021767\n",
      "[81,   399] loss: 0.040989\n",
      "[81,   499] loss: 0.048532\n",
      "[81,   599] loss: 0.042025\n",
      "[81,   699] loss: 0.024126\n",
      "[82,    99] loss: 0.060014\n",
      "[82,   199] loss: 0.031200\n",
      "[82,   299] loss: 0.022592\n",
      "[82,   399] loss: 0.038385\n",
      "[82,   499] loss: 0.044100\n",
      "[82,   599] loss: 0.039954\n",
      "[82,   699] loss: 0.024406\n",
      "[83,    99] loss: 0.054420\n",
      "[83,   199] loss: 0.010929\n",
      "[83,   299] loss: 0.020589\n",
      "[83,   399] loss: 0.037081\n",
      "[83,   499] loss: 0.044510\n",
      "[83,   599] loss: 0.038169\n",
      "[83,   699] loss: 0.020346\n",
      "[84,    99] loss: 0.052973\n",
      "[84,   199] loss: 0.010790\n",
      "[84,   299] loss: 0.019881\n",
      "[84,   399] loss: 0.035525\n",
      "[84,   499] loss: 0.042802\n",
      "[84,   599] loss: 0.038015\n",
      "[84,   699] loss: 0.019924\n",
      "[85,    99] loss: 0.051489\n",
      "[85,   199] loss: 0.010076\n",
      "[85,   299] loss: 0.018739\n",
      "[85,   399] loss: 0.035152\n",
      "[85,   499] loss: 0.040977\n",
      "[85,   599] loss: 0.037296\n",
      "[85,   699] loss: 0.019761\n",
      "[86,    99] loss: 0.050324\n",
      "[86,   199] loss: 0.009649\n",
      "[86,   299] loss: 0.018333\n",
      "[86,   399] loss: 0.033091\n",
      "[86,   499] loss: 0.041117\n",
      "[86,   599] loss: 0.036755\n",
      "[86,   699] loss: 0.019184\n",
      "[87,    99] loss: 0.048240\n",
      "[87,   199] loss: 0.009750\n",
      "[87,   299] loss: 0.017349\n",
      "[87,   399] loss: 0.031410\n",
      "[87,   499] loss: 0.039014\n",
      "[87,   599] loss: 0.035188\n",
      "[87,   699] loss: 0.019993\n",
      "[88,    99] loss: 0.049579\n",
      "[88,   199] loss: 0.049274\n",
      "[88,   299] loss: 0.018704\n",
      "[88,   399] loss: 0.030017\n",
      "[88,   499] loss: 0.034516\n",
      "[88,   599] loss: 0.033131\n",
      "[88,   699] loss: 0.017051\n",
      "[89,    99] loss: 0.042239\n",
      "[89,   199] loss: 0.008132\n",
      "[89,   299] loss: 0.016651\n",
      "[89,   399] loss: 0.027862\n",
      "[89,   499] loss: 0.035252\n",
      "[89,   599] loss: 0.031218\n",
      "[89,   699] loss: 0.015439\n",
      "[90,    99] loss: 0.041195\n",
      "[90,   199] loss: 0.008155\n",
      "[90,   299] loss: 0.015554\n",
      "[90,   399] loss: 0.027797\n",
      "[90,   499] loss: 0.034045\n",
      "[90,   599] loss: 0.031552\n",
      "[90,   699] loss: 0.014903\n",
      "[91,    99] loss: 0.039800\n",
      "[91,   199] loss: 0.007919\n",
      "[91,   299] loss: 0.014896\n",
      "[91,   399] loss: 0.027199\n",
      "[91,   499] loss: 0.034402\n",
      "[91,   599] loss: 0.031780\n",
      "[91,   699] loss: 0.014817\n",
      "[92,    99] loss: 0.038110\n",
      "[92,   199] loss: 0.007782\n",
      "[92,   299] loss: 0.014312\n",
      "[92,   399] loss: 0.025969\n",
      "[92,   499] loss: 0.033739\n",
      "[92,   599] loss: 0.031268\n",
      "[92,   699] loss: 0.014344\n",
      "[93,    99] loss: 0.036732\n",
      "[93,   199] loss: 0.007126\n",
      "[93,   299] loss: 0.013689\n",
      "[93,   399] loss: 0.024673\n",
      "[93,   499] loss: 0.032039\n",
      "[93,   599] loss: 0.030113\n",
      "[93,   699] loss: 0.014022\n",
      "[94,    99] loss: 0.035510\n",
      "[94,   199] loss: 0.006599\n",
      "[94,   299] loss: 0.013493\n",
      "[94,   399] loss: 0.022794\n",
      "[94,   499] loss: 0.031076\n",
      "[94,   599] loss: 0.030113\n",
      "[94,   699] loss: 0.014499\n",
      "[95,    99] loss: 0.037930\n",
      "[95,   199] loss: 0.066019\n",
      "[95,   299] loss: 0.013934\n",
      "[95,   399] loss: 0.022261\n",
      "[95,   499] loss: 0.026995\n",
      "[95,   599] loss: 0.026417\n",
      "[95,   699] loss: 0.012246\n",
      "[96,    99] loss: 0.028849\n",
      "[96,   199] loss: 0.006084\n",
      "[96,   299] loss: 0.012746\n",
      "[96,   399] loss: 0.021123\n",
      "[96,   499] loss: 0.028055\n",
      "[96,   599] loss: 0.025590\n",
      "[96,   699] loss: 0.011296\n",
      "[97,    99] loss: 0.028385\n",
      "[97,   199] loss: 0.005980\n",
      "[97,   299] loss: 0.012270\n",
      "[97,   399] loss: 0.019994\n",
      "[97,   499] loss: 0.027625\n",
      "[97,   599] loss: 0.025697\n",
      "[97,   699] loss: 0.010936\n",
      "[98,    99] loss: 0.027668\n",
      "[98,   199] loss: 0.005812\n",
      "[98,   299] loss: 0.011647\n",
      "[98,   399] loss: 0.019848\n",
      "[98,   499] loss: 0.026373\n",
      "[98,   599] loss: 0.025966\n",
      "[98,   699] loss: 0.010929\n",
      "[99,    99] loss: 0.026633\n",
      "[99,   199] loss: 0.005798\n",
      "[99,   299] loss: 0.011024\n",
      "[99,   399] loss: 0.018973\n",
      "[99,   499] loss: 0.026012\n",
      "[99,   599] loss: 0.025447\n",
      "[99,   699] loss: 0.010737\n",
      "[100,    99] loss: 0.025938\n",
      "[100,   199] loss: 0.005531\n",
      "[100,   299] loss: 0.010505\n",
      "[100,   399] loss: 0.018133\n",
      "[100,   499] loss: 0.025805\n",
      "[100,   599] loss: 0.025548\n",
      "[100,   699] loss: 0.010236\n",
      "Finished Training\n",
      "[1,    99] loss: 0.707730\n",
      "[1,   199] loss: 0.705981\n",
      "[1,   299] loss: 0.702953\n",
      "[1,   399] loss: 0.699495\n",
      "[1,   499] loss: 0.701432\n",
      "[1,   599] loss: 0.682302\n",
      "[1,   699] loss: 0.685657\n",
      "[2,    99] loss: 0.690059\n",
      "[2,   199] loss: 0.690545\n",
      "[2,   299] loss: 0.688780\n",
      "[2,   399] loss: 0.688883\n",
      "[2,   499] loss: 0.684874\n",
      "[2,   599] loss: 0.665042\n",
      "[2,   699] loss: 0.672212\n",
      "[3,    99] loss: 0.672314\n",
      "[3,   199] loss: 0.674916\n",
      "[3,   299] loss: 0.673344\n",
      "[3,   399] loss: 0.676571\n",
      "[3,   499] loss: 0.665743\n",
      "[3,   599] loss: 0.644651\n",
      "[3,   699] loss: 0.655500\n",
      "[4,    99] loss: 0.652332\n",
      "[4,   199] loss: 0.655909\n",
      "[4,   299] loss: 0.654140\n",
      "[4,   399] loss: 0.662015\n",
      "[4,   499] loss: 0.642892\n",
      "[4,   599] loss: 0.619688\n",
      "[4,   699] loss: 0.636390\n",
      "[5,    99] loss: 0.630018\n",
      "[5,   199] loss: 0.632013\n",
      "[5,   299] loss: 0.632727\n",
      "[5,   399] loss: 0.644987\n",
      "[5,   499] loss: 0.617795\n",
      "[5,   599] loss: 0.594118\n",
      "[5,   699] loss: 0.615136\n",
      "[6,    99] loss: 0.607043\n",
      "[6,   199] loss: 0.605356\n",
      "[6,   299] loss: 0.609440\n",
      "[6,   399] loss: 0.625981\n",
      "[6,   499] loss: 0.592016\n",
      "[6,   599] loss: 0.569306\n",
      "[6,   699] loss: 0.592548\n",
      "[7,    99] loss: 0.583443\n",
      "[7,   199] loss: 0.577745\n",
      "[7,   299] loss: 0.585084\n",
      "[7,   399] loss: 0.604896\n",
      "[7,   499] loss: 0.566107\n",
      "[7,   599] loss: 0.546040\n",
      "[7,   699] loss: 0.570270\n",
      "[8,    99] loss: 0.559824\n",
      "[8,   199] loss: 0.549761\n",
      "[8,   299] loss: 0.560781\n",
      "[8,   399] loss: 0.581865\n",
      "[8,   499] loss: 0.540397\n",
      "[8,   599] loss: 0.525065\n",
      "[8,   699] loss: 0.548408\n",
      "[9,    99] loss: 0.535754\n",
      "[9,   199] loss: 0.521332\n",
      "[9,   299] loss: 0.537019\n",
      "[9,   399] loss: 0.558619\n",
      "[9,   499] loss: 0.515675\n",
      "[9,   599] loss: 0.505308\n",
      "[9,   699] loss: 0.525260\n",
      "[10,    99] loss: 0.511476\n",
      "[10,   199] loss: 0.494137\n",
      "[10,   299] loss: 0.513631\n",
      "[10,   399] loss: 0.534408\n",
      "[10,   499] loss: 0.492316\n",
      "[10,   599] loss: 0.486319\n",
      "[10,   699] loss: 0.502503\n",
      "[11,    99] loss: 0.487049\n",
      "[11,   199] loss: 0.468588\n",
      "[11,   299] loss: 0.490243\n",
      "[11,   399] loss: 0.510596\n",
      "[11,   499] loss: 0.469580\n",
      "[11,   599] loss: 0.467961\n",
      "[11,   699] loss: 0.479551\n",
      "[12,    99] loss: 0.463529\n",
      "[12,   199] loss: 0.444390\n",
      "[12,   299] loss: 0.467348\n",
      "[12,   399] loss: 0.487285\n",
      "[12,   499] loss: 0.448001\n",
      "[12,   599] loss: 0.450352\n",
      "[12,   699] loss: 0.456757\n",
      "[13,    99] loss: 0.440094\n",
      "[13,   199] loss: 0.420949\n",
      "[13,   299] loss: 0.444529\n",
      "[13,   399] loss: 0.463545\n",
      "[13,   499] loss: 0.427113\n",
      "[13,   599] loss: 0.431722\n",
      "[13,   699] loss: 0.433646\n",
      "[14,    99] loss: 0.416212\n",
      "[14,   199] loss: 0.397357\n",
      "[14,   299] loss: 0.420557\n",
      "[14,   399] loss: 0.441117\n",
      "[14,   499] loss: 0.407424\n",
      "[14,   599] loss: 0.414190\n",
      "[14,   699] loss: 0.410099\n",
      "[15,    99] loss: 0.393781\n",
      "[15,   199] loss: 0.375822\n",
      "[15,   299] loss: 0.398335\n",
      "[15,   399] loss: 0.419540\n",
      "[15,   499] loss: 0.387829\n",
      "[15,   599] loss: 0.396719\n",
      "[15,   699] loss: 0.387998\n",
      "[16,    99] loss: 0.373809\n",
      "[16,   199] loss: 0.356291\n",
      "[16,   299] loss: 0.377766\n",
      "[16,   399] loss: 0.399890\n",
      "[16,   499] loss: 0.370194\n",
      "[16,   599] loss: 0.379843\n",
      "[16,   699] loss: 0.366107\n",
      "[17,    99] loss: 0.354680\n",
      "[17,   199] loss: 0.338367\n",
      "[17,   299] loss: 0.358742\n",
      "[17,   399] loss: 0.381754\n",
      "[17,   499] loss: 0.354035\n",
      "[17,   599] loss: 0.362892\n",
      "[17,   699] loss: 0.344536\n",
      "[18,    99] loss: 0.336754\n",
      "[18,   199] loss: 0.321805\n",
      "[18,   299] loss: 0.340698\n",
      "[18,   399] loss: 0.364908\n",
      "[18,   499] loss: 0.338550\n",
      "[18,   599] loss: 0.346529\n",
      "[18,   699] loss: 0.323977\n",
      "[19,    99] loss: 0.319506\n",
      "[19,   199] loss: 0.305969\n",
      "[19,   299] loss: 0.322998\n",
      "[19,   399] loss: 0.349784\n",
      "[19,   499] loss: 0.324607\n",
      "[19,   599] loss: 0.330066\n",
      "[19,   699] loss: 0.305098\n",
      "[20,    99] loss: 0.304024\n",
      "[20,   199] loss: 0.291518\n",
      "[20,   299] loss: 0.306735\n",
      "[20,   399] loss: 0.335738\n",
      "[20,   499] loss: 0.310991\n",
      "[20,   599] loss: 0.314791\n",
      "[20,   699] loss: 0.286875\n",
      "[21,    99] loss: 0.289549\n",
      "[21,   199] loss: 0.276893\n",
      "[21,   299] loss: 0.291234\n",
      "[21,   399] loss: 0.322319\n",
      "[21,   499] loss: 0.298797\n",
      "[21,   599] loss: 0.299699\n",
      "[21,   699] loss: 0.269435\n",
      "[22,    99] loss: 0.276468\n",
      "[22,   199] loss: 0.263877\n",
      "[22,   299] loss: 0.277103\n",
      "[22,   399] loss: 0.310205\n",
      "[22,   499] loss: 0.288131\n",
      "[22,   599] loss: 0.286416\n",
      "[22,   699] loss: 0.252606\n",
      "[23,    99] loss: 0.264371\n",
      "[23,   199] loss: 0.252449\n",
      "[23,   299] loss: 0.263369\n",
      "[23,   399] loss: 0.298859\n",
      "[23,   499] loss: 0.277810\n",
      "[23,   599] loss: 0.273453\n",
      "[23,   699] loss: 0.237679\n",
      "[24,    99] loss: 0.253382\n",
      "[24,   199] loss: 0.240772\n",
      "[24,   299] loss: 0.249905\n",
      "[24,   399] loss: 0.288273\n",
      "[24,   499] loss: 0.267343\n",
      "[24,   599] loss: 0.261262\n",
      "[24,   699] loss: 0.223608\n",
      "[25,    99] loss: 0.243183\n",
      "[25,   199] loss: 0.230120\n",
      "[25,   299] loss: 0.236936\n",
      "[25,   399] loss: 0.277324\n",
      "[25,   499] loss: 0.258161\n",
      "[25,   599] loss: 0.249702\n",
      "[25,   699] loss: 0.210125\n",
      "[26,    99] loss: 0.233520\n",
      "[26,   199] loss: 0.219779\n",
      "[26,   299] loss: 0.225131\n",
      "[26,   399] loss: 0.266534\n",
      "[26,   499] loss: 0.249124\n",
      "[26,   599] loss: 0.238426\n",
      "[26,   699] loss: 0.197771\n",
      "[27,    99] loss: 0.225006\n",
      "[27,   199] loss: 0.210495\n",
      "[27,   299] loss: 0.214418\n",
      "[27,   399] loss: 0.257446\n",
      "[27,   499] loss: 0.241353\n",
      "[27,   599] loss: 0.227485\n",
      "[27,   699] loss: 0.185327\n",
      "[28,    99] loss: 0.216841\n",
      "[28,   199] loss: 0.201545\n",
      "[28,   299] loss: 0.203899\n",
      "[28,   399] loss: 0.248120\n",
      "[28,   499] loss: 0.233671\n",
      "[28,   599] loss: 0.217016\n",
      "[28,   699] loss: 0.174850\n",
      "[29,    99] loss: 0.209195\n",
      "[29,   199] loss: 0.192515\n",
      "[29,   299] loss: 0.194249\n",
      "[29,   399] loss: 0.239581\n",
      "[29,   499] loss: 0.226912\n",
      "[29,   599] loss: 0.206994\n",
      "[29,   699] loss: 0.164596\n",
      "[30,    99] loss: 0.202272\n",
      "[30,   199] loss: 0.184285\n",
      "[30,   299] loss: 0.184890\n",
      "[30,   399] loss: 0.230821\n",
      "[30,   499] loss: 0.220819\n",
      "[30,   599] loss: 0.197220\n",
      "[30,   699] loss: 0.155139\n",
      "[31,    99] loss: 0.195746\n",
      "[31,   199] loss: 0.176530\n",
      "[31,   299] loss: 0.176481\n",
      "[31,   399] loss: 0.222271\n",
      "[31,   499] loss: 0.214911\n",
      "[31,   599] loss: 0.187646\n",
      "[31,   699] loss: 0.146231\n",
      "[32,    99] loss: 0.189757\n",
      "[32,   199] loss: 0.168325\n",
      "[32,   299] loss: 0.168372\n",
      "[32,   399] loss: 0.213988\n",
      "[32,   499] loss: 0.208806\n",
      "[32,   599] loss: 0.178754\n",
      "[32,   699] loss: 0.137356\n",
      "[33,    99] loss: 0.184477\n",
      "[33,   199] loss: 0.161007\n",
      "[33,   299] loss: 0.160216\n",
      "[33,   399] loss: 0.206036\n",
      "[33,   499] loss: 0.203975\n",
      "[33,   599] loss: 0.169995\n",
      "[33,   699] loss: 0.129913\n",
      "[34,    99] loss: 0.178815\n",
      "[34,   199] loss: 0.154521\n",
      "[34,   299] loss: 0.152474\n",
      "[34,   399] loss: 0.199040\n",
      "[34,   499] loss: 0.197537\n",
      "[34,   599] loss: 0.161120\n",
      "[34,   699] loss: 0.122716\n",
      "[35,    99] loss: 0.174053\n",
      "[35,   199] loss: 0.147580\n",
      "[35,   299] loss: 0.145003\n",
      "[35,   399] loss: 0.192049\n",
      "[35,   499] loss: 0.193059\n",
      "[35,   599] loss: 0.153150\n",
      "[35,   699] loss: 0.116271\n",
      "[36,    99] loss: 0.169197\n",
      "[36,   199] loss: 0.140719\n",
      "[36,   299] loss: 0.137302\n",
      "[36,   399] loss: 0.185149\n",
      "[36,   499] loss: 0.187100\n",
      "[36,   599] loss: 0.146017\n",
      "[36,   699] loss: 0.109619\n",
      "[37,    99] loss: 0.164386\n",
      "[37,   199] loss: 0.134127\n",
      "[37,   299] loss: 0.130039\n",
      "[37,   399] loss: 0.178536\n",
      "[37,   499] loss: 0.182941\n",
      "[37,   599] loss: 0.138734\n",
      "[37,   699] loss: 0.103814\n",
      "[38,    99] loss: 0.160096\n",
      "[38,   199] loss: 0.128080\n",
      "[38,   299] loss: 0.123911\n",
      "[38,   399] loss: 0.171910\n",
      "[38,   499] loss: 0.177209\n",
      "[38,   599] loss: 0.132352\n",
      "[38,   699] loss: 0.098098\n",
      "[39,    99] loss: 0.156211\n",
      "[39,   199] loss: 0.121830\n",
      "[39,   299] loss: 0.117059\n",
      "[39,   399] loss: 0.166029\n",
      "[39,   499] loss: 0.172456\n",
      "[39,   599] loss: 0.125732\n",
      "[39,   699] loss: 0.092792\n",
      "[40,    99] loss: 0.152343\n",
      "[40,   199] loss: 0.117171\n",
      "[40,   299] loss: 0.110861\n",
      "[40,   399] loss: 0.159851\n",
      "[40,   499] loss: 0.167343\n",
      "[40,   599] loss: 0.119306\n",
      "[40,   699] loss: 0.087959\n",
      "[41,    99] loss: 0.148606\n",
      "[41,   199] loss: 0.110954\n",
      "[41,   299] loss: 0.105733\n",
      "[41,   399] loss: 0.153938\n",
      "[41,   499] loss: 0.163324\n",
      "[41,   599] loss: 0.113907\n",
      "[41,   699] loss: 0.082972\n",
      "[42,    99] loss: 0.144855\n",
      "[42,   199] loss: 0.106154\n",
      "[42,   299] loss: 0.099683\n",
      "[42,   399] loss: 0.148435\n",
      "[42,   499] loss: 0.159053\n",
      "[42,   599] loss: 0.108139\n",
      "[42,   699] loss: 0.078978\n",
      "[43,    99] loss: 0.140931\n",
      "[43,   199] loss: 0.101595\n",
      "[43,   299] loss: 0.094590\n",
      "[43,   399] loss: 0.143039\n",
      "[43,   499] loss: 0.153909\n",
      "[43,   599] loss: 0.103000\n",
      "[43,   699] loss: 0.074989\n",
      "[44,    99] loss: 0.137489\n",
      "[44,   199] loss: 0.096644\n",
      "[44,   299] loss: 0.089154\n",
      "[44,   399] loss: 0.137820\n",
      "[44,   499] loss: 0.149657\n",
      "[44,   599] loss: 0.097885\n",
      "[44,   699] loss: 0.071383\n",
      "[45,    99] loss: 0.134290\n",
      "[45,   199] loss: 0.091936\n",
      "[45,   299] loss: 0.083381\n",
      "[45,   399] loss: 0.133271\n",
      "[45,   499] loss: 0.146244\n",
      "[45,   599] loss: 0.092882\n",
      "[45,   699] loss: 0.067739\n",
      "[46,    99] loss: 0.130145\n",
      "[46,   199] loss: 0.087939\n",
      "[46,   299] loss: 0.078893\n",
      "[46,   399] loss: 0.127858\n",
      "[46,   499] loss: 0.142129\n",
      "[46,   599] loss: 0.088566\n",
      "[46,   699] loss: 0.064290\n",
      "[47,    99] loss: 0.126973\n",
      "[47,   199] loss: 0.083685\n",
      "[47,   299] loss: 0.074492\n",
      "[47,   399] loss: 0.122711\n",
      "[47,   499] loss: 0.137570\n",
      "[47,   599] loss: 0.084560\n",
      "[47,   699] loss: 0.061020\n",
      "[48,    99] loss: 0.123769\n",
      "[48,   199] loss: 0.079289\n",
      "[48,   299] loss: 0.070214\n",
      "[48,   399] loss: 0.118301\n",
      "[48,   499] loss: 0.133644\n",
      "[48,   599] loss: 0.080188\n",
      "[48,   699] loss: 0.058063\n",
      "[49,    99] loss: 0.120797\n",
      "[49,   199] loss: 0.075102\n",
      "[49,   299] loss: 0.065771\n",
      "[49,   399] loss: 0.113412\n",
      "[49,   499] loss: 0.129276\n",
      "[49,   599] loss: 0.076418\n",
      "[49,   699] loss: 0.055253\n",
      "[50,    99] loss: 0.117487\n",
      "[50,   199] loss: 0.071298\n",
      "[50,   299] loss: 0.062546\n",
      "[50,   399] loss: 0.109004\n",
      "[50,   499] loss: 0.125597\n",
      "[50,   599] loss: 0.072381\n",
      "[50,   699] loss: 0.052612\n",
      "[51,    99] loss: 0.114700\n",
      "[51,   199] loss: 0.067772\n",
      "[51,   299] loss: 0.058216\n",
      "[51,   399] loss: 0.104419\n",
      "[51,   499] loss: 0.120863\n",
      "[51,   599] loss: 0.069311\n",
      "[51,   699] loss: 0.050290\n",
      "[52,    99] loss: 0.111617\n",
      "[52,   199] loss: 0.063681\n",
      "[52,   299] loss: 0.054966\n",
      "[52,   399] loss: 0.100031\n",
      "[52,   499] loss: 0.116996\n",
      "[52,   599] loss: 0.065827\n",
      "[52,   699] loss: 0.047772\n",
      "[53,    99] loss: 0.109136\n",
      "[53,   199] loss: 0.060135\n",
      "[53,   299] loss: 0.052338\n",
      "[53,   399] loss: 0.095339\n",
      "[53,   499] loss: 0.113395\n",
      "[53,   599] loss: 0.062451\n",
      "[53,   699] loss: 0.045382\n",
      "[54,    99] loss: 0.106343\n",
      "[54,   199] loss: 0.056682\n",
      "[54,   299] loss: 0.049358\n",
      "[54,   399] loss: 0.091718\n",
      "[54,   499] loss: 0.108960\n",
      "[54,   599] loss: 0.060037\n",
      "[54,   699] loss: 0.043140\n",
      "[55,    99] loss: 0.103300\n",
      "[55,   199] loss: 0.053652\n",
      "[55,   299] loss: 0.046154\n",
      "[55,   399] loss: 0.087524\n",
      "[55,   499] loss: 0.105507\n",
      "[55,   599] loss: 0.056837\n",
      "[55,   699] loss: 0.040933\n",
      "[56,    99] loss: 0.100495\n",
      "[56,   199] loss: 0.050637\n",
      "[56,   299] loss: 0.043781\n",
      "[56,   399] loss: 0.083733\n",
      "[56,   499] loss: 0.101227\n",
      "[56,   599] loss: 0.054512\n",
      "[56,   699] loss: 0.038946\n",
      "[57,    99] loss: 0.098054\n",
      "[57,   199] loss: 0.047676\n",
      "[57,   299] loss: 0.041670\n",
      "[57,   399] loss: 0.080266\n",
      "[57,   499] loss: 0.096343\n",
      "[57,   599] loss: 0.051602\n",
      "[57,   699] loss: 0.037195\n",
      "[58,    99] loss: 0.095464\n",
      "[58,   199] loss: 0.044716\n",
      "[58,   299] loss: 0.039069\n",
      "[58,   399] loss: 0.075751\n",
      "[58,   499] loss: 0.093788\n",
      "[58,   599] loss: 0.049705\n",
      "[58,   699] loss: 0.035247\n",
      "[59,    99] loss: 0.093522\n",
      "[59,   199] loss: 0.042108\n",
      "[59,   299] loss: 0.037037\n",
      "[59,   399] loss: 0.072968\n",
      "[59,   499] loss: 0.090287\n",
      "[59,   599] loss: 0.047088\n",
      "[59,   699] loss: 0.033306\n",
      "[60,    99] loss: 0.090879\n",
      "[60,   199] loss: 0.039957\n",
      "[60,   299] loss: 0.034947\n",
      "[60,   399] loss: 0.069262\n",
      "[60,   499] loss: 0.086777\n",
      "[60,   599] loss: 0.044605\n",
      "[60,   699] loss: 0.031146\n",
      "[61,    99] loss: 0.088204\n",
      "[61,   199] loss: 0.037866\n",
      "[61,   299] loss: 0.033168\n",
      "[61,   399] loss: 0.065868\n",
      "[61,   499] loss: 0.083729\n",
      "[61,   599] loss: 0.042349\n",
      "[61,   699] loss: 0.029868\n",
      "[62,    99] loss: 0.085838\n",
      "[62,   199] loss: 0.035499\n",
      "[62,   299] loss: 0.031599\n",
      "[62,   399] loss: 0.062750\n",
      "[62,   499] loss: 0.079804\n",
      "[62,   599] loss: 0.039978\n",
      "[62,   699] loss: 0.027905\n",
      "[63,    99] loss: 0.083745\n",
      "[63,   199] loss: 0.033370\n",
      "[63,   299] loss: 0.029669\n",
      "[63,   399] loss: 0.059644\n",
      "[63,   499] loss: 0.077633\n",
      "[63,   599] loss: 0.037814\n",
      "[63,   699] loss: 0.026491\n",
      "[64,    99] loss: 0.081733\n",
      "[64,   199] loss: 0.031750\n",
      "[64,   299] loss: 0.028189\n",
      "[64,   399] loss: 0.056691\n",
      "[64,   499] loss: 0.074036\n",
      "[64,   599] loss: 0.036674\n",
      "[64,   699] loss: 0.025212\n",
      "[65,    99] loss: 0.078935\n",
      "[65,   199] loss: 0.029534\n",
      "[65,   299] loss: 0.026793\n",
      "[65,   399] loss: 0.054467\n",
      "[65,   499] loss: 0.071191\n",
      "[65,   599] loss: 0.034486\n",
      "[65,   699] loss: 0.023821\n",
      "[66,    99] loss: 0.076901\n",
      "[66,   199] loss: 0.027965\n",
      "[66,   299] loss: 0.024925\n",
      "[66,   399] loss: 0.052153\n",
      "[66,   499] loss: 0.068247\n",
      "[66,   599] loss: 0.033007\n",
      "[66,   699] loss: 0.022582\n",
      "[67,    99] loss: 0.074212\n",
      "[67,   199] loss: 0.026564\n",
      "[67,   299] loss: 0.023860\n",
      "[67,   399] loss: 0.049431\n",
      "[67,   499] loss: 0.066008\n",
      "[67,   599] loss: 0.031189\n",
      "[67,   699] loss: 0.021378\n",
      "[68,    99] loss: 0.071852\n",
      "[68,   199] loss: 0.024907\n",
      "[68,   299] loss: 0.022523\n",
      "[68,   399] loss: 0.047074\n",
      "[68,   499] loss: 0.061905\n",
      "[68,   599] loss: 0.029592\n",
      "[68,   699] loss: 0.020119\n",
      "[69,    99] loss: 0.070228\n",
      "[69,   199] loss: 0.023419\n",
      "[69,   299] loss: 0.021406\n",
      "[69,   399] loss: 0.044375\n",
      "[69,   499] loss: 0.059577\n",
      "[69,   599] loss: 0.028427\n",
      "[69,   699] loss: 0.019150\n",
      "[70,    99] loss: 0.068204\n",
      "[70,   199] loss: 0.022080\n",
      "[70,   299] loss: 0.020357\n",
      "[70,   399] loss: 0.042433\n",
      "[70,   499] loss: 0.057158\n",
      "[70,   599] loss: 0.026754\n",
      "[70,   699] loss: 0.018080\n",
      "[71,    99] loss: 0.065619\n",
      "[71,   199] loss: 0.020977\n",
      "[71,   299] loss: 0.019121\n",
      "[71,   399] loss: 0.040630\n",
      "[71,   499] loss: 0.053748\n",
      "[71,   599] loss: 0.025884\n",
      "[71,   699] loss: 0.017125\n",
      "[72,    99] loss: 0.064001\n",
      "[72,   199] loss: 0.019657\n",
      "[72,   299] loss: 0.018188\n",
      "[72,   399] loss: 0.038299\n",
      "[72,   499] loss: 0.052240\n",
      "[72,   599] loss: 0.024296\n",
      "[72,   699] loss: 0.016072\n",
      "[73,    99] loss: 0.061822\n",
      "[73,   199] loss: 0.018739\n",
      "[73,   299] loss: 0.017143\n",
      "[73,   399] loss: 0.036148\n",
      "[73,   499] loss: 0.049052\n",
      "[73,   599] loss: 0.023115\n",
      "[73,   699] loss: 0.015384\n",
      "[74,    99] loss: 0.059881\n",
      "[74,   199] loss: 0.017309\n",
      "[74,   299] loss: 0.016111\n",
      "[74,   399] loss: 0.033824\n",
      "[74,   499] loss: 0.047725\n",
      "[74,   599] loss: 0.021945\n",
      "[74,   699] loss: 0.014656\n",
      "[75,    99] loss: 0.058413\n",
      "[75,   199] loss: 0.016594\n",
      "[75,   299] loss: 0.015772\n",
      "[75,   399] loss: 0.032056\n",
      "[75,   499] loss: 0.045395\n",
      "[75,   599] loss: 0.021013\n",
      "[75,   699] loss: 0.013656\n",
      "[76,    99] loss: 0.056094\n",
      "[76,   199] loss: 0.015615\n",
      "[76,   299] loss: 0.014750\n",
      "[76,   399] loss: 0.030185\n",
      "[76,   499] loss: 0.043639\n",
      "[76,   599] loss: 0.019765\n",
      "[76,   699] loss: 0.013029\n",
      "[77,    99] loss: 0.054917\n",
      "[77,   199] loss: 0.014642\n",
      "[77,   299] loss: 0.014108\n",
      "[77,   399] loss: 0.028559\n",
      "[77,   499] loss: 0.041956\n",
      "[77,   599] loss: 0.018941\n",
      "[77,   699] loss: 0.012320\n",
      "[78,    99] loss: 0.052448\n",
      "[78,   199] loss: 0.013755\n",
      "[78,   299] loss: 0.013233\n",
      "[78,   399] loss: 0.026878\n",
      "[78,   499] loss: 0.038802\n",
      "[78,   599] loss: 0.017930\n",
      "[78,   699] loss: 0.011562\n",
      "[79,    99] loss: 0.050578\n",
      "[79,   199] loss: 0.012976\n",
      "[79,   299] loss: 0.012469\n",
      "[79,   399] loss: 0.025512\n",
      "[79,   499] loss: 0.037889\n",
      "[79,   599] loss: 0.017190\n",
      "[79,   699] loss: 0.010828\n",
      "[80,    99] loss: 0.048951\n",
      "[80,   199] loss: 0.012269\n",
      "[80,   299] loss: 0.011777\n",
      "[80,   399] loss: 0.023985\n",
      "[80,   499] loss: 0.035435\n",
      "[80,   599] loss: 0.016179\n",
      "[80,   699] loss: 0.010468\n",
      "[81,    99] loss: 0.046835\n",
      "[81,   199] loss: 0.011543\n",
      "[81,   299] loss: 0.011162\n",
      "[81,   399] loss: 0.022841\n",
      "[81,   499] loss: 0.034051\n",
      "[81,   599] loss: 0.015315\n",
      "[81,   699] loss: 0.009798\n",
      "[82,    99] loss: 0.045025\n",
      "[82,   199] loss: 0.010801\n",
      "[82,   299] loss: 0.010737\n",
      "[82,   399] loss: 0.021398\n",
      "[82,   499] loss: 0.032033\n",
      "[82,   599] loss: 0.014628\n",
      "[82,   699] loss: 0.009191\n",
      "[83,    99] loss: 0.043368\n",
      "[83,   199] loss: 0.010257\n",
      "[83,   299] loss: 0.010100\n",
      "[83,   399] loss: 0.020069\n",
      "[83,   499] loss: 0.030562\n",
      "[83,   599] loss: 0.014094\n",
      "[83,   699] loss: 0.008868\n",
      "[84,    99] loss: 0.041790\n",
      "[84,   199] loss: 0.009604\n",
      "[84,   299] loss: 0.009538\n",
      "[84,   399] loss: 0.018887\n",
      "[84,   499] loss: 0.029079\n",
      "[84,   599] loss: 0.013183\n",
      "[84,   699] loss: 0.008401\n",
      "[85,    99] loss: 0.040109\n",
      "[85,   199] loss: 0.008913\n",
      "[85,   299] loss: 0.009023\n",
      "[85,   399] loss: 0.017831\n",
      "[85,   499] loss: 0.027659\n",
      "[85,   599] loss: 0.012722\n",
      "[85,   699] loss: 0.007935\n",
      "[86,    99] loss: 0.038492\n",
      "[86,   199] loss: 0.008526\n",
      "[86,   299] loss: 0.008709\n",
      "[86,   399] loss: 0.016809\n",
      "[86,   499] loss: 0.026106\n",
      "[86,   599] loss: 0.012392\n",
      "[86,   699] loss: 0.007584\n",
      "[87,    99] loss: 0.036502\n",
      "[87,   199] loss: 0.007985\n",
      "[87,   299] loss: 0.008221\n",
      "[87,   399] loss: 0.016025\n",
      "[87,   499] loss: 0.024909\n",
      "[87,   599] loss: 0.011591\n",
      "[87,   699] loss: 0.007233\n",
      "[88,    99] loss: 0.035367\n",
      "[88,   199] loss: 0.007543\n",
      "[88,   299] loss: 0.007751\n",
      "[88,   399] loss: 0.015130\n",
      "[88,   499] loss: 0.023829\n",
      "[88,   599] loss: 0.011097\n",
      "[88,   699] loss: 0.006826\n",
      "[89,    99] loss: 0.033482\n",
      "[89,   199] loss: 0.007063\n",
      "[89,   299] loss: 0.007460\n",
      "[89,   399] loss: 0.014210\n",
      "[89,   499] loss: 0.022609\n",
      "[89,   599] loss: 0.010366\n",
      "[89,   699] loss: 0.006355\n",
      "[90,    99] loss: 0.032341\n",
      "[90,   199] loss: 0.006616\n",
      "[90,   299] loss: 0.007046\n",
      "[90,   399] loss: 0.013338\n",
      "[90,   499] loss: 0.021739\n",
      "[90,   599] loss: 0.009846\n",
      "[90,   699] loss: 0.006013\n",
      "[91,    99] loss: 0.030871\n",
      "[91,   199] loss: 0.006277\n",
      "[91,   299] loss: 0.006825\n",
      "[91,   399] loss: 0.012756\n",
      "[91,   499] loss: 0.020417\n",
      "[91,   599] loss: 0.009181\n",
      "[91,   699] loss: 0.005790\n",
      "[92,    99] loss: 0.029446\n",
      "[92,   199] loss: 0.005845\n",
      "[92,   299] loss: 0.006356\n",
      "[92,   399] loss: 0.011756\n",
      "[92,   499] loss: 0.019678\n",
      "[92,   599] loss: 0.008940\n",
      "[92,   699] loss: 0.005314\n",
      "[93,    99] loss: 0.027672\n",
      "[93,   199] loss: 0.005564\n",
      "[93,   299] loss: 0.006115\n",
      "[93,   399] loss: 0.011126\n",
      "[93,   499] loss: 0.018683\n",
      "[93,   599] loss: 0.008292\n",
      "[93,   699] loss: 0.005095\n",
      "[94,    99] loss: 0.026373\n",
      "[94,   199] loss: 0.005257\n",
      "[94,   299] loss: 0.005899\n",
      "[94,   399] loss: 0.010615\n",
      "[94,   499] loss: 0.017675\n",
      "[94,   599] loss: 0.008050\n",
      "[94,   699] loss: 0.004934\n",
      "[95,    99] loss: 0.025232\n",
      "[95,   199] loss: 0.004975\n",
      "[95,   299] loss: 0.005488\n",
      "[95,   399] loss: 0.010014\n",
      "[95,   499] loss: 0.016953\n",
      "[95,   599] loss: 0.007677\n",
      "[95,   699] loss: 0.004667\n",
      "[96,    99] loss: 0.024085\n",
      "[96,   199] loss: 0.004651\n",
      "[96,   299] loss: 0.005215\n",
      "[96,   399] loss: 0.009215\n",
      "[96,   499] loss: 0.015815\n",
      "[96,   599] loss: 0.007244\n",
      "[96,   699] loss: 0.004316\n",
      "[97,    99] loss: 0.022573\n",
      "[97,   199] loss: 0.004361\n",
      "[97,   299] loss: 0.004799\n",
      "[97,   399] loss: 0.008892\n",
      "[97,   499] loss: 0.015360\n",
      "[97,   599] loss: 0.006894\n",
      "[97,   699] loss: 0.004144\n",
      "[98,    99] loss: 0.021683\n",
      "[98,   199] loss: 0.004253\n",
      "[98,   299] loss: 0.004597\n",
      "[98,   399] loss: 0.008081\n",
      "[98,   499] loss: 0.014531\n",
      "[98,   599] loss: 0.006476\n",
      "[98,   699] loss: 0.003992\n",
      "[99,    99] loss: 0.021251\n",
      "[99,   199] loss: 0.003908\n",
      "[99,   299] loss: 0.004483\n",
      "[99,   399] loss: 0.008027\n",
      "[99,   499] loss: 0.013737\n",
      "[99,   599] loss: 0.006387\n",
      "[99,   699] loss: 0.003866\n",
      "[100,    99] loss: 0.019745\n",
      "[100,   199] loss: 0.003713\n",
      "[100,   299] loss: 0.004088\n",
      "[100,   399] loss: 0.007058\n",
      "[100,   499] loss: 0.013193\n",
      "[100,   599] loss: 0.005570\n",
      "[100,   699] loss: 0.003557\n",
      "Finished Training\n",
      "[1,    99] loss: 0.695546\n",
      "[1,   199] loss: 0.688880\n",
      "[1,   299] loss: 0.681058\n",
      "[1,   399] loss: 0.675597\n",
      "[1,   499] loss: 0.679803\n",
      "[1,   599] loss: 0.682505\n",
      "[1,   699] loss: 0.682251\n",
      "[2,    99] loss: 0.653498\n",
      "[2,   199] loss: 0.671202\n",
      "[2,   299] loss: 0.662589\n",
      "[2,   399] loss: 0.655219\n",
      "[2,   499] loss: 0.651290\n",
      "[2,   599] loss: 0.654405\n",
      "[2,   699] loss: 0.670392\n",
      "[3,    99] loss: 0.620332\n",
      "[3,   199] loss: 0.654225\n",
      "[3,   299] loss: 0.645599\n",
      "[3,   399] loss: 0.636227\n",
      "[3,   499] loss: 0.627546\n",
      "[3,   599] loss: 0.635738\n",
      "[3,   699] loss: 0.658247\n",
      "[4,    99] loss: 0.593420\n",
      "[4,   199] loss: 0.636245\n",
      "[4,   299] loss: 0.627341\n",
      "[4,   399] loss: 0.617465\n",
      "[4,   499] loss: 0.605754\n",
      "[4,   599] loss: 0.618866\n",
      "[4,   699] loss: 0.646561\n",
      "[5,    99] loss: 0.571165\n",
      "[5,   199] loss: 0.619480\n",
      "[5,   299] loss: 0.610289\n",
      "[5,   399] loss: 0.600655\n",
      "[5,   499] loss: 0.584567\n",
      "[5,   599] loss: 0.603291\n",
      "[5,   699] loss: 0.635314\n",
      "[6,    99] loss: 0.551167\n",
      "[6,   199] loss: 0.604196\n",
      "[6,   299] loss: 0.594621\n",
      "[6,   399] loss: 0.585367\n",
      "[6,   499] loss: 0.565420\n",
      "[6,   599] loss: 0.588527\n",
      "[6,   699] loss: 0.623511\n",
      "[7,    99] loss: 0.534339\n",
      "[7,   199] loss: 0.589087\n",
      "[7,   299] loss: 0.580172\n",
      "[7,   399] loss: 0.570638\n",
      "[7,   499] loss: 0.547100\n",
      "[7,   599] loss: 0.573968\n",
      "[7,   699] loss: 0.611037\n",
      "[8,    99] loss: 0.518105\n",
      "[8,   199] loss: 0.574944\n",
      "[8,   299] loss: 0.566370\n",
      "[8,   399] loss: 0.555561\n",
      "[8,   499] loss: 0.529465\n",
      "[8,   599] loss: 0.559982\n",
      "[8,   699] loss: 0.597532\n",
      "[9,    99] loss: 0.502127\n",
      "[9,   199] loss: 0.560882\n",
      "[9,   299] loss: 0.552482\n",
      "[9,   399] loss: 0.540855\n",
      "[9,   499] loss: 0.512173\n",
      "[9,   599] loss: 0.544876\n",
      "[9,   699] loss: 0.583584\n",
      "[10,    99] loss: 0.486992\n",
      "[10,   199] loss: 0.546258\n",
      "[10,   299] loss: 0.538716\n",
      "[10,   399] loss: 0.525398\n",
      "[10,   499] loss: 0.495035\n",
      "[10,   599] loss: 0.529769\n",
      "[10,   699] loss: 0.568762\n",
      "[11,    99] loss: 0.471334\n",
      "[11,   199] loss: 0.532148\n",
      "[11,   299] loss: 0.524535\n",
      "[11,   399] loss: 0.510140\n",
      "[11,   499] loss: 0.477726\n",
      "[11,   599] loss: 0.513534\n",
      "[11,   699] loss: 0.553482\n",
      "[12,    99] loss: 0.454646\n",
      "[12,   199] loss: 0.517921\n",
      "[12,   299] loss: 0.510466\n",
      "[12,   399] loss: 0.494173\n",
      "[12,   499] loss: 0.460563\n",
      "[12,   599] loss: 0.497356\n",
      "[12,   699] loss: 0.538091\n",
      "[13,    99] loss: 0.438376\n",
      "[13,   199] loss: 0.502121\n",
      "[13,   299] loss: 0.496138\n",
      "[13,   399] loss: 0.478421\n",
      "[13,   499] loss: 0.442913\n",
      "[13,   599] loss: 0.481424\n",
      "[13,   699] loss: 0.521835\n",
      "[14,    99] loss: 0.421828\n",
      "[14,   199] loss: 0.486267\n",
      "[14,   299] loss: 0.481759\n",
      "[14,   399] loss: 0.462207\n",
      "[14,   499] loss: 0.425205\n",
      "[14,   599] loss: 0.465611\n",
      "[14,   699] loss: 0.504801\n",
      "[15,    99] loss: 0.405522\n",
      "[15,   199] loss: 0.469513\n",
      "[15,   299] loss: 0.467883\n",
      "[15,   399] loss: 0.445768\n",
      "[15,   499] loss: 0.406589\n",
      "[15,   599] loss: 0.448558\n",
      "[15,   699] loss: 0.487955\n",
      "[16,    99] loss: 0.389617\n",
      "[16,   199] loss: 0.452500\n",
      "[16,   299] loss: 0.454149\n",
      "[16,   399] loss: 0.429403\n",
      "[16,   499] loss: 0.388027\n",
      "[16,   599] loss: 0.431796\n",
      "[16,   699] loss: 0.471180\n",
      "[17,    99] loss: 0.373712\n",
      "[17,   199] loss: 0.435647\n",
      "[17,   299] loss: 0.440064\n",
      "[17,   399] loss: 0.412256\n",
      "[17,   499] loss: 0.369923\n",
      "[17,   599] loss: 0.416330\n",
      "[17,   699] loss: 0.454452\n",
      "[18,    99] loss: 0.358429\n",
      "[18,   199] loss: 0.418068\n",
      "[18,   299] loss: 0.426746\n",
      "[18,   399] loss: 0.395623\n",
      "[18,   499] loss: 0.352057\n",
      "[18,   599] loss: 0.400795\n",
      "[18,   699] loss: 0.437557\n",
      "[19,    99] loss: 0.343093\n",
      "[19,   199] loss: 0.401174\n",
      "[19,   299] loss: 0.413147\n",
      "[19,   399] loss: 0.380076\n",
      "[19,   499] loss: 0.334296\n",
      "[19,   599] loss: 0.385109\n",
      "[19,   699] loss: 0.420458\n",
      "[20,    99] loss: 0.328835\n",
      "[20,   199] loss: 0.382635\n",
      "[20,   299] loss: 0.400203\n",
      "[20,   399] loss: 0.364617\n",
      "[20,   499] loss: 0.317017\n",
      "[20,   599] loss: 0.369561\n",
      "[20,   699] loss: 0.402616\n",
      "[21,    99] loss: 0.314459\n",
      "[21,   199] loss: 0.365067\n",
      "[21,   299] loss: 0.386864\n",
      "[21,   399] loss: 0.349215\n",
      "[21,   499] loss: 0.299962\n",
      "[21,   599] loss: 0.354113\n",
      "[21,   699] loss: 0.385750\n",
      "[22,    99] loss: 0.300165\n",
      "[22,   199] loss: 0.349115\n",
      "[22,   299] loss: 0.373313\n",
      "[22,   399] loss: 0.333834\n",
      "[22,   499] loss: 0.284541\n",
      "[22,   599] loss: 0.340342\n",
      "[22,   699] loss: 0.369731\n",
      "[23,    99] loss: 0.286528\n",
      "[23,   199] loss: 0.332849\n",
      "[23,   299] loss: 0.360575\n",
      "[23,   399] loss: 0.319838\n",
      "[23,   499] loss: 0.269720\n",
      "[23,   599] loss: 0.326570\n",
      "[23,   699] loss: 0.354886\n",
      "[24,    99] loss: 0.273499\n",
      "[24,   199] loss: 0.316425\n",
      "[24,   299] loss: 0.348601\n",
      "[24,   399] loss: 0.305507\n",
      "[24,   499] loss: 0.255446\n",
      "[24,   599] loss: 0.314015\n",
      "[24,   699] loss: 0.340615\n",
      "[25,    99] loss: 0.261001\n",
      "[25,   199] loss: 0.301821\n",
      "[25,   299] loss: 0.336284\n",
      "[25,   399] loss: 0.292316\n",
      "[25,   499] loss: 0.240610\n",
      "[25,   599] loss: 0.301890\n",
      "[25,   699] loss: 0.327433\n",
      "[26,    99] loss: 0.248575\n",
      "[26,   199] loss: 0.286601\n",
      "[26,   299] loss: 0.324282\n",
      "[26,   399] loss: 0.280026\n",
      "[26,   499] loss: 0.226562\n",
      "[26,   599] loss: 0.289105\n",
      "[26,   699] loss: 0.315085\n",
      "[27,    99] loss: 0.236945\n",
      "[27,   199] loss: 0.272710\n",
      "[27,   299] loss: 0.313578\n",
      "[27,   399] loss: 0.267523\n",
      "[27,   499] loss: 0.214027\n",
      "[27,   599] loss: 0.277406\n",
      "[27,   699] loss: 0.302996\n",
      "[28,    99] loss: 0.226105\n",
      "[28,   199] loss: 0.260213\n",
      "[28,   299] loss: 0.301429\n",
      "[28,   399] loss: 0.256736\n",
      "[28,   499] loss: 0.202523\n",
      "[28,   599] loss: 0.265948\n",
      "[28,   699] loss: 0.292021\n",
      "[29,    99] loss: 0.216386\n",
      "[29,   199] loss: 0.248152\n",
      "[29,   299] loss: 0.291087\n",
      "[29,   399] loss: 0.245746\n",
      "[29,   499] loss: 0.190812\n",
      "[29,   599] loss: 0.255308\n",
      "[29,   699] loss: 0.281956\n",
      "[30,    99] loss: 0.206660\n",
      "[30,   199] loss: 0.235931\n",
      "[30,   299] loss: 0.280800\n",
      "[30,   399] loss: 0.235822\n",
      "[30,   499] loss: 0.180283\n",
      "[30,   599] loss: 0.245359\n",
      "[30,   699] loss: 0.271134\n",
      "[31,    99] loss: 0.197461\n",
      "[31,   199] loss: 0.225603\n",
      "[31,   299] loss: 0.270465\n",
      "[31,   399] loss: 0.226058\n",
      "[31,   499] loss: 0.170363\n",
      "[31,   599] loss: 0.235763\n",
      "[31,   699] loss: 0.260744\n",
      "[32,    99] loss: 0.189227\n",
      "[32,   199] loss: 0.215551\n",
      "[32,   299] loss: 0.260955\n",
      "[32,   399] loss: 0.216073\n",
      "[32,   499] loss: 0.161340\n",
      "[32,   599] loss: 0.226827\n",
      "[32,   699] loss: 0.250711\n",
      "[33,    99] loss: 0.181201\n",
      "[33,   199] loss: 0.206398\n",
      "[33,   299] loss: 0.250387\n",
      "[33,   399] loss: 0.207318\n",
      "[33,   499] loss: 0.153186\n",
      "[33,   599] loss: 0.217612\n",
      "[33,   699] loss: 0.241937\n",
      "[34,    99] loss: 0.174026\n",
      "[34,   199] loss: 0.196791\n",
      "[34,   299] loss: 0.240800\n",
      "[34,   399] loss: 0.198604\n",
      "[34,   499] loss: 0.145403\n",
      "[34,   599] loss: 0.209202\n",
      "[34,   699] loss: 0.233206\n",
      "[35,    99] loss: 0.166597\n",
      "[35,   199] loss: 0.188014\n",
      "[35,   299] loss: 0.231973\n",
      "[35,   399] loss: 0.190510\n",
      "[35,   499] loss: 0.138202\n",
      "[35,   599] loss: 0.201123\n",
      "[35,   699] loss: 0.224886\n",
      "[36,    99] loss: 0.161254\n",
      "[36,   199] loss: 0.179197\n",
      "[36,   299] loss: 0.222749\n",
      "[36,   399] loss: 0.182730\n",
      "[36,   499] loss: 0.131266\n",
      "[36,   599] loss: 0.192997\n",
      "[36,   699] loss: 0.217271\n",
      "[37,    99] loss: 0.154883\n",
      "[37,   199] loss: 0.171669\n",
      "[37,   299] loss: 0.214288\n",
      "[37,   399] loss: 0.174838\n",
      "[37,   499] loss: 0.124828\n",
      "[37,   599] loss: 0.185542\n",
      "[37,   699] loss: 0.209768\n",
      "[38,    99] loss: 0.149251\n",
      "[38,   199] loss: 0.163509\n",
      "[38,   299] loss: 0.206809\n",
      "[38,   399] loss: 0.168152\n",
      "[38,   499] loss: 0.118041\n",
      "[38,   599] loss: 0.178044\n",
      "[38,   699] loss: 0.201663\n",
      "[39,    99] loss: 0.144024\n",
      "[39,   199] loss: 0.156127\n",
      "[39,   299] loss: 0.199143\n",
      "[39,   399] loss: 0.161597\n",
      "[39,   499] loss: 0.112428\n",
      "[39,   599] loss: 0.170957\n",
      "[39,   699] loss: 0.194559\n",
      "[40,    99] loss: 0.138984\n",
      "[40,   199] loss: 0.149417\n",
      "[40,   299] loss: 0.191730\n",
      "[40,   399] loss: 0.155290\n",
      "[40,   499] loss: 0.106692\n",
      "[40,   599] loss: 0.164022\n",
      "[40,   699] loss: 0.187536\n",
      "[41,    99] loss: 0.133396\n",
      "[41,   199] loss: 0.142791\n",
      "[41,   299] loss: 0.184639\n",
      "[41,   399] loss: 0.149559\n",
      "[41,   499] loss: 0.101506\n",
      "[41,   599] loss: 0.157481\n",
      "[41,   699] loss: 0.180313\n",
      "[42,    99] loss: 0.128643\n",
      "[42,   199] loss: 0.136364\n",
      "[42,   299] loss: 0.177552\n",
      "[42,   399] loss: 0.143946\n",
      "[42,   499] loss: 0.096680\n",
      "[42,   599] loss: 0.151633\n",
      "[42,   699] loss: 0.174059\n",
      "[43,    99] loss: 0.124163\n",
      "[43,   199] loss: 0.130170\n",
      "[43,   299] loss: 0.170802\n",
      "[43,   399] loss: 0.138725\n",
      "[43,   499] loss: 0.092017\n",
      "[43,   599] loss: 0.145950\n",
      "[43,   699] loss: 0.167842\n",
      "[44,    99] loss: 0.119639\n",
      "[44,   199] loss: 0.125093\n",
      "[44,   299] loss: 0.164924\n",
      "[44,   399] loss: 0.133276\n",
      "[44,   499] loss: 0.087287\n",
      "[44,   599] loss: 0.140662\n",
      "[44,   699] loss: 0.161191\n",
      "[45,    99] loss: 0.115270\n",
      "[45,   199] loss: 0.119627\n",
      "[45,   299] loss: 0.158736\n",
      "[45,   399] loss: 0.128161\n",
      "[45,   499] loss: 0.083134\n",
      "[45,   599] loss: 0.135557\n",
      "[45,   699] loss: 0.154095\n",
      "[46,    99] loss: 0.111537\n",
      "[46,   199] loss: 0.114644\n",
      "[46,   299] loss: 0.151903\n",
      "[46,   399] loss: 0.123012\n",
      "[46,   499] loss: 0.078808\n",
      "[46,   599] loss: 0.130827\n",
      "[46,   699] loss: 0.148191\n",
      "[47,    99] loss: 0.108270\n",
      "[47,   199] loss: 0.109134\n",
      "[47,   299] loss: 0.145944\n",
      "[47,   399] loss: 0.118568\n",
      "[47,   499] loss: 0.074454\n",
      "[47,   599] loss: 0.125970\n",
      "[47,   699] loss: 0.141706\n",
      "[48,    99] loss: 0.104964\n",
      "[48,   199] loss: 0.104222\n",
      "[48,   299] loss: 0.140684\n",
      "[48,   399] loss: 0.113511\n",
      "[48,   499] loss: 0.070905\n",
      "[48,   599] loss: 0.121279\n",
      "[48,   699] loss: 0.136394\n",
      "[49,    99] loss: 0.100723\n",
      "[49,   199] loss: 0.099668\n",
      "[49,   299] loss: 0.134350\n",
      "[49,   399] loss: 0.109642\n",
      "[49,   499] loss: 0.067200\n",
      "[49,   599] loss: 0.117097\n",
      "[49,   699] loss: 0.129950\n",
      "[50,    99] loss: 0.097554\n",
      "[50,   199] loss: 0.094465\n",
      "[50,   299] loss: 0.129130\n",
      "[50,   399] loss: 0.106188\n",
      "[50,   499] loss: 0.063776\n",
      "[50,   599] loss: 0.112546\n",
      "[50,   699] loss: 0.124775\n",
      "[51,    99] loss: 0.093904\n",
      "[51,   199] loss: 0.090531\n",
      "[51,   299] loss: 0.123582\n",
      "[51,   399] loss: 0.101447\n",
      "[51,   499] loss: 0.060091\n",
      "[51,   599] loss: 0.108348\n",
      "[51,   699] loss: 0.118328\n",
      "[52,    99] loss: 0.091063\n",
      "[52,   199] loss: 0.086414\n",
      "[52,   299] loss: 0.119011\n",
      "[52,   399] loss: 0.097524\n",
      "[52,   499] loss: 0.056802\n",
      "[52,   599] loss: 0.104590\n",
      "[52,   699] loss: 0.113148\n",
      "[53,    99] loss: 0.087641\n",
      "[53,   199] loss: 0.082248\n",
      "[53,   299] loss: 0.114193\n",
      "[53,   399] loss: 0.093711\n",
      "[53,   499] loss: 0.053159\n",
      "[53,   599] loss: 0.100561\n",
      "[53,   699] loss: 0.107716\n",
      "[54,    99] loss: 0.084656\n",
      "[54,   199] loss: 0.078405\n",
      "[54,   299] loss: 0.110037\n",
      "[54,   399] loss: 0.090630\n",
      "[54,   499] loss: 0.049884\n",
      "[54,   599] loss: 0.096938\n",
      "[54,   699] loss: 0.102212\n",
      "[55,    99] loss: 0.081894\n",
      "[55,   199] loss: 0.075006\n",
      "[55,   299] loss: 0.105469\n",
      "[55,   399] loss: 0.086600\n",
      "[55,   499] loss: 0.046615\n",
      "[55,   599] loss: 0.093533\n",
      "[55,   699] loss: 0.096976\n",
      "[56,    99] loss: 0.078447\n",
      "[56,   199] loss: 0.071453\n",
      "[56,   299] loss: 0.100942\n",
      "[56,   399] loss: 0.083104\n",
      "[56,   499] loss: 0.043749\n",
      "[56,   599] loss: 0.089828\n",
      "[56,   699] loss: 0.093198\n",
      "[57,    99] loss: 0.075795\n",
      "[57,   199] loss: 0.068652\n",
      "[57,   299] loss: 0.096329\n",
      "[57,   399] loss: 0.079892\n",
      "[57,   499] loss: 0.040821\n",
      "[57,   599] loss: 0.086842\n",
      "[57,   699] loss: 0.088158\n",
      "[58,    99] loss: 0.073058\n",
      "[58,   199] loss: 0.065777\n",
      "[58,   299] loss: 0.092156\n",
      "[58,   399] loss: 0.076335\n",
      "[58,   499] loss: 0.038068\n",
      "[58,   599] loss: 0.083744\n",
      "[58,   699] loss: 0.083716\n",
      "[59,    99] loss: 0.070927\n",
      "[59,   199] loss: 0.062760\n",
      "[59,   299] loss: 0.088195\n",
      "[59,   399] loss: 0.070311\n",
      "[59,   499] loss: 0.035425\n",
      "[59,   599] loss: 0.081157\n",
      "[59,   699] loss: 0.079920\n",
      "[60,    99] loss: 0.067714\n",
      "[60,   199] loss: 0.060323\n",
      "[60,   299] loss: 0.085137\n",
      "[60,   399] loss: 0.067210\n",
      "[60,   499] loss: 0.033335\n",
      "[60,   599] loss: 0.077895\n",
      "[60,   699] loss: 0.076173\n",
      "[61,    99] loss: 0.064972\n",
      "[61,   199] loss: 0.058071\n",
      "[61,   299] loss: 0.081145\n",
      "[61,   399] loss: 0.065902\n",
      "[61,   499] loss: 0.031178\n",
      "[61,   599] loss: 0.074174\n",
      "[61,   699] loss: 0.071875\n",
      "[62,    99] loss: 0.062543\n",
      "[62,   199] loss: 0.054901\n",
      "[62,   299] loss: 0.077148\n",
      "[62,   399] loss: 0.062190\n",
      "[62,   499] loss: 0.029224\n",
      "[62,   599] loss: 0.070867\n",
      "[62,   699] loss: 0.067813\n",
      "[63,    99] loss: 0.060313\n",
      "[63,   199] loss: 0.052071\n",
      "[63,   299] loss: 0.074133\n",
      "[63,   399] loss: 0.061200\n",
      "[63,   499] loss: 0.027270\n",
      "[63,   599] loss: 0.068458\n",
      "[63,   699] loss: 0.065198\n",
      "[64,    99] loss: 0.057513\n",
      "[64,   199] loss: 0.050063\n",
      "[64,   299] loss: 0.070606\n",
      "[64,   399] loss: 0.057331\n",
      "[64,   499] loss: 0.025549\n",
      "[64,   599] loss: 0.065329\n",
      "[64,   699] loss: 0.061314\n",
      "[65,    99] loss: 0.055304\n",
      "[65,   199] loss: 0.048771\n",
      "[65,   299] loss: 0.067866\n",
      "[65,   399] loss: 0.055229\n",
      "[65,   499] loss: 0.023866\n",
      "[65,   599] loss: 0.062034\n",
      "[65,   699] loss: 0.058135\n",
      "[66,    99] loss: 0.053220\n",
      "[66,   199] loss: 0.046200\n",
      "[66,   299] loss: 0.064774\n",
      "[66,   399] loss: 0.052338\n",
      "[66,   499] loss: 0.022353\n",
      "[66,   599] loss: 0.060362\n",
      "[66,   699] loss: 0.054781\n",
      "[67,    99] loss: 0.050879\n",
      "[67,   199] loss: 0.044115\n",
      "[67,   299] loss: 0.061886\n",
      "[67,   399] loss: 0.052656\n",
      "[67,   499] loss: 0.020998\n",
      "[67,   599] loss: 0.057352\n",
      "[67,   699] loss: 0.051861\n",
      "[68,    99] loss: 0.048879\n",
      "[68,   199] loss: 0.042551\n",
      "[68,   299] loss: 0.058772\n",
      "[68,   399] loss: 0.049775\n",
      "[68,   499] loss: 0.019512\n",
      "[68,   599] loss: 0.055061\n",
      "[68,   699] loss: 0.049102\n",
      "[69,    99] loss: 0.046860\n",
      "[69,   199] loss: 0.040714\n",
      "[69,   299] loss: 0.056510\n",
      "[69,   399] loss: 0.045926\n",
      "[69,   499] loss: 0.018393\n",
      "[69,   599] loss: 0.052873\n",
      "[69,   699] loss: 0.046248\n",
      "[70,    99] loss: 0.044562\n",
      "[70,   199] loss: 0.039330\n",
      "[70,   299] loss: 0.053778\n",
      "[70,   399] loss: 0.046546\n",
      "[70,   499] loss: 0.017380\n",
      "[70,   599] loss: 0.050580\n",
      "[70,   699] loss: 0.043640\n",
      "[71,    99] loss: 0.042691\n",
      "[71,   199] loss: 0.037311\n",
      "[71,   299] loss: 0.051243\n",
      "[71,   399] loss: 0.043595\n",
      "[71,   499] loss: 0.016233\n",
      "[71,   599] loss: 0.048585\n",
      "[71,   699] loss: 0.041599\n",
      "[72,    99] loss: 0.041395\n",
      "[72,   199] loss: 0.035736\n",
      "[72,   299] loss: 0.049076\n",
      "[72,   399] loss: 0.041451\n",
      "[72,   499] loss: 0.015099\n",
      "[72,   599] loss: 0.046767\n",
      "[72,   699] loss: 0.039092\n",
      "[73,    99] loss: 0.039434\n",
      "[73,   199] loss: 0.034325\n",
      "[73,   299] loss: 0.046728\n",
      "[73,   399] loss: 0.040429\n",
      "[73,   499] loss: 0.014360\n",
      "[73,   599] loss: 0.044285\n",
      "[73,   699] loss: 0.036740\n",
      "[74,    99] loss: 0.037697\n",
      "[74,   199] loss: 0.033275\n",
      "[74,   299] loss: 0.044899\n",
      "[74,   399] loss: 0.040164\n",
      "[74,   499] loss: 0.013275\n",
      "[74,   599] loss: 0.042108\n",
      "[74,   699] loss: 0.034497\n",
      "[75,    99] loss: 0.035927\n",
      "[75,   199] loss: 0.031432\n",
      "[75,   299] loss: 0.042313\n",
      "[75,   399] loss: 0.038995\n",
      "[75,   499] loss: 0.012652\n",
      "[75,   599] loss: 0.039927\n",
      "[75,   699] loss: 0.033068\n",
      "[76,    99] loss: 0.034332\n",
      "[76,   199] loss: 0.030475\n",
      "[76,   299] loss: 0.039686\n",
      "[76,   399] loss: 0.036867\n",
      "[76,   499] loss: 0.011952\n",
      "[76,   599] loss: 0.038345\n",
      "[76,   699] loss: 0.031863\n",
      "[77,    99] loss: 0.033113\n",
      "[77,   199] loss: 0.028542\n",
      "[77,   299] loss: 0.038581\n",
      "[77,   399] loss: 0.037025\n",
      "[77,   499] loss: 0.011205\n",
      "[77,   599] loss: 0.036382\n",
      "[77,   699] loss: 0.029583\n",
      "[78,    99] loss: 0.031889\n",
      "[78,   199] loss: 0.028071\n",
      "[78,   299] loss: 0.036474\n",
      "[78,   399] loss: 0.032659\n",
      "[78,   499] loss: 0.010646\n",
      "[78,   599] loss: 0.035307\n",
      "[78,   699] loss: 0.028698\n",
      "[79,    99] loss: 0.029832\n",
      "[79,   199] loss: 0.026516\n",
      "[79,   299] loss: 0.034797\n",
      "[79,   399] loss: 0.032235\n",
      "[79,   499] loss: 0.009947\n",
      "[79,   599] loss: 0.032858\n",
      "[79,   699] loss: 0.026877\n",
      "[80,    99] loss: 0.028743\n",
      "[80,   199] loss: 0.025955\n",
      "[80,   299] loss: 0.032963\n",
      "[80,   399] loss: 0.031889\n",
      "[80,   499] loss: 0.009309\n",
      "[80,   599] loss: 0.032148\n",
      "[80,   699] loss: 0.025681\n",
      "[81,    99] loss: 0.027956\n",
      "[81,   199] loss: 0.023354\n",
      "[81,   299] loss: 0.031951\n",
      "[81,   399] loss: 0.033393\n",
      "[81,   499] loss: 0.008759\n",
      "[81,   599] loss: 0.029943\n",
      "[81,   699] loss: 0.023747\n",
      "[82,    99] loss: 0.026935\n",
      "[82,   199] loss: 0.023150\n",
      "[82,   299] loss: 0.029548\n",
      "[82,   399] loss: 0.030515\n",
      "[82,   499] loss: 0.008140\n",
      "[82,   599] loss: 0.029295\n",
      "[82,   699] loss: 0.023397\n",
      "[83,    99] loss: 0.024633\n",
      "[83,   199] loss: 0.022089\n",
      "[83,   299] loss: 0.028364\n",
      "[83,   399] loss: 0.026960\n",
      "[83,   499] loss: 0.007936\n",
      "[83,   599] loss: 0.027605\n",
      "[83,   699] loss: 0.022362\n",
      "[84,    99] loss: 0.023424\n",
      "[84,   199] loss: 0.021406\n",
      "[84,   299] loss: 0.027655\n",
      "[84,   399] loss: 0.024419\n",
      "[84,   499] loss: 0.007505\n",
      "[84,   599] loss: 0.026586\n",
      "[84,   699] loss: 0.021599\n",
      "[85,    99] loss: 0.022661\n",
      "[85,   199] loss: 0.020943\n",
      "[85,   299] loss: 0.026079\n",
      "[85,   399] loss: 0.023219\n",
      "[85,   499] loss: 0.007110\n",
      "[85,   599] loss: 0.025284\n",
      "[85,   699] loss: 0.020721\n",
      "[86,    99] loss: 0.021308\n",
      "[86,   199] loss: 0.019799\n",
      "[86,   299] loss: 0.025342\n",
      "[86,   399] loss: 0.022754\n",
      "[86,   499] loss: 0.006415\n",
      "[86,   599] loss: 0.024311\n",
      "[86,   699] loss: 0.019581\n",
      "[87,    99] loss: 0.020596\n",
      "[87,   199] loss: 0.019041\n",
      "[87,   299] loss: 0.023641\n",
      "[87,   399] loss: 0.023375\n",
      "[87,   499] loss: 0.006197\n",
      "[87,   599] loss: 0.021992\n",
      "[87,   699] loss: 0.017874\n",
      "[88,    99] loss: 0.019629\n",
      "[88,   199] loss: 0.017559\n",
      "[88,   299] loss: 0.021918\n",
      "[88,   399] loss: 0.023456\n",
      "[88,   499] loss: 0.005852\n",
      "[88,   599] loss: 0.021308\n",
      "[88,   699] loss: 0.017233\n",
      "[89,    99] loss: 0.019246\n",
      "[89,   199] loss: 0.016238\n",
      "[89,   299] loss: 0.021699\n",
      "[89,   399] loss: 0.026740\n",
      "[89,   499] loss: 0.005819\n",
      "[89,   599] loss: 0.023265\n",
      "[89,   699] loss: 0.016448\n",
      "[90,    99] loss: 0.017085\n",
      "[90,   199] loss: 0.015803\n",
      "[90,   299] loss: 0.019237\n",
      "[90,   399] loss: 0.019057\n",
      "[90,   499] loss: 0.005786\n",
      "[90,   599] loss: 0.019263\n",
      "[90,   699] loss: 0.016395\n",
      "[91,    99] loss: 0.016646\n",
      "[91,   199] loss: 0.016330\n",
      "[91,   299] loss: 0.018423\n",
      "[91,   399] loss: 0.018685\n",
      "[91,   499] loss: 0.005089\n",
      "[91,   599] loss: 0.018229\n",
      "[91,   699] loss: 0.015819\n",
      "[92,    99] loss: 0.015331\n",
      "[92,   199] loss: 0.015145\n",
      "[92,   299] loss: 0.018036\n",
      "[92,   399] loss: 0.018692\n",
      "[92,   499] loss: 0.004720\n",
      "[92,   599] loss: 0.017573\n",
      "[92,   699] loss: 0.015457\n",
      "[93,    99] loss: 0.015052\n",
      "[93,   199] loss: 0.015273\n",
      "[93,   299] loss: 0.016796\n",
      "[93,   399] loss: 0.018859\n",
      "[93,   499] loss: 0.004452\n",
      "[93,   599] loss: 0.016450\n",
      "[93,   699] loss: 0.015107\n",
      "[94,    99] loss: 0.013954\n",
      "[94,   199] loss: 0.013900\n",
      "[94,   299] loss: 0.016043\n",
      "[94,   399] loss: 0.018039\n",
      "[94,   499] loss: 0.004160\n",
      "[94,   599] loss: 0.015746\n",
      "[94,   699] loss: 0.014112\n",
      "[95,    99] loss: 0.013093\n",
      "[95,   199] loss: 0.013278\n",
      "[95,   299] loss: 0.014984\n",
      "[95,   399] loss: 0.018062\n",
      "[95,   499] loss: 0.003844\n",
      "[95,   599] loss: 0.014763\n",
      "[95,   699] loss: 0.013438\n",
      "[96,    99] loss: 0.012632\n",
      "[96,   199] loss: 0.013069\n",
      "[96,   299] loss: 0.014025\n",
      "[96,   399] loss: 0.017743\n",
      "[96,   499] loss: 0.003610\n",
      "[96,   599] loss: 0.014024\n",
      "[96,   699] loss: 0.012373\n",
      "[97,    99] loss: 0.011682\n",
      "[97,   199] loss: 0.011826\n",
      "[97,   299] loss: 0.014026\n",
      "[97,   399] loss: 0.018423\n",
      "[97,   499] loss: 0.003526\n",
      "[97,   599] loss: 0.013045\n",
      "[97,   699] loss: 0.010686\n",
      "[98,    99] loss: 0.012440\n",
      "[98,   199] loss: 0.009987\n",
      "[98,   299] loss: 0.012755\n",
      "[98,   399] loss: 0.017108\n",
      "[98,   499] loss: 0.003492\n",
      "[98,   599] loss: 0.012572\n",
      "[98,   699] loss: 0.011121\n",
      "[99,    99] loss: 0.011255\n",
      "[99,   199] loss: 0.012652\n",
      "[99,   299] loss: 0.011291\n",
      "[99,   399] loss: 0.015104\n",
      "[99,   499] loss: 0.003127\n",
      "[99,   599] loss: 0.011507\n",
      "[99,   699] loss: 0.011802\n",
      "[100,    99] loss: 0.010188\n",
      "[100,   199] loss: 0.010893\n",
      "[100,   299] loss: 0.011151\n",
      "[100,   399] loss: 0.014927\n",
      "[100,   499] loss: 0.003000\n",
      "[100,   599] loss: 0.011056\n",
      "[100,   699] loss: 0.012448\n",
      "Finished Training\n",
      "[1,    99] loss: 2.581096\n",
      "[1,   199] loss: 0.708774\n",
      "[1,   299] loss: 0.706721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    99] loss: 0.700488\n",
      "[2,   199] loss: 0.703435\n",
      "[2,   299] loss: 0.707253\n",
      "[3,    99] loss: 0.700809\n",
      "[3,   199] loss: 0.703644\n",
      "[3,   299] loss: 0.707397\n",
      "[4,    99] loss: 0.700924\n",
      "[4,   199] loss: 0.703727\n",
      "[4,   299] loss: 0.707459\n",
      "[5,    99] loss: 0.700980\n",
      "[5,   199] loss: 0.703770\n",
      "[5,   299] loss: 0.707492\n",
      "[6,    99] loss: 0.701011\n",
      "[6,   199] loss: 0.703795\n",
      "[6,   299] loss: 0.707511\n",
      "[7,    99] loss: 0.701030\n",
      "[7,   199] loss: 0.703810\n",
      "[7,   299] loss: 0.707523\n",
      "[8,    99] loss: 0.701042\n",
      "[8,   199] loss: 0.703819\n",
      "[8,   299] loss: 0.707531\n",
      "[9,    99] loss: 0.701050\n",
      "[9,   199] loss: 0.703826\n",
      "[9,   299] loss: 0.707536\n",
      "[10,    99] loss: 0.701055\n",
      "[10,   199] loss: 0.703830\n",
      "[10,   299] loss: 0.707540\n",
      "[11,    99] loss: 0.701059\n",
      "[11,   199] loss: 0.703833\n",
      "[11,   299] loss: 0.707542\n",
      "[12,    99] loss: 0.701061\n",
      "[12,   199] loss: 0.703835\n",
      "[12,   299] loss: 0.707544\n",
      "[13,    99] loss: 0.701063\n",
      "[13,   199] loss: 0.703836\n",
      "[13,   299] loss: 0.707545\n",
      "[14,    99] loss: 0.701064\n",
      "[14,   199] loss: 0.703837\n",
      "[14,   299] loss: 0.707545\n",
      "[15,    99] loss: 0.701065\n",
      "[15,   199] loss: 0.703838\n",
      "[15,   299] loss: 0.707546\n",
      "[16,    99] loss: 0.701065\n",
      "[16,   199] loss: 0.703838\n",
      "[16,   299] loss: 0.707546\n",
      "[17,    99] loss: 0.701066\n",
      "[17,   199] loss: 0.703838\n",
      "[17,   299] loss: 0.707547\n",
      "[18,    99] loss: 0.701066\n",
      "[18,   199] loss: 0.703838\n",
      "[18,   299] loss: 0.707547\n",
      "[19,    99] loss: 0.701066\n",
      "[19,   199] loss: 0.703839\n",
      "[19,   299] loss: 0.707547\n",
      "[20,    99] loss: 0.701066\n",
      "[20,   199] loss: 0.703839\n",
      "[20,   299] loss: 0.707547\n",
      "[21,    99] loss: 0.701066\n",
      "[21,   199] loss: 0.703839\n",
      "[21,   299] loss: 0.707547\n",
      "[22,    99] loss: 0.701066\n",
      "[22,   199] loss: 0.703839\n",
      "[22,   299] loss: 0.707547\n",
      "[23,    99] loss: 0.701066\n",
      "[23,   199] loss: 0.703839\n",
      "[23,   299] loss: 0.707547\n",
      "[24,    99] loss: 0.701066\n",
      "[24,   199] loss: 0.703839\n",
      "[24,   299] loss: 0.707547\n",
      "[25,    99] loss: 0.701066\n",
      "[25,   199] loss: 0.703839\n",
      "[25,   299] loss: 0.707547\n",
      "[26,    99] loss: 0.701066\n",
      "[26,   199] loss: 0.703839\n",
      "[26,   299] loss: 0.707547\n",
      "[27,    99] loss: 0.701066\n",
      "[27,   199] loss: 0.703839\n",
      "[27,   299] loss: 0.707547\n",
      "[28,    99] loss: 0.701066\n",
      "[28,   199] loss: 0.703839\n",
      "[28,   299] loss: 0.707547\n",
      "[29,    99] loss: 0.701066\n",
      "[29,   199] loss: 0.703839\n",
      "[29,   299] loss: 0.707547\n",
      "[30,    99] loss: 0.701066\n",
      "[30,   199] loss: 0.703839\n",
      "[30,   299] loss: 0.707547\n",
      "[31,    99] loss: 0.701066\n",
      "[31,   199] loss: 0.703839\n",
      "[31,   299] loss: 0.707547\n",
      "[32,    99] loss: 0.701066\n",
      "[32,   199] loss: 0.703839\n",
      "[32,   299] loss: 0.707547\n",
      "[33,    99] loss: 0.701066\n",
      "[33,   199] loss: 0.703839\n",
      "[33,   299] loss: 0.707547\n",
      "[34,    99] loss: 0.701066\n",
      "[34,   199] loss: 0.703839\n",
      "[34,   299] loss: 0.707547\n",
      "[35,    99] loss: 0.701066\n",
      "[35,   199] loss: 0.703839\n",
      "[35,   299] loss: 0.707547\n",
      "[36,    99] loss: 0.701066\n",
      "[36,   199] loss: 0.703839\n",
      "[36,   299] loss: 0.707547\n",
      "[37,    99] loss: 0.701066\n",
      "[37,   199] loss: 0.703839\n",
      "[37,   299] loss: 0.707547\n",
      "[38,    99] loss: 0.701066\n",
      "[38,   199] loss: 0.703839\n",
      "[38,   299] loss: 0.707547\n",
      "[39,    99] loss: 0.701066\n",
      "[39,   199] loss: 0.703839\n",
      "[39,   299] loss: 0.707547\n",
      "[40,    99] loss: 0.701066\n",
      "[40,   199] loss: 0.703839\n",
      "[40,   299] loss: 0.707547\n",
      "[41,    99] loss: 0.701066\n",
      "[41,   199] loss: 0.703839\n",
      "[41,   299] loss: 0.707547\n",
      "[42,    99] loss: 0.701066\n",
      "[42,   199] loss: 0.703839\n",
      "[42,   299] loss: 0.707547\n",
      "[43,    99] loss: 0.701066\n",
      "[43,   199] loss: 0.703839\n",
      "[43,   299] loss: 0.707547\n",
      "[44,    99] loss: 0.701066\n",
      "[44,   199] loss: 0.703839\n",
      "[44,   299] loss: 0.707547\n",
      "[45,    99] loss: 0.701066\n",
      "[45,   199] loss: 0.703839\n",
      "[45,   299] loss: 0.707547\n",
      "[46,    99] loss: 0.701066\n",
      "[46,   199] loss: 0.703839\n",
      "[46,   299] loss: 0.707547\n",
      "[47,    99] loss: 0.701066\n",
      "[47,   199] loss: 0.703839\n",
      "[47,   299] loss: 0.707547\n",
      "[48,    99] loss: 0.701066\n",
      "[48,   199] loss: 0.703839\n",
      "[48,   299] loss: 0.707547\n",
      "[49,    99] loss: 0.701066\n",
      "[49,   199] loss: 0.703839\n",
      "[49,   299] loss: 0.707547\n",
      "[50,    99] loss: 0.701066\n",
      "[50,   199] loss: 0.703839\n",
      "[50,   299] loss: 0.707547\n",
      "[51,    99] loss: 0.701066\n",
      "[51,   199] loss: 0.703839\n",
      "[51,   299] loss: 0.707547\n",
      "[52,    99] loss: 0.701066\n",
      "[52,   199] loss: 0.703839\n",
      "[52,   299] loss: 0.707547\n",
      "[53,    99] loss: 0.701066\n",
      "[53,   199] loss: 0.703839\n",
      "[53,   299] loss: 0.707547\n",
      "[54,    99] loss: 0.701066\n",
      "[54,   199] loss: 0.703839\n",
      "[54,   299] loss: 0.707547\n",
      "[55,    99] loss: 0.701066\n",
      "[55,   199] loss: 0.703839\n",
      "[55,   299] loss: 0.707547\n",
      "[56,    99] loss: 0.701066\n",
      "[56,   199] loss: 0.703839\n",
      "[56,   299] loss: 0.707547\n",
      "[57,    99] loss: 0.701066\n",
      "[57,   199] loss: 0.703839\n",
      "[57,   299] loss: 0.707547\n",
      "[58,    99] loss: 0.701066\n",
      "[58,   199] loss: 0.703839\n",
      "[58,   299] loss: 0.707547\n",
      "[59,    99] loss: 0.701066\n",
      "[59,   199] loss: 0.703839\n",
      "[59,   299] loss: 0.707547\n",
      "[60,    99] loss: 0.701066\n",
      "[60,   199] loss: 0.703839\n",
      "[60,   299] loss: 0.707547\n",
      "[61,    99] loss: 0.701066\n",
      "[61,   199] loss: 0.703839\n",
      "[61,   299] loss: 0.707547\n",
      "[62,    99] loss: 0.701066\n",
      "[62,   199] loss: 0.703839\n",
      "[62,   299] loss: 0.707547\n",
      "[63,    99] loss: 0.701066\n",
      "[63,   199] loss: 0.703839\n",
      "[63,   299] loss: 0.707547\n",
      "[64,    99] loss: 0.701066\n",
      "[64,   199] loss: 0.703839\n",
      "[64,   299] loss: 0.707547\n",
      "[65,    99] loss: 0.701066\n",
      "[65,   199] loss: 0.703839\n",
      "[65,   299] loss: 0.707547\n",
      "[66,    99] loss: 0.701066\n",
      "[66,   199] loss: 0.703839\n",
      "[66,   299] loss: 0.707547\n",
      "[67,    99] loss: 0.701066\n",
      "[67,   199] loss: 0.703839\n",
      "[67,   299] loss: 0.707547\n",
      "[68,    99] loss: 0.701066\n",
      "[68,   199] loss: 0.703839\n",
      "[68,   299] loss: 0.707547\n",
      "[69,    99] loss: 0.701066\n",
      "[69,   199] loss: 0.703839\n",
      "[69,   299] loss: 0.707547\n",
      "[70,    99] loss: 0.701066\n",
      "[70,   199] loss: 0.703839\n",
      "[70,   299] loss: 0.707547\n",
      "[71,    99] loss: 0.701066\n",
      "[71,   199] loss: 0.703839\n",
      "[71,   299] loss: 0.707547\n",
      "[72,    99] loss: 0.701066\n",
      "[72,   199] loss: 0.703839\n",
      "[72,   299] loss: 0.707547\n",
      "[73,    99] loss: 0.701066\n",
      "[73,   199] loss: 0.703839\n",
      "[73,   299] loss: 0.707547\n",
      "[74,    99] loss: 0.701066\n",
      "[74,   199] loss: 0.703839\n",
      "[74,   299] loss: 0.707547\n",
      "[75,    99] loss: 0.701066\n",
      "[75,   199] loss: 0.703839\n",
      "[75,   299] loss: 0.707547\n",
      "[76,    99] loss: 0.701066\n",
      "[76,   199] loss: 0.703839\n",
      "[76,   299] loss: 0.707547\n",
      "[77,    99] loss: 0.701066\n",
      "[77,   199] loss: 0.703839\n",
      "[77,   299] loss: 0.707547\n",
      "[78,    99] loss: 0.701066\n",
      "[78,   199] loss: 0.703839\n",
      "[78,   299] loss: 0.707547\n",
      "[79,    99] loss: 0.701066\n",
      "[79,   199] loss: 0.703839\n",
      "[79,   299] loss: 0.707547\n",
      "[80,    99] loss: 0.701066\n",
      "[80,   199] loss: 0.703839\n",
      "[80,   299] loss: 0.707547\n",
      "[81,    99] loss: 0.701066\n",
      "[81,   199] loss: 0.703839\n",
      "[81,   299] loss: 0.707547\n",
      "[82,    99] loss: 0.701066\n",
      "[82,   199] loss: 0.703839\n",
      "[82,   299] loss: 0.707547\n",
      "[83,    99] loss: 0.701066\n",
      "[83,   199] loss: 0.703839\n",
      "[83,   299] loss: 0.707547\n",
      "[84,    99] loss: 0.701066\n",
      "[84,   199] loss: 0.703839\n",
      "[84,   299] loss: 0.707547\n",
      "[85,    99] loss: 0.701066\n",
      "[85,   199] loss: 0.703839\n",
      "[85,   299] loss: 0.707547\n",
      "[86,    99] loss: 0.701066\n",
      "[86,   199] loss: 0.703839\n",
      "[86,   299] loss: 0.707547\n",
      "[87,    99] loss: 0.701066\n",
      "[87,   199] loss: 0.703839\n",
      "[87,   299] loss: 0.707547\n",
      "[88,    99] loss: 0.701066\n",
      "[88,   199] loss: 0.703839\n",
      "[88,   299] loss: 0.707547\n",
      "[89,    99] loss: 0.701066\n",
      "[89,   199] loss: 0.703839\n",
      "[89,   299] loss: 0.707547\n",
      "[90,    99] loss: 0.701066\n",
      "[90,   199] loss: 0.703839\n",
      "[90,   299] loss: 0.707547\n",
      "[91,    99] loss: 0.701066\n",
      "[91,   199] loss: 0.703839\n",
      "[91,   299] loss: 0.707547\n",
      "[92,    99] loss: 0.701066\n",
      "[92,   199] loss: 0.703839\n",
      "[92,   299] loss: 0.707547\n",
      "[93,    99] loss: 0.701066\n",
      "[93,   199] loss: 0.703839\n",
      "[93,   299] loss: 0.707547\n",
      "[94,    99] loss: 0.701066\n",
      "[94,   199] loss: 0.703839\n",
      "[94,   299] loss: 0.707547\n",
      "[95,    99] loss: 0.701066\n",
      "[95,   199] loss: 0.703839\n",
      "[95,   299] loss: 0.707547\n",
      "[96,    99] loss: 0.701066\n",
      "[96,   199] loss: 0.703839\n",
      "[96,   299] loss: 0.707547\n",
      "[97,    99] loss: 0.701066\n",
      "[97,   199] loss: 0.703839\n",
      "[97,   299] loss: 0.707547\n",
      "[98,    99] loss: 0.701066\n",
      "[98,   199] loss: 0.703839\n",
      "[98,   299] loss: 0.707547\n",
      "[99,    99] loss: 0.701066\n",
      "[99,   199] loss: 0.703839\n",
      "[99,   299] loss: 0.707547\n",
      "[100,    99] loss: 0.701066\n",
      "[100,   199] loss: 0.703839\n",
      "[100,   299] loss: 0.707547\n",
      "Finished Training\n",
      "[1,    99] loss: 1.261801\n",
      "[1,   199] loss: 0.722059\n",
      "[1,   299] loss: 0.707539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    99] loss: 0.695910\n",
      "[2,   199] loss: 0.703609\n",
      "[2,   299] loss: 0.702013\n",
      "[3,    99] loss: 0.696047\n",
      "[3,   199] loss: 0.699360\n",
      "[3,   299] loss: 0.702759\n",
      "[4,    99] loss: 0.696097\n",
      "[4,   199] loss: 0.699391\n",
      "[4,   299] loss: 0.702825\n",
      "[5,    99] loss: 0.696121\n",
      "[5,   199] loss: 0.699407\n",
      "[5,   299] loss: 0.702860\n",
      "[6,    99] loss: 0.696135\n",
      "[6,   199] loss: 0.699416\n",
      "[6,   299] loss: 0.702881\n",
      "[7,    99] loss: 0.696143\n",
      "[7,   199] loss: 0.699422\n",
      "[7,   299] loss: 0.702894\n",
      "[8,    99] loss: 0.696148\n",
      "[8,   199] loss: 0.699425\n",
      "[8,   299] loss: 0.702903\n",
      "[9,    99] loss: 0.696152\n",
      "[9,   199] loss: 0.699428\n",
      "[9,   299] loss: 0.702908\n",
      "[10,    99] loss: 0.696154\n",
      "[10,   199] loss: 0.699429\n",
      "[10,   299] loss: 0.702912\n",
      "[11,    99] loss: 0.696156\n",
      "[11,   199] loss: 0.699430\n",
      "[11,   299] loss: 0.702915\n",
      "[12,    99] loss: 0.696157\n",
      "[12,   199] loss: 0.699431\n",
      "[12,   299] loss: 0.702916\n",
      "[13,    99] loss: 0.696158\n",
      "[13,   199] loss: 0.699431\n",
      "[13,   299] loss: 0.702917\n",
      "[14,    99] loss: 0.696158\n",
      "[14,   199] loss: 0.699432\n",
      "[14,   299] loss: 0.702918\n",
      "[15,    99] loss: 0.696158\n",
      "[15,   199] loss: 0.699432\n",
      "[15,   299] loss: 0.702919\n",
      "[16,    99] loss: 0.696159\n",
      "[16,   199] loss: 0.699432\n",
      "[16,   299] loss: 0.702919\n",
      "[17,    99] loss: 0.696159\n",
      "[17,   199] loss: 0.699432\n",
      "[17,   299] loss: 0.702920\n",
      "[18,    99] loss: 0.696159\n",
      "[18,   199] loss: 0.699432\n",
      "[18,   299] loss: 0.702920\n",
      "[19,    99] loss: 0.696159\n",
      "[19,   199] loss: 0.699432\n",
      "[19,   299] loss: 0.702920\n",
      "[20,    99] loss: 0.696159\n",
      "[20,   199] loss: 0.699432\n",
      "[20,   299] loss: 0.702920\n",
      "[21,    99] loss: 0.696159\n",
      "[21,   199] loss: 0.699432\n",
      "[21,   299] loss: 0.702920\n",
      "[22,    99] loss: 0.696159\n",
      "[22,   199] loss: 0.699432\n",
      "[22,   299] loss: 0.702920\n",
      "[23,    99] loss: 0.696159\n",
      "[23,   199] loss: 0.699432\n",
      "[23,   299] loss: 0.702920\n",
      "[24,    99] loss: 0.696159\n",
      "[24,   199] loss: 0.699433\n",
      "[24,   299] loss: 0.702920\n",
      "[25,    99] loss: 0.696159\n",
      "[25,   199] loss: 0.699433\n",
      "[25,   299] loss: 0.702920\n",
      "[26,    99] loss: 0.696159\n",
      "[26,   199] loss: 0.699433\n",
      "[26,   299] loss: 0.702920\n",
      "[27,    99] loss: 0.696159\n",
      "[27,   199] loss: 0.699433\n",
      "[27,   299] loss: 0.702920\n",
      "[28,    99] loss: 0.696159\n",
      "[28,   199] loss: 0.699433\n",
      "[28,   299] loss: 0.702920\n",
      "[29,    99] loss: 0.696159\n",
      "[29,   199] loss: 0.699433\n",
      "[29,   299] loss: 0.702920\n",
      "[30,    99] loss: 0.696159\n",
      "[30,   199] loss: 0.699433\n",
      "[30,   299] loss: 0.702920\n",
      "[31,    99] loss: 0.696159\n",
      "[31,   199] loss: 0.699433\n",
      "[31,   299] loss: 0.702920\n",
      "[32,    99] loss: 0.696159\n",
      "[32,   199] loss: 0.699433\n",
      "[32,   299] loss: 0.702920\n",
      "[33,    99] loss: 0.696159\n",
      "[33,   199] loss: 0.699433\n",
      "[33,   299] loss: 0.702920\n",
      "[34,    99] loss: 0.696159\n",
      "[34,   199] loss: 0.699433\n",
      "[34,   299] loss: 0.702920\n",
      "[35,    99] loss: 0.696159\n",
      "[35,   199] loss: 0.699433\n",
      "[35,   299] loss: 0.702920\n",
      "[36,    99] loss: 0.696159\n",
      "[36,   199] loss: 0.699433\n",
      "[36,   299] loss: 0.702920\n",
      "[37,    99] loss: 0.696159\n",
      "[37,   199] loss: 0.699433\n",
      "[37,   299] loss: 0.702920\n",
      "[38,    99] loss: 0.696159\n",
      "[38,   199] loss: 0.699433\n",
      "[38,   299] loss: 0.702920\n",
      "[39,    99] loss: 0.696159\n",
      "[39,   199] loss: 0.699433\n",
      "[39,   299] loss: 0.702920\n",
      "[40,    99] loss: 0.696159\n",
      "[40,   199] loss: 0.699433\n",
      "[40,   299] loss: 0.702920\n",
      "[41,    99] loss: 0.696159\n",
      "[41,   199] loss: 0.699433\n",
      "[41,   299] loss: 0.702920\n",
      "[42,    99] loss: 0.696159\n",
      "[42,   199] loss: 0.699433\n",
      "[42,   299] loss: 0.702920\n",
      "[43,    99] loss: 0.696159\n",
      "[43,   199] loss: 0.699433\n",
      "[43,   299] loss: 0.702920\n",
      "[44,    99] loss: 0.696159\n",
      "[44,   199] loss: 0.699433\n",
      "[44,   299] loss: 0.702920\n",
      "[45,    99] loss: 0.696159\n",
      "[45,   199] loss: 0.699433\n",
      "[45,   299] loss: 0.702920\n",
      "[46,    99] loss: 0.696159\n",
      "[46,   199] loss: 0.699433\n",
      "[46,   299] loss: 0.702920\n",
      "[47,    99] loss: 0.696159\n",
      "[47,   199] loss: 0.699433\n",
      "[47,   299] loss: 0.702920\n",
      "[48,    99] loss: 0.696159\n",
      "[48,   199] loss: 0.699433\n",
      "[48,   299] loss: 0.702920\n",
      "[49,    99] loss: 0.696159\n",
      "[49,   199] loss: 0.699433\n",
      "[49,   299] loss: 0.702920\n",
      "[50,    99] loss: 0.696159\n",
      "[50,   199] loss: 0.699433\n",
      "[50,   299] loss: 0.702920\n",
      "[51,    99] loss: 0.696159\n",
      "[51,   199] loss: 0.699433\n",
      "[51,   299] loss: 0.702920\n",
      "[52,    99] loss: 0.696159\n",
      "[52,   199] loss: 0.699433\n",
      "[52,   299] loss: 0.702920\n",
      "[53,    99] loss: 0.696159\n",
      "[53,   199] loss: 0.699433\n",
      "[53,   299] loss: 0.702920\n",
      "[54,    99] loss: 0.696159\n",
      "[54,   199] loss: 0.699433\n",
      "[54,   299] loss: 0.702920\n",
      "[55,    99] loss: 0.696159\n",
      "[55,   199] loss: 0.699433\n",
      "[55,   299] loss: 0.702920\n",
      "[56,    99] loss: 0.696159\n",
      "[56,   199] loss: 0.699433\n",
      "[56,   299] loss: 0.702920\n",
      "[57,    99] loss: 0.696159\n",
      "[57,   199] loss: 0.699433\n",
      "[57,   299] loss: 0.702920\n",
      "[58,    99] loss: 0.696159\n",
      "[58,   199] loss: 0.699433\n",
      "[58,   299] loss: 0.702920\n",
      "[59,    99] loss: 0.696159\n",
      "[59,   199] loss: 0.699433\n",
      "[59,   299] loss: 0.702920\n",
      "[60,    99] loss: 0.696159\n",
      "[60,   199] loss: 0.699433\n",
      "[60,   299] loss: 0.702920\n",
      "[61,    99] loss: 0.696159\n",
      "[61,   199] loss: 0.699433\n",
      "[61,   299] loss: 0.702920\n",
      "[62,    99] loss: 0.696159\n",
      "[62,   199] loss: 0.699433\n",
      "[62,   299] loss: 0.702920\n",
      "[63,    99] loss: 0.696159\n",
      "[63,   199] loss: 0.699433\n",
      "[63,   299] loss: 0.702920\n",
      "[64,    99] loss: 0.696159\n",
      "[64,   199] loss: 0.699433\n",
      "[64,   299] loss: 0.702920\n",
      "[65,    99] loss: 0.696159\n",
      "[65,   199] loss: 0.699433\n",
      "[65,   299] loss: 0.702920\n",
      "[66,    99] loss: 0.696159\n",
      "[66,   199] loss: 0.699433\n",
      "[66,   299] loss: 0.702920\n",
      "[67,    99] loss: 0.696159\n",
      "[67,   199] loss: 0.699433\n",
      "[67,   299] loss: 0.702920\n",
      "[68,    99] loss: 0.696159\n",
      "[68,   199] loss: 0.699433\n",
      "[68,   299] loss: 0.702920\n",
      "[69,    99] loss: 0.696159\n",
      "[69,   199] loss: 0.699433\n",
      "[69,   299] loss: 0.702920\n",
      "[70,    99] loss: 0.696159\n",
      "[70,   199] loss: 0.699433\n",
      "[70,   299] loss: 0.702920\n",
      "[71,    99] loss: 0.696159\n",
      "[71,   199] loss: 0.699433\n",
      "[71,   299] loss: 0.702920\n",
      "[72,    99] loss: 0.696159\n",
      "[72,   199] loss: 0.699433\n",
      "[72,   299] loss: 0.702920\n",
      "[73,    99] loss: 0.696159\n",
      "[73,   199] loss: 0.699433\n",
      "[73,   299] loss: 0.702920\n",
      "[74,    99] loss: 0.696159\n",
      "[74,   199] loss: 0.699433\n",
      "[74,   299] loss: 0.702920\n",
      "[75,    99] loss: 0.696159\n",
      "[75,   199] loss: 0.699433\n",
      "[75,   299] loss: 0.702920\n",
      "[76,    99] loss: 0.696159\n",
      "[76,   199] loss: 0.699433\n",
      "[76,   299] loss: 0.702920\n",
      "[77,    99] loss: 0.696159\n",
      "[77,   199] loss: 0.699433\n",
      "[77,   299] loss: 0.702920\n",
      "[78,    99] loss: 0.696159\n",
      "[78,   199] loss: 0.699433\n",
      "[78,   299] loss: 0.702920\n",
      "[79,    99] loss: 0.696159\n",
      "[79,   199] loss: 0.699433\n",
      "[79,   299] loss: 0.702920\n",
      "[80,    99] loss: 0.696159\n",
      "[80,   199] loss: 0.699433\n",
      "[80,   299] loss: 0.702920\n",
      "[81,    99] loss: 0.696159\n",
      "[81,   199] loss: 0.699433\n",
      "[81,   299] loss: 0.702920\n",
      "[82,    99] loss: 0.696159\n",
      "[82,   199] loss: 0.699433\n",
      "[82,   299] loss: 0.702920\n",
      "[83,    99] loss: 0.696159\n",
      "[83,   199] loss: 0.699433\n",
      "[83,   299] loss: 0.702920\n",
      "[84,    99] loss: 0.696159\n",
      "[84,   199] loss: 0.699433\n",
      "[84,   299] loss: 0.702920\n",
      "[85,    99] loss: 0.696159\n",
      "[85,   199] loss: 0.699433\n",
      "[85,   299] loss: 0.702920\n",
      "[86,    99] loss: 0.696159\n",
      "[86,   199] loss: 0.699433\n",
      "[86,   299] loss: 0.702920\n",
      "[87,    99] loss: 0.696159\n",
      "[87,   199] loss: 0.699433\n",
      "[87,   299] loss: 0.702920\n",
      "[88,    99] loss: 0.696159\n",
      "[88,   199] loss: 0.699433\n",
      "[88,   299] loss: 0.702920\n",
      "[89,    99] loss: 0.696159\n",
      "[89,   199] loss: 0.699433\n",
      "[89,   299] loss: 0.702920\n",
      "[90,    99] loss: 0.696159\n",
      "[90,   199] loss: 0.699433\n",
      "[90,   299] loss: 0.702920\n",
      "[91,    99] loss: 0.696159\n",
      "[91,   199] loss: 0.699433\n",
      "[91,   299] loss: 0.702920\n",
      "[92,    99] loss: 0.696159\n",
      "[92,   199] loss: 0.699433\n",
      "[92,   299] loss: 0.702920\n",
      "[93,    99] loss: 0.696159\n",
      "[93,   199] loss: 0.699433\n",
      "[93,   299] loss: 0.702920\n",
      "[94,    99] loss: 0.696159\n",
      "[94,   199] loss: 0.699433\n",
      "[94,   299] loss: 0.702920\n",
      "[95,    99] loss: 0.696159\n",
      "[95,   199] loss: 0.699433\n",
      "[95,   299] loss: 0.702920\n",
      "[96,    99] loss: 0.696159\n",
      "[96,   199] loss: 0.699433\n",
      "[96,   299] loss: 0.702920\n",
      "[97,    99] loss: 0.696159\n",
      "[97,   199] loss: 0.699433\n",
      "[97,   299] loss: 0.702920\n",
      "[98,    99] loss: 0.696159\n",
      "[98,   199] loss: 0.699433\n",
      "[98,   299] loss: 0.702920\n",
      "[99,    99] loss: 0.696159\n",
      "[99,   199] loss: 0.699433\n",
      "[99,   299] loss: 0.702920\n",
      "[100,    99] loss: 0.696159\n",
      "[100,   199] loss: 0.699433\n",
      "[100,   299] loss: 0.702920\n",
      "Finished Training\n",
      "[1,    99] loss: 1.510980\n",
      "[1,   199] loss: 1.101313\n",
      "[1,   299] loss: 0.721695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    99] loss: 0.721217\n",
      "[2,   199] loss: 0.711978\n",
      "[2,   299] loss: 0.721824\n",
      "[3,    99] loss: 0.721646\n",
      "[3,   199] loss: 0.712281\n",
      "[3,   299] loss: 0.722035\n",
      "[4,    99] loss: 0.721794\n",
      "[4,   199] loss: 0.712404\n",
      "[4,   299] loss: 0.722131\n",
      "[5,    99] loss: 0.721864\n",
      "[5,   199] loss: 0.712467\n",
      "[5,   299] loss: 0.722183\n",
      "[6,    99] loss: 0.721903\n",
      "[6,   199] loss: 0.712504\n",
      "[6,   299] loss: 0.722213\n",
      "[7,    99] loss: 0.721927\n",
      "[7,   199] loss: 0.712526\n",
      "[7,   299] loss: 0.722233\n",
      "[8,    99] loss: 0.721941\n",
      "[8,   199] loss: 0.712540\n",
      "[8,   299] loss: 0.722245\n",
      "[9,    99] loss: 0.721951\n",
      "[9,   199] loss: 0.712550\n",
      "[9,   299] loss: 0.722253\n",
      "[10,    99] loss: 0.721957\n",
      "[10,   199] loss: 0.712556\n",
      "[10,   299] loss: 0.722259\n",
      "[11,    99] loss: 0.721961\n",
      "[11,   199] loss: 0.712560\n",
      "[11,   299] loss: 0.722262\n",
      "[12,    99] loss: 0.721964\n",
      "[12,   199] loss: 0.712563\n",
      "[12,   299] loss: 0.722265\n",
      "[13,    99] loss: 0.721966\n",
      "[13,   199] loss: 0.712565\n",
      "[13,   299] loss: 0.722267\n",
      "[14,    99] loss: 0.721967\n",
      "[14,   199] loss: 0.712567\n",
      "[14,   299] loss: 0.722268\n",
      "[15,    99] loss: 0.721968\n",
      "[15,   199] loss: 0.712568\n",
      "[15,   299] loss: 0.722269\n",
      "[16,    99] loss: 0.721969\n",
      "[16,   199] loss: 0.712568\n",
      "[16,   299] loss: 0.722269\n",
      "[17,    99] loss: 0.721969\n",
      "[17,   199] loss: 0.712569\n",
      "[17,   299] loss: 0.722270\n",
      "[18,    99] loss: 0.721970\n",
      "[18,   199] loss: 0.712569\n",
      "[18,   299] loss: 0.722270\n",
      "[19,    99] loss: 0.721970\n",
      "[19,   199] loss: 0.712569\n",
      "[19,   299] loss: 0.722270\n",
      "[20,    99] loss: 0.721970\n",
      "[20,   199] loss: 0.712569\n",
      "[20,   299] loss: 0.722270\n",
      "[21,    99] loss: 0.721970\n",
      "[21,   199] loss: 0.712569\n",
      "[21,   299] loss: 0.722270\n",
      "[22,    99] loss: 0.721970\n",
      "[22,   199] loss: 0.712569\n",
      "[22,   299] loss: 0.722271\n",
      "[23,    99] loss: 0.721970\n",
      "[23,   199] loss: 0.712570\n",
      "[23,   299] loss: 0.722271\n",
      "[24,    99] loss: 0.721970\n",
      "[24,   199] loss: 0.712570\n",
      "[24,   299] loss: 0.722271\n",
      "[25,    99] loss: 0.721970\n",
      "[25,   199] loss: 0.712570\n",
      "[25,   299] loss: 0.722271\n",
      "[26,    99] loss: 0.721970\n",
      "[26,   199] loss: 0.712570\n",
      "[26,   299] loss: 0.722271\n",
      "[27,    99] loss: 0.721970\n",
      "[27,   199] loss: 0.712570\n",
      "[27,   299] loss: 0.722271\n",
      "[28,    99] loss: 0.721970\n",
      "[28,   199] loss: 0.712570\n",
      "[28,   299] loss: 0.722271\n",
      "[29,    99] loss: 0.721970\n",
      "[29,   199] loss: 0.712570\n",
      "[29,   299] loss: 0.722271\n",
      "[30,    99] loss: 0.721970\n",
      "[30,   199] loss: 0.712570\n",
      "[30,   299] loss: 0.722271\n",
      "[31,    99] loss: 0.721970\n",
      "[31,   199] loss: 0.712570\n",
      "[31,   299] loss: 0.722271\n",
      "[32,    99] loss: 0.721970\n",
      "[32,   199] loss: 0.712570\n",
      "[32,   299] loss: 0.722271\n",
      "[33,    99] loss: 0.721970\n",
      "[33,   199] loss: 0.712570\n",
      "[33,   299] loss: 0.722271\n",
      "[34,    99] loss: 0.721970\n",
      "[34,   199] loss: 0.712570\n",
      "[34,   299] loss: 0.722271\n",
      "[35,    99] loss: 0.721970\n",
      "[35,   199] loss: 0.712570\n",
      "[35,   299] loss: 0.722271\n",
      "[36,    99] loss: 0.721970\n",
      "[36,   199] loss: 0.712570\n",
      "[36,   299] loss: 0.722271\n",
      "[37,    99] loss: 0.721970\n",
      "[37,   199] loss: 0.712570\n",
      "[37,   299] loss: 0.722271\n",
      "[38,    99] loss: 0.721970\n",
      "[38,   199] loss: 0.712570\n",
      "[38,   299] loss: 0.722271\n",
      "[39,    99] loss: 0.721970\n",
      "[39,   199] loss: 0.712570\n",
      "[39,   299] loss: 0.722271\n",
      "[40,    99] loss: 0.721970\n",
      "[40,   199] loss: 0.712570\n",
      "[40,   299] loss: 0.722271\n",
      "[41,    99] loss: 0.721970\n",
      "[41,   199] loss: 0.712570\n",
      "[41,   299] loss: 0.722271\n",
      "[42,    99] loss: 0.721970\n",
      "[42,   199] loss: 0.712570\n",
      "[42,   299] loss: 0.722271\n",
      "[43,    99] loss: 0.721970\n",
      "[43,   199] loss: 0.712570\n",
      "[43,   299] loss: 0.722271\n",
      "[44,    99] loss: 0.721970\n",
      "[44,   199] loss: 0.712570\n",
      "[44,   299] loss: 0.722271\n",
      "[45,    99] loss: 0.721970\n",
      "[45,   199] loss: 0.712570\n",
      "[45,   299] loss: 0.722271\n",
      "[46,    99] loss: 0.721970\n",
      "[46,   199] loss: 0.712570\n",
      "[46,   299] loss: 0.722271\n",
      "[47,    99] loss: 0.721970\n",
      "[47,   199] loss: 0.712570\n",
      "[47,   299] loss: 0.722271\n",
      "[48,    99] loss: 0.721970\n",
      "[48,   199] loss: 0.712570\n",
      "[48,   299] loss: 0.722271\n",
      "[49,    99] loss: 0.721970\n",
      "[49,   199] loss: 0.712570\n",
      "[49,   299] loss: 0.722271\n",
      "[50,    99] loss: 0.721970\n",
      "[50,   199] loss: 0.712570\n",
      "[50,   299] loss: 0.722271\n",
      "[51,    99] loss: 0.721970\n",
      "[51,   199] loss: 0.712570\n",
      "[51,   299] loss: 0.722271\n",
      "[52,    99] loss: 0.721970\n",
      "[52,   199] loss: 0.712570\n",
      "[52,   299] loss: 0.722271\n",
      "[53,    99] loss: 0.721970\n",
      "[53,   199] loss: 0.712570\n",
      "[53,   299] loss: 0.722271\n",
      "[54,    99] loss: 0.721970\n",
      "[54,   199] loss: 0.712570\n",
      "[54,   299] loss: 0.722271\n",
      "[55,    99] loss: 0.721970\n",
      "[55,   199] loss: 0.712570\n",
      "[55,   299] loss: 0.722271\n",
      "[56,    99] loss: 0.721970\n",
      "[56,   199] loss: 0.712570\n",
      "[56,   299] loss: 0.722271\n",
      "[57,    99] loss: 0.721970\n",
      "[57,   199] loss: 0.712570\n",
      "[57,   299] loss: 0.722271\n",
      "[58,    99] loss: 0.721970\n",
      "[58,   199] loss: 0.712570\n",
      "[58,   299] loss: 0.722271\n",
      "[59,    99] loss: 0.721970\n",
      "[59,   199] loss: 0.712570\n",
      "[59,   299] loss: 0.722271\n",
      "[60,    99] loss: 0.721970\n",
      "[60,   199] loss: 0.712570\n",
      "[60,   299] loss: 0.722271\n",
      "[61,    99] loss: 0.721970\n",
      "[61,   199] loss: 0.712570\n",
      "[61,   299] loss: 0.722271\n",
      "[62,    99] loss: 0.721970\n",
      "[62,   199] loss: 0.712570\n",
      "[62,   299] loss: 0.722271\n",
      "[63,    99] loss: 0.721970\n",
      "[63,   199] loss: 0.712570\n",
      "[63,   299] loss: 0.722271\n",
      "[64,    99] loss: 0.721970\n",
      "[64,   199] loss: 0.712570\n",
      "[64,   299] loss: 0.722271\n",
      "[65,    99] loss: 0.721970\n",
      "[65,   199] loss: 0.712570\n",
      "[65,   299] loss: 0.722271\n",
      "[66,    99] loss: 0.721970\n",
      "[66,   199] loss: 0.712570\n",
      "[66,   299] loss: 0.722271\n",
      "[67,    99] loss: 0.721970\n",
      "[67,   199] loss: 0.712570\n",
      "[67,   299] loss: 0.722271\n",
      "[68,    99] loss: 0.721970\n",
      "[68,   199] loss: 0.712570\n",
      "[68,   299] loss: 0.722271\n",
      "[69,    99] loss: 0.721970\n",
      "[69,   199] loss: 0.712570\n",
      "[69,   299] loss: 0.722271\n",
      "[70,    99] loss: 0.721970\n",
      "[70,   199] loss: 0.712570\n",
      "[70,   299] loss: 0.722271\n",
      "[71,    99] loss: 0.721970\n",
      "[71,   199] loss: 0.712570\n",
      "[71,   299] loss: 0.722271\n",
      "[72,    99] loss: 0.721970\n",
      "[72,   199] loss: 0.712570\n",
      "[72,   299] loss: 0.722271\n",
      "[73,    99] loss: 0.721970\n",
      "[73,   199] loss: 0.712570\n",
      "[73,   299] loss: 0.722271\n",
      "[74,    99] loss: 0.721970\n",
      "[74,   199] loss: 0.712570\n",
      "[74,   299] loss: 0.722271\n",
      "[75,    99] loss: 0.721970\n",
      "[75,   199] loss: 0.712570\n",
      "[75,   299] loss: 0.722271\n",
      "[76,    99] loss: 0.721970\n",
      "[76,   199] loss: 0.712570\n",
      "[76,   299] loss: 0.722271\n",
      "[77,    99] loss: 0.721970\n",
      "[77,   199] loss: 0.712570\n",
      "[77,   299] loss: 0.722271\n",
      "[78,    99] loss: 0.721970\n",
      "[78,   199] loss: 0.712570\n",
      "[78,   299] loss: 0.722271\n",
      "[79,    99] loss: 0.721970\n",
      "[79,   199] loss: 0.712570\n",
      "[79,   299] loss: 0.722271\n",
      "[80,    99] loss: 0.721970\n",
      "[80,   199] loss: 0.712570\n",
      "[80,   299] loss: 0.722271\n",
      "[81,    99] loss: 0.721970\n",
      "[81,   199] loss: 0.712570\n",
      "[81,   299] loss: 0.722271\n",
      "[82,    99] loss: 0.721970\n",
      "[82,   199] loss: 0.712570\n",
      "[82,   299] loss: 0.722271\n",
      "[83,    99] loss: 0.721970\n",
      "[83,   199] loss: 0.712570\n",
      "[83,   299] loss: 0.722271\n",
      "[84,    99] loss: 0.721970\n",
      "[84,   199] loss: 0.712570\n",
      "[84,   299] loss: 0.722271\n",
      "[85,    99] loss: 0.721970\n",
      "[85,   199] loss: 0.712570\n",
      "[85,   299] loss: 0.722271\n",
      "[86,    99] loss: 0.721970\n",
      "[86,   199] loss: 0.712570\n",
      "[86,   299] loss: 0.722271\n",
      "[87,    99] loss: 0.721970\n",
      "[87,   199] loss: 0.712570\n",
      "[87,   299] loss: 0.722271\n",
      "[88,    99] loss: 0.721970\n",
      "[88,   199] loss: 0.712570\n",
      "[88,   299] loss: 0.722271\n",
      "[89,    99] loss: 0.721970\n",
      "[89,   199] loss: 0.712570\n",
      "[89,   299] loss: 0.722271\n",
      "[90,    99] loss: 0.721970\n",
      "[90,   199] loss: 0.712570\n",
      "[90,   299] loss: 0.722271\n",
      "[91,    99] loss: 0.721970\n",
      "[91,   199] loss: 0.712570\n",
      "[91,   299] loss: 0.722271\n",
      "[92,    99] loss: 0.721970\n",
      "[92,   199] loss: 0.712570\n",
      "[92,   299] loss: 0.722271\n",
      "[93,    99] loss: 0.721970\n",
      "[93,   199] loss: 0.712570\n",
      "[93,   299] loss: 0.722271\n",
      "[94,    99] loss: 0.721970\n",
      "[94,   199] loss: 0.712570\n",
      "[94,   299] loss: 0.722271\n",
      "[95,    99] loss: 0.721970\n",
      "[95,   199] loss: 0.712570\n",
      "[95,   299] loss: 0.722271\n",
      "[96,    99] loss: 0.721970\n",
      "[96,   199] loss: 0.712570\n",
      "[96,   299] loss: 0.722271\n",
      "[97,    99] loss: 0.721970\n",
      "[97,   199] loss: 0.712570\n",
      "[97,   299] loss: 0.722271\n",
      "[98,    99] loss: 0.721970\n",
      "[98,   199] loss: 0.712570\n",
      "[98,   299] loss: 0.722271\n",
      "[99,    99] loss: 0.721970\n",
      "[99,   199] loss: 0.712570\n",
      "[99,   299] loss: 0.722271\n",
      "[100,    99] loss: 0.721970\n",
      "[100,   199] loss: 0.712570\n",
      "[100,   299] loss: 0.722271\n",
      "Finished Training\n",
      "[1,    99] loss: 1.312792\n",
      "[1,   199] loss: 0.698143\n",
      "[1,   299] loss: 0.704205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    99] loss: 0.712556\n",
      "[2,   199] loss: 0.698315\n",
      "[2,   299] loss: 0.704165\n",
      "[3,    99] loss: 0.712751\n",
      "[3,   199] loss: 0.698328\n",
      "[3,   299] loss: 0.704160\n",
      "[4,    99] loss: 0.712827\n",
      "[4,   199] loss: 0.698332\n",
      "[4,   299] loss: 0.704158\n",
      "[5,    99] loss: 0.712863\n",
      "[5,   199] loss: 0.698335\n",
      "[5,   299] loss: 0.704158\n",
      "[6,    99] loss: 0.712883\n",
      "[6,   199] loss: 0.698336\n",
      "[6,   299] loss: 0.704157\n",
      "[7,    99] loss: 0.712895\n",
      "[7,   199] loss: 0.698336\n",
      "[7,   299] loss: 0.704157\n",
      "[8,    99] loss: 0.712902\n",
      "[8,   199] loss: 0.698337\n",
      "[8,   299] loss: 0.704156\n",
      "[9,    99] loss: 0.712907\n",
      "[9,   199] loss: 0.698337\n",
      "[9,   299] loss: 0.704156\n",
      "[10,    99] loss: 0.712910\n",
      "[10,   199] loss: 0.698337\n",
      "[10,   299] loss: 0.704156\n",
      "[11,    99] loss: 0.712912\n",
      "[11,   199] loss: 0.698337\n",
      "[11,   299] loss: 0.704156\n",
      "[12,    99] loss: 0.712914\n",
      "[12,   199] loss: 0.698338\n",
      "[12,   299] loss: 0.704156\n",
      "[13,    99] loss: 0.712915\n",
      "[13,   199] loss: 0.698338\n",
      "[13,   299] loss: 0.704156\n",
      "[14,    99] loss: 0.712915\n",
      "[14,   199] loss: 0.698338\n",
      "[14,   299] loss: 0.704156\n",
      "[15,    99] loss: 0.712916\n",
      "[15,   199] loss: 0.698338\n",
      "[15,   299] loss: 0.704156\n",
      "[16,    99] loss: 0.712916\n",
      "[16,   199] loss: 0.698338\n",
      "[16,   299] loss: 0.704156\n",
      "[17,    99] loss: 0.712916\n",
      "[17,   199] loss: 0.698338\n",
      "[17,   299] loss: 0.704156\n",
      "[18,    99] loss: 0.712916\n",
      "[18,   199] loss: 0.698338\n",
      "[18,   299] loss: 0.704156\n",
      "[19,    99] loss: 0.712916\n",
      "[19,   199] loss: 0.698338\n",
      "[19,   299] loss: 0.704156\n",
      "[20,    99] loss: 0.712917\n",
      "[20,   199] loss: 0.698338\n",
      "[20,   299] loss: 0.704156\n",
      "[21,    99] loss: 0.712917\n",
      "[21,   199] loss: 0.698338\n",
      "[21,   299] loss: 0.704156\n",
      "[22,    99] loss: 0.712917\n",
      "[22,   199] loss: 0.698338\n",
      "[22,   299] loss: 0.704156\n",
      "[23,    99] loss: 0.712917\n",
      "[23,   199] loss: 0.698338\n",
      "[23,   299] loss: 0.704156\n",
      "[24,    99] loss: 0.712917\n",
      "[24,   199] loss: 0.698338\n",
      "[24,   299] loss: 0.704156\n",
      "[25,    99] loss: 0.712917\n",
      "[25,   199] loss: 0.698338\n",
      "[25,   299] loss: 0.704156\n",
      "[26,    99] loss: 0.712917\n",
      "[26,   199] loss: 0.698338\n",
      "[26,   299] loss: 0.704156\n",
      "[27,    99] loss: 0.712917\n",
      "[27,   199] loss: 0.698338\n",
      "[27,   299] loss: 0.704156\n",
      "[28,    99] loss: 0.712917\n",
      "[28,   199] loss: 0.698338\n",
      "[28,   299] loss: 0.704156\n",
      "[29,    99] loss: 0.712917\n",
      "[29,   199] loss: 0.698338\n",
      "[29,   299] loss: 0.704156\n",
      "[30,    99] loss: 0.712917\n",
      "[30,   199] loss: 0.698338\n",
      "[30,   299] loss: 0.704156\n",
      "[31,    99] loss: 0.712917\n",
      "[31,   199] loss: 0.698338\n",
      "[31,   299] loss: 0.704156\n",
      "[32,    99] loss: 0.712917\n",
      "[32,   199] loss: 0.698338\n",
      "[32,   299] loss: 0.704156\n",
      "[33,    99] loss: 0.712917\n",
      "[33,   199] loss: 0.698338\n",
      "[33,   299] loss: 0.704156\n",
      "[34,    99] loss: 0.712917\n",
      "[34,   199] loss: 0.698338\n",
      "[34,   299] loss: 0.704156\n",
      "[35,    99] loss: 0.712917\n",
      "[35,   199] loss: 0.698338\n",
      "[35,   299] loss: 0.704156\n",
      "[36,    99] loss: 0.712917\n",
      "[36,   199] loss: 0.698338\n",
      "[36,   299] loss: 0.704156\n",
      "[37,    99] loss: 0.712917\n",
      "[37,   199] loss: 0.698338\n",
      "[37,   299] loss: 0.704156\n",
      "[38,    99] loss: 0.712917\n",
      "[38,   199] loss: 0.698338\n",
      "[38,   299] loss: 0.704156\n",
      "[39,    99] loss: 0.712917\n",
      "[39,   199] loss: 0.698338\n",
      "[39,   299] loss: 0.704156\n",
      "[40,    99] loss: 0.712917\n",
      "[40,   199] loss: 0.698338\n",
      "[40,   299] loss: 0.704156\n",
      "[41,    99] loss: 0.712917\n",
      "[41,   199] loss: 0.698338\n",
      "[41,   299] loss: 0.704156\n",
      "[42,    99] loss: 0.712917\n",
      "[42,   199] loss: 0.698338\n",
      "[42,   299] loss: 0.704156\n",
      "[43,    99] loss: 0.712917\n",
      "[43,   199] loss: 0.698338\n",
      "[43,   299] loss: 0.704156\n",
      "[44,    99] loss: 0.712917\n",
      "[44,   199] loss: 0.698338\n",
      "[44,   299] loss: 0.704156\n",
      "[45,    99] loss: 0.712917\n",
      "[45,   199] loss: 0.698338\n",
      "[45,   299] loss: 0.704156\n",
      "[46,    99] loss: 0.712917\n",
      "[46,   199] loss: 0.698338\n",
      "[46,   299] loss: 0.704156\n",
      "[47,    99] loss: 0.712917\n",
      "[47,   199] loss: 0.698338\n",
      "[47,   299] loss: 0.704156\n",
      "[48,    99] loss: 0.712917\n",
      "[48,   199] loss: 0.698338\n",
      "[48,   299] loss: 0.704156\n",
      "[49,    99] loss: 0.712917\n",
      "[49,   199] loss: 0.698338\n",
      "[49,   299] loss: 0.704156\n",
      "[50,    99] loss: 0.712917\n",
      "[50,   199] loss: 0.698338\n",
      "[50,   299] loss: 0.704156\n",
      "[51,    99] loss: 0.712917\n",
      "[51,   199] loss: 0.698338\n",
      "[51,   299] loss: 0.704156\n",
      "[52,    99] loss: 0.712917\n",
      "[52,   199] loss: 0.698338\n",
      "[52,   299] loss: 0.704156\n",
      "[53,    99] loss: 0.712917\n",
      "[53,   199] loss: 0.698338\n",
      "[53,   299] loss: 0.704156\n",
      "[54,    99] loss: 0.712917\n",
      "[54,   199] loss: 0.698338\n",
      "[54,   299] loss: 0.704156\n",
      "[55,    99] loss: 0.712917\n",
      "[55,   199] loss: 0.698338\n",
      "[55,   299] loss: 0.704156\n",
      "[56,    99] loss: 0.712917\n",
      "[56,   199] loss: 0.698338\n",
      "[56,   299] loss: 0.704156\n",
      "[57,    99] loss: 0.712917\n",
      "[57,   199] loss: 0.698338\n",
      "[57,   299] loss: 0.704156\n",
      "[58,    99] loss: 0.712917\n",
      "[58,   199] loss: 0.698338\n",
      "[58,   299] loss: 0.704156\n",
      "[59,    99] loss: 0.712917\n",
      "[59,   199] loss: 0.698338\n",
      "[59,   299] loss: 0.704156\n",
      "[60,    99] loss: 0.712917\n",
      "[60,   199] loss: 0.698338\n",
      "[60,   299] loss: 0.704156\n",
      "[61,    99] loss: 0.712917\n",
      "[61,   199] loss: 0.698338\n",
      "[61,   299] loss: 0.704156\n",
      "[62,    99] loss: 0.712917\n",
      "[62,   199] loss: 0.698338\n",
      "[62,   299] loss: 0.704156\n",
      "[63,    99] loss: 0.712917\n",
      "[63,   199] loss: 0.698338\n",
      "[63,   299] loss: 0.704156\n",
      "[64,    99] loss: 0.712917\n",
      "[64,   199] loss: 0.698338\n",
      "[64,   299] loss: 0.704156\n",
      "[65,    99] loss: 0.712917\n",
      "[65,   199] loss: 0.698338\n",
      "[65,   299] loss: 0.704156\n",
      "[66,    99] loss: 0.712917\n",
      "[66,   199] loss: 0.698338\n",
      "[66,   299] loss: 0.704156\n",
      "[67,    99] loss: 0.712917\n",
      "[67,   199] loss: 0.698338\n",
      "[67,   299] loss: 0.704156\n",
      "[68,    99] loss: 0.712917\n",
      "[68,   199] loss: 0.698338\n",
      "[68,   299] loss: 0.704156\n",
      "[69,    99] loss: 0.712917\n",
      "[69,   199] loss: 0.698338\n",
      "[69,   299] loss: 0.704156\n",
      "[70,    99] loss: 0.712917\n",
      "[70,   199] loss: 0.698338\n",
      "[70,   299] loss: 0.704156\n",
      "[71,    99] loss: 0.712917\n",
      "[71,   199] loss: 0.698338\n",
      "[71,   299] loss: 0.704156\n",
      "[72,    99] loss: 0.712917\n",
      "[72,   199] loss: 0.698338\n",
      "[72,   299] loss: 0.704156\n",
      "[73,    99] loss: 0.712917\n",
      "[73,   199] loss: 0.698338\n",
      "[73,   299] loss: 0.704156\n",
      "[74,    99] loss: 0.712917\n",
      "[74,   199] loss: 0.698338\n",
      "[74,   299] loss: 0.704156\n",
      "[75,    99] loss: 0.712917\n",
      "[75,   199] loss: 0.698338\n",
      "[75,   299] loss: 0.704156\n",
      "[76,    99] loss: 0.712917\n",
      "[76,   199] loss: 0.698338\n",
      "[76,   299] loss: 0.704156\n",
      "[77,    99] loss: 0.712917\n",
      "[77,   199] loss: 0.698338\n",
      "[77,   299] loss: 0.704156\n",
      "[78,    99] loss: 0.712917\n",
      "[78,   199] loss: 0.698338\n",
      "[78,   299] loss: 0.704156\n",
      "[79,    99] loss: 0.712917\n",
      "[79,   199] loss: 0.698338\n",
      "[79,   299] loss: 0.704156\n",
      "[80,    99] loss: 0.712917\n",
      "[80,   199] loss: 0.698338\n",
      "[80,   299] loss: 0.704156\n",
      "[81,    99] loss: 0.712917\n",
      "[81,   199] loss: 0.698338\n",
      "[81,   299] loss: 0.704156\n",
      "[82,    99] loss: 0.712917\n",
      "[82,   199] loss: 0.698338\n",
      "[82,   299] loss: 0.704156\n",
      "[83,    99] loss: 0.712917\n",
      "[83,   199] loss: 0.698338\n",
      "[83,   299] loss: 0.704156\n",
      "[84,    99] loss: 0.712917\n",
      "[84,   199] loss: 0.698338\n",
      "[84,   299] loss: 0.704156\n",
      "[85,    99] loss: 0.712917\n",
      "[85,   199] loss: 0.698338\n",
      "[85,   299] loss: 0.704156\n",
      "[86,    99] loss: 0.712917\n",
      "[86,   199] loss: 0.698338\n",
      "[86,   299] loss: 0.704156\n",
      "[87,    99] loss: 0.712917\n",
      "[87,   199] loss: 0.698338\n",
      "[87,   299] loss: 0.704156\n",
      "[88,    99] loss: 0.712917\n",
      "[88,   199] loss: 0.698338\n",
      "[88,   299] loss: 0.704156\n",
      "[89,    99] loss: 0.712917\n",
      "[89,   199] loss: 0.698338\n",
      "[89,   299] loss: 0.704156\n",
      "[90,    99] loss: 0.712917\n",
      "[90,   199] loss: 0.698338\n",
      "[90,   299] loss: 0.704156\n",
      "[91,    99] loss: 0.712917\n",
      "[91,   199] loss: 0.698338\n",
      "[91,   299] loss: 0.704156\n",
      "[92,    99] loss: 0.712917\n",
      "[92,   199] loss: 0.698338\n",
      "[92,   299] loss: 0.704156\n",
      "[93,    99] loss: 0.712917\n",
      "[93,   199] loss: 0.698338\n",
      "[93,   299] loss: 0.704156\n",
      "[94,    99] loss: 0.712917\n",
      "[94,   199] loss: 0.698338\n",
      "[94,   299] loss: 0.704156\n",
      "[95,    99] loss: 0.712917\n",
      "[95,   199] loss: 0.698338\n",
      "[95,   299] loss: 0.704156\n",
      "[96,    99] loss: 0.712917\n",
      "[96,   199] loss: 0.698338\n",
      "[96,   299] loss: 0.704156\n",
      "[97,    99] loss: 0.712917\n",
      "[97,   199] loss: 0.698338\n",
      "[97,   299] loss: 0.704156\n",
      "[98,    99] loss: 0.712917\n",
      "[98,   199] loss: 0.698338\n",
      "[98,   299] loss: 0.704156\n",
      "[99,    99] loss: 0.712917\n",
      "[99,   199] loss: 0.698338\n",
      "[99,   299] loss: 0.704156\n",
      "[100,    99] loss: 0.712917\n",
      "[100,   199] loss: 0.698338\n",
      "[100,   299] loss: 0.704156\n",
      "Finished Training\n",
      "[1,    99] loss: 3.133458\n",
      "[1,   199] loss: 0.714393\n",
      "[1,   299] loss: 0.715514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    99] loss: 0.741117\n",
      "[2,   199] loss: 0.714628\n",
      "[2,   299] loss: 0.715386\n",
      "[3,    99] loss: 0.738422\n",
      "[3,   199] loss: 0.714704\n",
      "[3,   299] loss: 0.715375\n",
      "[4,    99] loss: 0.738422\n",
      "[4,   199] loss: 0.714733\n",
      "[4,   299] loss: 0.715370\n",
      "[5,    99] loss: 0.738422\n",
      "[5,   199] loss: 0.714747\n",
      "[5,   299] loss: 0.715367\n",
      "[6,    99] loss: 0.738422\n",
      "[6,   199] loss: 0.714755\n",
      "[6,   299] loss: 0.715366\n",
      "[7,    99] loss: 0.738423\n",
      "[7,   199] loss: 0.714760\n",
      "[7,   299] loss: 0.715365\n",
      "[8,    99] loss: 0.738423\n",
      "[8,   199] loss: 0.714763\n",
      "[8,   299] loss: 0.715364\n",
      "[9,    99] loss: 0.738423\n",
      "[9,   199] loss: 0.714766\n",
      "[9,   299] loss: 0.715363\n",
      "[10,    99] loss: 0.738423\n",
      "[10,   199] loss: 0.714767\n",
      "[10,   299] loss: 0.715363\n",
      "[11,    99] loss: 0.738423\n",
      "[11,   199] loss: 0.714768\n",
      "[11,   299] loss: 0.715363\n",
      "[12,    99] loss: 0.738423\n",
      "[12,   199] loss: 0.714769\n",
      "[12,   299] loss: 0.715363\n",
      "[13,    99] loss: 0.738423\n",
      "[13,   199] loss: 0.714769\n",
      "[13,   299] loss: 0.715362\n",
      "[14,    99] loss: 0.738423\n",
      "[14,   199] loss: 0.714769\n",
      "[14,   299] loss: 0.715362\n",
      "[15,    99] loss: 0.738423\n",
      "[15,   199] loss: 0.714770\n",
      "[15,   299] loss: 0.715362\n",
      "[16,    99] loss: 0.738423\n",
      "[16,   199] loss: 0.714770\n",
      "[16,   299] loss: 0.715362\n",
      "[17,    99] loss: 0.738423\n",
      "[17,   199] loss: 0.714770\n",
      "[17,   299] loss: 0.715362\n",
      "[18,    99] loss: 0.738423\n",
      "[18,   199] loss: 0.714770\n",
      "[18,   299] loss: 0.715362\n",
      "[19,    99] loss: 0.738423\n",
      "[19,   199] loss: 0.714770\n",
      "[19,   299] loss: 0.715362\n",
      "[20,    99] loss: 0.738423\n",
      "[20,   199] loss: 0.714770\n",
      "[20,   299] loss: 0.715362\n",
      "[21,    99] loss: 0.738423\n",
      "[21,   199] loss: 0.714770\n",
      "[21,   299] loss: 0.715362\n",
      "[22,    99] loss: 0.738423\n",
      "[22,   199] loss: 0.714770\n",
      "[22,   299] loss: 0.715362\n",
      "[23,    99] loss: 0.738423\n",
      "[23,   199] loss: 0.714770\n",
      "[23,   299] loss: 0.715362\n",
      "[24,    99] loss: 0.738423\n",
      "[24,   199] loss: 0.714770\n",
      "[24,   299] loss: 0.715362\n",
      "[25,    99] loss: 0.738423\n",
      "[25,   199] loss: 0.714770\n",
      "[25,   299] loss: 0.715362\n",
      "[26,    99] loss: 0.738423\n",
      "[26,   199] loss: 0.714770\n",
      "[26,   299] loss: 0.715362\n",
      "[27,    99] loss: 0.738423\n",
      "[27,   199] loss: 0.714770\n",
      "[27,   299] loss: 0.715362\n",
      "[28,    99] loss: 0.738423\n",
      "[28,   199] loss: 0.714770\n",
      "[28,   299] loss: 0.715362\n",
      "[29,    99] loss: 0.738423\n",
      "[29,   199] loss: 0.714770\n",
      "[29,   299] loss: 0.715362\n",
      "[30,    99] loss: 0.738423\n",
      "[30,   199] loss: 0.714770\n",
      "[30,   299] loss: 0.715362\n",
      "[31,    99] loss: 0.738423\n",
      "[31,   199] loss: 0.714770\n",
      "[31,   299] loss: 0.715362\n",
      "[32,    99] loss: 0.738423\n",
      "[32,   199] loss: 0.714770\n",
      "[32,   299] loss: 0.715362\n",
      "[33,    99] loss: 0.738423\n",
      "[33,   199] loss: 0.714770\n",
      "[33,   299] loss: 0.715362\n",
      "[34,    99] loss: 0.738423\n",
      "[34,   199] loss: 0.714770\n",
      "[34,   299] loss: 0.715362\n",
      "[35,    99] loss: 0.738423\n",
      "[35,   199] loss: 0.714770\n",
      "[35,   299] loss: 0.715362\n",
      "[36,    99] loss: 0.738423\n",
      "[36,   199] loss: 0.714770\n",
      "[36,   299] loss: 0.715362\n",
      "[37,    99] loss: 0.738423\n",
      "[37,   199] loss: 0.714770\n",
      "[37,   299] loss: 0.715362\n",
      "[38,    99] loss: 0.738423\n",
      "[38,   199] loss: 0.714770\n",
      "[38,   299] loss: 0.715362\n",
      "[39,    99] loss: 0.738423\n",
      "[39,   199] loss: 0.714770\n",
      "[39,   299] loss: 0.715362\n",
      "[40,    99] loss: 0.738423\n",
      "[40,   199] loss: 0.714770\n",
      "[40,   299] loss: 0.715362\n",
      "[41,    99] loss: 0.738423\n",
      "[41,   199] loss: 0.714770\n",
      "[41,   299] loss: 0.715362\n",
      "[42,    99] loss: 0.738423\n",
      "[42,   199] loss: 0.714770\n",
      "[42,   299] loss: 0.715362\n",
      "[43,    99] loss: 0.738423\n",
      "[43,   199] loss: 0.714770\n",
      "[43,   299] loss: 0.715362\n",
      "[44,    99] loss: 0.738423\n",
      "[44,   199] loss: 0.714770\n",
      "[44,   299] loss: 0.715362\n",
      "[45,    99] loss: 0.738423\n",
      "[45,   199] loss: 0.714770\n",
      "[45,   299] loss: 0.715362\n",
      "[46,    99] loss: 0.738423\n",
      "[46,   199] loss: 0.714770\n",
      "[46,   299] loss: 0.715362\n",
      "[47,    99] loss: 0.738423\n",
      "[47,   199] loss: 0.714770\n",
      "[47,   299] loss: 0.715362\n",
      "[48,    99] loss: 0.738423\n",
      "[48,   199] loss: 0.714770\n",
      "[48,   299] loss: 0.715362\n",
      "[49,    99] loss: 0.738423\n",
      "[49,   199] loss: 0.714770\n",
      "[49,   299] loss: 0.715362\n",
      "[50,    99] loss: 0.738423\n",
      "[50,   199] loss: 0.714770\n",
      "[50,   299] loss: 0.715362\n",
      "[51,    99] loss: 0.738423\n",
      "[51,   199] loss: 0.714770\n",
      "[51,   299] loss: 0.715362\n",
      "[52,    99] loss: 0.738423\n",
      "[52,   199] loss: 0.714770\n",
      "[52,   299] loss: 0.715362\n",
      "[53,    99] loss: 0.738423\n",
      "[53,   199] loss: 0.714770\n",
      "[53,   299] loss: 0.715362\n",
      "[54,    99] loss: 0.738423\n",
      "[54,   199] loss: 0.714770\n",
      "[54,   299] loss: 0.715362\n",
      "[55,    99] loss: 0.738423\n",
      "[55,   199] loss: 0.714770\n",
      "[55,   299] loss: 0.715362\n",
      "[56,    99] loss: 0.738423\n",
      "[56,   199] loss: 0.714770\n",
      "[56,   299] loss: 0.715362\n",
      "[57,    99] loss: 0.738423\n",
      "[57,   199] loss: 0.714770\n",
      "[57,   299] loss: 0.715362\n",
      "[58,    99] loss: 0.738423\n",
      "[58,   199] loss: 0.714770\n",
      "[58,   299] loss: 0.715362\n",
      "[59,    99] loss: 0.738423\n",
      "[59,   199] loss: 0.714770\n",
      "[59,   299] loss: 0.715362\n",
      "[60,    99] loss: 0.738423\n",
      "[60,   199] loss: 0.714770\n",
      "[60,   299] loss: 0.715362\n",
      "[61,    99] loss: 0.738423\n",
      "[61,   199] loss: 0.714770\n",
      "[61,   299] loss: 0.715362\n",
      "[62,    99] loss: 0.738423\n",
      "[62,   199] loss: 0.714770\n",
      "[62,   299] loss: 0.715362\n",
      "[63,    99] loss: 0.738423\n",
      "[63,   199] loss: 0.714770\n",
      "[63,   299] loss: 0.715362\n",
      "[64,    99] loss: 0.738423\n",
      "[64,   199] loss: 0.714770\n",
      "[64,   299] loss: 0.715362\n",
      "[65,    99] loss: 0.738423\n",
      "[65,   199] loss: 0.714770\n",
      "[65,   299] loss: 0.715362\n",
      "[66,    99] loss: 0.738423\n",
      "[66,   199] loss: 0.714770\n",
      "[66,   299] loss: 0.715362\n",
      "[67,    99] loss: 0.738423\n",
      "[67,   199] loss: 0.714770\n",
      "[67,   299] loss: 0.715362\n",
      "[68,    99] loss: 0.738423\n",
      "[68,   199] loss: 0.714770\n",
      "[68,   299] loss: 0.715362\n",
      "[69,    99] loss: 0.738423\n",
      "[69,   199] loss: 0.714770\n",
      "[69,   299] loss: 0.715362\n",
      "[70,    99] loss: 0.738423\n",
      "[70,   199] loss: 0.714770\n",
      "[70,   299] loss: 0.715362\n",
      "[71,    99] loss: 0.738423\n",
      "[71,   199] loss: 0.714770\n",
      "[71,   299] loss: 0.715362\n",
      "[72,    99] loss: 0.738423\n",
      "[72,   199] loss: 0.714770\n",
      "[72,   299] loss: 0.715362\n",
      "[73,    99] loss: 0.738423\n",
      "[73,   199] loss: 0.714770\n",
      "[73,   299] loss: 0.715362\n",
      "[74,    99] loss: 0.738423\n",
      "[74,   199] loss: 0.714770\n",
      "[74,   299] loss: 0.715362\n",
      "[75,    99] loss: 0.738423\n",
      "[75,   199] loss: 0.714770\n",
      "[75,   299] loss: 0.715362\n",
      "[76,    99] loss: 0.738423\n",
      "[76,   199] loss: 0.714770\n",
      "[76,   299] loss: 0.715362\n",
      "[77,    99] loss: 0.738423\n",
      "[77,   199] loss: 0.714770\n",
      "[77,   299] loss: 0.715362\n",
      "[78,    99] loss: 0.738423\n",
      "[78,   199] loss: 0.714770\n",
      "[78,   299] loss: 0.715362\n",
      "[79,    99] loss: 0.738423\n",
      "[79,   199] loss: 0.714770\n",
      "[79,   299] loss: 0.715362\n",
      "[80,    99] loss: 0.738423\n",
      "[80,   199] loss: 0.714770\n",
      "[80,   299] loss: 0.715362\n",
      "[81,    99] loss: 0.738423\n",
      "[81,   199] loss: 0.714770\n",
      "[81,   299] loss: 0.715362\n",
      "[82,    99] loss: 0.738423\n",
      "[82,   199] loss: 0.714770\n",
      "[82,   299] loss: 0.715362\n",
      "[83,    99] loss: 0.738423\n",
      "[83,   199] loss: 0.714770\n",
      "[83,   299] loss: 0.715362\n",
      "[84,    99] loss: 0.738423\n",
      "[84,   199] loss: 0.714770\n",
      "[84,   299] loss: 0.715362\n",
      "[85,    99] loss: 0.738423\n",
      "[85,   199] loss: 0.714770\n",
      "[85,   299] loss: 0.715362\n",
      "[86,    99] loss: 0.738423\n",
      "[86,   199] loss: 0.714770\n",
      "[86,   299] loss: 0.715362\n",
      "[87,    99] loss: 0.738423\n",
      "[87,   199] loss: 0.714770\n",
      "[87,   299] loss: 0.715362\n",
      "[88,    99] loss: 0.738423\n",
      "[88,   199] loss: 0.714770\n",
      "[88,   299] loss: 0.715362\n",
      "[89,    99] loss: 0.738423\n",
      "[89,   199] loss: 0.714770\n",
      "[89,   299] loss: 0.715362\n",
      "[90,    99] loss: 0.738423\n",
      "[90,   199] loss: 0.714770\n",
      "[90,   299] loss: 0.715362\n",
      "[91,    99] loss: 0.738423\n",
      "[91,   199] loss: 0.714770\n",
      "[91,   299] loss: 0.715362\n",
      "[92,    99] loss: 0.738423\n",
      "[92,   199] loss: 0.714770\n",
      "[92,   299] loss: 0.715362\n",
      "[93,    99] loss: 0.738423\n",
      "[93,   199] loss: 0.714770\n",
      "[93,   299] loss: 0.715362\n",
      "[94,    99] loss: 0.738423\n",
      "[94,   199] loss: 0.714770\n",
      "[94,   299] loss: 0.715362\n",
      "[95,    99] loss: 0.738423\n",
      "[95,   199] loss: 0.714770\n",
      "[95,   299] loss: 0.715362\n",
      "[96,    99] loss: 0.738423\n",
      "[96,   199] loss: 0.714770\n",
      "[96,   299] loss: 0.715362\n",
      "[97,    99] loss: 0.738423\n",
      "[97,   199] loss: 0.714770\n",
      "[97,   299] loss: 0.715362\n",
      "[98,    99] loss: 0.738423\n",
      "[98,   199] loss: 0.714770\n",
      "[98,   299] loss: 0.715362\n",
      "[99,    99] loss: 0.738423\n",
      "[99,   199] loss: 0.714770\n",
      "[99,   299] loss: 0.715362\n",
      "[100,    99] loss: 0.738423\n",
      "[100,   199] loss: 0.714770\n",
      "[100,   299] loss: 0.715362\n",
      "Finished Training\n",
      "[1,    99] loss: 0.698452\n",
      "[1,   199] loss: 0.687029\n",
      "[1,   299] loss: 0.655955\n",
      "[2,    99] loss: 0.628899\n",
      "[2,   199] loss: 0.631705\n",
      "[2,   299] loss: 0.616486\n",
      "[3,    99] loss: 0.606204\n",
      "[3,   199] loss: 0.580371\n",
      "[3,   299] loss: 0.587806\n",
      "[4,    99] loss: 0.547782\n",
      "[4,   199] loss: 0.559215\n",
      "[4,   299] loss: 0.554020\n",
      "[5,    99] loss: 0.528373\n",
      "[5,   199] loss: 0.654143\n",
      "[5,   299] loss: 0.505261\n",
      "[6,    99] loss: 0.505755\n",
      "[6,   199] loss: 0.544308\n",
      "[6,   299] loss: 0.562637\n",
      "[7,    99] loss: 0.457026\n",
      "[7,   199] loss: 0.428985\n",
      "[7,   299] loss: 0.347070\n",
      "[8,    99] loss: 0.476667\n",
      "[8,   199] loss: 0.478053\n",
      "[8,   299] loss: 0.411934\n",
      "[9,    99] loss: 0.415128\n",
      "[9,   199] loss: 0.435405\n",
      "[9,   299] loss: 0.367700\n",
      "[10,    99] loss: 0.436516\n",
      "[10,   199] loss: 0.487686\n",
      "[10,   299] loss: 0.346991\n",
      "[11,    99] loss: 0.455680\n",
      "[11,   199] loss: 0.393511\n",
      "[11,   299] loss: 0.350127\n",
      "[12,    99] loss: 0.367147\n",
      "[12,   199] loss: 0.353526\n",
      "[12,   299] loss: 0.290548\n",
      "[13,    99] loss: 0.431320\n",
      "[13,   199] loss: 0.367681\n",
      "[13,   299] loss: 0.276161\n",
      "[14,    99] loss: 0.347328\n",
      "[14,   199] loss: 0.354641\n",
      "[14,   299] loss: 0.260579\n",
      "[15,    99] loss: 0.309549\n",
      "[15,   199] loss: 0.335731\n",
      "[15,   299] loss: 0.252976\n",
      "[16,    99] loss: 0.327196\n",
      "[16,   199] loss: 0.263209\n",
      "[16,   299] loss: 0.215149\n",
      "[17,    99] loss: 0.295820\n",
      "[17,   199] loss: 0.311477\n",
      "[17,   299] loss: 0.205619\n",
      "[18,    99] loss: 0.286272\n",
      "[18,   199] loss: 0.342782\n",
      "[18,   299] loss: 0.241168\n",
      "[19,    99] loss: 0.327951\n",
      "[19,   199] loss: 0.560703\n",
      "[19,   299] loss: 0.279922\n",
      "[20,    99] loss: 0.272625\n",
      "[20,   199] loss: 0.254226\n",
      "[20,   299] loss: 0.187051\n",
      "[21,    99] loss: 0.274703\n",
      "[21,   199] loss: 0.312691\n",
      "[21,   299] loss: 0.173370\n",
      "[22,    99] loss: 0.276689\n",
      "[22,   199] loss: 0.329594\n",
      "[22,   299] loss: 0.221637\n",
      "[23,    99] loss: 0.339116\n",
      "[23,   199] loss: 0.286800\n",
      "[23,   299] loss: 0.246615\n",
      "[24,    99] loss: 0.197410\n",
      "[24,   199] loss: 0.264490\n",
      "[24,   299] loss: 0.160113\n",
      "[25,    99] loss: 0.230803\n",
      "[25,   199] loss: 0.294135\n",
      "[25,   299] loss: 0.146057\n",
      "[26,    99] loss: 0.138051\n",
      "[26,   199] loss: 0.209442\n",
      "[26,   299] loss: 0.103666\n",
      "[27,    99] loss: 0.206257\n",
      "[27,   199] loss: 0.174493\n",
      "[27,   299] loss: 0.179242\n",
      "[28,    99] loss: 0.251095\n",
      "[28,   199] loss: 0.175793\n",
      "[28,   299] loss: 0.093301\n",
      "[29,    99] loss: 0.172574\n",
      "[29,   199] loss: 0.245839\n",
      "[29,   299] loss: 0.175805\n",
      "[30,    99] loss: 0.187743\n",
      "[30,   199] loss: 0.191588\n",
      "[30,   299] loss: 0.106909\n",
      "[31,    99] loss: 0.125839\n",
      "[31,   199] loss: 0.183571\n",
      "[31,   299] loss: 0.119192\n",
      "[32,    99] loss: 0.167664\n",
      "[32,   199] loss: 0.425960\n",
      "[32,   299] loss: 0.194420\n",
      "[33,    99] loss: 0.207013\n",
      "[33,   199] loss: 0.206535\n",
      "[33,   299] loss: 0.126284\n",
      "[34,    99] loss: 0.166613\n",
      "[34,   199] loss: 0.125075\n",
      "[34,   299] loss: 0.072187\n",
      "[35,    99] loss: 0.135220\n",
      "[35,   199] loss: 0.197615\n",
      "[35,   299] loss: 0.184418\n",
      "[36,    99] loss: 0.485970\n",
      "[36,   199] loss: 0.276791\n",
      "[36,   299] loss: 0.148198\n",
      "[37,    99] loss: 0.142383\n",
      "[37,   199] loss: 0.183803\n",
      "[37,   299] loss: 0.085775\n",
      "[38,    99] loss: 0.130311\n",
      "[38,   199] loss: 0.164910\n",
      "[38,   299] loss: 0.065631\n",
      "[39,    99] loss: 0.131130\n",
      "[39,   199] loss: 0.198849\n",
      "[39,   299] loss: 0.113366\n",
      "[40,    99] loss: 0.159174\n",
      "[40,   199] loss: 0.199466\n",
      "[40,   299] loss: 0.095931\n",
      "[41,    99] loss: 0.226894\n",
      "[41,   199] loss: 0.155997\n",
      "[41,   299] loss: 0.095964\n",
      "[42,    99] loss: 0.225764\n",
      "[42,   199] loss: 0.121023\n",
      "[42,   299] loss: 0.060187\n",
      "[43,    99] loss: 0.187041\n",
      "[43,   199] loss: 0.166663\n",
      "[43,   299] loss: 0.059341\n",
      "[44,    99] loss: 0.119676\n",
      "[44,   199] loss: 0.156762\n",
      "[44,   299] loss: 0.064067\n",
      "[45,    99] loss: 0.138498\n",
      "[45,   199] loss: 0.091356\n",
      "[45,   299] loss: 0.038938\n",
      "[46,    99] loss: 0.092176\n",
      "[46,   199] loss: 0.098093\n",
      "[46,   299] loss: 0.055358\n",
      "[47,    99] loss: 0.185646\n",
      "[47,   199] loss: 0.274095\n",
      "[47,   299] loss: 0.125795\n",
      "[48,    99] loss: 0.097917\n",
      "[48,   199] loss: 0.183865\n",
      "[48,   299] loss: 0.056007\n",
      "[49,    99] loss: 0.081657\n",
      "[49,   199] loss: 0.159714\n",
      "[49,   299] loss: 0.056667\n",
      "[50,    99] loss: 0.168505\n",
      "[50,   199] loss: 0.316255\n",
      "[50,   299] loss: 0.179402\n",
      "[51,    99] loss: 0.150030\n",
      "[51,   199] loss: 0.205028\n",
      "[51,   299] loss: 0.096881\n",
      "[52,    99] loss: 0.175046\n",
      "[52,   199] loss: 0.083648\n",
      "[52,   299] loss: 0.054784\n",
      "[53,    99] loss: 0.233428\n",
      "[53,   199] loss: 0.133726\n",
      "[53,   299] loss: 0.062555\n",
      "[54,    99] loss: 0.111992\n",
      "[54,   199] loss: 0.143752\n",
      "[54,   299] loss: 0.082265\n",
      "[55,    99] loss: 0.077415\n",
      "[55,   199] loss: 0.074768\n",
      "[55,   299] loss: 0.029726\n",
      "[56,    99] loss: 0.169505\n",
      "[56,   199] loss: 0.152460\n",
      "[56,   299] loss: 0.085085\n",
      "[57,    99] loss: 0.128846\n",
      "[57,   199] loss: 0.053008\n",
      "[57,   299] loss: 0.036481\n",
      "[58,    99] loss: 0.172846\n",
      "[58,   199] loss: 0.119815\n",
      "[58,   299] loss: 0.163420\n",
      "[59,    99] loss: 0.069630\n",
      "[59,   199] loss: 0.227529\n",
      "[59,   299] loss: 0.045991\n",
      "[60,    99] loss: 0.077038\n",
      "[60,   199] loss: 0.232310\n",
      "[60,   299] loss: 0.093652\n",
      "[61,    99] loss: 0.058270\n",
      "[61,   199] loss: 0.079284\n",
      "[61,   299] loss: 0.027241\n",
      "[62,    99] loss: 0.256578\n",
      "[62,   199] loss: 0.084837\n",
      "[62,   299] loss: 0.112213\n",
      "[63,    99] loss: 0.386433\n",
      "[63,   199] loss: 0.178804\n",
      "[63,   299] loss: 0.152730\n",
      "[64,    99] loss: 0.064852\n",
      "[64,   199] loss: 0.055556\n",
      "[64,   299] loss: 0.034586\n",
      "[65,    99] loss: 0.117939\n",
      "[65,   199] loss: 0.052548\n",
      "[65,   299] loss: 0.028472\n",
      "[66,    99] loss: 0.069189\n",
      "[66,   199] loss: 0.075608\n",
      "[66,   299] loss: 0.024514\n",
      "[67,    99] loss: 0.074768\n",
      "[67,   199] loss: 0.073045\n",
      "[67,   299] loss: 0.099544\n",
      "[68,    99] loss: 0.084957\n",
      "[68,   199] loss: 0.256201\n",
      "[68,   299] loss: 0.149200\n",
      "[69,    99] loss: 0.110096\n",
      "[69,   199] loss: 0.160437\n",
      "[69,   299] loss: 0.758921\n",
      "[70,    99] loss: 0.160673\n",
      "[70,   199] loss: 0.109573\n",
      "[70,   299] loss: 0.062474\n",
      "[71,    99] loss: 0.184484\n",
      "[71,   199] loss: 0.040955\n",
      "[71,   299] loss: 0.035615\n",
      "[72,    99] loss: 0.086299\n",
      "[72,   199] loss: 0.084344\n",
      "[72,   299] loss: 0.027412\n",
      "[73,    99] loss: 0.056915\n",
      "[73,   199] loss: 0.070167\n",
      "[73,   299] loss: 0.049612\n",
      "[74,    99] loss: 0.090040\n",
      "[74,   199] loss: 0.062702\n",
      "[74,   299] loss: 0.029274\n",
      "[75,    99] loss: 0.082710\n",
      "[75,   199] loss: 0.134234\n",
      "[75,   299] loss: 0.073136\n",
      "[76,    99] loss: 0.101021\n",
      "[76,   199] loss: 0.093612\n",
      "[76,   299] loss: 0.037595\n",
      "[77,    99] loss: 0.479681\n",
      "[77,   199] loss: 0.123729\n",
      "[77,   299] loss: 0.085636\n",
      "[78,    99] loss: 0.124412\n",
      "[78,   199] loss: 0.084421\n",
      "[78,   299] loss: 0.026162\n",
      "[79,    99] loss: 0.049602\n",
      "[79,   199] loss: 0.060816\n",
      "[79,   299] loss: 0.035478\n",
      "[80,    99] loss: 0.114027\n",
      "[80,   199] loss: 0.105102\n",
      "[80,   299] loss: 0.040866\n",
      "[81,    99] loss: 0.072833\n",
      "[81,   199] loss: 0.098790\n",
      "[81,   299] loss: 0.090717\n",
      "[82,    99] loss: 0.051289\n",
      "[82,   199] loss: 0.064553\n",
      "[82,   299] loss: 0.024466\n",
      "[83,    99] loss: 0.119335\n",
      "[83,   199] loss: 0.192450\n",
      "[83,   299] loss: 0.075839\n",
      "[84,    99] loss: 0.119202\n",
      "[84,   199] loss: 0.159335\n",
      "[84,   299] loss: 0.090842\n",
      "[85,    99] loss: 0.359713\n",
      "[85,   199] loss: 0.082448\n",
      "[85,   299] loss: 0.055268\n",
      "[86,    99] loss: 0.081986\n",
      "[86,   199] loss: 0.059217\n",
      "[86,   299] loss: 0.027347\n",
      "[87,    99] loss: 0.193942\n",
      "[87,   199] loss: 0.138706\n",
      "[87,   299] loss: 0.082641\n",
      "[88,    99] loss: 0.086619\n",
      "[88,   199] loss: 0.089407\n",
      "[88,   299] loss: 0.032420\n",
      "[89,    99] loss: 0.090506\n",
      "[89,   199] loss: 0.092466\n",
      "[89,   299] loss: 0.036449\n",
      "[90,    99] loss: 0.057147\n",
      "[90,   199] loss: 0.052332\n",
      "[90,   299] loss: 0.026670\n",
      "[91,    99] loss: 0.075883\n",
      "[91,   199] loss: 0.068651\n",
      "[91,   299] loss: 0.029661\n",
      "[92,    99] loss: 0.053903\n",
      "[92,   199] loss: 0.063799\n",
      "[92,   299] loss: 0.016870\n",
      "[93,    99] loss: 0.044956\n",
      "[93,   199] loss: 1.116155\n",
      "[93,   299] loss: 0.102094\n",
      "[94,    99] loss: 0.411205\n",
      "[94,   199] loss: 0.274319\n",
      "[94,   299] loss: 0.074029\n",
      "[95,    99] loss: 0.107416\n",
      "[95,   199] loss: 0.055712\n",
      "[95,   299] loss: 0.043517\n",
      "[96,    99] loss: 0.095151\n",
      "[96,   199] loss: 0.059176\n",
      "[96,   299] loss: 0.021132\n",
      "[97,    99] loss: 0.064933\n",
      "[97,   199] loss: 0.047555\n",
      "[97,   299] loss: 0.015385\n",
      "[98,    99] loss: 0.082502\n",
      "[98,   199] loss: 0.057649\n",
      "[98,   299] loss: 0.116296\n",
      "[99,    99] loss: 0.032618\n",
      "[99,   199] loss: 0.062879\n",
      "[99,   299] loss: 0.047615\n",
      "[100,    99] loss: 0.039297\n",
      "[100,   199] loss: 0.058086\n",
      "[100,   299] loss: 0.030356\n",
      "Finished Training\n",
      "[1,    99] loss: 0.699682\n",
      "[1,   199] loss: 0.647517\n",
      "[1,   299] loss: 0.699410\n",
      "[2,    99] loss: 0.613967\n",
      "[2,   199] loss: 0.549094\n",
      "[2,   299] loss: 0.664481\n",
      "[3,    99] loss: 0.541865\n",
      "[3,   199] loss: 0.502555\n",
      "[3,   299] loss: 0.548561\n",
      "[4,    99] loss: 0.501043\n",
      "[4,   199] loss: 0.459858\n",
      "[4,   299] loss: 0.676412\n",
      "[5,    99] loss: 0.473471\n",
      "[5,   199] loss: 0.469404\n",
      "[5,   299] loss: 0.427836\n",
      "[6,    99] loss: 0.485704\n",
      "[6,   199] loss: 0.435835\n",
      "[6,   299] loss: 0.395441\n",
      "[7,    99] loss: 0.463530\n",
      "[7,   199] loss: 0.408192\n",
      "[7,   299] loss: 0.368572\n",
      "[8,    99] loss: 0.409188\n",
      "[8,   199] loss: 0.320849\n",
      "[8,   299] loss: 0.365650\n",
      "[9,    99] loss: 0.340328\n",
      "[9,   199] loss: 0.337693\n",
      "[9,   299] loss: 0.319350\n",
      "[10,    99] loss: 0.341331\n",
      "[10,   199] loss: 0.291436\n",
      "[10,   299] loss: 0.334952\n",
      "[11,    99] loss: 0.367587\n",
      "[11,   199] loss: 0.334148\n",
      "[11,   299] loss: 0.295921\n",
      "[12,    99] loss: 0.284900\n",
      "[12,   199] loss: 0.318708\n",
      "[12,   299] loss: 0.236988\n",
      "[13,    99] loss: 0.234171\n",
      "[13,   199] loss: 0.311510\n",
      "[13,   299] loss: 0.395642\n",
      "[14,    99] loss: 0.204745\n",
      "[14,   199] loss: 0.282521\n",
      "[14,   299] loss: 0.254624\n",
      "[15,    99] loss: 0.249015\n",
      "[15,   199] loss: 0.226957\n",
      "[15,   299] loss: 0.323795\n",
      "[16,    99] loss: 0.230053\n",
      "[16,   199] loss: 0.225131\n",
      "[16,   299] loss: 0.276801\n",
      "[17,    99] loss: 0.228310\n",
      "[17,   199] loss: 0.189358\n",
      "[17,   299] loss: 0.135143\n",
      "[18,    99] loss: 0.232210\n",
      "[18,   199] loss: 0.206751\n",
      "[18,   299] loss: 0.265670\n",
      "[19,    99] loss: 0.204115\n",
      "[19,   199] loss: 0.197026\n",
      "[19,   299] loss: 0.200669\n",
      "[20,    99] loss: 0.222170\n",
      "[20,   199] loss: 0.140568\n",
      "[20,   299] loss: 0.125603\n",
      "[21,    99] loss: 0.236488\n",
      "[21,   199] loss: 0.204160\n",
      "[21,   299] loss: 0.389886\n",
      "[22,    99] loss: 0.182729\n",
      "[22,   199] loss: 0.171607\n",
      "[22,   299] loss: 0.125791\n",
      "[23,    99] loss: 0.174663\n",
      "[23,   199] loss: 0.146814\n",
      "[23,   299] loss: 0.152065\n",
      "[24,    99] loss: 0.162889\n",
      "[24,   199] loss: 0.177155\n",
      "[24,   299] loss: 0.117890\n",
      "[25,    99] loss: 0.167077\n",
      "[25,   199] loss: 0.097105\n",
      "[25,   299] loss: 0.140674\n",
      "[26,    99] loss: 0.156720\n",
      "[26,   199] loss: 0.135431\n",
      "[26,   299] loss: 0.119304\n",
      "[27,    99] loss: 0.151140\n",
      "[27,   199] loss: 0.126228\n",
      "[27,   299] loss: 0.075389\n",
      "[28,    99] loss: 0.122977\n",
      "[28,   199] loss: 0.107484\n",
      "[28,   299] loss: 0.113340\n",
      "[29,    99] loss: 0.107951\n",
      "[29,   199] loss: 0.223581\n",
      "[29,   299] loss: 0.279880\n",
      "[30,    99] loss: 0.211842\n",
      "[30,   199] loss: 0.156680\n",
      "[30,   299] loss: 0.077902\n",
      "[31,    99] loss: 0.126909\n",
      "[31,   199] loss: 0.151026\n",
      "[31,   299] loss: 0.108948\n",
      "[32,    99] loss: 0.083136\n",
      "[32,   199] loss: 0.067847\n",
      "[32,   299] loss: 0.081677\n",
      "[33,    99] loss: 0.056859\n",
      "[33,   199] loss: 0.061646\n",
      "[33,   299] loss: 0.029482\n",
      "[34,    99] loss: 0.064657\n",
      "[34,   199] loss: 0.058210\n",
      "[34,   299] loss: 0.138184\n",
      "[35,    99] loss: 0.290522\n",
      "[35,   199] loss: 0.220749\n",
      "[35,   299] loss: 0.162935\n",
      "[36,    99] loss: 0.097688\n",
      "[36,   199] loss: 0.114121\n",
      "[36,   299] loss: 0.129596\n",
      "[37,    99] loss: 0.092812\n",
      "[37,   199] loss: 0.067767\n",
      "[37,   299] loss: 0.103306\n",
      "[38,    99] loss: 0.064291\n",
      "[38,   199] loss: 0.052116\n",
      "[38,   299] loss: 0.045387\n",
      "[39,    99] loss: 0.090122\n",
      "[39,   199] loss: 0.135380\n",
      "[39,   299] loss: 0.144480\n",
      "[40,    99] loss: 0.188133\n",
      "[40,   199] loss: 0.129929\n",
      "[40,   299] loss: 0.213102\n",
      "[41,    99] loss: 0.165098\n",
      "[41,   199] loss: 0.121242\n",
      "[41,   299] loss: 0.086468\n",
      "[42,    99] loss: 0.076919\n",
      "[42,   199] loss: 0.130722\n",
      "[42,   299] loss: 0.038400\n",
      "[43,    99] loss: 0.040204\n",
      "[43,   199] loss: 0.109492\n",
      "[43,   299] loss: 0.120586\n",
      "[44,    99] loss: 0.039487\n",
      "[44,   199] loss: 0.046913\n",
      "[44,   299] loss: 0.029687\n",
      "[45,    99] loss: 0.055819\n",
      "[45,   199] loss: 0.055226\n",
      "[45,   299] loss: 0.021522\n",
      "[46,    99] loss: 0.046411\n",
      "[46,   199] loss: 0.039980\n",
      "[46,   299] loss: 0.645835\n",
      "[47,    99] loss: 0.202641\n",
      "[47,   199] loss: 0.294922\n",
      "[47,   299] loss: 0.165469\n",
      "[48,    99] loss: 0.072770\n",
      "[48,   199] loss: 0.068869\n",
      "[48,   299] loss: 0.122677\n",
      "[49,    99] loss: 0.042316\n",
      "[49,   199] loss: 0.068259\n",
      "[49,   299] loss: 0.071834\n",
      "[50,    99] loss: 0.025709\n",
      "[50,   199] loss: 0.038932\n",
      "[50,   299] loss: 0.027496\n",
      "[51,    99] loss: 0.086140\n",
      "[51,   199] loss: 0.082673\n",
      "[51,   299] loss: 0.091305\n",
      "[52,    99] loss: 0.235917\n",
      "[52,   199] loss: 0.129223\n",
      "[52,   299] loss: 0.073170\n",
      "[53,    99] loss: 0.039997\n",
      "[53,   199] loss: 0.054276\n",
      "[53,   299] loss: 0.120908\n",
      "[54,    99] loss: 0.079481\n",
      "[54,   199] loss: 0.033888\n",
      "[54,   299] loss: 0.037206\n",
      "[55,    99] loss: 0.041008\n",
      "[55,   199] loss: 0.028746\n",
      "[55,   299] loss: 0.069325\n",
      "[56,    99] loss: 0.146514\n",
      "[56,   199] loss: 0.111182\n",
      "[56,   299] loss: 0.079357\n",
      "[57,    99] loss: 0.074393\n",
      "[57,   199] loss: 0.139657\n",
      "[57,   299] loss: 0.034684\n",
      "[58,    99] loss: 0.061078\n",
      "[58,   199] loss: 0.110628\n",
      "[58,   299] loss: 0.047589\n",
      "[59,    99] loss: 0.085797\n",
      "[59,   199] loss: 0.090704\n",
      "[59,   299] loss: 0.074096\n",
      "[60,    99] loss: 0.071604\n",
      "[60,   199] loss: 0.098429\n",
      "[60,   299] loss: 0.069276\n",
      "[61,    99] loss: 0.048026\n",
      "[61,   199] loss: 0.014327\n",
      "[61,   299] loss: 0.010660\n",
      "[62,    99] loss: 0.020738\n",
      "[62,   199] loss: 0.044250\n",
      "[62,   299] loss: 0.191587\n",
      "[63,    99] loss: 0.198337\n",
      "[63,   199] loss: 0.047076\n",
      "[63,   299] loss: 0.046898\n",
      "[64,    99] loss: 0.064370\n",
      "[64,   199] loss: 0.124509\n",
      "[64,   299] loss: 0.026107\n",
      "[65,    99] loss: 0.028239\n",
      "[65,   199] loss: 0.012248\n",
      "[65,   299] loss: 0.051161\n",
      "[66,    99] loss: 0.067086\n",
      "[66,   199] loss: 0.060674\n",
      "[66,   299] loss: 0.128101\n",
      "[67,    99] loss: 0.761241\n",
      "[67,   199] loss: 0.150903\n",
      "[67,   299] loss: 0.105005\n",
      "[68,    99] loss: 0.025810\n",
      "[68,   199] loss: 0.085804\n",
      "[68,   299] loss: 0.430560\n",
      "[69,    99] loss: 0.215580\n",
      "[69,   199] loss: 0.072275\n",
      "[69,   299] loss: 0.070363\n",
      "[70,    99] loss: 0.026457\n",
      "[70,   199] loss: 0.039921\n",
      "[70,   299] loss: 0.011517\n",
      "[71,    99] loss: 0.024794\n",
      "[71,   199] loss: 0.066832\n",
      "[71,   299] loss: 0.077414\n",
      "[72,    99] loss: 0.117498\n",
      "[72,   199] loss: 0.052366\n",
      "[72,   299] loss: 0.036150\n",
      "[73,    99] loss: 0.021685\n",
      "[73,   199] loss: 0.025259\n",
      "[73,   299] loss: 0.021455\n",
      "[74,    99] loss: 0.185125\n",
      "[74,   199] loss: 0.075699\n",
      "[74,   299] loss: 0.088845\n",
      "[75,    99] loss: 0.121966\n",
      "[75,   199] loss: 0.062608\n",
      "[75,   299] loss: 0.051360\n",
      "[76,    99] loss: 0.109310\n",
      "[76,   199] loss: 0.072087\n",
      "[76,   299] loss: 0.033004\n",
      "[77,    99] loss: 0.108598\n",
      "[77,   199] loss: 0.010041\n",
      "[77,   299] loss: 0.031946\n",
      "[78,    99] loss: 0.025776\n",
      "[78,   199] loss: 0.010713\n",
      "[78,   299] loss: 0.006617\n",
      "[79,    99] loss: 0.007951\n",
      "[79,   199] loss: 0.016439\n",
      "[79,   299] loss: 0.219172\n",
      "[80,    99] loss: 0.270980\n",
      "[80,   199] loss: 0.090553\n",
      "[80,   299] loss: 0.091094\n",
      "[81,    99] loss: 0.055394\n",
      "[81,   199] loss: 0.095613\n",
      "[81,   299] loss: 0.044609\n",
      "[82,    99] loss: 0.035910\n",
      "[82,   199] loss: 0.014313\n",
      "[82,   299] loss: 0.214776\n",
      "[83,    99] loss: 0.098758\n",
      "[83,   199] loss: 0.127275\n",
      "[83,   299] loss: 0.221958\n",
      "[84,    99] loss: 0.072481\n",
      "[84,   199] loss: 0.052931\n",
      "[84,   299] loss: 0.022194\n",
      "[85,    99] loss: 0.030126\n",
      "[85,   199] loss: 0.026456\n",
      "[85,   299] loss: 0.032227\n",
      "[86,    99] loss: 0.031671\n",
      "[86,   199] loss: 0.057388\n",
      "[86,   299] loss: 0.267340\n",
      "[87,    99] loss: 0.078335\n",
      "[87,   199] loss: 0.039272\n",
      "[87,   299] loss: 0.047278\n",
      "[88,    99] loss: 0.095929\n",
      "[88,   199] loss: 0.012648\n",
      "[88,   299] loss: 0.011287\n",
      "[89,    99] loss: 0.018227\n",
      "[89,   199] loss: 0.006019\n",
      "[89,   299] loss: 0.003876\n",
      "[90,    99] loss: 0.006533\n",
      "[90,   199] loss: 0.009195\n",
      "[90,   299] loss: 0.003783\n",
      "[91,    99] loss: 0.002753\n",
      "[91,   199] loss: 0.039028\n",
      "[91,   299] loss: 0.065314\n",
      "[92,    99] loss: 0.344183\n",
      "[92,   199] loss: 0.135824\n",
      "[92,   299] loss: 0.145712\n",
      "[93,    99] loss: 0.030488\n",
      "[93,   199] loss: 0.011265\n",
      "[93,   299] loss: 0.098719\n",
      "[94,    99] loss: 0.029616\n",
      "[94,   199] loss: 0.003444\n",
      "[94,   299] loss: 0.043116\n",
      "[95,    99] loss: 0.073204\n",
      "[95,   199] loss: 0.025069\n",
      "[95,   299] loss: 0.048009\n",
      "[96,    99] loss: 0.085419\n",
      "[96,   199] loss: 0.025157\n",
      "[96,   299] loss: 0.030024\n",
      "[97,    99] loss: 0.011004\n",
      "[97,   199] loss: 0.121265\n",
      "[97,   299] loss: 0.072741\n",
      "[98,    99] loss: 0.382435\n",
      "[98,   199] loss: 0.073790\n",
      "[98,   299] loss: 0.079723\n",
      "[99,    99] loss: 0.094022\n",
      "[99,   199] loss: 0.030035\n",
      "[99,   299] loss: 0.040839\n",
      "[100,    99] loss: 0.013006\n",
      "[100,   199] loss: 0.015927\n",
      "[100,   299] loss: 0.012991\n",
      "Finished Training\n",
      "[1,    99] loss: 0.737699\n",
      "[1,   199] loss: 0.680734\n",
      "[1,   299] loss: 0.668391\n",
      "[2,    99] loss: 0.645923\n",
      "[2,   199] loss: 0.600282\n",
      "[2,   299] loss: 0.640125\n",
      "[3,    99] loss: 0.548059\n",
      "[3,   199] loss: 0.636057\n",
      "[3,   299] loss: 0.592665\n",
      "[4,    99] loss: 0.427642\n",
      "[4,   199] loss: 0.507888\n",
      "[4,   299] loss: 0.537792\n",
      "[5,    99] loss: 0.349178\n",
      "[5,   199] loss: 0.532945\n",
      "[5,   299] loss: 0.427302\n",
      "[6,    99] loss: 0.338221\n",
      "[6,   199] loss: 0.415144\n",
      "[6,   299] loss: 0.351983\n",
      "[7,    99] loss: 0.287122\n",
      "[7,   199] loss: 0.378892\n",
      "[7,   299] loss: 0.331091\n",
      "[8,    99] loss: 0.249047\n",
      "[8,   199] loss: 0.343999\n",
      "[8,   299] loss: 0.297049\n",
      "[9,    99] loss: 0.286509\n",
      "[9,   199] loss: 0.346338\n",
      "[9,   299] loss: 0.340385\n",
      "[10,    99] loss: 0.152416\n",
      "[10,   199] loss: 0.356991\n",
      "[10,   299] loss: 0.370670\n",
      "[11,    99] loss: 0.193667\n",
      "[11,   199] loss: 0.306715\n",
      "[11,   299] loss: 0.263146\n",
      "[12,    99] loss: 0.207640\n",
      "[12,   199] loss: 0.290337\n",
      "[12,   299] loss: 0.295751\n",
      "[13,    99] loss: 0.183383\n",
      "[13,   199] loss: 0.302797\n",
      "[13,   299] loss: 0.296060\n",
      "[14,    99] loss: 0.128035\n",
      "[14,   199] loss: 0.228780\n",
      "[14,   299] loss: 0.398650\n",
      "[15,    99] loss: 0.147647\n",
      "[15,   199] loss: 0.283771\n",
      "[15,   299] loss: 0.244105\n",
      "[16,    99] loss: 0.243078\n",
      "[16,   199] loss: 0.234477\n",
      "[16,   299] loss: 0.216449\n",
      "[17,    99] loss: 0.142175\n",
      "[17,   199] loss: 0.197591\n",
      "[17,   299] loss: 0.418268\n",
      "[18,    99] loss: 0.126765\n",
      "[18,   199] loss: 0.206607\n",
      "[18,   299] loss: 0.227720\n",
      "[19,    99] loss: 0.156691\n",
      "[19,   199] loss: 0.237282\n",
      "[19,   299] loss: 0.160182\n",
      "[20,    99] loss: 0.204332\n",
      "[20,   199] loss: 0.231784\n",
      "[20,   299] loss: 0.193626\n",
      "[21,    99] loss: 0.157772\n",
      "[21,   199] loss: 0.212378\n",
      "[21,   299] loss: 0.202805\n",
      "[22,    99] loss: 0.164939\n",
      "[22,   199] loss: 0.218520\n",
      "[22,   299] loss: 0.218276\n",
      "[23,    99] loss: 0.129154\n",
      "[23,   199] loss: 0.174539\n",
      "[23,   299] loss: 0.173101\n",
      "[24,    99] loss: 0.183171\n",
      "[24,   199] loss: 0.218494\n",
      "[24,   299] loss: 0.193616\n",
      "[25,    99] loss: 0.168648\n",
      "[25,   199] loss: 0.161744\n",
      "[25,   299] loss: 0.166321\n",
      "[26,    99] loss: 0.171731\n",
      "[26,   199] loss: 0.190770\n",
      "[26,   299] loss: 0.098689\n",
      "[27,    99] loss: 0.113627\n",
      "[27,   199] loss: 0.115239\n",
      "[27,   299] loss: 0.133317\n",
      "[28,    99] loss: 0.246917\n",
      "[28,   199] loss: 0.150016\n",
      "[28,   299] loss: 0.158213\n",
      "[29,    99] loss: 0.124463\n",
      "[29,   199] loss: 0.161132\n",
      "[29,   299] loss: 0.161409\n",
      "[30,    99] loss: 0.167687\n",
      "[30,   199] loss: 0.135644\n",
      "[30,   299] loss: 0.158177\n",
      "[31,    99] loss: 0.264944\n",
      "[31,   199] loss: 0.179177\n",
      "[31,   299] loss: 0.101840\n",
      "[32,    99] loss: 0.096559\n",
      "[32,   199] loss: 0.218868\n",
      "[32,   299] loss: 0.128615\n",
      "[33,    99] loss: 0.098250\n",
      "[33,   199] loss: 0.158248\n",
      "[33,   299] loss: 0.077740\n",
      "[34,    99] loss: 0.291767\n",
      "[34,   199] loss: 0.118247\n",
      "[34,   299] loss: 0.108806\n",
      "[35,    99] loss: 0.092235\n",
      "[35,   199] loss: 0.131654\n",
      "[35,   299] loss: 0.073595\n",
      "[36,    99] loss: 0.099289\n",
      "[36,   199] loss: 0.176018\n",
      "[36,   299] loss: 0.088405\n",
      "[37,    99] loss: 0.190379\n",
      "[37,   199] loss: 0.157241\n",
      "[37,   299] loss: 0.082926\n",
      "[38,    99] loss: 0.073042\n",
      "[38,   199] loss: 0.117249\n",
      "[38,   299] loss: 0.159024\n",
      "[39,    99] loss: 0.148242\n",
      "[39,   199] loss: 0.172695\n",
      "[39,   299] loss: 0.112105\n",
      "[40,    99] loss: 0.128198\n",
      "[40,   199] loss: 0.117548\n",
      "[40,   299] loss: 0.119092\n",
      "[41,    99] loss: 0.096220\n",
      "[41,   199] loss: 0.119014\n",
      "[41,   299] loss: 0.372530\n",
      "[42,    99] loss: 0.136426\n",
      "[42,   199] loss: 0.136330\n",
      "[42,   299] loss: 0.088779\n",
      "[43,    99] loss: 0.378412\n",
      "[43,   199] loss: 0.122388\n",
      "[43,   299] loss: 0.073966\n",
      "[44,    99] loss: 0.061331\n",
      "[44,   199] loss: 0.136375\n",
      "[44,   299] loss: 0.070861\n",
      "[45,    99] loss: 0.049207\n",
      "[45,   199] loss: 0.084285\n",
      "[45,   299] loss: 0.103153\n",
      "[46,    99] loss: 0.098939\n",
      "[46,   199] loss: 0.114259\n",
      "[46,   299] loss: 0.041929\n",
      "[47,    99] loss: 0.113541\n",
      "[47,   199] loss: 0.154143\n",
      "[47,   299] loss: 0.185860\n",
      "[48,    99] loss: 0.081856\n",
      "[48,   199] loss: 0.099130\n",
      "[48,   299] loss: 0.098438\n",
      "[49,    99] loss: 0.134851\n",
      "[49,   199] loss: 0.131908\n",
      "[49,   299] loss: 0.218594\n",
      "[50,    99] loss: 0.186373\n",
      "[50,   199] loss: 0.203843\n",
      "[50,   299] loss: 0.136397\n",
      "[51,    99] loss: 0.122109\n",
      "[51,   199] loss: 0.166918\n",
      "[51,   299] loss: 0.261664\n",
      "[52,    99] loss: 0.104075\n",
      "[52,   199] loss: 0.083971\n",
      "[52,   299] loss: 0.092128\n",
      "[53,    99] loss: 0.051675\n",
      "[53,   199] loss: 0.054903\n",
      "[53,   299] loss: 0.159760\n",
      "[54,    99] loss: 0.067225\n",
      "[54,   199] loss: 0.060781\n",
      "[54,   299] loss: 0.058187\n",
      "[55,    99] loss: 0.029015\n",
      "[55,   199] loss: 0.074902\n",
      "[55,   299] loss: 0.076404\n",
      "[56,    99] loss: 0.330619\n",
      "[56,   199] loss: 0.118664\n",
      "[56,   299] loss: 0.200552\n",
      "[57,    99] loss: 0.072044\n",
      "[57,   199] loss: 0.084758\n",
      "[57,   299] loss: 0.156180\n",
      "[58,    99] loss: 0.114406\n",
      "[58,   199] loss: 0.088171\n",
      "[58,   299] loss: 0.289942\n",
      "[59,    99] loss: 0.077022\n",
      "[59,   199] loss: 0.072856\n",
      "[59,   299] loss: 0.130544\n",
      "[60,    99] loss: 0.056604\n",
      "[60,   199] loss: 0.133498\n",
      "[60,   299] loss: 0.199070\n",
      "[61,    99] loss: 0.094739\n",
      "[61,   199] loss: 0.070652\n",
      "[61,   299] loss: 0.071218\n",
      "[62,    99] loss: 0.091045\n",
      "[62,   199] loss: 0.089444\n",
      "[62,   299] loss: 0.042349\n",
      "[63,    99] loss: 0.046434\n",
      "[63,   199] loss: 0.029963\n",
      "[63,   299] loss: 0.027566\n",
      "[64,    99] loss: 0.298936\n",
      "[64,   199] loss: 0.038502\n",
      "[64,   299] loss: 0.052041\n",
      "[65,    99] loss: 0.053049\n",
      "[65,   199] loss: 0.100599\n",
      "[65,   299] loss: 0.123247\n",
      "[66,    99] loss: 0.041698\n",
      "[66,   199] loss: 0.070031\n",
      "[66,   299] loss: 0.106468\n",
      "[67,    99] loss: 0.107264\n",
      "[67,   199] loss: 0.136167\n",
      "[67,   299] loss: 0.047801\n",
      "[68,    99] loss: 0.223309\n",
      "[68,   199] loss: 0.159069\n",
      "[68,   299] loss: 0.075932\n",
      "[69,    99] loss: 0.126285\n",
      "[69,   199] loss: 0.046798\n",
      "[69,   299] loss: 0.025743\n",
      "[70,    99] loss: 0.017742\n",
      "[70,   199] loss: 0.026518\n",
      "[70,   299] loss: 0.283075\n",
      "[71,    99] loss: 0.141336\n",
      "[71,   199] loss: 0.150072\n",
      "[71,   299] loss: 0.146487\n",
      "[72,    99] loss: 0.042383\n",
      "[72,   199] loss: 0.044249\n",
      "[72,   299] loss: 0.013756\n",
      "[73,    99] loss: 0.062653\n",
      "[73,   199] loss: 0.048306\n",
      "[73,   299] loss: 0.089486\n",
      "[74,    99] loss: 0.036402\n",
      "[74,   199] loss: 0.025498\n",
      "[74,   299] loss: 0.082404\n",
      "[75,    99] loss: 0.035425\n",
      "[75,   199] loss: 0.053941\n",
      "[75,   299] loss: 0.061570\n",
      "[76,    99] loss: 0.007532\n",
      "[76,   199] loss: 0.046642\n",
      "[76,   299] loss: 0.012131\n",
      "[77,    99] loss: 0.218883\n",
      "[77,   199] loss: 0.084205\n",
      "[77,   299] loss: 0.138726\n",
      "[78,    99] loss: 0.071079\n",
      "[78,   199] loss: 0.112087\n",
      "[78,   299] loss: 0.077952\n",
      "[79,    99] loss: 0.012740\n",
      "[79,   199] loss: 0.062816\n",
      "[79,   299] loss: 0.234452\n",
      "[80,    99] loss: 0.106947\n",
      "[80,   199] loss: 0.043111\n",
      "[80,   299] loss: 0.106244\n",
      "[81,    99] loss: 0.013778\n",
      "[81,   199] loss: 0.032294\n",
      "[81,   299] loss: 0.088312\n",
      "[82,    99] loss: 0.042993\n",
      "[82,   199] loss: 0.063681\n",
      "[82,   299] loss: 0.028953\n",
      "[83,    99] loss: 0.086921\n",
      "[83,   199] loss: 0.022805\n",
      "[83,   299] loss: 0.070774\n",
      "[84,    99] loss: 0.037081\n",
      "[84,   199] loss: 0.118259\n",
      "[84,   299] loss: 0.158855\n",
      "[85,    99] loss: 0.081833\n",
      "[85,   199] loss: 0.093643\n",
      "[85,   299] loss: 0.112025\n",
      "[86,    99] loss: 0.027650\n",
      "[86,   199] loss: 0.137568\n",
      "[86,   299] loss: 0.125308\n",
      "[87,    99] loss: 0.077911\n",
      "[87,   199] loss: 0.280422\n",
      "[87,   299] loss: 0.157466\n",
      "[88,    99] loss: 0.171755\n",
      "[88,   199] loss: 0.069619\n",
      "[88,   299] loss: 0.046620\n",
      "[89,    99] loss: 0.098602\n",
      "[89,   199] loss: 0.040743\n",
      "[89,   299] loss: 0.017649\n",
      "[90,    99] loss: 0.020025\n",
      "[90,   199] loss: 0.025140\n",
      "[90,   299] loss: 0.010217\n",
      "[91,    99] loss: 0.269170\n",
      "[91,   199] loss: 0.105101\n",
      "[91,   299] loss: 0.115197\n",
      "[92,    99] loss: 0.069753\n",
      "[92,   199] loss: 0.033410\n",
      "[92,   299] loss: 0.039532\n",
      "[93,    99] loss: 0.019301\n",
      "[93,   199] loss: 0.028034\n",
      "[93,   299] loss: 0.009727\n",
      "[94,    99] loss: 0.054847\n",
      "[94,   199] loss: 0.025294\n",
      "[94,   299] loss: 0.031833\n",
      "[95,    99] loss: 0.076205\n",
      "[95,   199] loss: 0.044917\n",
      "[95,   299] loss: 0.159649\n",
      "[96,    99] loss: 0.070649\n",
      "[96,   199] loss: 0.049827\n",
      "[96,   299] loss: 0.037893\n",
      "[97,    99] loss: 0.018944\n",
      "[97,   199] loss: 0.043699\n",
      "[97,   299] loss: 0.213105\n",
      "[98,    99] loss: 0.036537\n",
      "[98,   199] loss: 0.078310\n",
      "[98,   299] loss: 0.030857\n",
      "[99,    99] loss: 0.007718\n",
      "[99,   199] loss: 0.032429\n",
      "[99,   299] loss: 0.004668\n",
      "[100,    99] loss: 0.005465\n",
      "[100,   199] loss: 0.038670\n",
      "[100,   299] loss: 0.099862\n",
      "Finished Training\n",
      "[1,    99] loss: 0.695709\n",
      "[1,   199] loss: 0.648047\n",
      "[1,   299] loss: 0.712625\n",
      "[2,    99] loss: 0.629705\n",
      "[2,   199] loss: 0.595966\n",
      "[2,   299] loss: 0.691997\n",
      "[3,    99] loss: 0.582530\n",
      "[3,   199] loss: 0.614163\n",
      "[3,   299] loss: 0.587102\n",
      "[4,    99] loss: 0.587453\n",
      "[4,   199] loss: 0.592943\n",
      "[4,   299] loss: 0.581239\n",
      "[5,    99] loss: 0.546203\n",
      "[5,   199] loss: 0.530619\n",
      "[5,   299] loss: 0.541434\n",
      "[6,    99] loss: 0.645385\n",
      "[6,   199] loss: 0.496554\n",
      "[6,   299] loss: 0.535751\n",
      "[7,    99] loss: 0.507962\n",
      "[7,   199] loss: 0.463020\n",
      "[7,   299] loss: 0.542621\n",
      "[8,    99] loss: 0.430240\n",
      "[8,   199] loss: 0.437166\n",
      "[8,   299] loss: 0.475508\n",
      "[9,    99] loss: 0.434242\n",
      "[9,   199] loss: 0.357449\n",
      "[9,   299] loss: 0.423475\n",
      "[10,    99] loss: 0.368918\n",
      "[10,   199] loss: 0.382963\n",
      "[10,   299] loss: 0.479418\n",
      "[11,    99] loss: 0.360987\n",
      "[11,   199] loss: 0.398994\n",
      "[11,   299] loss: 0.480151\n",
      "[12,    99] loss: 0.326601\n",
      "[12,   199] loss: 0.323988\n",
      "[12,   299] loss: 0.381588\n",
      "[13,    99] loss: 0.313441\n",
      "[13,   199] loss: 0.278824\n",
      "[13,   299] loss: 0.373308\n",
      "[14,    99] loss: 0.296356\n",
      "[14,   199] loss: 0.373218\n",
      "[14,   299] loss: 0.410476\n",
      "[15,    99] loss: 0.276099\n",
      "[15,   199] loss: 0.237784\n",
      "[15,   299] loss: 0.441527\n",
      "[16,    99] loss: 0.222887\n",
      "[16,   199] loss: 0.181109\n",
      "[16,   299] loss: 0.338557\n",
      "[17,    99] loss: 0.230341\n",
      "[17,   199] loss: 0.259056\n",
      "[17,   299] loss: 0.275808\n",
      "[18,    99] loss: 0.189829\n",
      "[18,   199] loss: 0.120765\n",
      "[18,   299] loss: 0.184918\n",
      "[19,    99] loss: 0.226557\n",
      "[19,   199] loss: 0.198573\n",
      "[19,   299] loss: 0.254699\n",
      "[20,    99] loss: 0.194897\n",
      "[20,   199] loss: 0.381045\n",
      "[20,   299] loss: 0.265763\n",
      "[21,    99] loss: 0.171524\n",
      "[21,   199] loss: 0.133209\n",
      "[21,   299] loss: 0.320071\n",
      "[22,    99] loss: 0.140544\n",
      "[22,   199] loss: 0.102515\n",
      "[22,   299] loss: 0.162910\n",
      "[23,    99] loss: 0.115672\n",
      "[23,   199] loss: 0.247370\n",
      "[23,   299] loss: 0.177955\n",
      "[24,    99] loss: 0.092856\n",
      "[24,   199] loss: 0.157124\n",
      "[24,   299] loss: 0.340731\n",
      "[25,    99] loss: 0.178498\n",
      "[25,   199] loss: 0.237321\n",
      "[25,   299] loss: 0.230275\n",
      "[26,    99] loss: 0.255875\n",
      "[26,   199] loss: 0.182405\n",
      "[26,   299] loss: 0.217185\n",
      "[27,    99] loss: 0.089375\n",
      "[27,   199] loss: 0.148848\n",
      "[27,   299] loss: 0.541598\n",
      "[28,    99] loss: 0.089985\n",
      "[28,   199] loss: 0.069363\n",
      "[28,   299] loss: 0.132954\n",
      "[29,    99] loss: 0.063169\n",
      "[29,   199] loss: 0.053789\n",
      "[29,   299] loss: 0.144754\n",
      "[30,    99] loss: 0.097805\n",
      "[30,   199] loss: 0.168001\n",
      "[30,   299] loss: 0.225994\n",
      "[31,    99] loss: 0.180781\n",
      "[31,   199] loss: 0.094756\n",
      "[31,   299] loss: 0.308219\n",
      "[32,    99] loss: 0.106686\n",
      "[32,   199] loss: 0.141771\n",
      "[32,   299] loss: 0.128333\n",
      "[33,    99] loss: 0.035332\n",
      "[33,   199] loss: 0.090556\n",
      "[33,   299] loss: 0.146274\n",
      "[34,    99] loss: 0.122065\n",
      "[34,   199] loss: 0.228824\n",
      "[34,   299] loss: 0.262498\n",
      "[35,    99] loss: 0.196586\n",
      "[35,   199] loss: 0.062173\n",
      "[35,   299] loss: 0.160636\n",
      "[36,    99] loss: 0.056728\n",
      "[36,   199] loss: 0.069255\n",
      "[36,   299] loss: 0.155456\n",
      "[37,    99] loss: 0.078351\n",
      "[37,   199] loss: 0.037606\n",
      "[37,   299] loss: 0.100845\n",
      "[38,    99] loss: 0.082107\n",
      "[38,   199] loss: 0.103166\n",
      "[38,   299] loss: 0.254067\n",
      "[39,    99] loss: 0.173258\n",
      "[39,   199] loss: 0.259842\n",
      "[39,   299] loss: 0.304293\n",
      "[40,    99] loss: 0.077709\n",
      "[40,   199] loss: 0.044284\n",
      "[40,   299] loss: 0.064544\n",
      "[41,    99] loss: 0.043143\n",
      "[41,   199] loss: 0.160791\n",
      "[41,   299] loss: 0.187158\n",
      "[42,    99] loss: 0.070198\n",
      "[42,   199] loss: 0.138973\n",
      "[42,   299] loss: 0.165972\n",
      "[43,    99] loss: 0.037022\n",
      "[43,   199] loss: 0.043343\n",
      "[43,   299] loss: 0.069119\n",
      "[44,    99] loss: 0.052252\n",
      "[44,   199] loss: 0.028685\n",
      "[44,   299] loss: 0.078546\n",
      "[45,    99] loss: 0.020080\n",
      "[45,   199] loss: 0.033938\n",
      "[45,   299] loss: 0.077274\n",
      "[46,    99] loss: 0.103967\n",
      "[46,   199] loss: 0.057512\n",
      "[46,   299] loss: 0.091915\n",
      "[47,    99] loss: 0.068547\n",
      "[47,   199] loss: 0.034368\n",
      "[47,   299] loss: 0.035892\n",
      "[48,    99] loss: 0.118001\n",
      "[48,   199] loss: 0.149481\n",
      "[48,   299] loss: 0.168422\n",
      "[49,    99] loss: 0.075200\n",
      "[49,   199] loss: 0.100125\n",
      "[49,   299] loss: 0.094920\n",
      "[50,    99] loss: 0.053226\n",
      "[50,   199] loss: 0.134960\n",
      "[50,   299] loss: 0.341491\n",
      "[51,    99] loss: 0.214642\n",
      "[51,   199] loss: 0.231452\n",
      "[51,   299] loss: 0.069696\n",
      "[52,    99] loss: 0.044530\n",
      "[52,   199] loss: 0.049269\n",
      "[52,   299] loss: 0.056809\n",
      "[53,    99] loss: 0.027299\n",
      "[53,   199] loss: 0.044398\n",
      "[53,   299] loss: 0.096704\n",
      "[54,    99] loss: 0.125454\n",
      "[54,   199] loss: 0.197085\n",
      "[54,   299] loss: 0.185509\n",
      "[55,    99] loss: 0.075312\n",
      "[55,   199] loss: 0.129962\n",
      "[55,   299] loss: 0.235202\n",
      "[56,    99] loss: 0.177558\n",
      "[56,   199] loss: 0.220972\n",
      "[56,   299] loss: 0.108605\n",
      "[57,    99] loss: 0.165450\n",
      "[57,   199] loss: 0.103276\n",
      "[57,   299] loss: 0.094293\n",
      "[58,    99] loss: 0.058724\n",
      "[58,   199] loss: 0.030160\n",
      "[58,   299] loss: 0.052065\n",
      "[59,    99] loss: 0.014539\n",
      "[59,   199] loss: 0.097640\n",
      "[59,   299] loss: 0.120023\n",
      "[60,    99] loss: 0.151485\n",
      "[60,   199] loss: 0.088264\n",
      "[60,   299] loss: 0.086084\n",
      "[61,    99] loss: 0.029378\n",
      "[61,   199] loss: 0.056976\n",
      "[61,   299] loss: 0.047876\n",
      "[62,    99] loss: 0.065275\n",
      "[62,   199] loss: 0.018547\n",
      "[62,   299] loss: 0.049221\n",
      "[63,    99] loss: 0.025384\n",
      "[63,   199] loss: 0.029311\n",
      "[63,   299] loss: 0.042305\n",
      "[64,    99] loss: 0.014229\n",
      "[64,   199] loss: 0.012364\n",
      "[64,   299] loss: 0.233615\n",
      "[65,    99] loss: 0.014074\n",
      "[65,   199] loss: 0.076814\n",
      "[65,   299] loss: 0.136525\n",
      "[66,    99] loss: 0.098106\n",
      "[66,   199] loss: 0.175460\n",
      "[66,   299] loss: 0.080662\n",
      "[67,    99] loss: 0.072421\n",
      "[67,   199] loss: 0.051223\n",
      "[67,   299] loss: 0.029501\n",
      "[68,    99] loss: 0.020819\n",
      "[68,   199] loss: 0.007808\n",
      "[68,   299] loss: 0.025409\n",
      "[69,    99] loss: 0.012346\n",
      "[69,   199] loss: 0.061468\n",
      "[69,   299] loss: 0.013629\n",
      "[70,    99] loss: 0.009619\n",
      "[70,   199] loss: 0.059903\n",
      "[70,   299] loss: 0.008629\n",
      "[71,    99] loss: 0.017602\n",
      "[71,   199] loss: 0.059925\n",
      "[71,   299] loss: 0.009147\n",
      "[72,    99] loss: 0.079267\n",
      "[72,   199] loss: 0.304900\n",
      "[72,   299] loss: 0.223342\n",
      "[73,    99] loss: 0.417232\n",
      "[73,   199] loss: 0.276858\n",
      "[73,   299] loss: 0.210237\n",
      "[74,    99] loss: 0.154634\n",
      "[74,   199] loss: 0.216615\n",
      "[74,   299] loss: 0.161455\n",
      "[75,    99] loss: 0.092987\n",
      "[75,   199] loss: 0.089961\n",
      "[75,   299] loss: 0.037995\n",
      "[76,    99] loss: 0.066946\n",
      "[76,   199] loss: 0.022450\n",
      "[76,   299] loss: 0.030292\n",
      "[77,    99] loss: 0.035649\n",
      "[77,   199] loss: 0.008812\n",
      "[77,   299] loss: 0.010361\n",
      "[78,    99] loss: 0.031054\n",
      "[78,   199] loss: 0.007927\n",
      "[78,   299] loss: 0.028557\n",
      "[79,    99] loss: 0.036234\n",
      "[79,   199] loss: 0.096444\n",
      "[79,   299] loss: 0.124188\n",
      "[80,    99] loss: 0.048626\n",
      "[80,   199] loss: 0.006824\n",
      "[80,   299] loss: 0.050224\n",
      "[81,    99] loss: 0.035148\n",
      "[81,   199] loss: 0.073095\n",
      "[81,   299] loss: 0.115576\n",
      "[82,    99] loss: 0.058592\n",
      "[82,   199] loss: 0.008784\n",
      "[82,   299] loss: 0.039900\n",
      "[83,    99] loss: 0.079077\n",
      "[83,   199] loss: 0.128535\n",
      "[83,   299] loss: 0.155115\n",
      "[84,    99] loss: 0.076400\n",
      "[84,   199] loss: 0.065455\n",
      "[84,   299] loss: 0.298520\n",
      "[85,    99] loss: 0.076747\n",
      "[85,   199] loss: 0.089154\n",
      "[85,   299] loss: 0.031776\n",
      "[86,    99] loss: 0.009573\n",
      "[86,   199] loss: 0.009797\n",
      "[86,   299] loss: 0.016741\n",
      "[87,    99] loss: 0.020339\n",
      "[87,   199] loss: 0.047826\n",
      "[87,   299] loss: 0.224126\n",
      "[88,    99] loss: 0.066310\n",
      "[88,   199] loss: 0.029758\n",
      "[88,   299] loss: 0.058834\n",
      "[89,    99] loss: 0.034850\n",
      "[89,   199] loss: 0.023195\n",
      "[89,   299] loss: 0.061025\n",
      "[90,    99] loss: 0.009597\n",
      "[90,   199] loss: 0.024888\n",
      "[90,   299] loss: 0.021470\n",
      "[91,    99] loss: 0.007007\n",
      "[91,   199] loss: 0.022968\n",
      "[91,   299] loss: 0.021287\n",
      "[92,    99] loss: 0.008152\n",
      "[92,   199] loss: 0.033826\n",
      "[92,   299] loss: 0.105161\n",
      "[93,    99] loss: 0.102307\n",
      "[93,   199] loss: 0.181673\n",
      "[93,   299] loss: 0.375072\n",
      "[94,    99] loss: 0.208886\n",
      "[94,   199] loss: 0.228673\n",
      "[94,   299] loss: 0.396822\n",
      "[95,    99] loss: 0.125318\n",
      "[95,   199] loss: 0.025842\n",
      "[95,   299] loss: 0.044948\n",
      "[96,    99] loss: 0.040623\n",
      "[96,   199] loss: 0.063116\n",
      "[96,   299] loss: 0.066636\n",
      "[97,    99] loss: 0.038816\n",
      "[97,   199] loss: 0.087972\n",
      "[97,   299] loss: 0.034027\n",
      "[98,    99] loss: 0.007948\n",
      "[98,   199] loss: 0.028013\n",
      "[98,   299] loss: 0.178490\n",
      "[99,    99] loss: 0.065826\n",
      "[99,   199] loss: 0.076196\n",
      "[99,   299] loss: 0.106657\n",
      "[100,    99] loss: 0.010331\n",
      "[100,   199] loss: 0.133994\n",
      "[100,   299] loss: 0.057372\n",
      "Finished Training\n",
      "[1,    99] loss: 0.721263\n",
      "[1,   199] loss: 0.665903\n",
      "[1,   299] loss: 0.661679\n",
      "[2,    99] loss: 0.620753\n",
      "[2,   199] loss: 0.627470\n",
      "[2,   299] loss: 0.577787\n",
      "[3,    99] loss: 0.638340\n",
      "[3,   199] loss: 0.556540\n",
      "[3,   299] loss: 0.541230\n",
      "[4,    99] loss: 0.636459\n",
      "[4,   199] loss: 0.550732\n",
      "[4,   299] loss: 0.484133\n",
      "[5,    99] loss: 0.411440\n",
      "[5,   199] loss: 0.441154\n",
      "[5,   299] loss: 0.412588\n",
      "[6,    99] loss: 0.367503\n",
      "[6,   199] loss: 0.397701\n",
      "[6,   299] loss: 0.342100\n",
      "[7,    99] loss: 0.339854\n",
      "[7,   199] loss: 0.385842\n",
      "[7,   299] loss: 0.342864\n",
      "[8,    99] loss: 0.281007\n",
      "[8,   199] loss: 0.311859\n",
      "[8,   299] loss: 0.341294\n",
      "[9,    99] loss: 0.452357\n",
      "[9,   199] loss: 0.324686\n",
      "[9,   299] loss: 0.287594\n",
      "[10,    99] loss: 0.244749\n",
      "[10,   199] loss: 0.308421\n",
      "[10,   299] loss: 0.352144\n",
      "[11,    99] loss: 0.551597\n",
      "[11,   199] loss: 0.323751\n",
      "[11,   299] loss: 0.268473\n",
      "[12,    99] loss: 0.233563\n",
      "[12,   199] loss: 0.301523\n",
      "[12,   299] loss: 0.280405\n",
      "[13,    99] loss: 0.227441\n",
      "[13,   199] loss: 0.292471\n",
      "[13,   299] loss: 0.235949\n",
      "[14,    99] loss: 0.203117\n",
      "[14,   199] loss: 0.235975\n",
      "[14,   299] loss: 0.190630\n",
      "[15,    99] loss: 0.196364\n",
      "[15,   199] loss: 0.513974\n",
      "[15,   299] loss: 0.229114\n",
      "[16,    99] loss: 0.209790\n",
      "[16,   199] loss: 0.254434\n",
      "[16,   299] loss: 0.221919\n",
      "[17,    99] loss: 0.182741\n",
      "[17,   199] loss: 0.314343\n",
      "[17,   299] loss: 0.260370\n",
      "[18,    99] loss: 0.445658\n",
      "[18,   199] loss: 0.251527\n",
      "[18,   299] loss: 0.191501\n",
      "[19,    99] loss: 0.203199\n",
      "[19,   199] loss: 0.200745\n",
      "[19,   299] loss: 0.146526\n",
      "[20,    99] loss: 0.157492\n",
      "[20,   199] loss: 0.188962\n",
      "[20,   299] loss: 0.203145\n",
      "[21,    99] loss: 0.260618\n",
      "[21,   199] loss: 0.326635\n",
      "[21,   299] loss: 0.309197\n",
      "[22,    99] loss: 0.149357\n",
      "[22,   199] loss: 0.185853\n",
      "[22,   299] loss: 0.195940\n",
      "[23,    99] loss: 0.260980\n",
      "[23,   199] loss: 0.428492\n",
      "[23,   299] loss: 0.183664\n",
      "[24,    99] loss: 0.151603\n",
      "[24,   199] loss: 0.237654\n",
      "[24,   299] loss: 0.214457\n",
      "[25,    99] loss: 0.123816\n",
      "[25,   199] loss: 0.174239\n",
      "[25,   299] loss: 0.169212\n",
      "[26,    99] loss: 0.135122\n",
      "[26,   199] loss: 0.169657\n",
      "[26,   299] loss: 0.178243\n",
      "[27,    99] loss: 0.108413\n",
      "[27,   199] loss: 0.418439\n",
      "[27,   299] loss: 0.312118\n",
      "[28,    99] loss: 0.139193\n",
      "[28,   199] loss: 0.132181\n",
      "[28,   299] loss: 0.118415\n",
      "[29,    99] loss: 0.166851\n",
      "[29,   199] loss: 0.234650\n",
      "[29,   299] loss: 0.156814\n",
      "[30,    99] loss: 0.352252\n",
      "[30,   199] loss: 0.144137\n",
      "[30,   299] loss: 0.104306\n",
      "[31,    99] loss: 0.116331\n",
      "[31,   199] loss: 0.094204\n",
      "[31,   299] loss: 0.076381\n",
      "[32,    99] loss: 0.219176\n",
      "[32,   199] loss: 0.141343\n",
      "[32,   299] loss: 0.257224\n",
      "[33,    99] loss: 0.119786\n",
      "[33,   199] loss: 0.108935\n",
      "[33,   299] loss: 0.118524\n",
      "[34,    99] loss: 0.126335\n",
      "[34,   199] loss: 0.125828\n",
      "[34,   299] loss: 0.042922\n",
      "[35,    99] loss: 0.341940\n",
      "[35,   199] loss: 0.275211\n",
      "[35,   299] loss: 0.118564\n",
      "[36,    99] loss: 0.112491\n",
      "[36,   199] loss: 0.267145\n",
      "[36,   299] loss: 0.130532\n",
      "[37,    99] loss: 0.214439\n",
      "[37,   199] loss: 0.147454\n",
      "[37,   299] loss: 0.048141\n",
      "[38,    99] loss: 0.111288\n",
      "[38,   199] loss: 0.099286\n",
      "[38,   299] loss: 0.059240\n",
      "[39,    99] loss: 0.095180\n",
      "[39,   199] loss: 0.162972\n",
      "[39,   299] loss: 0.213874\n",
      "[40,    99] loss: 0.134624\n",
      "[40,   199] loss: 0.138713\n",
      "[40,   299] loss: 0.094196\n",
      "[41,    99] loss: 0.440091\n",
      "[41,   199] loss: 0.258479\n",
      "[41,   299] loss: 0.144252\n",
      "[42,    99] loss: 0.102454\n",
      "[42,   199] loss: 0.113500\n",
      "[42,   299] loss: 0.044585\n",
      "[43,    99] loss: 0.144572\n",
      "[43,   199] loss: 0.107608\n",
      "[43,   299] loss: 0.096286\n",
      "[44,    99] loss: 0.085504\n",
      "[44,   199] loss: 0.156602\n",
      "[44,   299] loss: 0.150298\n",
      "[45,    99] loss: 0.049652\n",
      "[45,   199] loss: 0.263921\n",
      "[45,   299] loss: 0.051253\n",
      "[46,    99] loss: 0.102221\n",
      "[46,   199] loss: 0.231444\n",
      "[46,   299] loss: 0.156840\n",
      "[47,    99] loss: 0.351997\n",
      "[47,   199] loss: 0.192165\n",
      "[47,   299] loss: 0.057622\n",
      "[48,    99] loss: 0.038549\n",
      "[48,   199] loss: 0.133321\n",
      "[48,   299] loss: 0.156942\n",
      "[49,    99] loss: 0.075575\n",
      "[49,   199] loss: 0.043983\n",
      "[49,   299] loss: 0.019675\n",
      "[50,    99] loss: 0.034338\n",
      "[50,   199] loss: 0.094769\n",
      "[50,   299] loss: 0.043618\n",
      "[51,    99] loss: 0.027058\n",
      "[51,   199] loss: 0.039817\n",
      "[51,   299] loss: 0.057437\n",
      "[52,    99] loss: 0.098316\n",
      "[52,   199] loss: 0.063336\n",
      "[52,   299] loss: 0.031716\n",
      "[53,    99] loss: 0.041531\n",
      "[53,   199] loss: 0.280538\n",
      "[53,   299] loss: 0.307588\n",
      "[54,    99] loss: 0.052512\n",
      "[54,   199] loss: 0.056144\n",
      "[54,   299] loss: 0.052942\n",
      "[55,    99] loss: 0.020992\n",
      "[55,   199] loss: 0.058534\n",
      "[55,   299] loss: 0.059137\n",
      "[56,    99] loss: 0.475655\n",
      "[56,   199] loss: 0.102477\n",
      "[56,   299] loss: 0.035659\n",
      "[57,    99] loss: 0.049876\n",
      "[57,   199] loss: 0.042461\n",
      "[57,   299] loss: 0.020808\n",
      "[58,    99] loss: 0.040254\n",
      "[58,   199] loss: 0.094074\n",
      "[58,   299] loss: 0.065551\n",
      "[59,    99] loss: 0.021674\n",
      "[59,   199] loss: 0.071899\n",
      "[59,   299] loss: 0.196454\n",
      "[60,    99] loss: 0.141418\n",
      "[60,   199] loss: 0.186095\n",
      "[60,   299] loss: 0.102371\n",
      "[61,    99] loss: 0.152702\n",
      "[61,   199] loss: 0.105518\n",
      "[61,   299] loss: 0.081518\n",
      "[62,    99] loss: 0.133593\n",
      "[62,   199] loss: 0.106740\n",
      "[62,   299] loss: 0.035944\n",
      "[63,    99] loss: 0.132771\n",
      "[63,   199] loss: 0.158691\n",
      "[63,   299] loss: 0.053830\n",
      "[64,    99] loss: 0.082935\n",
      "[64,   199] loss: 0.098896\n",
      "[64,   299] loss: 0.030207\n",
      "[65,    99] loss: 0.013560\n",
      "[65,   199] loss: 0.023653\n",
      "[65,   299] loss: 0.014690\n",
      "[66,    99] loss: 0.018975\n",
      "[66,   199] loss: 0.074192\n",
      "[66,   299] loss: 0.066185\n",
      "[67,    99] loss: 0.028040\n",
      "[67,   199] loss: 0.059481\n",
      "[67,   299] loss: 0.010494\n",
      "[68,    99] loss: 0.003502\n",
      "[68,   199] loss: 0.023328\n",
      "[68,   299] loss: 0.007653\n",
      "[69,    99] loss: 0.168260\n",
      "[69,   199] loss: 0.180907\n",
      "[69,   299] loss: 0.088031\n",
      "[70,    99] loss: 0.103910\n",
      "[70,   199] loss: 0.107813\n",
      "[70,   299] loss: 0.155362\n",
      "[71,    99] loss: 0.239894\n",
      "[71,   199] loss: 0.195813\n",
      "[71,   299] loss: 0.135881\n",
      "[72,    99] loss: 0.048744\n",
      "[72,   199] loss: 0.066361\n",
      "[72,   299] loss: 0.044888\n",
      "[73,    99] loss: 0.094969\n",
      "[73,   199] loss: 0.144586\n",
      "[73,   299] loss: 0.117056\n",
      "[74,    99] loss: 0.081922\n",
      "[74,   199] loss: 0.077347\n",
      "[74,   299] loss: 0.059514\n",
      "[75,    99] loss: 0.075371\n",
      "[75,   199] loss: 0.073404\n",
      "[75,   299] loss: 0.072074\n",
      "[76,    99] loss: 0.400226\n",
      "[76,   199] loss: 0.243829\n",
      "[76,   299] loss: 0.228980\n",
      "[77,    99] loss: 0.335318\n",
      "[77,   199] loss: 0.293248\n",
      "[77,   299] loss: 0.113913\n",
      "[78,    99] loss: 0.059075\n",
      "[78,   199] loss: 0.027265\n",
      "[78,   299] loss: 0.016796\n",
      "[79,    99] loss: 0.008568\n",
      "[79,   199] loss: 0.012016\n",
      "[79,   299] loss: 0.005402\n",
      "[80,    99] loss: 0.030171\n",
      "[80,   199] loss: 0.053902\n",
      "[80,   299] loss: 0.041672\n",
      "[81,    99] loss: 0.041297\n",
      "[81,   199] loss: 0.071146\n",
      "[81,   299] loss: 0.017446\n",
      "[82,    99] loss: 0.006790\n",
      "[82,   199] loss: 0.019847\n",
      "[82,   299] loss: 0.015502\n",
      "[83,    99] loss: 0.005648\n",
      "[83,   199] loss: 0.019579\n",
      "[83,   299] loss: 0.073611\n",
      "[84,    99] loss: 0.050858\n",
      "[84,   199] loss: 0.116683\n",
      "[84,   299] loss: 0.149649\n",
      "[85,    99] loss: 0.151291\n",
      "[85,   199] loss: 0.516155\n",
      "[85,   299] loss: 0.239599\n",
      "[86,    99] loss: 0.078514\n",
      "[86,   199] loss: 0.145367\n",
      "[86,   299] loss: 0.038771\n",
      "[87,    99] loss: 0.015494\n",
      "[87,   199] loss: 0.053822\n",
      "[87,   299] loss: 0.008219\n",
      "[88,    99] loss: 0.004264\n",
      "[88,   199] loss: 0.018140\n",
      "[88,   299] loss: 0.012552\n",
      "[89,    99] loss: 0.008201\n",
      "[89,   199] loss: 0.107606\n",
      "[89,   299] loss: 0.033664\n",
      "[90,    99] loss: 0.004742\n",
      "[90,   199] loss: 0.018622\n",
      "[90,   299] loss: 0.005268\n",
      "[91,    99] loss: 0.002290\n",
      "[91,   199] loss: 0.016876\n",
      "[91,   299] loss: 0.003035\n",
      "[92,    99] loss: 0.001918\n",
      "[92,   199] loss: 0.016737\n",
      "[92,   299] loss: 0.002055\n",
      "[93,    99] loss: 0.001851\n",
      "[93,   199] loss: 0.016350\n",
      "[93,   299] loss: 0.001648\n",
      "[94,    99] loss: 0.001779\n",
      "[94,   199] loss: 0.016328\n",
      "[94,   299] loss: 0.001581\n",
      "[95,    99] loss: 0.001736\n",
      "[95,   199] loss: 0.016325\n",
      "[95,   299] loss: 0.001730\n",
      "[96,    99] loss: 0.001871\n",
      "[96,   199] loss: 0.016442\n",
      "[96,   299] loss: 0.015762\n",
      "[97,    99] loss: 0.002076\n",
      "[97,   199] loss: 0.015611\n",
      "[97,   299] loss: 0.015090\n",
      "[98,    99] loss: 0.002436\n",
      "[98,   199] loss: 0.015057\n",
      "[98,   299] loss: 0.014648\n",
      "[99,    99] loss: 0.002733\n",
      "[99,   199] loss: 0.014703\n",
      "[99,   299] loss: 0.014366\n",
      "[100,    99] loss: 0.002954\n",
      "[100,   199] loss: 0.014475\n",
      "[100,   299] loss: 0.014187\n",
      "Finished Training\n",
      "[1,    99] loss: 0.676622\n",
      "[1,   199] loss: 0.666442\n",
      "[1,   299] loss: 0.632548\n",
      "[2,    99] loss: 0.593890\n",
      "[2,   199] loss: 0.595225\n",
      "[2,   299] loss: 0.519364\n",
      "[3,    99] loss: 0.494159\n",
      "[3,   199] loss: 0.503505\n",
      "[3,   299] loss: 0.423053\n",
      "[4,    99] loss: 0.409584\n",
      "[4,   199] loss: 0.407604\n",
      "[4,   299] loss: 0.350731\n",
      "[5,    99] loss: 0.318913\n",
      "[5,   199] loss: 0.317051\n",
      "[5,   299] loss: 0.292099\n",
      "[6,    99] loss: 0.260820\n",
      "[6,   199] loss: 0.248150\n",
      "[6,   299] loss: 0.240684\n",
      "[7,    99] loss: 0.232010\n",
      "[7,   199] loss: 0.192420\n",
      "[7,   299] loss: 0.197380\n",
      "[8,    99] loss: 0.198131\n",
      "[8,   199] loss: 0.155301\n",
      "[8,   299] loss: 0.171917\n",
      "[9,    99] loss: 0.167720\n",
      "[9,   199] loss: 0.126531\n",
      "[9,   299] loss: 0.154075\n",
      "[10,    99] loss: 0.168161\n",
      "[10,   199] loss: 0.115393\n",
      "[10,   299] loss: 0.145986\n",
      "[11,    99] loss: 0.123119\n",
      "[11,   199] loss: 0.100421\n",
      "[11,   299] loss: 0.133850\n",
      "[12,    99] loss: 0.100186\n",
      "[12,   199] loss: 0.098175\n",
      "[12,   299] loss: 0.108724\n",
      "[13,    99] loss: 0.095559\n",
      "[13,   199] loss: 0.084967\n",
      "[13,   299] loss: 0.123906\n",
      "[14,    99] loss: 0.092205\n",
      "[14,   199] loss: 0.084925\n",
      "[14,   299] loss: 0.097574\n",
      "[15,    99] loss: 0.077665\n",
      "[15,   199] loss: 0.084628\n",
      "[15,   299] loss: 0.098607\n",
      "[16,    99] loss: 0.075914\n",
      "[16,   199] loss: 0.075214\n",
      "[16,   299] loss: 0.088592\n",
      "[17,    99] loss: 0.075085\n",
      "[17,   199] loss: 0.081116\n",
      "[17,   299] loss: 0.106979\n",
      "[18,    99] loss: 0.070138\n",
      "[18,   199] loss: 0.079795\n",
      "[18,   299] loss: 0.097151\n",
      "[19,    99] loss: 0.076912\n",
      "[19,   199] loss: 0.058871\n",
      "[19,   299] loss: 0.087026\n",
      "[20,    99] loss: 0.064682\n",
      "[20,   199] loss: 0.094566\n",
      "[20,   299] loss: 0.147645\n",
      "[21,    99] loss: 0.065810\n",
      "[21,   199] loss: 0.051483\n",
      "[21,   299] loss: 0.069436\n",
      "[22,    99] loss: 0.075991\n",
      "[22,   199] loss: 0.052283\n",
      "[22,   299] loss: 0.068264\n",
      "[23,    99] loss: 0.083035\n",
      "[23,   199] loss: 0.057991\n",
      "[23,   299] loss: 0.072788\n",
      "[24,    99] loss: 0.071344\n",
      "[24,   199] loss: 0.059101\n",
      "[24,   299] loss: 0.058687\n",
      "[25,    99] loss: 0.046500\n",
      "[25,   199] loss: 0.047086\n",
      "[25,   299] loss: 0.059640\n",
      "[26,    99] loss: 0.049350\n",
      "[26,   199] loss: 0.044566\n",
      "[26,   299] loss: 0.064320\n",
      "[27,    99] loss: 0.056462\n",
      "[27,   199] loss: 0.056078\n",
      "[27,   299] loss: 0.054627\n",
      "[28,    99] loss: 0.042517\n",
      "[28,   199] loss: 0.036740\n",
      "[28,   299] loss: 0.054551\n",
      "[29,    99] loss: 0.057547\n",
      "[29,   199] loss: 0.040116\n",
      "[29,   299] loss: 0.050556\n",
      "[30,    99] loss: 0.056754\n",
      "[30,   199] loss: 0.039935\n",
      "[30,   299] loss: 0.047903\n",
      "[31,    99] loss: 0.037409\n",
      "[31,   199] loss: 0.031339\n",
      "[31,   299] loss: 0.042021\n",
      "[32,    99] loss: 0.042462\n",
      "[32,   199] loss: 0.028326\n",
      "[32,   299] loss: 0.058087\n",
      "[33,    99] loss: 0.051860\n",
      "[33,   199] loss: 0.037164\n",
      "[33,   299] loss: 0.048341\n",
      "[34,    99] loss: 0.067478\n",
      "[34,   199] loss: 0.120112\n",
      "[34,   299] loss: 0.166266\n",
      "[35,    99] loss: 0.079112\n",
      "[35,   199] loss: 0.061182\n",
      "[35,   299] loss: 0.071553\n",
      "[36,    99] loss: 0.025947\n",
      "[36,   199] loss: 0.042435\n",
      "[36,   299] loss: 0.042405\n",
      "[37,    99] loss: 0.025579\n",
      "[37,   199] loss: 0.016119\n",
      "[37,   299] loss: 0.034856\n",
      "[38,    99] loss: 0.036167\n",
      "[38,   199] loss: 0.019778\n",
      "[38,   299] loss: 0.040000\n",
      "[39,    99] loss: 0.035678\n",
      "[39,   199] loss: 0.019395\n",
      "[39,   299] loss: 0.049381\n",
      "[40,    99] loss: 0.028581\n",
      "[40,   199] loss: 0.018829\n",
      "[40,   299] loss: 0.044818\n",
      "[41,    99] loss: 0.029842\n",
      "[41,   199] loss: 0.023814\n",
      "[41,   299] loss: 0.052393\n",
      "[42,    99] loss: 0.105631\n",
      "[42,   199] loss: 0.069121\n",
      "[42,   299] loss: 0.072763\n",
      "[43,    99] loss: 0.060146\n",
      "[43,   199] loss: 0.044764\n",
      "[43,   299] loss: 0.029511\n",
      "[44,    99] loss: 0.021269\n",
      "[44,   199] loss: 0.036318\n",
      "[44,   299] loss: 0.063418\n",
      "[45,    99] loss: 0.021684\n",
      "[45,   199] loss: 0.040109\n",
      "[45,   299] loss: 0.037483\n",
      "[46,    99] loss: 0.068572\n",
      "[46,   199] loss: 0.030043\n",
      "[46,   299] loss: 0.196061\n",
      "[47,    99] loss: 0.025163\n",
      "[47,   199] loss: 0.053674\n",
      "[47,   299] loss: 0.038605\n",
      "[48,    99] loss: 0.021075\n",
      "[48,   199] loss: 0.030324\n",
      "[48,   299] loss: 0.060040\n",
      "[49,    99] loss: 0.063648\n",
      "[49,   199] loss: 0.024219\n",
      "[49,   299] loss: 0.046538\n",
      "[50,    99] loss: 0.228361\n",
      "[50,   199] loss: 0.027162\n",
      "[50,   299] loss: 0.026314\n",
      "[51,    99] loss: 0.012436\n",
      "[51,   199] loss: 0.009691\n",
      "[51,   299] loss: 0.019245\n",
      "[52,    99] loss: 0.015347\n",
      "[52,   199] loss: 0.014644\n",
      "[52,   299] loss: 0.045286\n",
      "[53,    99] loss: 0.023325\n",
      "[53,   199] loss: 0.015453\n",
      "[53,   299] loss: 0.026480\n",
      "[54,    99] loss: 0.016414\n",
      "[54,   199] loss: 0.008144\n",
      "[54,   299] loss: 0.031605\n",
      "[55,    99] loss: 0.041812\n",
      "[55,   199] loss: 0.015391\n",
      "[55,   299] loss: 0.041557\n",
      "[56,    99] loss: 0.019958\n",
      "[56,   199] loss: 0.013148\n",
      "[56,   299] loss: 0.040366\n",
      "[57,    99] loss: 0.024344\n",
      "[57,   199] loss: 0.010140\n",
      "[57,   299] loss: 0.039463\n",
      "[58,    99] loss: 0.022706\n",
      "[58,   199] loss: 0.012809\n",
      "[58,   299] loss: 0.034078\n",
      "[59,    99] loss: 0.018808\n",
      "[59,   199] loss: 0.014379\n",
      "[59,   299] loss: 0.029394\n",
      "[60,    99] loss: 0.285770\n",
      "[60,   199] loss: 0.168851\n",
      "[60,   299] loss: 0.086422\n",
      "[61,    99] loss: 0.051982\n",
      "[61,   199] loss: 0.047487\n",
      "[61,   299] loss: 0.021393\n",
      "[62,    99] loss: 0.006186\n",
      "[62,   199] loss: 0.018980\n",
      "[62,   299] loss: 0.013299\n",
      "[63,    99] loss: 0.004706\n",
      "[63,   199] loss: 0.004790\n",
      "[63,   299] loss: 0.012367\n",
      "[64,    99] loss: 0.004021\n",
      "[64,   199] loss: 0.003738\n",
      "[64,   299] loss: 0.011654\n",
      "[65,    99] loss: 0.003500\n",
      "[65,   199] loss: 0.004545\n",
      "[65,   299] loss: 0.017044\n",
      "[66,    99] loss: 0.003585\n",
      "[66,   199] loss: 0.013717\n",
      "[66,   299] loss: 0.016119\n",
      "[67,    99] loss: 0.008107\n",
      "[67,   199] loss: 0.015315\n",
      "[67,   299] loss: 0.049214\n",
      "[68,    99] loss: 0.038389\n",
      "[68,   199] loss: 0.065762\n",
      "[68,   299] loss: 0.226915\n",
      "[69,    99] loss: 0.043931\n",
      "[69,   199] loss: 0.041412\n",
      "[69,   299] loss: 0.037143\n",
      "[70,    99] loss: 0.014353\n",
      "[70,   199] loss: 0.019027\n",
      "[70,   299] loss: 0.018605\n",
      "[71,    99] loss: 0.009538\n",
      "[71,   199] loss: 0.005163\n",
      "[71,   299] loss: 0.012656\n",
      "[72,    99] loss: 0.003489\n",
      "[72,   199] loss: 0.003081\n",
      "[72,   299] loss: 0.011157\n",
      "[73,    99] loss: 0.003416\n",
      "[73,   199] loss: 0.003012\n",
      "[73,   299] loss: 0.009458\n",
      "[74,    99] loss: 0.002416\n",
      "[74,   199] loss: 0.003665\n",
      "[74,   299] loss: 0.014953\n",
      "[75,    99] loss: 0.002650\n",
      "[75,   199] loss: 0.009257\n",
      "[75,   299] loss: 0.020181\n",
      "[76,    99] loss: 0.324765\n",
      "[76,   199] loss: 0.122704\n",
      "[76,   299] loss: 0.136757\n",
      "[77,    99] loss: 0.031342\n",
      "[77,   199] loss: 0.032020\n",
      "[77,   299] loss: 0.030029\n",
      "[78,    99] loss: 0.008625\n",
      "[78,   199] loss: 0.006333\n",
      "[78,   299] loss: 0.010098\n",
      "[79,    99] loss: 0.003582\n",
      "[79,   199] loss: 0.003825\n",
      "[79,   299] loss: 0.008385\n",
      "[80,    99] loss: 0.003011\n",
      "[80,   199] loss: 0.003274\n",
      "[80,   299] loss: 0.007677\n",
      "[81,    99] loss: 0.003073\n",
      "[81,   199] loss: 0.003414\n",
      "[81,   299] loss: 0.010662\n",
      "[82,    99] loss: 0.001739\n",
      "[82,   199] loss: 0.002339\n",
      "[82,   299] loss: 0.009813\n",
      "[83,    99] loss: 0.001481\n",
      "[83,   199] loss: 0.002673\n",
      "[83,   299] loss: 0.007531\n",
      "[84,    99] loss: 0.001646\n",
      "[84,   199] loss: 0.003635\n",
      "[84,   299] loss: 0.035543\n",
      "[85,    99] loss: 0.132066\n",
      "[85,   199] loss: 0.072044\n",
      "[85,   299] loss: 0.036031\n",
      "[86,    99] loss: 0.013421\n",
      "[86,   199] loss: 0.019285\n",
      "[86,   299] loss: 0.016289\n",
      "[87,    99] loss: 0.004770\n",
      "[87,   199] loss: 0.006889\n",
      "[87,   299] loss: 0.008777\n",
      "[88,    99] loss: 0.001869\n",
      "[88,   199] loss: 0.002428\n",
      "[88,   299] loss: 0.007358\n",
      "[89,    99] loss: 0.001544\n",
      "[89,   199] loss: 0.001634\n",
      "[89,   299] loss: 0.011342\n",
      "[90,    99] loss: 0.001417\n",
      "[90,   199] loss: 0.001322\n",
      "[90,   299] loss: 0.007107\n",
      "[91,    99] loss: 0.001084\n",
      "[91,   199] loss: 0.001393\n",
      "[91,   299] loss: 0.012576\n",
      "[92,    99] loss: 0.001847\n",
      "[92,   199] loss: 0.003772\n",
      "[92,   299] loss: 0.097269\n",
      "[93,    99] loss: 0.107351\n",
      "[93,   199] loss: 0.080411\n",
      "[93,   299] loss: 0.044606\n",
      "[94,    99] loss: 0.011040\n",
      "[94,   199] loss: 0.014810\n",
      "[94,   299] loss: 0.009145\n",
      "[95,    99] loss: 0.003697\n",
      "[95,   199] loss: 0.012418\n",
      "[95,   299] loss: 0.007086\n",
      "[96,    99] loss: 0.002042\n",
      "[96,   199] loss: 0.003474\n",
      "[96,   299] loss: 0.005864\n",
      "[97,    99] loss: 0.001608\n",
      "[97,   199] loss: 0.002159\n",
      "[97,   299] loss: 0.006089\n",
      "[98,    99] loss: 0.001300\n",
      "[98,   199] loss: 0.002091\n",
      "[98,   299] loss: 0.008976\n",
      "[99,    99] loss: 0.001179\n",
      "[99,   199] loss: 0.003835\n",
      "[99,   299] loss: 0.013950\n",
      "[100,    99] loss: 0.001236\n",
      "[100,   199] loss: 0.016229\n",
      "[100,   299] loss: 0.009971\n",
      "Finished Training\n",
      "[1,    99] loss: 0.685207\n",
      "[1,   199] loss: 0.636979\n",
      "[1,   299] loss: 0.615950\n",
      "[2,    99] loss: 0.611132\n",
      "[2,   199] loss: 0.533121\n",
      "[2,   299] loss: 0.527377\n",
      "[3,    99] loss: 0.532368\n",
      "[3,   199] loss: 0.448742\n",
      "[3,   299] loss: 0.445883\n",
      "[4,    99] loss: 0.456759\n",
      "[4,   199] loss: 0.368810\n",
      "[4,   299] loss: 0.375965\n",
      "[5,    99] loss: 0.400873\n",
      "[5,   199] loss: 0.313186\n",
      "[5,   299] loss: 0.324915\n",
      "[6,    99] loss: 0.347198\n",
      "[6,   199] loss: 0.256112\n",
      "[6,   299] loss: 0.283313\n",
      "[7,    99] loss: 0.298520\n",
      "[7,   199] loss: 0.221410\n",
      "[7,   299] loss: 0.251448\n",
      "[8,    99] loss: 0.259839\n",
      "[8,   199] loss: 0.188654\n",
      "[8,   299] loss: 0.221292\n",
      "[9,    99] loss: 0.235968\n",
      "[9,   199] loss: 0.161538\n",
      "[9,   299] loss: 0.191174\n",
      "[10,    99] loss: 0.200145\n",
      "[10,   199] loss: 0.149635\n",
      "[10,   299] loss: 0.174565\n",
      "[11,    99] loss: 0.170374\n",
      "[11,   199] loss: 0.122848\n",
      "[11,   299] loss: 0.147971\n",
      "[12,    99] loss: 0.157750\n",
      "[12,   199] loss: 0.099206\n",
      "[12,   299] loss: 0.129445\n",
      "[13,    99] loss: 0.131361\n",
      "[13,   199] loss: 0.090618\n",
      "[13,   299] loss: 0.110244\n",
      "[14,    99] loss: 0.136092\n",
      "[14,   199] loss: 0.072405\n",
      "[14,   299] loss: 0.102950\n",
      "[15,    99] loss: 0.110204\n",
      "[15,   199] loss: 0.103846\n",
      "[15,   299] loss: 0.104460\n",
      "[16,    99] loss: 0.130060\n",
      "[16,   199] loss: 0.081379\n",
      "[16,   299] loss: 0.083470\n",
      "[17,    99] loss: 0.088084\n",
      "[17,   199] loss: 0.072068\n",
      "[17,   299] loss: 0.089296\n",
      "[18,    99] loss: 0.120915\n",
      "[18,   199] loss: 0.068029\n",
      "[18,   299] loss: 0.108410\n",
      "[19,    99] loss: 0.096783\n",
      "[19,   199] loss: 0.074443\n",
      "[19,   299] loss: 0.075569\n",
      "[20,    99] loss: 0.081453\n",
      "[20,   199] loss: 0.050815\n",
      "[20,   299] loss: 0.075970\n",
      "[21,    99] loss: 0.069588\n",
      "[21,   199] loss: 0.047936\n",
      "[21,   299] loss: 0.071087\n",
      "[22,    99] loss: 0.063279\n",
      "[22,   199] loss: 0.037020\n",
      "[22,   299] loss: 0.061244\n",
      "[23,    99] loss: 0.061017\n",
      "[23,   199] loss: 0.042350\n",
      "[23,   299] loss: 0.079595\n",
      "[24,    99] loss: 0.103851\n",
      "[24,   199] loss: 0.090428\n",
      "[24,   299] loss: 0.130961\n",
      "[25,    99] loss: 0.118786\n",
      "[25,   199] loss: 0.108832\n",
      "[25,   299] loss: 0.067913\n",
      "[26,    99] loss: 0.073580\n",
      "[26,   199] loss: 0.040819\n",
      "[26,   299] loss: 0.044043\n",
      "[27,    99] loss: 0.041390\n",
      "[27,   199] loss: 0.025579\n",
      "[27,   299] loss: 0.045462\n",
      "[28,    99] loss: 0.052766\n",
      "[28,   199] loss: 0.030267\n",
      "[28,   299] loss: 0.047159\n",
      "[29,    99] loss: 0.049576\n",
      "[29,   199] loss: 0.082410\n",
      "[29,   299] loss: 0.060792\n",
      "[30,    99] loss: 0.115713\n",
      "[30,   199] loss: 0.027970\n",
      "[30,   299] loss: 0.039890\n",
      "[31,    99] loss: 0.040878\n",
      "[31,   199] loss: 0.030486\n",
      "[31,   299] loss: 0.046695\n",
      "[32,    99] loss: 0.045487\n",
      "[32,   199] loss: 0.021770\n",
      "[32,   299] loss: 0.043220\n",
      "[33,    99] loss: 0.154228\n",
      "[33,   199] loss: 0.061591\n",
      "[33,   299] loss: 0.064460\n",
      "[34,    99] loss: 0.071669\n",
      "[34,   199] loss: 0.048277\n",
      "[34,   299] loss: 0.040968\n",
      "[35,    99] loss: 0.049287\n",
      "[35,   199] loss: 0.022137\n",
      "[35,   299] loss: 0.067644\n",
      "[36,    99] loss: 0.056662\n",
      "[36,   199] loss: 0.102298\n",
      "[36,   299] loss: 0.031547\n",
      "[37,    99] loss: 0.033197\n",
      "[37,   199] loss: 0.022919\n",
      "[37,   299] loss: 0.055994\n",
      "[38,    99] loss: 0.026261\n",
      "[38,   199] loss: 0.066952\n",
      "[38,   299] loss: 0.054559\n",
      "[39,    99] loss: 0.051931\n",
      "[39,   199] loss: 0.025020\n",
      "[39,   299] loss: 0.027617\n",
      "[40,    99] loss: 0.041072\n",
      "[40,   199] loss: 0.030304\n",
      "[40,   299] loss: 0.040794\n",
      "[41,    99] loss: 0.039450\n",
      "[41,   199] loss: 0.026764\n",
      "[41,   299] loss: 0.041414\n",
      "[42,    99] loss: 0.062228\n",
      "[42,   199] loss: 0.036611\n",
      "[42,   299] loss: 0.053436\n",
      "[43,    99] loss: 0.098752\n",
      "[43,   199] loss: 0.024744\n",
      "[43,   299] loss: 0.028680\n",
      "[44,    99] loss: 0.034281\n",
      "[44,   199] loss: 0.040623\n",
      "[44,   299] loss: 0.050511\n",
      "[45,    99] loss: 0.056061\n",
      "[45,   199] loss: 0.029302\n",
      "[45,   299] loss: 0.027934\n",
      "[46,    99] loss: 0.028899\n",
      "[46,   199] loss: 0.012312\n",
      "[46,   299] loss: 0.056103\n",
      "[47,    99] loss: 0.075047\n",
      "[47,   199] loss: 0.030928\n",
      "[47,   299] loss: 0.021391\n",
      "[48,    99] loss: 0.025478\n",
      "[48,   199] loss: 0.039226\n",
      "[48,   299] loss: 0.047491\n",
      "[49,    99] loss: 0.093549\n",
      "[49,   199] loss: 0.022043\n",
      "[49,   299] loss: 0.040895\n",
      "[50,    99] loss: 0.029345\n",
      "[50,   199] loss: 0.015865\n",
      "[50,   299] loss: 0.035536\n",
      "[51,    99] loss: 0.027391\n",
      "[51,   199] loss: 0.050767\n",
      "[51,   299] loss: 0.044596\n",
      "[52,    99] loss: 0.016776\n",
      "[52,   199] loss: 0.009712\n",
      "[52,   299] loss: 0.045717\n",
      "[53,    99] loss: 0.059691\n",
      "[53,   199] loss: 0.049202\n",
      "[53,   299] loss: 0.020761\n",
      "[54,    99] loss: 0.025496\n",
      "[54,   199] loss: 0.009535\n",
      "[54,   299] loss: 0.028958\n",
      "[55,    99] loss: 0.022202\n",
      "[55,   199] loss: 0.012168\n",
      "[55,   299] loss: 0.034774\n",
      "[56,    99] loss: 0.019133\n",
      "[56,   199] loss: 0.009091\n",
      "[56,   299] loss: 0.033901\n",
      "[57,    99] loss: 0.023792\n",
      "[57,   199] loss: 0.010121\n",
      "[57,   299] loss: 0.031678\n",
      "[58,    99] loss: 0.038455\n",
      "[58,   199] loss: 0.011768\n",
      "[58,   299] loss: 0.045012\n",
      "[59,    99] loss: 0.023723\n",
      "[59,   199] loss: 0.071085\n",
      "[59,   299] loss: 0.086783\n",
      "[60,    99] loss: 0.047308\n",
      "[60,   199] loss: 0.056998\n",
      "[60,   299] loss: 0.054975\n",
      "[61,    99] loss: 0.074880\n",
      "[61,   199] loss: 0.028319\n",
      "[61,   299] loss: 0.051456\n",
      "[62,    99] loss: 0.012034\n",
      "[62,   199] loss: 0.002336\n",
      "[62,   299] loss: 0.020388\n",
      "[63,    99] loss: 0.013914\n",
      "[63,   199] loss: 0.002943\n",
      "[63,   299] loss: 0.019008\n",
      "[64,    99] loss: 0.009159\n",
      "[64,   199] loss: 0.002131\n",
      "[64,   299] loss: 0.021137\n",
      "[65,    99] loss: 0.009969\n",
      "[65,   199] loss: 0.001999\n",
      "[65,   299] loss: 0.025571\n",
      "[66,    99] loss: 0.011646\n",
      "[66,   199] loss: 0.001730\n",
      "[66,   299] loss: 0.031269\n",
      "[67,    99] loss: 0.017593\n",
      "[67,   199] loss: 0.002906\n",
      "[67,   299] loss: 0.033863\n",
      "[68,    99] loss: 0.012395\n",
      "[68,   199] loss: 0.001938\n",
      "[68,   299] loss: 0.026121\n",
      "[69,    99] loss: 0.008897\n",
      "[69,   199] loss: 0.001312\n",
      "[69,   299] loss: 0.021065\n",
      "[70,    99] loss: 0.017389\n",
      "[70,   199] loss: 0.001520\n",
      "[70,   299] loss: 0.025492\n",
      "[71,    99] loss: 0.111777\n",
      "[71,   199] loss: 0.094740\n",
      "[71,   299] loss: 0.183644\n",
      "[72,    99] loss: 0.063125\n",
      "[72,   199] loss: 0.072993\n",
      "[72,   299] loss: 0.035784\n",
      "[73,    99] loss: 0.013271\n",
      "[73,   199] loss: 0.007509\n",
      "[73,   299] loss: 0.013329\n",
      "[74,    99] loss: 0.006415\n",
      "[74,   199] loss: 0.002707\n",
      "[74,   299] loss: 0.004443\n",
      "[75,    99] loss: 0.003771\n",
      "[75,   199] loss: 0.001674\n",
      "[75,   299] loss: 0.003907\n",
      "[76,    99] loss: 0.003272\n",
      "[76,   199] loss: 0.001248\n",
      "[76,   299] loss: 0.005935\n",
      "[77,    99] loss: 0.006732\n",
      "[77,   199] loss: 0.001783\n",
      "[77,   299] loss: 0.032217\n",
      "[78,    99] loss: 0.103168\n",
      "[78,   199] loss: 0.081838\n",
      "[78,   299] loss: 0.200248\n",
      "[79,    99] loss: 0.110301\n",
      "[79,   199] loss: 0.110087\n",
      "[79,   299] loss: 0.023622\n",
      "[80,    99] loss: 0.009650\n",
      "[80,   199] loss: 0.002181\n",
      "[80,   299] loss: 0.007830\n",
      "[81,    99] loss: 0.006354\n",
      "[81,   199] loss: 0.001878\n",
      "[81,   299] loss: 0.003832\n",
      "[82,    99] loss: 0.003452\n",
      "[82,   199] loss: 0.001224\n",
      "[82,   299] loss: 0.003226\n",
      "[83,    99] loss: 0.003030\n",
      "[83,   199] loss: 0.000964\n",
      "[83,   299] loss: 0.003170\n",
      "[84,    99] loss: 0.003573\n",
      "[84,   199] loss: 0.000789\n",
      "[84,   299] loss: 0.007019\n",
      "[85,    99] loss: 0.011461\n",
      "[85,   199] loss: 0.001409\n",
      "[85,   299] loss: 0.020614\n",
      "[86,    99] loss: 0.166743\n",
      "[86,   199] loss: 0.156097\n",
      "[86,   299] loss: 0.070776\n",
      "[87,    99] loss: 0.034797\n",
      "[87,   199] loss: 0.032040\n",
      "[87,   299] loss: 0.022054\n",
      "[88,    99] loss: 0.017113\n",
      "[88,   199] loss: 0.007933\n",
      "[88,   299] loss: 0.008189\n",
      "[89,    99] loss: 0.009804\n",
      "[89,   199] loss: 0.004625\n",
      "[89,   299] loss: 0.003935\n",
      "[90,    99] loss: 0.005775\n",
      "[90,   199] loss: 0.001891\n",
      "[90,   299] loss: 0.003404\n",
      "[91,    99] loss: 0.004053\n",
      "[91,   199] loss: 0.001042\n",
      "[91,   299] loss: 0.003346\n",
      "[92,    99] loss: 0.003604\n",
      "[92,   199] loss: 0.000854\n",
      "[92,   299] loss: 0.016582\n",
      "[93,    99] loss: 0.011350\n",
      "[93,   199] loss: 0.002689\n",
      "[93,   299] loss: 0.038253\n",
      "[94,    99] loss: 0.008312\n",
      "[94,   199] loss: 0.001203\n",
      "[94,   299] loss: 0.015173\n",
      "[95,    99] loss: 0.017801\n",
      "[95,   199] loss: 0.001669\n",
      "[95,   299] loss: 0.030549\n",
      "[96,    99] loss: 0.006468\n",
      "[96,   199] loss: 0.110662\n",
      "[96,   299] loss: 0.084438\n",
      "[97,    99] loss: 0.106569\n",
      "[97,   199] loss: 0.097306\n",
      "[97,   299] loss: 0.096174\n",
      "[98,    99] loss: 0.034174\n",
      "[98,   199] loss: 0.019209\n",
      "[98,   299] loss: 0.009317\n",
      "[99,    99] loss: 0.014920\n",
      "[99,   199] loss: 0.013338\n",
      "[99,   299] loss: 0.003914\n",
      "[100,    99] loss: 0.019685\n",
      "[100,   199] loss: 0.039562\n",
      "[100,   299] loss: 0.002445\n",
      "Finished Training\n",
      "[1,    99] loss: 0.682396\n",
      "[1,   199] loss: 0.661998\n",
      "[1,   299] loss: 0.639888\n",
      "[2,    99] loss: 0.599264\n",
      "[2,   199] loss: 0.572794\n",
      "[2,   299] loss: 0.553820\n",
      "[3,    99] loss: 0.505468\n",
      "[3,   199] loss: 0.498743\n",
      "[3,   299] loss: 0.463536\n",
      "[4,    99] loss: 0.410743\n",
      "[4,   199] loss: 0.422744\n",
      "[4,   299] loss: 0.379169\n",
      "[5,    99] loss: 0.337579\n",
      "[5,   199] loss: 0.349902\n",
      "[5,   299] loss: 0.306155\n",
      "[6,    99] loss: 0.291509\n",
      "[6,   199] loss: 0.287802\n",
      "[6,   299] loss: 0.251969\n",
      "[7,    99] loss: 0.245759\n",
      "[7,   199] loss: 0.231592\n",
      "[7,   299] loss: 0.214792\n",
      "[8,    99] loss: 0.215244\n",
      "[8,   199] loss: 0.196070\n",
      "[8,   299] loss: 0.187510\n",
      "[9,    99] loss: 0.196962\n",
      "[9,   199] loss: 0.163879\n",
      "[9,   299] loss: 0.145915\n",
      "[10,    99] loss: 0.174458\n",
      "[10,   199] loss: 0.136485\n",
      "[10,   299] loss: 0.130817\n",
      "[11,    99] loss: 0.151137\n",
      "[11,   199] loss: 0.118943\n",
      "[11,   299] loss: 0.115920\n",
      "[12,    99] loss: 0.143695\n",
      "[12,   199] loss: 0.107793\n",
      "[12,   299] loss: 0.098024\n",
      "[13,    99] loss: 0.133355\n",
      "[13,   199] loss: 0.095573\n",
      "[13,   299] loss: 0.089582\n",
      "[14,    99] loss: 0.121422\n",
      "[14,   199] loss: 0.096566\n",
      "[14,   299] loss: 0.080226\n",
      "[15,    99] loss: 0.117853\n",
      "[15,   199] loss: 0.083392\n",
      "[15,   299] loss: 0.077598\n",
      "[16,    99] loss: 0.097460\n",
      "[16,   199] loss: 0.079608\n",
      "[16,   299] loss: 0.070409\n",
      "[17,    99] loss: 0.093681\n",
      "[17,   199] loss: 0.130581\n",
      "[17,   299] loss: 0.089660\n",
      "[18,    99] loss: 0.087396\n",
      "[18,   199] loss: 0.072689\n",
      "[18,   299] loss: 0.057622\n",
      "[19,    99] loss: 0.094199\n",
      "[19,   199] loss: 0.072465\n",
      "[19,   299] loss: 0.041081\n",
      "[20,    99] loss: 0.101389\n",
      "[20,   199] loss: 0.077752\n",
      "[20,   299] loss: 0.037954\n",
      "[21,    99] loss: 0.081203\n",
      "[21,   199] loss: 0.075166\n",
      "[21,   299] loss: 0.032485\n",
      "[22,    99] loss: 0.084166\n",
      "[22,   199] loss: 0.081325\n",
      "[22,   299] loss: 0.032715\n",
      "[23,    99] loss: 0.072003\n",
      "[23,   199] loss: 0.082105\n",
      "[23,   299] loss: 0.037262\n",
      "[24,    99] loss: 0.063770\n",
      "[24,   199] loss: 0.070482\n",
      "[24,   299] loss: 0.027618\n",
      "[25,    99] loss: 0.042358\n",
      "[25,   199] loss: 0.068158\n",
      "[25,   299] loss: 0.018015\n",
      "[26,    99] loss: 0.062908\n",
      "[26,   199] loss: 0.130056\n",
      "[26,   299] loss: 0.029467\n",
      "[27,    99] loss: 0.061814\n",
      "[27,   199] loss: 0.074032\n",
      "[27,   299] loss: 0.042118\n",
      "[28,    99] loss: 0.058177\n",
      "[28,   199] loss: 0.042238\n",
      "[28,   299] loss: 0.023471\n",
      "[29,    99] loss: 0.035800\n",
      "[29,   199] loss: 0.037883\n",
      "[29,   299] loss: 0.028763\n",
      "[30,    99] loss: 0.036189\n",
      "[30,   199] loss: 0.033700\n",
      "[30,   299] loss: 0.041433\n",
      "[31,    99] loss: 0.039201\n",
      "[31,   199] loss: 0.036466\n",
      "[31,   299] loss: 0.024896\n",
      "[32,    99] loss: 0.041379\n",
      "[32,   199] loss: 0.090315\n",
      "[32,   299] loss: 0.056347\n",
      "[33,    99] loss: 0.083665\n",
      "[33,   199] loss: 0.031347\n",
      "[33,   299] loss: 0.018043\n",
      "[34,    99] loss: 0.056087\n",
      "[34,   199] loss: 0.013438\n",
      "[34,   299] loss: 0.022481\n",
      "[35,    99] loss: 0.028349\n",
      "[35,   199] loss: 0.012478\n",
      "[35,   299] loss: 0.008639\n",
      "[36,    99] loss: 0.012046\n",
      "[36,   199] loss: 0.008956\n",
      "[36,   299] loss: 0.003988\n",
      "[37,    99] loss: 0.012296\n",
      "[37,   199] loss: 0.007166\n",
      "[37,   299] loss: 0.003386\n",
      "[38,    99] loss: 0.030875\n",
      "[38,   199] loss: 0.009442\n",
      "[38,   299] loss: 0.003101\n",
      "[39,    99] loss: 0.033546\n",
      "[39,   199] loss: 0.066105\n",
      "[39,   299] loss: 0.291966\n",
      "[40,    99] loss: 0.072511\n",
      "[40,   199] loss: 0.060227\n",
      "[40,   299] loss: 0.017739\n",
      "[41,    99] loss: 0.023870\n",
      "[41,   199] loss: 0.008383\n",
      "[41,   299] loss: 0.010128\n",
      "[42,    99] loss: 0.034297\n",
      "[42,   199] loss: 0.009896\n",
      "[42,   299] loss: 0.004938\n",
      "[43,    99] loss: 0.039776\n",
      "[43,   199] loss: 0.007161\n",
      "[43,   299] loss: 0.003747\n",
      "[44,    99] loss: 0.049352\n",
      "[44,   199] loss: 0.006995\n",
      "[44,   299] loss: 0.004431\n",
      "[45,    99] loss: 0.035641\n",
      "[45,   199] loss: 0.006379\n",
      "[45,   299] loss: 0.005165\n",
      "[46,    99] loss: 0.021655\n",
      "[46,   199] loss: 0.006829\n",
      "[46,   299] loss: 0.002829\n",
      "[47,    99] loss: 0.022549\n",
      "[47,   199] loss: 0.074410\n",
      "[47,   299] loss: 0.089234\n",
      "[48,    99] loss: 0.088618\n",
      "[48,   199] loss: 0.228729\n",
      "[48,   299] loss: 0.040263\n",
      "[49,    99] loss: 0.014383\n",
      "[49,   199] loss: 0.013378\n",
      "[49,   299] loss: 0.009124\n",
      "[50,    99] loss: 0.005262\n",
      "[50,   199] loss: 0.006116\n",
      "[50,   299] loss: 0.002701\n",
      "[51,    99] loss: 0.005756\n",
      "[51,   199] loss: 0.004365\n",
      "[51,   299] loss: 0.002500\n",
      "[52,    99] loss: 0.004736\n",
      "[52,   199] loss: 0.003802\n",
      "[52,   299] loss: 0.002035\n",
      "[53,    99] loss: 0.004242\n",
      "[53,   199] loss: 0.002360\n",
      "[53,   299] loss: 0.001482\n",
      "[54,    99] loss: 0.004364\n",
      "[54,   199] loss: 0.002122\n",
      "[54,   299] loss: 0.001365\n",
      "[55,    99] loss: 0.039362\n",
      "[55,   199] loss: 0.002971\n",
      "[55,   299] loss: 0.001575\n",
      "[56,    99] loss: 0.032615\n",
      "[56,   199] loss: 0.065617\n",
      "[56,   299] loss: 0.201263\n",
      "[57,    99] loss: 0.050867\n",
      "[57,   199] loss: 0.028284\n",
      "[57,   299] loss: 0.017622\n",
      "[58,    99] loss: 0.018743\n",
      "[58,   199] loss: 0.005553\n",
      "[58,   299] loss: 0.003832\n",
      "[59,    99] loss: 0.006176\n",
      "[59,   199] loss: 0.003025\n",
      "[59,   299] loss: 0.001601\n",
      "[60,    99] loss: 0.003883\n",
      "[60,   199] loss: 0.002194\n",
      "[60,   299] loss: 0.001343\n",
      "[61,    99] loss: 0.004712\n",
      "[61,   199] loss: 0.001926\n",
      "[61,   299] loss: 0.001165\n",
      "[62,    99] loss: 0.032240\n",
      "[62,   199] loss: 0.002883\n",
      "[62,   299] loss: 0.002633\n",
      "[63,    99] loss: 0.111519\n",
      "[63,   199] loss: 0.336521\n",
      "[63,   299] loss: 0.075693\n",
      "[64,    99] loss: 0.028312\n",
      "[64,   199] loss: 0.099164\n",
      "[64,   299] loss: 0.019545\n",
      "[65,    99] loss: 0.008598\n",
      "[65,   199] loss: 0.004681\n",
      "[65,   299] loss: 0.002494\n",
      "[66,    99] loss: 0.003539\n",
      "[66,   199] loss: 0.002339\n",
      "[66,   299] loss: 0.001824\n",
      "[67,    99] loss: 0.003639\n",
      "[67,   199] loss: 0.001845\n",
      "[67,   299] loss: 0.001468\n",
      "[68,    99] loss: 0.002385\n",
      "[68,   199] loss: 0.001494\n",
      "[68,   299] loss: 0.001154\n",
      "[69,    99] loss: 0.001990\n",
      "[69,   199] loss: 0.001262\n",
      "[69,   299] loss: 0.000969\n",
      "[70,    99] loss: 0.001839\n",
      "[70,   199] loss: 0.001074\n",
      "[70,   299] loss: 0.000813\n",
      "[71,    99] loss: 0.001837\n",
      "[71,   199] loss: 0.000939\n",
      "[71,   299] loss: 0.000683\n",
      "[72,    99] loss: 0.070757\n",
      "[72,   199] loss: 0.152781\n",
      "[72,   299] loss: 0.069411\n",
      "[73,    99] loss: 0.071978\n",
      "[73,   199] loss: 0.019778\n",
      "[73,   299] loss: 0.019615\n",
      "[74,    99] loss: 0.010136\n",
      "[74,   199] loss: 0.021023\n",
      "[74,   299] loss: 0.027845\n",
      "[75,    99] loss: 0.010240\n",
      "[75,   199] loss: 0.005823\n",
      "[75,   299] loss: 0.006124\n",
      "[76,    99] loss: 0.002483\n",
      "[76,   199] loss: 0.004509\n",
      "[76,   299] loss: 0.005654\n",
      "[77,    99] loss: 0.004982\n",
      "[77,   199] loss: 0.011740\n",
      "[77,   299] loss: 0.030360\n",
      "[78,    99] loss: 0.020732\n",
      "[78,   199] loss: 0.016046\n",
      "[78,   299] loss: 0.011911\n",
      "[79,    99] loss: 0.010628\n",
      "[79,   199] loss: 0.006354\n",
      "[79,   299] loss: 0.005364\n",
      "[80,    99] loss: 0.007248\n",
      "[80,   199] loss: 0.006084\n",
      "[80,   299] loss: 0.008104\n",
      "[81,    99] loss: 0.002129\n",
      "[81,   199] loss: 0.011571\n",
      "[81,   299] loss: 0.023840\n",
      "[82,    99] loss: 0.001290\n",
      "[82,   199] loss: 0.003629\n",
      "[82,   299] loss: 0.000957\n",
      "[83,    99] loss: 0.000881\n",
      "[83,   199] loss: 0.000708\n",
      "[83,   299] loss: 0.000452\n",
      "[84,    99] loss: 0.000688\n",
      "[84,   199] loss: 0.000557\n",
      "[84,   299] loss: 0.000366\n",
      "[85,    99] loss: 0.000589\n",
      "[85,   199] loss: 0.000466\n",
      "[85,   299] loss: 0.000309\n",
      "[86,    99] loss: 0.000511\n",
      "[86,   199] loss: 0.000403\n",
      "[86,   299] loss: 0.000259\n",
      "[87,    99] loss: 0.000442\n",
      "[87,   199] loss: 0.000354\n",
      "[87,   299] loss: 0.000221\n",
      "[88,    99] loss: 0.000390\n",
      "[88,   199] loss: 0.000313\n",
      "[88,   299] loss: 0.000189\n",
      "[89,    99] loss: 0.000346\n",
      "[89,   199] loss: 0.000281\n",
      "[89,   299] loss: 0.000162\n",
      "[90,    99] loss: 0.000331\n",
      "[90,   199] loss: 0.000325\n",
      "[90,   299] loss: 0.000480\n",
      "[91,    99] loss: 0.524042\n",
      "[91,   199] loss: 0.137292\n",
      "[91,   299] loss: 0.018695\n",
      "[92,    99] loss: 0.005156\n",
      "[92,   199] loss: 0.045989\n",
      "[92,   299] loss: 0.041546\n",
      "[93,    99] loss: 0.017447\n",
      "[93,   199] loss: 0.028742\n",
      "[93,   299] loss: 0.030266\n",
      "[94,    99] loss: 0.004018\n",
      "[94,   199] loss: 0.001744\n",
      "[94,   299] loss: 0.001175\n",
      "[95,    99] loss: 0.001887\n",
      "[95,   199] loss: 0.001219\n",
      "[95,   299] loss: 0.000763\n",
      "[96,    99] loss: 0.001111\n",
      "[96,   199] loss: 0.000917\n",
      "[96,   299] loss: 0.000647\n",
      "[97,    99] loss: 0.000897\n",
      "[97,   199] loss: 0.000766\n",
      "[97,   299] loss: 0.000534\n",
      "[98,    99] loss: 0.000766\n",
      "[98,   199] loss: 0.000656\n",
      "[98,   299] loss: 0.000458\n",
      "[99,    99] loss: 0.000679\n",
      "[99,   199] loss: 0.000572\n",
      "[99,   299] loss: 0.000396\n",
      "[100,    99] loss: 0.000599\n",
      "[100,   199] loss: 0.000502\n",
      "[100,   299] loss: 0.000345\n",
      "Finished Training\n",
      "[1,    99] loss: 0.678829\n",
      "[1,   199] loss: 0.661863\n",
      "[1,   299] loss: 0.645525\n",
      "[2,    99] loss: 0.574148\n",
      "[2,   199] loss: 0.544087\n",
      "[2,   299] loss: 0.513774\n",
      "[3,    99] loss: 0.462060\n",
      "[3,   199] loss: 0.407634\n",
      "[3,   299] loss: 0.402717\n",
      "[4,    99] loss: 0.370282\n",
      "[4,   199] loss: 0.303075\n",
      "[4,   299] loss: 0.343598\n",
      "[5,    99] loss: 0.293572\n",
      "[5,   199] loss: 0.236673\n",
      "[5,   299] loss: 0.279042\n",
      "[6,    99] loss: 0.229233\n",
      "[6,   199] loss: 0.186960\n",
      "[6,   299] loss: 0.239867\n",
      "[7,    99] loss: 0.195066\n",
      "[7,   199] loss: 0.154430\n",
      "[7,   299] loss: 0.214736\n",
      "[8,    99] loss: 0.176147\n",
      "[8,   199] loss: 0.137376\n",
      "[8,   299] loss: 0.181745\n",
      "[9,    99] loss: 0.152608\n",
      "[9,   199] loss: 0.119111\n",
      "[9,   299] loss: 0.166111\n",
      "[10,    99] loss: 0.128944\n",
      "[10,   199] loss: 0.100769\n",
      "[10,   299] loss: 0.127054\n",
      "[11,    99] loss: 0.108797\n",
      "[11,   199] loss: 0.087375\n",
      "[11,   299] loss: 0.118938\n",
      "[12,    99] loss: 0.102018\n",
      "[12,   199] loss: 0.079931\n",
      "[12,   299] loss: 0.084704\n",
      "[13,    99] loss: 0.094848\n",
      "[13,   199] loss: 0.078287\n",
      "[13,   299] loss: 0.077694\n",
      "[14,    99] loss: 0.117136\n",
      "[14,   199] loss: 0.076005\n",
      "[14,   299] loss: 0.103692\n",
      "[15,    99] loss: 0.106222\n",
      "[15,   199] loss: 0.061818\n",
      "[15,   299] loss: 0.113283\n",
      "[16,    99] loss: 0.124322\n",
      "[16,   199] loss: 0.057547\n",
      "[16,   299] loss: 0.077283\n",
      "[17,    99] loss: 0.058424\n",
      "[17,   199] loss: 0.066410\n",
      "[17,   299] loss: 0.057054\n",
      "[18,    99] loss: 0.051929\n",
      "[18,   199] loss: 0.044443\n",
      "[18,   299] loss: 0.079276\n",
      "[19,    99] loss: 0.054997\n",
      "[19,   199] loss: 0.065288\n",
      "[19,   299] loss: 0.037732\n",
      "[20,    99] loss: 0.048210\n",
      "[20,   199] loss: 0.032233\n",
      "[20,   299] loss: 0.037545\n",
      "[21,    99] loss: 0.059166\n",
      "[21,   199] loss: 0.039505\n",
      "[21,   299] loss: 0.065098\n",
      "[22,    99] loss: 0.111393\n",
      "[22,   199] loss: 0.037208\n",
      "[22,   299] loss: 0.037290\n",
      "[23,    99] loss: 0.145751\n",
      "[23,   199] loss: 0.052661\n",
      "[23,   299] loss: 0.080690\n",
      "[24,    99] loss: 0.101923\n",
      "[24,   199] loss: 0.057204\n",
      "[24,   299] loss: 0.046581\n",
      "[25,    99] loss: 0.064310\n",
      "[25,   199] loss: 0.040860\n",
      "[25,   299] loss: 0.032706\n",
      "[26,    99] loss: 0.039534\n",
      "[26,   199] loss: 0.025013\n",
      "[26,   299] loss: 0.021332\n",
      "[27,    99] loss: 0.030778\n",
      "[27,   199] loss: 0.051099\n",
      "[27,   299] loss: 0.046026\n",
      "[28,    99] loss: 0.046033\n",
      "[28,   199] loss: 0.027550\n",
      "[28,   299] loss: 0.021785\n",
      "[29,    99] loss: 0.035492\n",
      "[29,   199] loss: 0.032420\n",
      "[29,   299] loss: 0.067190\n",
      "[30,    99] loss: 0.036882\n",
      "[30,   199] loss: 0.016181\n",
      "[30,   299] loss: 0.061684\n",
      "[31,    99] loss: 0.037599\n",
      "[31,   199] loss: 0.030296\n",
      "[31,   299] loss: 0.021463\n",
      "[32,    99] loss: 0.080253\n",
      "[32,   199] loss: 0.033908\n",
      "[32,   299] loss: 0.114494\n",
      "[33,    99] loss: 0.051589\n",
      "[33,   199] loss: 0.052889\n",
      "[33,   299] loss: 0.081404\n",
      "[34,    99] loss: 0.036305\n",
      "[34,   199] loss: 0.018671\n",
      "[34,   299] loss: 0.017553\n",
      "[35,    99] loss: 0.012653\n",
      "[35,   199] loss: 0.042972\n",
      "[35,   299] loss: 0.010318\n",
      "[36,    99] loss: 0.017527\n",
      "[36,   199] loss: 0.011811\n",
      "[36,   299] loss: 0.012831\n",
      "[37,    99] loss: 0.033556\n",
      "[37,   199] loss: 0.020919\n",
      "[37,   299] loss: 0.012355\n",
      "[38,    99] loss: 0.020726\n",
      "[38,   199] loss: 0.048501\n",
      "[38,   299] loss: 0.164193\n",
      "[39,    99] loss: 0.129791\n",
      "[39,   199] loss: 0.037287\n",
      "[39,   299] loss: 0.025794\n",
      "[40,    99] loss: 0.030180\n",
      "[40,   199] loss: 0.014455\n",
      "[40,   299] loss: 0.016259\n",
      "[41,    99] loss: 0.011143\n",
      "[41,   199] loss: 0.011581\n",
      "[41,   299] loss: 0.016884\n",
      "[42,    99] loss: 0.008061\n",
      "[42,   199] loss: 0.019864\n",
      "[42,   299] loss: 0.031397\n",
      "[43,    99] loss: 0.011619\n",
      "[43,   199] loss: 0.020417\n",
      "[43,   299] loss: 0.032388\n",
      "[44,    99] loss: 0.010137\n",
      "[44,   199] loss: 0.022955\n",
      "[44,   299] loss: 0.013864\n",
      "[45,    99] loss: 0.008960\n",
      "[45,   199] loss: 0.005523\n",
      "[45,   299] loss: 0.016959\n",
      "[46,    99] loss: 0.006894\n",
      "[46,   199] loss: 0.015359\n",
      "[46,   299] loss: 0.011072\n",
      "[47,    99] loss: 0.006007\n",
      "[47,   199] loss: 0.011934\n",
      "[47,   299] loss: 0.009489\n",
      "[48,    99] loss: 0.008332\n",
      "[48,   199] loss: 0.077236\n",
      "[48,   299] loss: 0.260216\n",
      "[49,    99] loss: 0.083261\n",
      "[49,   199] loss: 0.015220\n",
      "[49,   299] loss: 0.118142\n",
      "[50,    99] loss: 0.026979\n",
      "[50,   199] loss: 0.018372\n",
      "[50,   299] loss: 0.015897\n",
      "[51,    99] loss: 0.009795\n",
      "[51,   199] loss: 0.024718\n",
      "[51,   299] loss: 0.030686\n",
      "[52,    99] loss: 0.024279\n",
      "[52,   199] loss: 0.062642\n",
      "[52,   299] loss: 0.014013\n",
      "[53,    99] loss: 0.011743\n",
      "[53,   199] loss: 0.009675\n",
      "[53,   299] loss: 0.010345\n",
      "[54,    99] loss: 0.004572\n",
      "[54,   199] loss: 0.004125\n",
      "[54,   299] loss: 0.004733\n",
      "[55,    99] loss: 0.003998\n",
      "[55,   199] loss: 0.003753\n",
      "[55,   299] loss: 0.003431\n",
      "[56,    99] loss: 0.003143\n",
      "[56,   199] loss: 0.003768\n",
      "[56,   299] loss: 0.003385\n",
      "[57,    99] loss: 0.002617\n",
      "[57,   199] loss: 0.004537\n",
      "[57,   299] loss: 0.003897\n",
      "[58,    99] loss: 0.008600\n",
      "[58,   199] loss: 0.028602\n",
      "[58,   299] loss: 0.011448\n",
      "[59,    99] loss: 0.101150\n",
      "[59,   199] loss: 0.175609\n",
      "[59,   299] loss: 0.189611\n",
      "[60,    99] loss: 0.070227\n",
      "[60,   199] loss: 0.023617\n",
      "[60,   299] loss: 0.069332\n",
      "[61,    99] loss: 0.093165\n",
      "[61,   199] loss: 0.004386\n",
      "[61,   299] loss: 0.015827\n",
      "[62,    99] loss: 0.010467\n",
      "[62,   199] loss: 0.003436\n",
      "[62,   299] loss: 0.006080\n",
      "[63,    99] loss: 0.005762\n",
      "[63,   199] loss: 0.001678\n",
      "[63,   299] loss: 0.003652\n",
      "[64,    99] loss: 0.004600\n",
      "[64,   199] loss: 0.001368\n",
      "[64,   299] loss: 0.003989\n",
      "[65,    99] loss: 0.070761\n",
      "[65,   199] loss: 0.091801\n",
      "[65,   299] loss: 0.050708\n",
      "[66,    99] loss: 0.019659\n",
      "[66,   199] loss: 0.031196\n",
      "[66,   299] loss: 0.023832\n",
      "[67,    99] loss: 0.012770\n",
      "[67,   199] loss: 0.007478\n",
      "[67,   299] loss: 0.005818\n",
      "[68,    99] loss: 0.003561\n",
      "[68,   199] loss: 0.002799\n",
      "[68,   299] loss: 0.002969\n",
      "[69,    99] loss: 0.002751\n",
      "[69,   199] loss: 0.001893\n",
      "[69,   299] loss: 0.002123\n",
      "[70,    99] loss: 0.002358\n",
      "[70,   199] loss: 0.001556\n",
      "[70,   299] loss: 0.001755\n",
      "[71,    99] loss: 0.002007\n",
      "[71,   199] loss: 0.001532\n",
      "[71,   299] loss: 0.001556\n",
      "[72,    99] loss: 0.001678\n",
      "[72,   199] loss: 0.001253\n",
      "[72,   299] loss: 0.001400\n",
      "[73,    99] loss: 0.001447\n",
      "[73,   199] loss: 0.001953\n",
      "[73,   299] loss: 0.001713\n",
      "[74,    99] loss: 0.001301\n",
      "[74,   199] loss: 0.046109\n",
      "[74,   299] loss: 0.145823\n",
      "[75,    99] loss: 0.217721\n",
      "[75,   199] loss: 0.030310\n",
      "[75,   299] loss: 0.085208\n",
      "[76,    99] loss: 0.047785\n",
      "[76,   199] loss: 0.018552\n",
      "[76,   299] loss: 0.012465\n",
      "[77,    99] loss: 0.008305\n",
      "[77,   199] loss: 0.017218\n",
      "[77,   299] loss: 0.007409\n",
      "[78,    99] loss: 0.005828\n",
      "[78,   199] loss: 0.002799\n",
      "[78,   299] loss: 0.002765\n",
      "[79,    99] loss: 0.002331\n",
      "[79,   199] loss: 0.001774\n",
      "[79,   299] loss: 0.001956\n",
      "[80,    99] loss: 0.001655\n",
      "[80,   199] loss: 0.001379\n",
      "[80,   299] loss: 0.001563\n",
      "[81,    99] loss: 0.001388\n",
      "[81,   199] loss: 0.001157\n",
      "[81,   299] loss: 0.001310\n",
      "[82,    99] loss: 0.001178\n",
      "[82,   199] loss: 0.000972\n",
      "[82,   299] loss: 0.001121\n",
      "[83,    99] loss: 0.000994\n",
      "[83,   199] loss: 0.000809\n",
      "[83,   299] loss: 0.000976\n",
      "[84,    99] loss: 0.000861\n",
      "[84,   199] loss: 0.000744\n",
      "[84,   299] loss: 0.000852\n",
      "[85,    99] loss: 0.109406\n",
      "[85,   199] loss: 0.117504\n",
      "[85,   299] loss: 0.086220\n",
      "[86,    99] loss: 0.030131\n",
      "[86,   199] loss: 0.024532\n",
      "[86,   299] loss: 0.083017\n",
      "[87,    99] loss: 0.051879\n",
      "[87,   199] loss: 0.006056\n",
      "[87,   299] loss: 0.009400\n",
      "[88,    99] loss: 0.016894\n",
      "[88,   199] loss: 0.008156\n",
      "[88,   299] loss: 0.035376\n",
      "[89,    99] loss: 0.014442\n",
      "[89,   199] loss: 0.023059\n",
      "[89,   299] loss: 0.022842\n",
      "[90,    99] loss: 0.100002\n",
      "[90,   199] loss: 0.055076\n",
      "[90,   299] loss: 0.033594\n",
      "[91,    99] loss: 0.038699\n",
      "[91,   199] loss: 0.007341\n",
      "[91,   299] loss: 0.004564\n",
      "[92,    99] loss: 0.002374\n",
      "[92,   199] loss: 0.001446\n",
      "[92,   299] loss: 0.001450\n",
      "[93,    99] loss: 0.001419\n",
      "[93,   199] loss: 0.000869\n",
      "[93,   299] loss: 0.001116\n",
      "[94,    99] loss: 0.001157\n",
      "[94,   199] loss: 0.000740\n",
      "[94,   299] loss: 0.000948\n",
      "[95,    99] loss: 0.001008\n",
      "[95,   199] loss: 0.000646\n",
      "[95,   299] loss: 0.000827\n",
      "[96,    99] loss: 0.000890\n",
      "[96,   199] loss: 0.000565\n",
      "[96,   299] loss: 0.000732\n",
      "[97,    99] loss: 0.000790\n",
      "[97,   199] loss: 0.000521\n",
      "[97,   299] loss: 0.000642\n",
      "[98,    99] loss: 0.000752\n",
      "[98,   199] loss: 0.000839\n",
      "[98,   299] loss: 0.000775\n",
      "[99,    99] loss: 0.000570\n",
      "[99,   199] loss: 0.000482\n",
      "[99,   299] loss: 0.000518\n",
      "[100,    99] loss: 0.060663\n",
      "[100,   199] loss: 0.068320\n",
      "[100,   299] loss: 0.004171\n",
      "Finished Training\n",
      "[1,    99] loss: 0.697262\n",
      "[1,   199] loss: 0.665940\n",
      "[1,   299] loss: 0.634272\n",
      "[2,    99] loss: 0.602513\n",
      "[2,   199] loss: 0.620603\n",
      "[2,   299] loss: 0.551109\n",
      "[3,    99] loss: 0.532703\n",
      "[3,   199] loss: 0.563023\n",
      "[3,   299] loss: 0.477676\n",
      "[4,    99] loss: 0.455983\n",
      "[4,   199] loss: 0.485556\n",
      "[4,   299] loss: 0.400804\n",
      "[5,    99] loss: 0.382052\n",
      "[5,   199] loss: 0.406751\n",
      "[5,   299] loss: 0.339900\n",
      "[6,    99] loss: 0.303395\n",
      "[6,   199] loss: 0.337821\n",
      "[6,   299] loss: 0.285658\n",
      "[7,    99] loss: 0.253630\n",
      "[7,   199] loss: 0.285049\n",
      "[7,   299] loss: 0.235766\n",
      "[8,    99] loss: 0.219979\n",
      "[8,   199] loss: 0.232087\n",
      "[8,   299] loss: 0.200473\n",
      "[9,    99] loss: 0.192265\n",
      "[9,   199] loss: 0.235595\n",
      "[9,   299] loss: 0.174211\n",
      "[10,    99] loss: 0.154190\n",
      "[10,   199] loss: 0.189540\n",
      "[10,   299] loss: 0.152545\n",
      "[11,    99] loss: 0.146121\n",
      "[11,   199] loss: 0.164300\n",
      "[11,   299] loss: 0.133578\n",
      "[12,    99] loss: 0.115126\n",
      "[12,   199] loss: 0.137271\n",
      "[12,   299] loss: 0.126987\n",
      "[13,    99] loss: 0.095627\n",
      "[13,   199] loss: 0.095683\n",
      "[13,   299] loss: 0.107039\n",
      "[14,    99] loss: 0.125443\n",
      "[14,   199] loss: 0.125546\n",
      "[14,   299] loss: 0.098951\n",
      "[15,    99] loss: 0.073133\n",
      "[15,   199] loss: 0.063783\n",
      "[15,   299] loss: 0.087283\n",
      "[16,    99] loss: 0.083773\n",
      "[16,   199] loss: 0.124169\n",
      "[16,   299] loss: 0.082309\n",
      "[17,    99] loss: 0.068368\n",
      "[17,   199] loss: 0.044478\n",
      "[17,   299] loss: 0.058091\n",
      "[18,    99] loss: 0.075297\n",
      "[18,   199] loss: 0.110397\n",
      "[18,   299] loss: 0.060983\n",
      "[19,    99] loss: 0.052398\n",
      "[19,   199] loss: 0.035468\n",
      "[19,   299] loss: 0.053274\n",
      "[20,    99] loss: 0.077488\n",
      "[20,   199] loss: 0.089824\n",
      "[20,   299] loss: 0.056943\n",
      "[21,    99] loss: 0.062070\n",
      "[21,   199] loss: 0.060351\n",
      "[21,   299] loss: 0.064195\n",
      "[22,    99] loss: 0.059200\n",
      "[22,   199] loss: 0.061674\n",
      "[22,   299] loss: 0.059009\n",
      "[23,    99] loss: 0.044167\n",
      "[23,   199] loss: 0.065523\n",
      "[23,   299] loss: 0.047394\n",
      "[24,    99] loss: 0.057664\n",
      "[24,   199] loss: 0.037983\n",
      "[24,   299] loss: 0.057765\n",
      "[25,    99] loss: 0.144838\n",
      "[25,   199] loss: 0.066106\n",
      "[25,   299] loss: 0.036100\n",
      "[26,    99] loss: 0.038790\n",
      "[26,   199] loss: 0.044883\n",
      "[26,   299] loss: 0.022030\n",
      "[27,    99] loss: 0.050237\n",
      "[27,   199] loss: 0.074833\n",
      "[27,   299] loss: 0.028375\n",
      "[28,    99] loss: 0.037375\n",
      "[28,   199] loss: 0.019944\n",
      "[28,   299] loss: 0.015693\n",
      "[29,    99] loss: 0.023707\n",
      "[29,   199] loss: 0.010586\n",
      "[29,   299] loss: 0.015625\n",
      "[30,    99] loss: 0.032755\n",
      "[30,   199] loss: 0.016505\n",
      "[30,   299] loss: 0.013314\n",
      "[31,    99] loss: 0.022628\n",
      "[31,   199] loss: 0.007760\n",
      "[31,   299] loss: 0.011180\n",
      "[32,    99] loss: 0.023797\n",
      "[32,   199] loss: 0.007934\n",
      "[32,   299] loss: 0.011909\n",
      "[33,    99] loss: 0.025584\n",
      "[33,   199] loss: 0.008202\n",
      "[33,   299] loss: 0.012768\n",
      "[34,    99] loss: 0.028325\n",
      "[34,   199] loss: 0.011137\n",
      "[34,   299] loss: 0.049606\n",
      "[35,    99] loss: 0.093273\n",
      "[35,   199] loss: 0.084390\n",
      "[35,   299] loss: 0.037102\n",
      "[36,    99] loss: 0.026813\n",
      "[36,   199] loss: 0.134836\n",
      "[36,   299] loss: 0.055776\n",
      "[37,    99] loss: 0.100230\n",
      "[37,   199] loss: 0.036345\n",
      "[37,   299] loss: 0.019051\n",
      "[38,    99] loss: 0.016189\n",
      "[38,   199] loss: 0.007676\n",
      "[38,   299] loss: 0.006028\n",
      "[39,    99] loss: 0.031105\n",
      "[39,   199] loss: 0.011354\n",
      "[39,   299] loss: 0.004990\n",
      "[40,    99] loss: 0.004690\n",
      "[40,   199] loss: 0.004367\n",
      "[40,   299] loss: 0.004514\n",
      "[41,    99] loss: 0.003696\n",
      "[41,   199] loss: 0.003482\n",
      "[41,   299] loss: 0.004598\n",
      "[42,    99] loss: 0.005679\n",
      "[42,   199] loss: 0.005125\n",
      "[42,   299] loss: 0.004635\n",
      "[43,    99] loss: 0.004276\n",
      "[43,   199] loss: 0.003231\n",
      "[43,   299] loss: 0.006356\n",
      "[44,    99] loss: 0.011949\n",
      "[44,   199] loss: 0.141245\n",
      "[44,   299] loss: 0.168064\n",
      "[45,    99] loss: 0.241332\n",
      "[45,   199] loss: 0.075486\n",
      "[45,   299] loss: 0.023228\n",
      "[46,    99] loss: 0.043872\n",
      "[46,   199] loss: 0.014074\n",
      "[46,   299] loss: 0.006582\n",
      "[47,    99] loss: 0.013592\n",
      "[47,   199] loss: 0.010012\n",
      "[47,   299] loss: 0.005251\n",
      "[48,    99] loss: 0.028170\n",
      "[48,   199] loss: 0.015674\n",
      "[48,   299] loss: 0.005331\n",
      "[49,    99] loss: 0.004399\n",
      "[49,   199] loss: 0.003988\n",
      "[49,   299] loss: 0.003671\n",
      "[50,    99] loss: 0.003014\n",
      "[50,   199] loss: 0.002810\n",
      "[50,   299] loss: 0.002942\n",
      "[51,    99] loss: 0.002290\n",
      "[51,   199] loss: 0.002337\n",
      "[51,   299] loss: 0.002376\n",
      "[52,    99] loss: 0.002010\n",
      "[52,   199] loss: 0.002014\n",
      "[52,   299] loss: 0.002000\n",
      "[53,    99] loss: 0.001819\n",
      "[53,   199] loss: 0.001746\n",
      "[53,   299] loss: 0.001831\n",
      "[54,    99] loss: 0.001841\n",
      "[54,   199] loss: 0.001502\n",
      "[54,   299] loss: 0.001633\n",
      "[55,    99] loss: 0.003613\n",
      "[55,   199] loss: 0.001613\n",
      "[55,   299] loss: 0.001823\n",
      "[56,    99] loss: 0.285609\n",
      "[56,   199] loss: 0.070534\n",
      "[56,   299] loss: 0.043476\n",
      "[57,    99] loss: 0.021626\n",
      "[57,   199] loss: 0.011462\n",
      "[57,   299] loss: 0.013840\n",
      "[58,    99] loss: 0.004220\n",
      "[58,   199] loss: 0.051013\n",
      "[58,   299] loss: 0.043891\n",
      "[59,    99] loss: 0.106372\n",
      "[59,   199] loss: 0.018121\n",
      "[59,   299] loss: 0.007090\n",
      "[60,    99] loss: 0.004797\n",
      "[60,   199] loss: 0.021344\n",
      "[60,   299] loss: 0.065358\n",
      "[61,    99] loss: 0.011825\n",
      "[61,   199] loss: 0.019920\n",
      "[61,   299] loss: 0.014085\n",
      "[62,    99] loss: 0.027527\n",
      "[62,   199] loss: 0.037897\n",
      "[62,   299] loss: 0.004130\n",
      "[63,    99] loss: 0.001945\n",
      "[63,   199] loss: 0.003039\n",
      "[63,   299] loss: 0.002794\n",
      "[64,    99] loss: 0.001246\n",
      "[64,   199] loss: 0.001902\n",
      "[64,   299] loss: 0.001973\n",
      "[65,    99] loss: 0.001129\n",
      "[65,   199] loss: 0.001381\n",
      "[65,   299] loss: 0.001620\n",
      "[66,    99] loss: 0.001003\n",
      "[66,   199] loss: 0.001184\n",
      "[66,   299] loss: 0.001374\n",
      "[67,    99] loss: 0.000910\n",
      "[67,   199] loss: 0.001041\n",
      "[67,   299] loss: 0.001206\n",
      "[68,    99] loss: 0.000843\n",
      "[68,   199] loss: 0.000925\n",
      "[68,   299] loss: 0.001078\n",
      "[69,    99] loss: 0.000789\n",
      "[69,   199] loss: 0.000855\n",
      "[69,   299] loss: 0.001018\n",
      "[70,    99] loss: 0.000771\n",
      "[70,   199] loss: 0.000834\n",
      "[70,   299] loss: 0.001067\n",
      "[71,    99] loss: 0.000978\n",
      "[71,   199] loss: 0.005348\n",
      "[71,   299] loss: 0.153309\n",
      "[72,    99] loss: 0.332631\n",
      "[72,   199] loss: 0.091761\n",
      "[72,   299] loss: 0.089743\n",
      "[73,    99] loss: 0.016207\n",
      "[73,   199] loss: 0.015171\n",
      "[73,   299] loss: 0.016359\n",
      "[74,    99] loss: 0.008070\n",
      "[74,   199] loss: 0.007422\n",
      "[74,   299] loss: 0.007230\n",
      "[75,    99] loss: 0.005598\n",
      "[75,   199] loss: 0.002684\n",
      "[75,   299] loss: 0.004190\n",
      "[76,    99] loss: 0.001529\n",
      "[76,   199] loss: 0.001928\n",
      "[76,   299] loss: 0.001855\n",
      "[77,    99] loss: 0.000997\n",
      "[77,   199] loss: 0.001457\n",
      "[77,   299] loss: 0.001572\n",
      "[78,    99] loss: 0.000859\n",
      "[78,   199] loss: 0.001219\n",
      "[78,   299] loss: 0.001417\n",
      "[79,    99] loss: 0.000765\n",
      "[79,   199] loss: 0.001049\n",
      "[79,   299] loss: 0.001297\n",
      "[80,    99] loss: 0.000683\n",
      "[80,   199] loss: 0.000885\n",
      "[80,   299] loss: 0.001165\n",
      "[81,    99] loss: 0.000622\n",
      "[81,   199] loss: 0.000771\n",
      "[81,   299] loss: 0.001112\n",
      "[82,    99] loss: 0.000671\n",
      "[82,   199] loss: 0.000663\n",
      "[82,   299] loss: 0.001175\n",
      "[83,    99] loss: 0.001627\n",
      "[83,   199] loss: 0.007714\n",
      "[83,   299] loss: 0.230020\n",
      "[84,    99] loss: 0.262282\n",
      "[84,   199] loss: 0.105189\n",
      "[84,   299] loss: 0.046437\n",
      "[85,    99] loss: 0.037585\n",
      "[85,   199] loss: 0.011536\n",
      "[85,   299] loss: 0.007139\n",
      "[86,    99] loss: 0.005833\n",
      "[86,   199] loss: 0.003469\n",
      "[86,   299] loss: 0.003610\n",
      "[87,    99] loss: 0.002993\n",
      "[87,   199] loss: 0.002385\n",
      "[87,   299] loss: 0.002405\n",
      "[88,    99] loss: 0.001366\n",
      "[88,   199] loss: 0.001652\n",
      "[88,   299] loss: 0.001879\n",
      "[89,    99] loss: 0.001181\n",
      "[89,   199] loss: 0.001380\n",
      "[89,   299] loss: 0.001545\n",
      "[90,    99] loss: 0.001056\n",
      "[90,   199] loss: 0.001168\n",
      "[90,   299] loss: 0.001306\n",
      "[91,    99] loss: 0.000956\n",
      "[91,   199] loss: 0.001000\n",
      "[91,   299] loss: 0.001115\n",
      "[92,    99] loss: 0.000840\n",
      "[92,   199] loss: 0.000870\n",
      "[92,   299] loss: 0.000949\n",
      "[93,    99] loss: 0.000768\n",
      "[93,   199] loss: 0.000757\n",
      "[93,   299] loss: 0.000826\n",
      "[94,    99] loss: 0.000698\n",
      "[94,   199] loss: 0.000655\n",
      "[94,   299] loss: 0.000748\n",
      "[95,    99] loss: 0.000636\n",
      "[95,   199] loss: 0.000577\n",
      "[95,   299] loss: 0.000679\n",
      "[96,    99] loss: 0.000583\n",
      "[96,   199] loss: 0.000508\n",
      "[96,   299] loss: 0.000632\n",
      "[97,    99] loss: 0.000569\n",
      "[97,   199] loss: 0.000447\n",
      "[97,   299] loss: 0.000784\n",
      "[98,    99] loss: 0.002128\n",
      "[98,   199] loss: 0.225132\n",
      "[98,   299] loss: 0.077446\n",
      "[99,    99] loss: 0.146160\n",
      "[99,   199] loss: 0.070091\n",
      "[99,   299] loss: 0.051013\n",
      "[100,    99] loss: 0.011002\n",
      "[100,   199] loss: 0.013887\n",
      "[100,   299] loss: 0.008654\n",
      "Finished Training\n",
      "[1,    99] loss: 0.695902\n",
      "[1,   199] loss: 0.688981\n",
      "[1,   299] loss: 0.691385\n",
      "[2,    99] loss: 0.684912\n",
      "[2,   199] loss: 0.679751\n",
      "[2,   299] loss: 0.678811\n",
      "[3,    99] loss: 0.674922\n",
      "[3,   199] loss: 0.668961\n",
      "[3,   299] loss: 0.665135\n",
      "[4,    99] loss: 0.662505\n",
      "[4,   199] loss: 0.654838\n",
      "[4,   299] loss: 0.649701\n",
      "[5,    99] loss: 0.647274\n",
      "[5,   199] loss: 0.638260\n",
      "[5,   299] loss: 0.632265\n",
      "[6,    99] loss: 0.630573\n",
      "[6,   199] loss: 0.620796\n",
      "[6,   299] loss: 0.613824\n",
      "[7,    99] loss: 0.612625\n",
      "[7,   199] loss: 0.603085\n",
      "[7,   299] loss: 0.594812\n",
      "[8,    99] loss: 0.594092\n",
      "[8,   199] loss: 0.585834\n",
      "[8,   299] loss: 0.576531\n",
      "[9,    99] loss: 0.575827\n",
      "[9,   199] loss: 0.569812\n",
      "[9,   299] loss: 0.558304\n",
      "[10,    99] loss: 0.558110\n",
      "[10,   199] loss: 0.554527\n",
      "[10,   299] loss: 0.540385\n",
      "[11,    99] loss: 0.540850\n",
      "[11,   199] loss: 0.539835\n",
      "[11,   299] loss: 0.522574\n",
      "[12,    99] loss: 0.523503\n",
      "[12,   199] loss: 0.525685\n",
      "[12,   299] loss: 0.505104\n",
      "[13,    99] loss: 0.506600\n",
      "[13,   199] loss: 0.511900\n",
      "[13,   299] loss: 0.487656\n",
      "[14,    99] loss: 0.490070\n",
      "[14,   199] loss: 0.498639\n",
      "[14,   299] loss: 0.470467\n",
      "[15,    99] loss: 0.473902\n",
      "[15,   199] loss: 0.485375\n",
      "[15,   299] loss: 0.453957\n",
      "[16,    99] loss: 0.457819\n",
      "[16,   199] loss: 0.472571\n",
      "[16,   299] loss: 0.437335\n",
      "[17,    99] loss: 0.442119\n",
      "[17,   199] loss: 0.460133\n",
      "[17,   299] loss: 0.421308\n",
      "[18,    99] loss: 0.426906\n",
      "[18,   199] loss: 0.448211\n",
      "[18,   299] loss: 0.405954\n",
      "[19,    99] loss: 0.412212\n",
      "[19,   199] loss: 0.436378\n",
      "[19,   299] loss: 0.390982\n",
      "[20,    99] loss: 0.397776\n",
      "[20,   199] loss: 0.424511\n",
      "[20,   299] loss: 0.376626\n",
      "[21,    99] loss: 0.383955\n",
      "[21,   199] loss: 0.412733\n",
      "[21,   299] loss: 0.362806\n",
      "[22,    99] loss: 0.370517\n",
      "[22,   199] loss: 0.401262\n",
      "[22,   299] loss: 0.349655\n",
      "[23,    99] loss: 0.357474\n",
      "[23,   199] loss: 0.390241\n",
      "[23,   299] loss: 0.336831\n",
      "[24,    99] loss: 0.345129\n",
      "[24,   199] loss: 0.379747\n",
      "[24,   299] loss: 0.324438\n",
      "[25,    99] loss: 0.333183\n",
      "[25,   199] loss: 0.368996\n",
      "[25,   299] loss: 0.312835\n",
      "[26,    99] loss: 0.322033\n",
      "[26,   199] loss: 0.358810\n",
      "[26,   299] loss: 0.301526\n",
      "[27,    99] loss: 0.310903\n",
      "[27,   199] loss: 0.348900\n",
      "[27,   299] loss: 0.290572\n",
      "[28,    99] loss: 0.300503\n",
      "[28,   199] loss: 0.339184\n",
      "[28,   299] loss: 0.280072\n",
      "[29,    99] loss: 0.290463\n",
      "[29,   199] loss: 0.329812\n",
      "[29,   299] loss: 0.270082\n",
      "[30,    99] loss: 0.280818\n",
      "[30,   199] loss: 0.320426\n",
      "[30,   299] loss: 0.260387\n",
      "[31,    99] loss: 0.271664\n",
      "[31,   199] loss: 0.311215\n",
      "[31,   299] loss: 0.251340\n",
      "[32,    99] loss: 0.262854\n",
      "[32,   199] loss: 0.302382\n",
      "[32,   299] loss: 0.242548\n",
      "[33,    99] loss: 0.253974\n",
      "[33,   199] loss: 0.293785\n",
      "[33,   299] loss: 0.233918\n",
      "[34,    99] loss: 0.246076\n",
      "[34,   199] loss: 0.284943\n",
      "[34,   299] loss: 0.226179\n",
      "[35,    99] loss: 0.238290\n",
      "[35,   199] loss: 0.276514\n",
      "[35,   299] loss: 0.218280\n",
      "[36,    99] loss: 0.230730\n",
      "[36,   199] loss: 0.268542\n",
      "[36,   299] loss: 0.210766\n",
      "[37,    99] loss: 0.223554\n",
      "[37,   199] loss: 0.260665\n",
      "[37,   299] loss: 0.203550\n",
      "[38,    99] loss: 0.216698\n",
      "[38,   199] loss: 0.252977\n",
      "[38,   299] loss: 0.196758\n",
      "[39,    99] loss: 0.210074\n",
      "[39,   199] loss: 0.245317\n",
      "[39,   299] loss: 0.190271\n",
      "[40,    99] loss: 0.203656\n",
      "[40,   199] loss: 0.238096\n",
      "[40,   299] loss: 0.184020\n",
      "[41,    99] loss: 0.197744\n",
      "[41,   199] loss: 0.231007\n",
      "[41,   299] loss: 0.177851\n",
      "[42,    99] loss: 0.192063\n",
      "[42,   199] loss: 0.224163\n",
      "[42,   299] loss: 0.172068\n",
      "[43,    99] loss: 0.186636\n",
      "[43,   199] loss: 0.217570\n",
      "[43,   299] loss: 0.166607\n",
      "[44,    99] loss: 0.181602\n",
      "[44,   199] loss: 0.211016\n",
      "[44,   299] loss: 0.161420\n",
      "[45,    99] loss: 0.176537\n",
      "[45,   199] loss: 0.204566\n",
      "[45,   299] loss: 0.156358\n",
      "[46,    99] loss: 0.171751\n",
      "[46,   199] loss: 0.198299\n",
      "[46,   299] loss: 0.151363\n",
      "[47,    99] loss: 0.167329\n",
      "[47,   199] loss: 0.192261\n",
      "[47,   299] loss: 0.146532\n",
      "[48,    99] loss: 0.162773\n",
      "[48,   199] loss: 0.186278\n",
      "[48,   299] loss: 0.141782\n",
      "[49,    99] loss: 0.158542\n",
      "[49,   199] loss: 0.180845\n",
      "[49,   299] loss: 0.137297\n",
      "[50,    99] loss: 0.154276\n",
      "[50,   199] loss: 0.175076\n",
      "[50,   299] loss: 0.133209\n",
      "[51,    99] loss: 0.150343\n",
      "[51,   199] loss: 0.170030\n",
      "[51,   299] loss: 0.128962\n",
      "[52,    99] loss: 0.146648\n",
      "[52,   199] loss: 0.164753\n",
      "[52,   299] loss: 0.124920\n",
      "[53,    99] loss: 0.142776\n",
      "[53,   199] loss: 0.159751\n",
      "[53,   299] loss: 0.121290\n",
      "[54,    99] loss: 0.139097\n",
      "[54,   199] loss: 0.154999\n",
      "[54,   299] loss: 0.117512\n",
      "[55,    99] loss: 0.135845\n",
      "[55,   199] loss: 0.150493\n",
      "[55,   299] loss: 0.113834\n",
      "[56,    99] loss: 0.132533\n",
      "[56,   199] loss: 0.145866\n",
      "[56,   299] loss: 0.110666\n",
      "[57,    99] loss: 0.129168\n",
      "[57,   199] loss: 0.141578\n",
      "[57,   299] loss: 0.107141\n",
      "[58,    99] loss: 0.126145\n",
      "[58,   199] loss: 0.137354\n",
      "[58,   299] loss: 0.103833\n",
      "[59,    99] loss: 0.123085\n",
      "[59,   199] loss: 0.133467\n",
      "[59,   299] loss: 0.100791\n",
      "[60,    99] loss: 0.120316\n",
      "[60,   199] loss: 0.129639\n",
      "[60,   299] loss: 0.098035\n",
      "[61,    99] loss: 0.117179\n",
      "[61,   199] loss: 0.125798\n",
      "[61,   299] loss: 0.094912\n",
      "[62,    99] loss: 0.114555\n",
      "[62,   199] loss: 0.122050\n",
      "[62,   299] loss: 0.091993\n",
      "[63,    99] loss: 0.111969\n",
      "[63,   199] loss: 0.118670\n",
      "[63,   299] loss: 0.089032\n",
      "[64,    99] loss: 0.109502\n",
      "[64,   199] loss: 0.115274\n",
      "[64,   299] loss: 0.086617\n",
      "[65,    99] loss: 0.106907\n",
      "[65,   199] loss: 0.112284\n",
      "[65,   299] loss: 0.084079\n",
      "[66,    99] loss: 0.104532\n",
      "[66,   199] loss: 0.109191\n",
      "[66,   299] loss: 0.081202\n",
      "[67,    99] loss: 0.102310\n",
      "[67,   199] loss: 0.106281\n",
      "[67,   299] loss: 0.078886\n",
      "[68,    99] loss: 0.100189\n",
      "[68,   199] loss: 0.103403\n",
      "[68,   299] loss: 0.076291\n",
      "[69,    99] loss: 0.098104\n",
      "[69,   199] loss: 0.100588\n",
      "[69,   299] loss: 0.074220\n",
      "[70,    99] loss: 0.095908\n",
      "[70,   199] loss: 0.098276\n",
      "[70,   299] loss: 0.071744\n",
      "[71,    99] loss: 0.093874\n",
      "[71,   199] loss: 0.095899\n",
      "[71,   299] loss: 0.069364\n",
      "[72,    99] loss: 0.091977\n",
      "[72,   199] loss: 0.093211\n",
      "[72,   299] loss: 0.067380\n",
      "[73,    99] loss: 0.090155\n",
      "[73,   199] loss: 0.091062\n",
      "[73,   299] loss: 0.065225\n",
      "[74,    99] loss: 0.088515\n",
      "[74,   199] loss: 0.088338\n",
      "[74,   299] loss: 0.063093\n",
      "[75,    99] loss: 0.086756\n",
      "[75,   199] loss: 0.086586\n",
      "[75,   299] loss: 0.061184\n",
      "[76,    99] loss: 0.084959\n",
      "[76,   199] loss: 0.084570\n",
      "[76,   299] loss: 0.059324\n",
      "[77,    99] loss: 0.083404\n",
      "[77,   199] loss: 0.082766\n",
      "[77,   299] loss: 0.057489\n",
      "[78,    99] loss: 0.081686\n",
      "[78,   199] loss: 0.080586\n",
      "[78,   299] loss: 0.055596\n",
      "[79,    99] loss: 0.080070\n",
      "[79,   199] loss: 0.079355\n",
      "[79,   299] loss: 0.054167\n",
      "[80,    99] loss: 0.078672\n",
      "[80,   199] loss: 0.077164\n",
      "[80,   299] loss: 0.052234\n",
      "[81,    99] loss: 0.077131\n",
      "[81,   199] loss: 0.075494\n",
      "[81,   299] loss: 0.050957\n",
      "[82,    99] loss: 0.075664\n",
      "[82,   199] loss: 0.073865\n",
      "[82,   299] loss: 0.049054\n",
      "[83,    99] loss: 0.074189\n",
      "[83,   199] loss: 0.072335\n",
      "[83,   299] loss: 0.047832\n",
      "[84,    99] loss: 0.072756\n",
      "[84,   199] loss: 0.070495\n",
      "[84,   299] loss: 0.046243\n",
      "[85,    99] loss: 0.071355\n",
      "[85,   199] loss: 0.068912\n",
      "[85,   299] loss: 0.044922\n",
      "[86,    99] loss: 0.069945\n",
      "[86,   199] loss: 0.067780\n",
      "[86,   299] loss: 0.043551\n",
      "[87,    99] loss: 0.068732\n",
      "[87,   199] loss: 0.066177\n",
      "[87,   299] loss: 0.042161\n",
      "[88,    99] loss: 0.067349\n",
      "[88,   199] loss: 0.064771\n",
      "[88,   299] loss: 0.040800\n",
      "[89,    99] loss: 0.066086\n",
      "[89,   199] loss: 0.063561\n",
      "[89,   299] loss: 0.039632\n",
      "[90,    99] loss: 0.064835\n",
      "[90,   199] loss: 0.062117\n",
      "[90,   299] loss: 0.038399\n",
      "[91,    99] loss: 0.063580\n",
      "[91,   199] loss: 0.060720\n",
      "[91,   299] loss: 0.037385\n",
      "[92,    99] loss: 0.062163\n",
      "[92,   199] loss: 0.059547\n",
      "[92,   299] loss: 0.036309\n",
      "[93,    99] loss: 0.061149\n",
      "[93,   199] loss: 0.058052\n",
      "[93,   299] loss: 0.035157\n",
      "[94,    99] loss: 0.059927\n",
      "[94,   199] loss: 0.057103\n",
      "[94,   299] loss: 0.034159\n",
      "[95,    99] loss: 0.058916\n",
      "[95,   199] loss: 0.056080\n",
      "[95,   299] loss: 0.033113\n",
      "[96,    99] loss: 0.057582\n",
      "[96,   199] loss: 0.054834\n",
      "[96,   299] loss: 0.032173\n",
      "[97,    99] loss: 0.056482\n",
      "[97,   199] loss: 0.053614\n",
      "[97,   299] loss: 0.031102\n",
      "[98,    99] loss: 0.055486\n",
      "[98,   199] loss: 0.052762\n",
      "[98,   299] loss: 0.030238\n",
      "[99,    99] loss: 0.054353\n",
      "[99,   199] loss: 0.051693\n",
      "[99,   299] loss: 0.029345\n",
      "[100,    99] loss: 0.053327\n",
      "[100,   199] loss: 0.050465\n",
      "[100,   299] loss: 0.028539\n",
      "Finished Training\n",
      "[1,    99] loss: 0.695672\n",
      "[1,   199] loss: 0.687223\n",
      "[1,   299] loss: 0.690670\n",
      "[2,    99] loss: 0.658461\n",
      "[2,   199] loss: 0.670092\n",
      "[2,   299] loss: 0.667365\n",
      "[3,    99] loss: 0.632623\n",
      "[3,   199] loss: 0.658489\n",
      "[3,   299] loss: 0.651395\n",
      "[4,    99] loss: 0.614018\n",
      "[4,   199] loss: 0.649353\n",
      "[4,   299] loss: 0.638993\n",
      "[5,    99] loss: 0.599100\n",
      "[5,   199] loss: 0.640243\n",
      "[5,   299] loss: 0.627110\n",
      "[6,    99] loss: 0.585566\n",
      "[6,   199] loss: 0.630726\n",
      "[6,   299] loss: 0.615532\n",
      "[7,    99] loss: 0.572347\n",
      "[7,   199] loss: 0.620772\n",
      "[7,   299] loss: 0.604056\n",
      "[8,    99] loss: 0.559937\n",
      "[8,   199] loss: 0.610407\n",
      "[8,   299] loss: 0.592687\n",
      "[9,    99] loss: 0.547553\n",
      "[9,   199] loss: 0.599720\n",
      "[9,   299] loss: 0.581115\n",
      "[10,    99] loss: 0.535373\n",
      "[10,   199] loss: 0.588188\n",
      "[10,   299] loss: 0.569398\n",
      "[11,    99] loss: 0.523250\n",
      "[11,   199] loss: 0.576269\n",
      "[11,   299] loss: 0.557144\n",
      "[12,    99] loss: 0.511293\n",
      "[12,   199] loss: 0.564017\n",
      "[12,   299] loss: 0.544587\n",
      "[13,    99] loss: 0.499509\n",
      "[13,   199] loss: 0.551083\n",
      "[13,   299] loss: 0.532165\n",
      "[14,    99] loss: 0.487684\n",
      "[14,   199] loss: 0.537693\n",
      "[14,   299] loss: 0.519689\n",
      "[15,    99] loss: 0.476091\n",
      "[15,   199] loss: 0.524522\n",
      "[15,   299] loss: 0.507239\n",
      "[16,    99] loss: 0.464601\n",
      "[16,   199] loss: 0.511261\n",
      "[16,   299] loss: 0.494771\n",
      "[17,    99] loss: 0.453242\n",
      "[17,   199] loss: 0.497846\n",
      "[17,   299] loss: 0.482378\n",
      "[18,    99] loss: 0.442203\n",
      "[18,   199] loss: 0.484607\n",
      "[18,   299] loss: 0.469962\n",
      "[19,    99] loss: 0.431258\n",
      "[19,   199] loss: 0.471596\n",
      "[19,   299] loss: 0.457690\n",
      "[20,    99] loss: 0.420892\n",
      "[20,   199] loss: 0.458437\n",
      "[20,   299] loss: 0.445743\n",
      "[21,    99] loss: 0.410606\n",
      "[21,   199] loss: 0.445769\n",
      "[21,   299] loss: 0.433935\n",
      "[22,    99] loss: 0.400506\n",
      "[22,   199] loss: 0.433292\n",
      "[22,   299] loss: 0.422429\n",
      "[23,    99] loss: 0.390543\n",
      "[23,   199] loss: 0.421512\n",
      "[23,   299] loss: 0.411473\n",
      "[24,    99] loss: 0.380788\n",
      "[24,   199] loss: 0.409455\n",
      "[24,   299] loss: 0.400514\n",
      "[25,    99] loss: 0.371415\n",
      "[25,   199] loss: 0.397882\n",
      "[25,   299] loss: 0.389646\n",
      "[26,    99] loss: 0.362206\n",
      "[26,   199] loss: 0.386500\n",
      "[26,   299] loss: 0.379197\n",
      "[27,    99] loss: 0.353531\n",
      "[27,   199] loss: 0.375594\n",
      "[27,   299] loss: 0.368994\n",
      "[28,    99] loss: 0.344849\n",
      "[28,   199] loss: 0.364774\n",
      "[28,   299] loss: 0.359132\n",
      "[29,    99] loss: 0.336576\n",
      "[29,   199] loss: 0.354415\n",
      "[29,   299] loss: 0.349726\n",
      "[30,    99] loss: 0.328650\n",
      "[30,   199] loss: 0.344550\n",
      "[30,   299] loss: 0.340287\n",
      "[31,    99] loss: 0.320397\n",
      "[31,   199] loss: 0.334961\n",
      "[31,   299] loss: 0.331238\n",
      "[32,    99] loss: 0.312698\n",
      "[32,   199] loss: 0.325288\n",
      "[32,   299] loss: 0.322291\n",
      "[33,    99] loss: 0.304685\n",
      "[33,   199] loss: 0.316527\n",
      "[33,   299] loss: 0.313991\n",
      "[34,    99] loss: 0.296536\n",
      "[34,   199] loss: 0.307926\n",
      "[34,   299] loss: 0.305758\n",
      "[35,    99] loss: 0.289305\n",
      "[35,   199] loss: 0.299544\n",
      "[35,   299] loss: 0.297697\n",
      "[36,    99] loss: 0.281556\n",
      "[36,   199] loss: 0.291544\n",
      "[36,   299] loss: 0.289850\n",
      "[37,    99] loss: 0.274371\n",
      "[37,   199] loss: 0.284057\n",
      "[37,   299] loss: 0.282086\n",
      "[38,    99] loss: 0.266660\n",
      "[38,   199] loss: 0.276834\n",
      "[38,   299] loss: 0.274583\n",
      "[39,    99] loss: 0.260055\n",
      "[39,   199] loss: 0.269690\n",
      "[39,   299] loss: 0.266709\n",
      "[40,    99] loss: 0.252835\n",
      "[40,   199] loss: 0.262624\n",
      "[40,   299] loss: 0.259431\n",
      "[41,    99] loss: 0.246537\n",
      "[41,   199] loss: 0.255982\n",
      "[41,   299] loss: 0.252241\n",
      "[42,    99] loss: 0.239439\n",
      "[42,   199] loss: 0.249432\n",
      "[42,   299] loss: 0.245355\n",
      "[43,    99] loss: 0.233047\n",
      "[43,   199] loss: 0.243122\n",
      "[43,   299] loss: 0.238695\n",
      "[44,    99] loss: 0.226261\n",
      "[44,   199] loss: 0.237220\n",
      "[44,   299] loss: 0.232333\n",
      "[45,    99] loss: 0.219729\n",
      "[45,   199] loss: 0.231133\n",
      "[45,   299] loss: 0.226035\n",
      "[46,    99] loss: 0.213323\n",
      "[46,   199] loss: 0.225652\n",
      "[46,   299] loss: 0.219913\n",
      "[47,    99] loss: 0.207026\n",
      "[47,   199] loss: 0.220272\n",
      "[47,   299] loss: 0.213964\n",
      "[48,    99] loss: 0.201014\n",
      "[48,   199] loss: 0.214849\n",
      "[48,   299] loss: 0.208201\n",
      "[49,    99] loss: 0.194778\n",
      "[49,   199] loss: 0.209815\n",
      "[49,   299] loss: 0.202327\n",
      "[50,    99] loss: 0.189122\n",
      "[50,   199] loss: 0.204692\n",
      "[50,   299] loss: 0.197184\n",
      "[51,    99] loss: 0.183171\n",
      "[51,   199] loss: 0.200183\n",
      "[51,   299] loss: 0.191641\n",
      "[52,    99] loss: 0.178404\n",
      "[52,   199] loss: 0.195062\n",
      "[52,   299] loss: 0.186617\n",
      "[53,    99] loss: 0.172522\n",
      "[53,   199] loss: 0.190511\n",
      "[53,   299] loss: 0.181587\n",
      "[54,    99] loss: 0.167958\n",
      "[54,   199] loss: 0.186026\n",
      "[54,   299] loss: 0.176674\n",
      "[55,    99] loss: 0.162681\n",
      "[55,   199] loss: 0.181677\n",
      "[55,   299] loss: 0.171653\n",
      "[56,    99] loss: 0.157955\n",
      "[56,   199] loss: 0.177357\n",
      "[56,   299] loss: 0.166756\n",
      "[57,    99] loss: 0.152960\n",
      "[57,   199] loss: 0.173674\n",
      "[57,   299] loss: 0.161967\n",
      "[58,    99] loss: 0.148778\n",
      "[58,   199] loss: 0.169685\n",
      "[58,   299] loss: 0.157772\n",
      "[59,    99] loss: 0.144308\n",
      "[59,   199] loss: 0.165534\n",
      "[59,   299] loss: 0.153358\n",
      "[60,    99] loss: 0.140039\n",
      "[60,   199] loss: 0.161957\n",
      "[60,   299] loss: 0.148812\n",
      "[61,    99] loss: 0.135696\n",
      "[61,   199] loss: 0.158510\n",
      "[61,   299] loss: 0.144350\n",
      "[62,    99] loss: 0.131888\n",
      "[62,   199] loss: 0.154825\n",
      "[62,   299] loss: 0.140234\n",
      "[63,    99] loss: 0.127562\n",
      "[63,   199] loss: 0.151516\n",
      "[63,   299] loss: 0.136168\n",
      "[64,    99] loss: 0.124168\n",
      "[64,   199] loss: 0.148110\n",
      "[64,   299] loss: 0.132212\n",
      "[65,    99] loss: 0.119955\n",
      "[65,   199] loss: 0.144877\n",
      "[65,   299] loss: 0.128042\n",
      "[66,    99] loss: 0.117329\n",
      "[66,   199] loss: 0.141641\n",
      "[66,   299] loss: 0.124384\n",
      "[67,    99] loss: 0.112982\n",
      "[67,   199] loss: 0.138531\n",
      "[67,   299] loss: 0.120792\n",
      "[68,    99] loss: 0.109524\n",
      "[68,   199] loss: 0.135509\n",
      "[68,   299] loss: 0.116788\n",
      "[69,    99] loss: 0.106827\n",
      "[69,   199] loss: 0.132658\n",
      "[69,   299] loss: 0.113638\n",
      "[70,    99] loss: 0.103090\n",
      "[70,   199] loss: 0.129450\n",
      "[70,   299] loss: 0.110081\n",
      "[71,    99] loss: 0.099732\n",
      "[71,   199] loss: 0.126649\n",
      "[71,   299] loss: 0.107063\n",
      "[72,    99] loss: 0.096823\n",
      "[72,   199] loss: 0.123444\n",
      "[72,   299] loss: 0.103497\n",
      "[73,    99] loss: 0.094450\n",
      "[73,   199] loss: 0.120840\n",
      "[73,   299] loss: 0.100387\n",
      "[74,    99] loss: 0.090937\n",
      "[74,   199] loss: 0.118098\n",
      "[74,   299] loss: 0.097207\n",
      "[75,    99] loss: 0.088373\n",
      "[75,   199] loss: 0.115328\n",
      "[75,   299] loss: 0.094383\n",
      "[76,    99] loss: 0.085517\n",
      "[76,   199] loss: 0.112635\n",
      "[76,   299] loss: 0.091520\n",
      "[77,    99] loss: 0.083249\n",
      "[77,   199] loss: 0.110145\n",
      "[77,   299] loss: 0.088519\n",
      "[78,    99] loss: 0.080315\n",
      "[78,   199] loss: 0.107554\n",
      "[78,   299] loss: 0.085764\n",
      "[79,    99] loss: 0.078288\n",
      "[79,   199] loss: 0.104959\n",
      "[79,   299] loss: 0.083147\n",
      "[80,    99] loss: 0.075340\n",
      "[80,   199] loss: 0.102705\n",
      "[80,   299] loss: 0.080501\n",
      "[81,    99] loss: 0.073788\n",
      "[81,   199] loss: 0.100401\n",
      "[81,   299] loss: 0.078288\n",
      "[82,    99] loss: 0.071409\n",
      "[82,   199] loss: 0.097737\n",
      "[82,   299] loss: 0.075692\n",
      "[83,    99] loss: 0.069241\n",
      "[83,   199] loss: 0.095749\n",
      "[83,   299] loss: 0.073495\n",
      "[84,    99] loss: 0.067137\n",
      "[84,   199] loss: 0.093148\n",
      "[84,   299] loss: 0.071124\n",
      "[85,    99] loss: 0.064947\n",
      "[85,   199] loss: 0.091122\n",
      "[85,   299] loss: 0.068834\n",
      "[86,    99] loss: 0.062808\n",
      "[86,   199] loss: 0.089274\n",
      "[86,   299] loss: 0.066693\n",
      "[87,    99] loss: 0.061108\n",
      "[87,   199] loss: 0.087276\n",
      "[87,   299] loss: 0.064735\n",
      "[88,    99] loss: 0.059166\n",
      "[88,   199] loss: 0.085040\n",
      "[88,   299] loss: 0.062857\n",
      "[89,    99] loss: 0.057377\n",
      "[89,   199] loss: 0.083251\n",
      "[89,   299] loss: 0.060748\n",
      "[90,    99] loss: 0.055676\n",
      "[90,   199] loss: 0.081439\n",
      "[90,   299] loss: 0.059009\n",
      "[91,    99] loss: 0.054080\n",
      "[91,   199] loss: 0.079318\n",
      "[91,   299] loss: 0.057144\n",
      "[92,    99] loss: 0.051995\n",
      "[92,   199] loss: 0.077723\n",
      "[92,   299] loss: 0.055703\n",
      "[93,    99] loss: 0.050737\n",
      "[93,   199] loss: 0.075804\n",
      "[93,   299] loss: 0.054068\n",
      "[94,    99] loss: 0.049204\n",
      "[94,   199] loss: 0.073643\n",
      "[94,   299] loss: 0.052389\n",
      "[95,    99] loss: 0.047670\n",
      "[95,   199] loss: 0.071756\n",
      "[95,   299] loss: 0.050960\n",
      "[96,    99] loss: 0.046152\n",
      "[96,   199] loss: 0.070198\n",
      "[96,   299] loss: 0.049236\n",
      "[97,    99] loss: 0.044893\n",
      "[97,   199] loss: 0.068040\n",
      "[97,   299] loss: 0.047853\n",
      "[98,    99] loss: 0.043309\n",
      "[98,   199] loss: 0.066872\n",
      "[98,   299] loss: 0.046530\n",
      "[99,    99] loss: 0.041982\n",
      "[99,   199] loss: 0.064876\n",
      "[99,   299] loss: 0.044981\n",
      "[100,    99] loss: 0.040966\n",
      "[100,   199] loss: 0.063315\n",
      "[100,   299] loss: 0.043536\n",
      "Finished Training\n",
      "[1,    99] loss: 0.695343\n",
      "[1,   199] loss: 0.691593\n",
      "[1,   299] loss: 0.688982\n",
      "[2,    99] loss: 0.680407\n",
      "[2,   199] loss: 0.678144\n",
      "[2,   299] loss: 0.678662\n",
      "[3,    99] loss: 0.670934\n",
      "[3,   199] loss: 0.667906\n",
      "[3,   299] loss: 0.669362\n",
      "[4,    99] loss: 0.660957\n",
      "[4,   199] loss: 0.657144\n",
      "[4,   299] loss: 0.659152\n",
      "[5,    99] loss: 0.649344\n",
      "[5,   199] loss: 0.645068\n",
      "[5,   299] loss: 0.647166\n",
      "[6,    99] loss: 0.637094\n",
      "[6,   199] loss: 0.632796\n",
      "[6,   299] loss: 0.634847\n",
      "[7,    99] loss: 0.624988\n",
      "[7,   199] loss: 0.620423\n",
      "[7,   299] loss: 0.621475\n",
      "[8,    99] loss: 0.612349\n",
      "[8,   199] loss: 0.607720\n",
      "[8,   299] loss: 0.607845\n",
      "[9,    99] loss: 0.598972\n",
      "[9,   199] loss: 0.594856\n",
      "[9,   299] loss: 0.593327\n",
      "[10,    99] loss: 0.585993\n",
      "[10,   199] loss: 0.582668\n",
      "[10,   299] loss: 0.579627\n",
      "[11,    99] loss: 0.572891\n",
      "[11,   199] loss: 0.571208\n",
      "[11,   299] loss: 0.565834\n",
      "[12,    99] loss: 0.560322\n",
      "[12,   199] loss: 0.560191\n",
      "[12,   299] loss: 0.552066\n",
      "[13,    99] loss: 0.548221\n",
      "[13,   199] loss: 0.549152\n",
      "[13,   299] loss: 0.538316\n",
      "[14,    99] loss: 0.536193\n",
      "[14,   199] loss: 0.538241\n",
      "[14,   299] loss: 0.524746\n",
      "[15,    99] loss: 0.524288\n",
      "[15,   199] loss: 0.527715\n",
      "[15,   299] loss: 0.511222\n",
      "[16,    99] loss: 0.512794\n",
      "[16,   199] loss: 0.517172\n",
      "[16,   299] loss: 0.497691\n",
      "[17,    99] loss: 0.501425\n",
      "[17,   199] loss: 0.506881\n",
      "[17,   299] loss: 0.484153\n",
      "[18,    99] loss: 0.489981\n",
      "[18,   199] loss: 0.496660\n",
      "[18,   299] loss: 0.470841\n",
      "[19,    99] loss: 0.478629\n",
      "[19,   199] loss: 0.486331\n",
      "[19,   299] loss: 0.457385\n",
      "[20,    99] loss: 0.467625\n",
      "[20,   199] loss: 0.476145\n",
      "[20,   299] loss: 0.443873\n",
      "[21,    99] loss: 0.456866\n",
      "[21,   199] loss: 0.466086\n",
      "[21,   299] loss: 0.430650\n",
      "[22,    99] loss: 0.446261\n",
      "[22,   199] loss: 0.455834\n",
      "[22,   299] loss: 0.417705\n",
      "[23,    99] loss: 0.435932\n",
      "[23,   199] loss: 0.445766\n",
      "[23,   299] loss: 0.404758\n",
      "[24,    99] loss: 0.425771\n",
      "[24,   199] loss: 0.435598\n",
      "[24,   299] loss: 0.391896\n",
      "[25,    99] loss: 0.415652\n",
      "[25,   199] loss: 0.425446\n",
      "[25,   299] loss: 0.378973\n",
      "[26,    99] loss: 0.405975\n",
      "[26,   199] loss: 0.415447\n",
      "[26,   299] loss: 0.366178\n",
      "[27,    99] loss: 0.396380\n",
      "[27,   199] loss: 0.405537\n",
      "[27,   299] loss: 0.354033\n",
      "[28,    99] loss: 0.387099\n",
      "[28,   199] loss: 0.395644\n",
      "[28,   299] loss: 0.342157\n",
      "[29,    99] loss: 0.378128\n",
      "[29,   199] loss: 0.385760\n",
      "[29,   299] loss: 0.330708\n",
      "[30,    99] loss: 0.369320\n",
      "[30,   199] loss: 0.376221\n",
      "[30,   299] loss: 0.319365\n",
      "[31,    99] loss: 0.360881\n",
      "[31,   199] loss: 0.367088\n",
      "[31,   299] loss: 0.308619\n",
      "[32,    99] loss: 0.352542\n",
      "[32,   199] loss: 0.357590\n",
      "[32,   299] loss: 0.298258\n",
      "[33,    99] loss: 0.344645\n",
      "[33,   199] loss: 0.348294\n",
      "[33,   299] loss: 0.288279\n",
      "[34,    99] loss: 0.337008\n",
      "[34,   199] loss: 0.339001\n",
      "[34,   299] loss: 0.278935\n",
      "[35,    99] loss: 0.329459\n",
      "[35,   199] loss: 0.330039\n",
      "[35,   299] loss: 0.269688\n",
      "[36,    99] loss: 0.322353\n",
      "[36,   199] loss: 0.321140\n",
      "[36,   299] loss: 0.260878\n",
      "[37,    99] loss: 0.315304\n",
      "[37,   199] loss: 0.312487\n",
      "[37,   299] loss: 0.252503\n",
      "[38,    99] loss: 0.308487\n",
      "[38,   199] loss: 0.304039\n",
      "[38,   299] loss: 0.244407\n",
      "[39,    99] loss: 0.301623\n",
      "[39,   199] loss: 0.295754\n",
      "[39,   299] loss: 0.236374\n",
      "[40,    99] loss: 0.294998\n",
      "[40,   199] loss: 0.287836\n",
      "[40,   299] loss: 0.228706\n",
      "[41,    99] loss: 0.288620\n",
      "[41,   199] loss: 0.280147\n",
      "[41,   299] loss: 0.221467\n",
      "[42,    99] loss: 0.282434\n",
      "[42,   199] loss: 0.272527\n",
      "[42,   299] loss: 0.214178\n",
      "[43,    99] loss: 0.276632\n",
      "[43,   199] loss: 0.265063\n",
      "[43,   299] loss: 0.207858\n",
      "[44,    99] loss: 0.270721\n",
      "[44,   199] loss: 0.257936\n",
      "[44,   299] loss: 0.201233\n",
      "[45,    99] loss: 0.265095\n",
      "[45,   199] loss: 0.250914\n",
      "[45,   299] loss: 0.195408\n",
      "[46,    99] loss: 0.259340\n",
      "[46,   199] loss: 0.244114\n",
      "[46,   299] loss: 0.189580\n",
      "[47,    99] loss: 0.253751\n",
      "[47,   199] loss: 0.237328\n",
      "[47,   299] loss: 0.184012\n",
      "[48,    99] loss: 0.248338\n",
      "[48,   199] loss: 0.230451\n",
      "[48,   299] loss: 0.178913\n",
      "[49,    99] loss: 0.243022\n",
      "[49,   199] loss: 0.223850\n",
      "[49,   299] loss: 0.173327\n",
      "[50,    99] loss: 0.237137\n",
      "[50,   199] loss: 0.217293\n",
      "[50,   299] loss: 0.168775\n",
      "[51,    99] loss: 0.232396\n",
      "[51,   199] loss: 0.210993\n",
      "[51,   299] loss: 0.163618\n",
      "[52,    99] loss: 0.227178\n",
      "[52,   199] loss: 0.205082\n",
      "[52,   299] loss: 0.159181\n",
      "[53,    99] loss: 0.222373\n",
      "[53,   199] loss: 0.199073\n",
      "[53,   299] loss: 0.154309\n",
      "[54,    99] loss: 0.217542\n",
      "[54,   199] loss: 0.193286\n",
      "[54,   299] loss: 0.150264\n",
      "[55,    99] loss: 0.212842\n",
      "[55,   199] loss: 0.187630\n",
      "[55,   299] loss: 0.145832\n",
      "[56,    99] loss: 0.207927\n",
      "[56,   199] loss: 0.182205\n",
      "[56,   299] loss: 0.142050\n",
      "[57,    99] loss: 0.203543\n",
      "[57,   199] loss: 0.176742\n",
      "[57,   299] loss: 0.137971\n",
      "[58,    99] loss: 0.198850\n",
      "[58,   199] loss: 0.171537\n",
      "[58,   299] loss: 0.134253\n",
      "[59,    99] loss: 0.194525\n",
      "[59,   199] loss: 0.166288\n",
      "[59,   299] loss: 0.130210\n",
      "[60,    99] loss: 0.190516\n",
      "[60,   199] loss: 0.161392\n",
      "[60,   299] loss: 0.126896\n",
      "[61,    99] loss: 0.185807\n",
      "[61,   199] loss: 0.156667\n",
      "[61,   299] loss: 0.123705\n",
      "[62,    99] loss: 0.182027\n",
      "[62,   199] loss: 0.151743\n",
      "[62,   299] loss: 0.119895\n",
      "[63,    99] loss: 0.177833\n",
      "[63,   199] loss: 0.147045\n",
      "[63,   299] loss: 0.117002\n",
      "[64,    99] loss: 0.173784\n",
      "[64,   199] loss: 0.142865\n",
      "[64,   299] loss: 0.113450\n",
      "[65,    99] loss: 0.169945\n",
      "[65,   199] loss: 0.138549\n",
      "[65,   299] loss: 0.110655\n",
      "[66,    99] loss: 0.166025\n",
      "[66,   199] loss: 0.134182\n",
      "[66,   299] loss: 0.107311\n",
      "[67,    99] loss: 0.162230\n",
      "[67,   199] loss: 0.130260\n",
      "[67,   299] loss: 0.104610\n",
      "[68,    99] loss: 0.158313\n",
      "[68,   199] loss: 0.126368\n",
      "[68,   299] loss: 0.101570\n",
      "[69,    99] loss: 0.154851\n",
      "[69,   199] loss: 0.122633\n",
      "[69,   299] loss: 0.099031\n",
      "[70,    99] loss: 0.151230\n",
      "[70,   199] loss: 0.118635\n",
      "[70,   299] loss: 0.096193\n",
      "[71,    99] loss: 0.147654\n",
      "[71,   199] loss: 0.115313\n",
      "[71,   299] loss: 0.093779\n",
      "[72,    99] loss: 0.143928\n",
      "[72,   199] loss: 0.111691\n",
      "[72,   299] loss: 0.091656\n",
      "[73,    99] loss: 0.140483\n",
      "[73,   199] loss: 0.108395\n",
      "[73,   299] loss: 0.089359\n",
      "[74,    99] loss: 0.136857\n",
      "[74,   199] loss: 0.105165\n",
      "[74,   299] loss: 0.086699\n",
      "[75,    99] loss: 0.133428\n",
      "[75,   199] loss: 0.101859\n",
      "[75,   299] loss: 0.084755\n",
      "[76,    99] loss: 0.130334\n",
      "[76,   199] loss: 0.098521\n",
      "[76,   299] loss: 0.082446\n",
      "[77,    99] loss: 0.126831\n",
      "[77,   199] loss: 0.095683\n",
      "[77,   299] loss: 0.080243\n",
      "[78,    99] loss: 0.123631\n",
      "[78,   199] loss: 0.092831\n",
      "[78,   299] loss: 0.078357\n",
      "[79,    99] loss: 0.120426\n",
      "[79,   199] loss: 0.089868\n",
      "[79,   299] loss: 0.076268\n",
      "[80,    99] loss: 0.117462\n",
      "[80,   199] loss: 0.086939\n",
      "[80,   299] loss: 0.074327\n",
      "[81,    99] loss: 0.114220\n",
      "[81,   199] loss: 0.084141\n",
      "[81,   299] loss: 0.072425\n",
      "[82,    99] loss: 0.111824\n",
      "[82,   199] loss: 0.081328\n",
      "[82,   299] loss: 0.070669\n",
      "[83,    99] loss: 0.108599\n",
      "[83,   199] loss: 0.078907\n",
      "[83,   299] loss: 0.068704\n",
      "[84,    99] loss: 0.105980\n",
      "[84,   199] loss: 0.076538\n",
      "[84,   299] loss: 0.067342\n",
      "[85,    99] loss: 0.102971\n",
      "[85,   199] loss: 0.073935\n",
      "[85,   299] loss: 0.065596\n",
      "[86,    99] loss: 0.100502\n",
      "[86,   199] loss: 0.071607\n",
      "[86,   299] loss: 0.064042\n",
      "[87,    99] loss: 0.097640\n",
      "[87,   199] loss: 0.069739\n",
      "[87,   299] loss: 0.062305\n",
      "[88,    99] loss: 0.095220\n",
      "[88,   199] loss: 0.067240\n",
      "[88,   299] loss: 0.061043\n",
      "[89,    99] loss: 0.092649\n",
      "[89,   199] loss: 0.064989\n",
      "[89,   299] loss: 0.059463\n",
      "[90,    99] loss: 0.089782\n",
      "[90,   199] loss: 0.063067\n",
      "[90,   299] loss: 0.057887\n",
      "[91,    99] loss: 0.087217\n",
      "[91,   199] loss: 0.061078\n",
      "[91,   299] loss: 0.056435\n",
      "[92,    99] loss: 0.085201\n",
      "[92,   199] loss: 0.058878\n",
      "[92,   299] loss: 0.055384\n",
      "[93,    99] loss: 0.082587\n",
      "[93,   199] loss: 0.057022\n",
      "[93,   299] loss: 0.053747\n",
      "[94,    99] loss: 0.080237\n",
      "[94,   199] loss: 0.055215\n",
      "[94,   299] loss: 0.052289\n",
      "[95,    99] loss: 0.077800\n",
      "[95,   199] loss: 0.053311\n",
      "[95,   299] loss: 0.051044\n",
      "[96,    99] loss: 0.075490\n",
      "[96,   199] loss: 0.051499\n",
      "[96,   299] loss: 0.049657\n",
      "[97,    99] loss: 0.073222\n",
      "[97,   199] loss: 0.049875\n",
      "[97,   299] loss: 0.048638\n",
      "[98,    99] loss: 0.070887\n",
      "[98,   199] loss: 0.048172\n",
      "[98,   299] loss: 0.047227\n",
      "[99,    99] loss: 0.068575\n",
      "[99,   199] loss: 0.046328\n",
      "[99,   299] loss: 0.045838\n",
      "[100,    99] loss: 0.066469\n",
      "[100,   199] loss: 0.044890\n",
      "[100,   299] loss: 0.044662\n",
      "Finished Training\n",
      "[1,    99] loss: 0.690208\n",
      "[1,   199] loss: 0.692024\n",
      "[1,   299] loss: 0.686099\n",
      "[2,    99] loss: 0.677024\n",
      "[2,   199] loss: 0.678581\n",
      "[2,   299] loss: 0.678129\n",
      "[3,    99] loss: 0.665191\n",
      "[3,   199] loss: 0.665558\n",
      "[3,   299] loss: 0.669566\n",
      "[4,    99] loss: 0.651561\n",
      "[4,   199] loss: 0.652702\n",
      "[4,   299] loss: 0.659673\n",
      "[5,    99] loss: 0.637566\n",
      "[5,   199] loss: 0.639484\n",
      "[5,   299] loss: 0.649046\n",
      "[6,    99] loss: 0.622683\n",
      "[6,   199] loss: 0.624732\n",
      "[6,   299] loss: 0.636854\n",
      "[7,    99] loss: 0.606663\n",
      "[7,   199] loss: 0.609560\n",
      "[7,   299] loss: 0.624106\n",
      "[8,    99] loss: 0.589949\n",
      "[8,   199] loss: 0.594073\n",
      "[8,   299] loss: 0.609950\n",
      "[9,    99] loss: 0.572189\n",
      "[9,   199] loss: 0.578343\n",
      "[9,   299] loss: 0.594729\n",
      "[10,    99] loss: 0.554316\n",
      "[10,   199] loss: 0.562079\n",
      "[10,   299] loss: 0.578971\n",
      "[11,    99] loss: 0.535966\n",
      "[11,   199] loss: 0.546425\n",
      "[11,   299] loss: 0.562881\n",
      "[12,    99] loss: 0.517543\n",
      "[12,   199] loss: 0.530898\n",
      "[12,   299] loss: 0.546581\n",
      "[13,    99] loss: 0.499104\n",
      "[13,   199] loss: 0.515720\n",
      "[13,   299] loss: 0.530267\n",
      "[14,    99] loss: 0.480476\n",
      "[14,   199] loss: 0.500705\n",
      "[14,   299] loss: 0.513898\n",
      "[15,    99] loss: 0.462337\n",
      "[15,   199] loss: 0.486269\n",
      "[15,   299] loss: 0.497593\n",
      "[16,    99] loss: 0.444611\n",
      "[16,   199] loss: 0.471728\n",
      "[16,   299] loss: 0.481807\n",
      "[17,    99] loss: 0.427578\n",
      "[17,   199] loss: 0.457627\n",
      "[17,   299] loss: 0.466449\n",
      "[18,    99] loss: 0.411139\n",
      "[18,   199] loss: 0.444237\n",
      "[18,   299] loss: 0.451522\n",
      "[19,    99] loss: 0.395155\n",
      "[19,   199] loss: 0.431043\n",
      "[19,   299] loss: 0.437356\n",
      "[20,    99] loss: 0.379848\n",
      "[20,   199] loss: 0.418253\n",
      "[20,   299] loss: 0.423262\n",
      "[21,    99] loss: 0.365179\n",
      "[21,   199] loss: 0.405920\n",
      "[21,   299] loss: 0.409723\n",
      "[22,    99] loss: 0.351113\n",
      "[22,   199] loss: 0.393694\n",
      "[22,   299] loss: 0.396741\n",
      "[23,    99] loss: 0.337672\n",
      "[23,   199] loss: 0.382010\n",
      "[23,   299] loss: 0.384013\n",
      "[24,    99] loss: 0.324802\n",
      "[24,   199] loss: 0.370736\n",
      "[24,   299] loss: 0.371779\n",
      "[25,    99] loss: 0.312671\n",
      "[25,   199] loss: 0.359602\n",
      "[25,   299] loss: 0.359906\n",
      "[26,    99] loss: 0.301140\n",
      "[26,   199] loss: 0.348531\n",
      "[26,   299] loss: 0.348288\n",
      "[27,    99] loss: 0.289904\n",
      "[27,   199] loss: 0.338063\n",
      "[27,   299] loss: 0.337159\n",
      "[28,    99] loss: 0.279287\n",
      "[28,   199] loss: 0.327617\n",
      "[28,   299] loss: 0.326336\n",
      "[29,    99] loss: 0.268852\n",
      "[29,   199] loss: 0.317532\n",
      "[29,   299] loss: 0.315893\n",
      "[30,    99] loss: 0.258748\n",
      "[30,   199] loss: 0.307715\n",
      "[30,   299] loss: 0.305632\n",
      "[31,    99] loss: 0.249110\n",
      "[31,   199] loss: 0.298245\n",
      "[31,   299] loss: 0.295396\n",
      "[32,    99] loss: 0.239879\n",
      "[32,   199] loss: 0.289066\n",
      "[32,   299] loss: 0.285771\n",
      "[33,    99] loss: 0.231233\n",
      "[33,   199] loss: 0.279760\n",
      "[33,   299] loss: 0.276484\n",
      "[34,    99] loss: 0.223150\n",
      "[34,   199] loss: 0.270933\n",
      "[34,   299] loss: 0.267723\n",
      "[35,    99] loss: 0.215213\n",
      "[35,   199] loss: 0.262948\n",
      "[35,   299] loss: 0.259412\n",
      "[36,    99] loss: 0.207831\n",
      "[36,   199] loss: 0.255204\n",
      "[36,   299] loss: 0.251604\n",
      "[37,    99] loss: 0.200481\n",
      "[37,   199] loss: 0.248121\n",
      "[37,   299] loss: 0.243807\n",
      "[38,    99] loss: 0.193950\n",
      "[38,   199] loss: 0.241039\n",
      "[38,   299] loss: 0.236360\n",
      "[39,    99] loss: 0.187697\n",
      "[39,   199] loss: 0.234258\n",
      "[39,   299] loss: 0.228852\n",
      "[40,    99] loss: 0.181741\n",
      "[40,   199] loss: 0.227549\n",
      "[40,   299] loss: 0.221948\n",
      "[41,    99] loss: 0.176166\n",
      "[41,   199] loss: 0.220949\n",
      "[41,   299] loss: 0.215092\n",
      "[42,    99] loss: 0.170904\n",
      "[42,   199] loss: 0.214809\n",
      "[42,   299] loss: 0.208486\n",
      "[43,    99] loss: 0.165877\n",
      "[43,   199] loss: 0.208868\n",
      "[43,   299] loss: 0.202043\n",
      "[44,    99] loss: 0.160993\n",
      "[44,   199] loss: 0.203171\n",
      "[44,   299] loss: 0.195662\n",
      "[45,    99] loss: 0.156398\n",
      "[45,   199] loss: 0.197625\n",
      "[45,   299] loss: 0.189488\n",
      "[46,    99] loss: 0.151974\n",
      "[46,   199] loss: 0.192452\n",
      "[46,   299] loss: 0.183753\n",
      "[47,    99] loss: 0.147650\n",
      "[47,   199] loss: 0.187324\n",
      "[47,   299] loss: 0.178129\n",
      "[48,    99] loss: 0.143653\n",
      "[48,   199] loss: 0.182533\n",
      "[48,   299] loss: 0.172726\n",
      "[49,    99] loss: 0.139889\n",
      "[49,   199] loss: 0.177850\n",
      "[49,   299] loss: 0.167167\n",
      "[50,    99] loss: 0.136301\n",
      "[50,   199] loss: 0.173355\n",
      "[50,   299] loss: 0.161861\n",
      "[51,    99] loss: 0.132461\n",
      "[51,   199] loss: 0.169379\n",
      "[51,   299] loss: 0.156894\n",
      "[52,    99] loss: 0.129231\n",
      "[52,   199] loss: 0.164610\n",
      "[52,   299] loss: 0.151930\n",
      "[53,    99] loss: 0.125820\n",
      "[53,   199] loss: 0.160721\n",
      "[53,   299] loss: 0.147305\n",
      "[54,    99] loss: 0.122417\n",
      "[54,   199] loss: 0.156804\n",
      "[54,   299] loss: 0.142786\n",
      "[55,    99] loss: 0.119128\n",
      "[55,   199] loss: 0.153284\n",
      "[55,   299] loss: 0.138259\n",
      "[56,    99] loss: 0.115926\n",
      "[56,   199] loss: 0.149515\n",
      "[56,   299] loss: 0.134208\n",
      "[57,    99] loss: 0.112904\n",
      "[57,   199] loss: 0.145947\n",
      "[57,   299] loss: 0.130040\n",
      "[58,    99] loss: 0.109632\n",
      "[58,   199] loss: 0.142584\n",
      "[58,   299] loss: 0.126413\n",
      "[59,    99] loss: 0.106501\n",
      "[59,   199] loss: 0.139422\n",
      "[59,   299] loss: 0.122411\n",
      "[60,    99] loss: 0.103521\n",
      "[60,   199] loss: 0.136427\n",
      "[60,   299] loss: 0.118846\n",
      "[61,    99] loss: 0.100711\n",
      "[61,   199] loss: 0.133297\n",
      "[61,   299] loss: 0.115278\n",
      "[62,    99] loss: 0.098034\n",
      "[62,   199] loss: 0.130425\n",
      "[62,   299] loss: 0.111970\n",
      "[63,    99] loss: 0.095473\n",
      "[63,   199] loss: 0.127290\n",
      "[63,   299] loss: 0.108558\n",
      "[64,    99] loss: 0.092803\n",
      "[64,   199] loss: 0.124658\n",
      "[64,   299] loss: 0.105387\n",
      "[65,    99] loss: 0.090145\n",
      "[65,   199] loss: 0.121712\n",
      "[65,   299] loss: 0.102434\n",
      "[66,    99] loss: 0.087519\n",
      "[66,   199] loss: 0.119145\n",
      "[66,   299] loss: 0.099283\n",
      "[67,    99] loss: 0.085071\n",
      "[67,   199] loss: 0.116522\n",
      "[67,   299] loss: 0.096406\n",
      "[68,    99] loss: 0.082690\n",
      "[68,   199] loss: 0.113864\n",
      "[68,   299] loss: 0.093475\n",
      "[69,    99] loss: 0.080420\n",
      "[69,   199] loss: 0.111173\n",
      "[69,   299] loss: 0.090841\n",
      "[70,    99] loss: 0.078073\n",
      "[70,   199] loss: 0.108802\n",
      "[70,   299] loss: 0.088119\n",
      "[71,    99] loss: 0.075800\n",
      "[71,   199] loss: 0.106278\n",
      "[71,   299] loss: 0.085793\n",
      "[72,    99] loss: 0.073929\n",
      "[72,   199] loss: 0.103486\n",
      "[72,   299] loss: 0.082976\n",
      "[73,    99] loss: 0.071732\n",
      "[73,   199] loss: 0.100894\n",
      "[73,   299] loss: 0.080685\n",
      "[74,    99] loss: 0.069719\n",
      "[74,   199] loss: 0.098728\n",
      "[74,   299] loss: 0.078418\n",
      "[75,    99] loss: 0.067686\n",
      "[75,   199] loss: 0.096636\n",
      "[75,   299] loss: 0.076218\n",
      "[76,    99] loss: 0.065980\n",
      "[76,   199] loss: 0.094224\n",
      "[76,   299] loss: 0.073985\n",
      "[77,    99] loss: 0.064056\n",
      "[77,   199] loss: 0.092213\n",
      "[77,   299] loss: 0.071924\n",
      "[78,    99] loss: 0.062407\n",
      "[78,   199] loss: 0.090020\n",
      "[78,   299] loss: 0.069823\n",
      "[79,    99] loss: 0.060826\n",
      "[79,   199] loss: 0.087752\n",
      "[79,   299] loss: 0.068036\n",
      "[80,    99] loss: 0.059157\n",
      "[80,   199] loss: 0.085795\n",
      "[80,   299] loss: 0.065979\n",
      "[81,    99] loss: 0.057616\n",
      "[81,   199] loss: 0.083746\n",
      "[81,   299] loss: 0.064039\n",
      "[82,    99] loss: 0.056049\n",
      "[82,   199] loss: 0.081779\n",
      "[82,   299] loss: 0.062415\n",
      "[83,    99] loss: 0.054483\n",
      "[83,   199] loss: 0.079840\n",
      "[83,   299] loss: 0.060677\n",
      "[84,    99] loss: 0.052875\n",
      "[84,   199] loss: 0.077800\n",
      "[84,   299] loss: 0.059002\n",
      "[85,    99] loss: 0.051588\n",
      "[85,   199] loss: 0.076075\n",
      "[85,   299] loss: 0.057054\n",
      "[86,    99] loss: 0.050244\n",
      "[86,   199] loss: 0.074197\n",
      "[86,   299] loss: 0.055782\n",
      "[87,    99] loss: 0.048925\n",
      "[87,   199] loss: 0.072180\n",
      "[87,   299] loss: 0.053947\n",
      "[88,    99] loss: 0.047475\n",
      "[88,   199] loss: 0.070602\n",
      "[88,   299] loss: 0.052477\n",
      "[89,    99] loss: 0.046421\n",
      "[89,   199] loss: 0.068708\n",
      "[89,   299] loss: 0.050938\n",
      "[90,    99] loss: 0.044898\n",
      "[90,   199] loss: 0.067224\n",
      "[90,   299] loss: 0.049577\n",
      "[91,    99] loss: 0.043623\n",
      "[91,   199] loss: 0.064978\n",
      "[91,   299] loss: 0.047996\n",
      "[92,    99] loss: 0.042526\n",
      "[92,   199] loss: 0.062981\n",
      "[92,   299] loss: 0.046767\n",
      "[93,    99] loss: 0.041452\n",
      "[93,   199] loss: 0.061433\n",
      "[93,   299] loss: 0.045123\n",
      "[94,    99] loss: 0.040417\n",
      "[94,   199] loss: 0.059610\n",
      "[94,   299] loss: 0.043848\n",
      "[95,    99] loss: 0.039502\n",
      "[95,   199] loss: 0.058030\n",
      "[95,   299] loss: 0.042523\n",
      "[96,    99] loss: 0.038580\n",
      "[96,   199] loss: 0.056652\n",
      "[96,   299] loss: 0.041389\n",
      "[97,    99] loss: 0.037662\n",
      "[97,   199] loss: 0.054773\n",
      "[97,   299] loss: 0.040337\n",
      "[98,    99] loss: 0.036595\n",
      "[98,   199] loss: 0.053352\n",
      "[98,   299] loss: 0.039111\n",
      "[99,    99] loss: 0.035728\n",
      "[99,   199] loss: 0.051536\n",
      "[99,   299] loss: 0.037799\n",
      "[100,    99] loss: 0.034639\n",
      "[100,   199] loss: 0.050153\n",
      "[100,   299] loss: 0.037034\n",
      "Finished Training\n",
      "[1,    99] loss: 0.682029\n",
      "[1,   199] loss: 0.694836\n",
      "[1,   299] loss: 0.684616\n",
      "[2,    99] loss: 0.674760\n",
      "[2,   199] loss: 0.676803\n",
      "[2,   299] loss: 0.673571\n",
      "[3,    99] loss: 0.668099\n",
      "[3,   199] loss: 0.657878\n",
      "[3,   299] loss: 0.661145\n",
      "[4,    99] loss: 0.660314\n",
      "[4,   199] loss: 0.638100\n",
      "[4,   299] loss: 0.648161\n",
      "[5,    99] loss: 0.650154\n",
      "[5,   199] loss: 0.619081\n",
      "[5,   299] loss: 0.634419\n",
      "[6,    99] loss: 0.638235\n",
      "[6,   199] loss: 0.600278\n",
      "[6,   299] loss: 0.619746\n",
      "[7,    99] loss: 0.626144\n",
      "[7,   199] loss: 0.581949\n",
      "[7,   299] loss: 0.605268\n",
      "[8,    99] loss: 0.614254\n",
      "[8,   199] loss: 0.564652\n",
      "[8,   299] loss: 0.591052\n",
      "[9,    99] loss: 0.602127\n",
      "[9,   199] loss: 0.548149\n",
      "[9,   299] loss: 0.577445\n",
      "[10,    99] loss: 0.590288\n",
      "[10,   199] loss: 0.532394\n",
      "[10,   299] loss: 0.564168\n",
      "[11,    99] loss: 0.578512\n",
      "[11,   199] loss: 0.517296\n",
      "[11,   299] loss: 0.550550\n",
      "[12,    99] loss: 0.566904\n",
      "[12,   199] loss: 0.502646\n",
      "[12,   299] loss: 0.537353\n",
      "[13,    99] loss: 0.554948\n",
      "[13,   199] loss: 0.488647\n",
      "[13,   299] loss: 0.523930\n",
      "[14,    99] loss: 0.542675\n",
      "[14,   199] loss: 0.474942\n",
      "[14,   299] loss: 0.510220\n",
      "[15,    99] loss: 0.529666\n",
      "[15,   199] loss: 0.461461\n",
      "[15,   299] loss: 0.496200\n",
      "[16,    99] loss: 0.516857\n",
      "[16,   199] loss: 0.448679\n",
      "[16,   299] loss: 0.482251\n",
      "[17,    99] loss: 0.503811\n",
      "[17,   199] loss: 0.436241\n",
      "[17,   299] loss: 0.468361\n",
      "[18,    99] loss: 0.490805\n",
      "[18,   199] loss: 0.423839\n",
      "[18,   299] loss: 0.454837\n",
      "[19,    99] loss: 0.478029\n",
      "[19,   199] loss: 0.411904\n",
      "[19,   299] loss: 0.441527\n",
      "[20,    99] loss: 0.465469\n",
      "[20,   199] loss: 0.400123\n",
      "[20,   299] loss: 0.428660\n",
      "[21,    99] loss: 0.453512\n",
      "[21,   199] loss: 0.388787\n",
      "[21,   299] loss: 0.415968\n",
      "[22,    99] loss: 0.441302\n",
      "[22,   199] loss: 0.377640\n",
      "[22,   299] loss: 0.403478\n",
      "[23,    99] loss: 0.429398\n",
      "[23,   199] loss: 0.366939\n",
      "[23,   299] loss: 0.391582\n",
      "[24,    99] loss: 0.417580\n",
      "[24,   199] loss: 0.356321\n",
      "[24,   299] loss: 0.380037\n",
      "[25,    99] loss: 0.405631\n",
      "[25,   199] loss: 0.345981\n",
      "[25,   299] loss: 0.369013\n",
      "[26,    99] loss: 0.394434\n",
      "[26,   199] loss: 0.335867\n",
      "[26,   299] loss: 0.358404\n",
      "[27,    99] loss: 0.383300\n",
      "[27,   199] loss: 0.326152\n",
      "[27,   299] loss: 0.347988\n",
      "[28,    99] loss: 0.372639\n",
      "[28,   199] loss: 0.316725\n",
      "[28,   299] loss: 0.337981\n",
      "[29,    99] loss: 0.361616\n",
      "[29,   199] loss: 0.308153\n",
      "[29,   299] loss: 0.328391\n",
      "[30,    99] loss: 0.351239\n",
      "[30,   199] loss: 0.299278\n",
      "[30,   299] loss: 0.319520\n",
      "[31,    99] loss: 0.341184\n",
      "[31,   199] loss: 0.290883\n",
      "[31,   299] loss: 0.310946\n",
      "[32,    99] loss: 0.331178\n",
      "[32,   199] loss: 0.282768\n",
      "[32,   299] loss: 0.302543\n",
      "[33,    99] loss: 0.321573\n",
      "[33,   199] loss: 0.274386\n",
      "[33,   299] loss: 0.294135\n",
      "[34,    99] loss: 0.311927\n",
      "[34,   199] loss: 0.266549\n",
      "[34,   299] loss: 0.286199\n",
      "[35,    99] loss: 0.302196\n",
      "[35,   199] loss: 0.258579\n",
      "[35,   299] loss: 0.278914\n",
      "[36,    99] loss: 0.293200\n",
      "[36,   199] loss: 0.250837\n",
      "[36,   299] loss: 0.271556\n",
      "[37,    99] loss: 0.284174\n",
      "[37,   199] loss: 0.242306\n",
      "[37,   299] loss: 0.263855\n",
      "[38,    99] loss: 0.275360\n",
      "[38,   199] loss: 0.235085\n",
      "[38,   299] loss: 0.256598\n",
      "[39,    99] loss: 0.267156\n",
      "[39,   199] loss: 0.228294\n",
      "[39,   299] loss: 0.249864\n",
      "[40,    99] loss: 0.259071\n",
      "[40,   199] loss: 0.221749\n",
      "[40,   299] loss: 0.242671\n",
      "[41,    99] loss: 0.251058\n",
      "[41,   199] loss: 0.215140\n",
      "[41,   299] loss: 0.235993\n",
      "[42,    99] loss: 0.242962\n",
      "[42,   199] loss: 0.208766\n",
      "[42,   299] loss: 0.229635\n",
      "[43,    99] loss: 0.235015\n",
      "[43,   199] loss: 0.202683\n",
      "[43,   299] loss: 0.223139\n",
      "[44,    99] loss: 0.227288\n",
      "[44,   199] loss: 0.197101\n",
      "[44,   299] loss: 0.217116\n",
      "[45,    99] loss: 0.219930\n",
      "[45,   199] loss: 0.191301\n",
      "[45,   299] loss: 0.211059\n",
      "[46,    99] loss: 0.212724\n",
      "[46,   199] loss: 0.186000\n",
      "[46,   299] loss: 0.205175\n",
      "[47,    99] loss: 0.205855\n",
      "[47,   199] loss: 0.180545\n",
      "[47,   299] loss: 0.199660\n",
      "[48,    99] loss: 0.199190\n",
      "[48,   199] loss: 0.175363\n",
      "[48,   299] loss: 0.194109\n",
      "[49,    99] loss: 0.192762\n",
      "[49,   199] loss: 0.170038\n",
      "[49,   299] loss: 0.188994\n",
      "[50,    99] loss: 0.186453\n",
      "[50,   199] loss: 0.165066\n",
      "[50,   299] loss: 0.183974\n",
      "[51,    99] loss: 0.180590\n",
      "[51,   199] loss: 0.160543\n",
      "[51,   299] loss: 0.179165\n",
      "[52,    99] loss: 0.174633\n",
      "[52,   199] loss: 0.155992\n",
      "[52,   299] loss: 0.174340\n",
      "[53,    99] loss: 0.169477\n",
      "[53,   199] loss: 0.151390\n",
      "[53,   299] loss: 0.169222\n",
      "[54,    99] loss: 0.164372\n",
      "[54,   199] loss: 0.146958\n",
      "[54,   299] loss: 0.164736\n",
      "[55,    99] loss: 0.159244\n",
      "[55,   199] loss: 0.142913\n",
      "[55,   299] loss: 0.160441\n",
      "[56,    99] loss: 0.154466\n",
      "[56,   199] loss: 0.138507\n",
      "[56,   299] loss: 0.155616\n",
      "[57,    99] loss: 0.149734\n",
      "[57,   199] loss: 0.134697\n",
      "[57,   299] loss: 0.151587\n",
      "[58,    99] loss: 0.144876\n",
      "[58,   199] loss: 0.130894\n",
      "[58,   299] loss: 0.147163\n",
      "[59,    99] loss: 0.140301\n",
      "[59,   199] loss: 0.126799\n",
      "[59,   299] loss: 0.142671\n",
      "[60,    99] loss: 0.136187\n",
      "[60,   199] loss: 0.123257\n",
      "[60,   299] loss: 0.138557\n",
      "[61,    99] loss: 0.131550\n",
      "[61,   199] loss: 0.119385\n",
      "[61,   299] loss: 0.134387\n",
      "[62,    99] loss: 0.127423\n",
      "[62,   199] loss: 0.115711\n",
      "[62,   299] loss: 0.130691\n",
      "[63,    99] loss: 0.123315\n",
      "[63,   199] loss: 0.111937\n",
      "[63,   299] loss: 0.127096\n",
      "[64,    99] loss: 0.119477\n",
      "[64,   199] loss: 0.108746\n",
      "[64,   299] loss: 0.123752\n",
      "[65,    99] loss: 0.115728\n",
      "[65,   199] loss: 0.105324\n",
      "[65,   299] loss: 0.119919\n",
      "[66,    99] loss: 0.112092\n",
      "[66,   199] loss: 0.102183\n",
      "[66,   299] loss: 0.116497\n",
      "[67,    99] loss: 0.108587\n",
      "[67,   199] loss: 0.098777\n",
      "[67,   299] loss: 0.113588\n",
      "[68,    99] loss: 0.105320\n",
      "[68,   199] loss: 0.095779\n",
      "[68,   299] loss: 0.110432\n",
      "[69,    99] loss: 0.102328\n",
      "[69,   199] loss: 0.093102\n",
      "[69,   299] loss: 0.107400\n",
      "[70,    99] loss: 0.099134\n",
      "[70,   199] loss: 0.090179\n",
      "[70,   299] loss: 0.104779\n",
      "[71,    99] loss: 0.095826\n",
      "[71,   199] loss: 0.087073\n",
      "[71,   299] loss: 0.101590\n",
      "[72,    99] loss: 0.093189\n",
      "[72,   199] loss: 0.084586\n",
      "[72,   299] loss: 0.098578\n",
      "[73,    99] loss: 0.090104\n",
      "[73,   199] loss: 0.081412\n",
      "[73,   299] loss: 0.096175\n",
      "[74,    99] loss: 0.087248\n",
      "[74,   199] loss: 0.078925\n",
      "[74,   299] loss: 0.093390\n",
      "[75,    99] loss: 0.084459\n",
      "[75,   199] loss: 0.076294\n",
      "[75,   299] loss: 0.090810\n",
      "[76,    99] loss: 0.082140\n",
      "[76,   199] loss: 0.073718\n",
      "[76,   299] loss: 0.088136\n",
      "[77,    99] loss: 0.079538\n",
      "[77,   199] loss: 0.071008\n",
      "[77,   299] loss: 0.085663\n",
      "[78,    99] loss: 0.077325\n",
      "[78,   199] loss: 0.068788\n",
      "[78,   299] loss: 0.082985\n",
      "[79,    99] loss: 0.074736\n",
      "[79,   199] loss: 0.066511\n",
      "[79,   299] loss: 0.080722\n",
      "[80,    99] loss: 0.072445\n",
      "[80,   199] loss: 0.063956\n",
      "[80,   299] loss: 0.078503\n",
      "[81,    99] loss: 0.070067\n",
      "[81,   199] loss: 0.062060\n",
      "[81,   299] loss: 0.076220\n",
      "[82,    99] loss: 0.068094\n",
      "[82,   199] loss: 0.059604\n",
      "[82,   299] loss: 0.074150\n",
      "[83,    99] loss: 0.065891\n",
      "[83,   199] loss: 0.057790\n",
      "[83,   299] loss: 0.071814\n",
      "[84,    99] loss: 0.063582\n",
      "[84,   199] loss: 0.055344\n",
      "[84,   299] loss: 0.070315\n",
      "[85,    99] loss: 0.061762\n",
      "[85,   199] loss: 0.053658\n",
      "[85,   299] loss: 0.067830\n",
      "[86,    99] loss: 0.059779\n",
      "[86,   199] loss: 0.051331\n",
      "[86,   299] loss: 0.066562\n",
      "[87,    99] loss: 0.057814\n",
      "[87,   199] loss: 0.049804\n",
      "[87,   299] loss: 0.064375\n",
      "[88,    99] loss: 0.055965\n",
      "[88,   199] loss: 0.047929\n",
      "[88,   299] loss: 0.062476\n",
      "[89,    99] loss: 0.054019\n",
      "[89,   199] loss: 0.046217\n",
      "[89,   299] loss: 0.060917\n",
      "[90,    99] loss: 0.052556\n",
      "[90,   199] loss: 0.044124\n",
      "[90,   299] loss: 0.059105\n",
      "[91,    99] loss: 0.050877\n",
      "[91,   199] loss: 0.042329\n",
      "[91,   299] loss: 0.057591\n",
      "[92,    99] loss: 0.049401\n",
      "[92,   199] loss: 0.040508\n",
      "[92,   299] loss: 0.055947\n",
      "[93,    99] loss: 0.047543\n",
      "[93,   199] loss: 0.038769\n",
      "[93,   299] loss: 0.054107\n",
      "[94,    99] loss: 0.045928\n",
      "[94,   199] loss: 0.037046\n",
      "[94,   299] loss: 0.052561\n",
      "[95,    99] loss: 0.044509\n",
      "[95,   199] loss: 0.035398\n",
      "[95,   299] loss: 0.051370\n",
      "[96,    99] loss: 0.043038\n",
      "[96,   199] loss: 0.033980\n",
      "[96,   299] loss: 0.049535\n",
      "[97,    99] loss: 0.041290\n",
      "[97,   199] loss: 0.032667\n",
      "[97,   299] loss: 0.048438\n",
      "[98,    99] loss: 0.040213\n",
      "[98,   199] loss: 0.031058\n",
      "[98,   299] loss: 0.047115\n",
      "[99,    99] loss: 0.039117\n",
      "[99,   199] loss: 0.030098\n",
      "[99,   299] loss: 0.045456\n",
      "[100,    99] loss: 0.037327\n",
      "[100,   199] loss: 0.028740\n",
      "[100,   299] loss: 0.044353\n",
      "Finished Training\n",
      "[1,    99] loss: 0.970795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    99] loss: 0.817501\n",
      "[3,    99] loss: 0.699518\n",
      "[4,    99] loss: 0.699591\n",
      "[5,    99] loss: 0.699689\n",
      "[6,    99] loss: 0.699738\n",
      "[7,    99] loss: 0.699771\n",
      "[8,    99] loss: 0.699793\n",
      "[9,    99] loss: 0.699809\n",
      "[10,    99] loss: 0.699821\n",
      "[11,    99] loss: 0.699831\n",
      "[12,    99] loss: 0.699838\n",
      "[13,    99] loss: 0.699843\n",
      "[14,    99] loss: 0.699848\n",
      "[15,    99] loss: 0.699851\n",
      "[16,    99] loss: 0.699854\n",
      "[17,    99] loss: 0.699856\n",
      "[18,    99] loss: 0.699858\n",
      "[19,    99] loss: 0.699860\n",
      "[20,    99] loss: 0.699861\n",
      "[21,    99] loss: 0.699862\n",
      "[22,    99] loss: 0.699863\n",
      "[23,    99] loss: 0.699864\n",
      "[24,    99] loss: 0.699864\n",
      "[25,    99] loss: 0.699865\n",
      "[26,    99] loss: 0.699865\n",
      "[27,    99] loss: 0.699865\n",
      "[28,    99] loss: 0.699866\n",
      "[29,    99] loss: 0.699866\n",
      "[30,    99] loss: 0.699866\n",
      "[31,    99] loss: 0.699866\n",
      "[32,    99] loss: 0.699866\n",
      "[33,    99] loss: 0.699866\n",
      "[34,    99] loss: 0.699866\n",
      "[35,    99] loss: 0.699866\n",
      "[36,    99] loss: 0.699866\n",
      "[37,    99] loss: 0.699867\n",
      "[38,    99] loss: 0.699867\n",
      "[39,    99] loss: 0.699867\n",
      "[40,    99] loss: 0.699867\n",
      "[41,    99] loss: 0.699867\n",
      "[42,    99] loss: 0.699867\n",
      "[43,    99] loss: 0.699867\n",
      "[44,    99] loss: 0.699867\n",
      "[45,    99] loss: 0.699867\n",
      "[46,    99] loss: 0.699867\n",
      "[47,    99] loss: 0.699867\n",
      "[48,    99] loss: 0.699867\n",
      "[49,    99] loss: 0.699867\n",
      "[50,    99] loss: 0.699867\n",
      "[51,    99] loss: 0.699867\n",
      "[52,    99] loss: 0.699867\n",
      "[53,    99] loss: 0.699867\n",
      "[54,    99] loss: 0.699867\n",
      "[55,    99] loss: 0.699867\n",
      "[56,    99] loss: 0.699867\n",
      "[57,    99] loss: 0.699867\n",
      "[58,    99] loss: 0.699867\n",
      "[59,    99] loss: 0.699867\n",
      "[60,    99] loss: 0.699867\n",
      "[61,    99] loss: 0.699867\n",
      "[62,    99] loss: 0.699867\n",
      "[63,    99] loss: 0.699867\n",
      "[64,    99] loss: 0.699867\n",
      "[65,    99] loss: 0.699867\n",
      "[66,    99] loss: 0.699867\n",
      "[67,    99] loss: 0.699867\n",
      "[68,    99] loss: 0.699867\n",
      "[69,    99] loss: 0.699867\n",
      "[70,    99] loss: 0.699867\n",
      "[71,    99] loss: 0.699867\n",
      "[72,    99] loss: 0.699867\n",
      "[73,    99] loss: 0.699867\n",
      "[74,    99] loss: 0.699867\n",
      "[75,    99] loss: 0.699867\n",
      "[76,    99] loss: 0.699867\n",
      "[77,    99] loss: 0.699867\n",
      "[78,    99] loss: 0.699867\n",
      "[79,    99] loss: 0.699867\n",
      "[80,    99] loss: 0.699867\n",
      "[81,    99] loss: 0.699867\n",
      "[82,    99] loss: 0.699867\n",
      "[83,    99] loss: 0.699867\n",
      "[84,    99] loss: 0.699867\n",
      "[85,    99] loss: 0.699867\n",
      "[86,    99] loss: 0.699867\n",
      "[87,    99] loss: 0.699867\n",
      "[88,    99] loss: 0.699867\n",
      "[89,    99] loss: 0.699867\n",
      "[90,    99] loss: 0.699867\n",
      "[91,    99] loss: 0.699867\n",
      "[92,    99] loss: 0.699867\n",
      "[93,    99] loss: 0.699867\n",
      "[94,    99] loss: 0.699867\n",
      "[95,    99] loss: 0.699867\n",
      "[96,    99] loss: 0.699867\n",
      "[97,    99] loss: 0.699867\n",
      "[98,    99] loss: 0.699867\n",
      "[99,    99] loss: 0.699867\n",
      "[100,    99] loss: 0.699867\n",
      "Finished Training\n",
      "[1,    99] loss: 1.161338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    99] loss: 0.700416\n",
      "[3,    99] loss: 0.684242\n",
      "[4,    99] loss: 0.729735\n",
      "[5,    99] loss: 0.701376\n",
      "[6,    99] loss: 0.700813\n",
      "[7,    99] loss: 0.700821\n",
      "[8,    99] loss: 0.700826\n",
      "[9,    99] loss: 0.700830\n",
      "[10,    99] loss: 0.700833\n",
      "[11,    99] loss: 0.700836\n",
      "[12,    99] loss: 0.700837\n",
      "[13,    99] loss: 0.700839\n",
      "[14,    99] loss: 0.700840\n",
      "[15,    99] loss: 0.700841\n",
      "[16,    99] loss: 0.700841\n",
      "[17,    99] loss: 0.700842\n",
      "[18,    99] loss: 0.700842\n",
      "[19,    99] loss: 0.700843\n",
      "[20,    99] loss: 0.700843\n",
      "[21,    99] loss: 0.700843\n",
      "[22,    99] loss: 0.700843\n",
      "[23,    99] loss: 0.700843\n",
      "[24,    99] loss: 0.700844\n",
      "[25,    99] loss: 0.700844\n",
      "[26,    99] loss: 0.700844\n",
      "[27,    99] loss: 0.700844\n",
      "[28,    99] loss: 0.700844\n",
      "[29,    99] loss: 0.700844\n",
      "[30,    99] loss: 0.700844\n",
      "[31,    99] loss: 0.700844\n",
      "[32,    99] loss: 0.700844\n",
      "[33,    99] loss: 0.700844\n",
      "[34,    99] loss: 0.700844\n",
      "[35,    99] loss: 0.700844\n",
      "[36,    99] loss: 0.700844\n",
      "[37,    99] loss: 0.700844\n",
      "[38,    99] loss: 0.700844\n",
      "[39,    99] loss: 0.700844\n",
      "[40,    99] loss: 0.700844\n",
      "[41,    99] loss: 0.700844\n",
      "[42,    99] loss: 0.700844\n",
      "[43,    99] loss: 0.700844\n",
      "[44,    99] loss: 0.700844\n",
      "[45,    99] loss: 0.700844\n",
      "[46,    99] loss: 0.700844\n",
      "[47,    99] loss: 0.700844\n",
      "[48,    99] loss: 0.700844\n",
      "[49,    99] loss: 0.700844\n",
      "[50,    99] loss: 0.700844\n",
      "[51,    99] loss: 0.700844\n",
      "[52,    99] loss: 0.700844\n",
      "[53,    99] loss: 0.700844\n",
      "[54,    99] loss: 0.700844\n",
      "[55,    99] loss: 0.700844\n",
      "[56,    99] loss: 0.700844\n",
      "[57,    99] loss: 0.700844\n",
      "[58,    99] loss: 0.700844\n",
      "[59,    99] loss: 0.700844\n",
      "[60,    99] loss: 0.700844\n",
      "[61,    99] loss: 0.700844\n",
      "[62,    99] loss: 0.700844\n",
      "[63,    99] loss: 0.700844\n",
      "[64,    99] loss: 0.700844\n",
      "[65,    99] loss: 0.700844\n",
      "[66,    99] loss: 0.700844\n",
      "[67,    99] loss: 0.700844\n",
      "[68,    99] loss: 0.700844\n",
      "[69,    99] loss: 0.700844\n",
      "[70,    99] loss: 0.700844\n",
      "[71,    99] loss: 0.700844\n",
      "[72,    99] loss: 0.700844\n",
      "[73,    99] loss: 0.700844\n",
      "[74,    99] loss: 0.700844\n",
      "[75,    99] loss: 0.700844\n",
      "[76,    99] loss: 0.700844\n",
      "[77,    99] loss: 0.700844\n",
      "[78,    99] loss: 0.700844\n",
      "[79,    99] loss: 0.700844\n",
      "[80,    99] loss: 0.700844\n",
      "[81,    99] loss: 0.700844\n",
      "[82,    99] loss: 0.700844\n",
      "[83,    99] loss: 0.700844\n",
      "[84,    99] loss: 0.700844\n",
      "[85,    99] loss: 0.700844\n",
      "[86,    99] loss: 0.700844\n",
      "[87,    99] loss: 0.700844\n",
      "[88,    99] loss: 0.700844\n",
      "[89,    99] loss: 0.700844\n",
      "[90,    99] loss: 0.700844\n",
      "[91,    99] loss: 0.700844\n",
      "[92,    99] loss: 0.700844\n",
      "[93,    99] loss: 0.700844\n",
      "[94,    99] loss: 0.700844\n",
      "[95,    99] loss: 0.700844\n",
      "[96,    99] loss: 0.700844\n",
      "[97,    99] loss: 0.700844\n",
      "[98,    99] loss: 0.700844\n",
      "[99,    99] loss: 0.700844\n",
      "[100,    99] loss: 0.700844\n",
      "Finished Training\n",
      "[1,    99] loss: 1.061107\n",
      "[2,    99] loss: 0.712455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,    99] loss: 0.708073\n",
      "[4,    99] loss: 0.708305\n",
      "[5,    99] loss: 0.708427\n",
      "[6,    99] loss: 0.708501\n",
      "[7,    99] loss: 0.708550\n",
      "[8,    99] loss: 0.708584\n",
      "[9,    99] loss: 0.708608\n",
      "[10,    99] loss: 0.708626\n",
      "[11,    99] loss: 0.708640\n",
      "[12,    99] loss: 0.708651\n",
      "[13,    99] loss: 0.708659\n",
      "[14,    99] loss: 0.708665\n",
      "[15,    99] loss: 0.708671\n",
      "[16,    99] loss: 0.708675\n",
      "[17,    99] loss: 0.708678\n",
      "[18,    99] loss: 0.708681\n",
      "[19,    99] loss: 0.708683\n",
      "[20,    99] loss: 0.708685\n",
      "[21,    99] loss: 0.708687\n",
      "[22,    99] loss: 0.708688\n",
      "[23,    99] loss: 0.708689\n",
      "[24,    99] loss: 0.708690\n",
      "[25,    99] loss: 0.708690\n",
      "[26,    99] loss: 0.708691\n",
      "[27,    99] loss: 0.708691\n",
      "[28,    99] loss: 0.708692\n",
      "[29,    99] loss: 0.708692\n",
      "[30,    99] loss: 0.708692\n",
      "[31,    99] loss: 0.708692\n",
      "[32,    99] loss: 0.708693\n",
      "[33,    99] loss: 0.708693\n",
      "[34,    99] loss: 0.708693\n",
      "[35,    99] loss: 0.708693\n",
      "[36,    99] loss: 0.708693\n",
      "[37,    99] loss: 0.708693\n",
      "[38,    99] loss: 0.708693\n",
      "[39,    99] loss: 0.708693\n",
      "[40,    99] loss: 0.708693\n",
      "[41,    99] loss: 0.708693\n",
      "[42,    99] loss: 0.708693\n",
      "[43,    99] loss: 0.708693\n",
      "[44,    99] loss: 0.708693\n",
      "[45,    99] loss: 0.708693\n",
      "[46,    99] loss: 0.708693\n",
      "[47,    99] loss: 0.708693\n",
      "[48,    99] loss: 0.708693\n",
      "[49,    99] loss: 0.708693\n",
      "[50,    99] loss: 0.708693\n",
      "[51,    99] loss: 0.708693\n",
      "[52,    99] loss: 0.708693\n",
      "[53,    99] loss: 0.708693\n",
      "[54,    99] loss: 0.708693\n",
      "[55,    99] loss: 0.708693\n",
      "[56,    99] loss: 0.708693\n",
      "[57,    99] loss: 0.708693\n",
      "[58,    99] loss: 0.708693\n",
      "[59,    99] loss: 0.708693\n",
      "[60,    99] loss: 0.708693\n",
      "[61,    99] loss: 0.708693\n",
      "[62,    99] loss: 0.708693\n",
      "[63,    99] loss: 0.708693\n",
      "[64,    99] loss: 0.708693\n",
      "[65,    99] loss: 0.708693\n",
      "[66,    99] loss: 0.708693\n",
      "[67,    99] loss: 0.708693\n",
      "[68,    99] loss: 0.708693\n",
      "[69,    99] loss: 0.708693\n",
      "[70,    99] loss: 0.708693\n",
      "[71,    99] loss: 0.708693\n",
      "[72,    99] loss: 0.708693\n",
      "[73,    99] loss: 0.708693\n",
      "[74,    99] loss: 0.708693\n",
      "[75,    99] loss: 0.708693\n",
      "[76,    99] loss: 0.708693\n",
      "[77,    99] loss: 0.708693\n",
      "[78,    99] loss: 0.708693\n",
      "[79,    99] loss: 0.708693\n",
      "[80,    99] loss: 0.708693\n",
      "[81,    99] loss: 0.708693\n",
      "[82,    99] loss: 0.708693\n",
      "[83,    99] loss: 0.708693\n",
      "[84,    99] loss: 0.708693\n",
      "[85,    99] loss: 0.708693\n",
      "[86,    99] loss: 0.708693\n",
      "[87,    99] loss: 0.708693\n",
      "[88,    99] loss: 0.708693\n",
      "[89,    99] loss: 0.708693\n",
      "[90,    99] loss: 0.708693\n",
      "[91,    99] loss: 0.708693\n",
      "[92,    99] loss: 0.708693\n",
      "[93,    99] loss: 0.708693\n",
      "[94,    99] loss: 0.708693\n",
      "[95,    99] loss: 0.708693\n",
      "[96,    99] loss: 0.708693\n",
      "[97,    99] loss: 0.708693\n",
      "[98,    99] loss: 0.708693\n",
      "[99,    99] loss: 0.708693\n",
      "[100,    99] loss: 0.708693\n",
      "Finished Training\n",
      "[1,    99] loss: 1.203158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    99] loss: 0.700772\n",
      "[3,    99] loss: 0.704608\n",
      "[4,    99] loss: 0.702514\n",
      "[5,    99] loss: 0.702593\n",
      "[6,    99] loss: 0.702736\n",
      "[7,    99] loss: 0.702829\n",
      "[8,    99] loss: 0.702894\n",
      "[9,    99] loss: 0.702942\n",
      "[10,    99] loss: 0.702977\n",
      "[11,    99] loss: 0.703004\n",
      "[12,    99] loss: 0.703025\n",
      "[13,    99] loss: 0.703041\n",
      "[14,    99] loss: 0.703054\n",
      "[15,    99] loss: 0.703065\n",
      "[16,    99] loss: 0.703073\n",
      "[17,    99] loss: 0.703080\n",
      "[18,    99] loss: 0.703085\n",
      "[19,    99] loss: 0.703090\n",
      "[20,    99] loss: 0.703094\n",
      "[21,    99] loss: 0.703097\n",
      "[22,    99] loss: 0.703099\n",
      "[23,    99] loss: 0.703101\n",
      "[24,    99] loss: 0.703103\n",
      "[25,    99] loss: 0.703104\n",
      "[26,    99] loss: 0.703105\n",
      "[27,    99] loss: 0.703106\n",
      "[28,    99] loss: 0.703107\n",
      "[29,    99] loss: 0.703108\n",
      "[30,    99] loss: 0.703108\n",
      "[31,    99] loss: 0.703109\n",
      "[32,    99] loss: 0.703109\n",
      "[33,    99] loss: 0.703109\n",
      "[34,    99] loss: 0.703110\n",
      "[35,    99] loss: 0.703110\n",
      "[36,    99] loss: 0.703110\n",
      "[37,    99] loss: 0.703110\n",
      "[38,    99] loss: 0.703110\n",
      "[39,    99] loss: 0.703110\n",
      "[40,    99] loss: 0.703111\n",
      "[41,    99] loss: 0.703111\n",
      "[42,    99] loss: 0.703111\n",
      "[43,    99] loss: 0.703111\n",
      "[44,    99] loss: 0.703111\n",
      "[45,    99] loss: 0.703111\n",
      "[46,    99] loss: 0.703111\n",
      "[47,    99] loss: 0.703111\n",
      "[48,    99] loss: 0.703111\n",
      "[49,    99] loss: 0.703111\n",
      "[50,    99] loss: 0.703111\n",
      "[51,    99] loss: 0.703111\n",
      "[52,    99] loss: 0.703111\n",
      "[53,    99] loss: 0.703111\n",
      "[54,    99] loss: 0.703111\n",
      "[55,    99] loss: 0.703111\n",
      "[56,    99] loss: 0.703111\n",
      "[57,    99] loss: 0.703111\n",
      "[58,    99] loss: 0.703111\n",
      "[59,    99] loss: 0.703111\n",
      "[60,    99] loss: 0.703111\n",
      "[61,    99] loss: 0.703111\n",
      "[62,    99] loss: 0.703111\n",
      "[63,    99] loss: 0.703111\n",
      "[64,    99] loss: 0.703111\n",
      "[65,    99] loss: 0.703111\n",
      "[66,    99] loss: 0.703111\n",
      "[67,    99] loss: 0.703111\n",
      "[68,    99] loss: 0.703111\n",
      "[69,    99] loss: 0.703111\n",
      "[70,    99] loss: 0.703111\n",
      "[71,    99] loss: 0.703111\n",
      "[72,    99] loss: 0.703111\n",
      "[73,    99] loss: 0.703111\n",
      "[74,    99] loss: 0.703111\n",
      "[75,    99] loss: 0.703111\n",
      "[76,    99] loss: 0.703111\n",
      "[77,    99] loss: 0.703111\n",
      "[78,    99] loss: 0.703111\n",
      "[79,    99] loss: 0.703111\n",
      "[80,    99] loss: 0.703111\n",
      "[81,    99] loss: 0.703111\n",
      "[82,    99] loss: 0.703111\n",
      "[83,    99] loss: 0.703111\n",
      "[84,    99] loss: 0.703111\n",
      "[85,    99] loss: 0.703111\n",
      "[86,    99] loss: 0.703111\n",
      "[87,    99] loss: 0.703111\n",
      "[88,    99] loss: 0.703111\n",
      "[89,    99] loss: 0.703111\n",
      "[90,    99] loss: 0.703111\n",
      "[91,    99] loss: 0.703111\n",
      "[92,    99] loss: 0.703111\n",
      "[93,    99] loss: 0.703111\n",
      "[94,    99] loss: 0.703111\n",
      "[95,    99] loss: 0.703111\n",
      "[96,    99] loss: 0.703111\n",
      "[97,    99] loss: 0.703111\n",
      "[98,    99] loss: 0.703111\n",
      "[99,    99] loss: 0.703111\n",
      "[100,    99] loss: 0.703111\n",
      "Finished Training\n",
      "[1,    99] loss: 2.077030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    99] loss: 0.705102\n",
      "[3,    99] loss: 0.704281\n",
      "[4,    99] loss: 0.756296\n",
      "[5,    99] loss: 0.706628\n",
      "[6,    99] loss: 0.706253\n",
      "[7,    99] loss: 0.706171\n",
      "[8,    99] loss: 0.706143\n",
      "[9,    99] loss: 0.706122\n",
      "[10,    99] loss: 0.706107\n",
      "[11,    99] loss: 0.706095\n",
      "[12,    99] loss: 0.706086\n",
      "[13,    99] loss: 0.706079\n",
      "[14,    99] loss: 0.706073\n",
      "[15,    99] loss: 0.706069\n",
      "[16,    99] loss: 0.706065\n",
      "[17,    99] loss: 0.706062\n",
      "[18,    99] loss: 0.706059\n",
      "[19,    99] loss: 0.706057\n",
      "[20,    99] loss: 0.706055\n",
      "[21,    99] loss: 0.706054\n",
      "[22,    99] loss: 0.706053\n",
      "[23,    99] loss: 0.706052\n",
      "[24,    99] loss: 0.706051\n",
      "[25,    99] loss: 0.706050\n",
      "[26,    99] loss: 0.706050\n",
      "[27,    99] loss: 0.706049\n",
      "[28,    99] loss: 0.706049\n",
      "[29,    99] loss: 0.706048\n",
      "[30,    99] loss: 0.706048\n",
      "[31,    99] loss: 0.706048\n",
      "[32,    99] loss: 0.706048\n",
      "[33,    99] loss: 0.706047\n",
      "[34,    99] loss: 0.706047\n",
      "[35,    99] loss: 0.706047\n",
      "[36,    99] loss: 0.706047\n",
      "[37,    99] loss: 0.706047\n",
      "[38,    99] loss: 0.706047\n",
      "[39,    99] loss: 0.706047\n",
      "[40,    99] loss: 0.706047\n",
      "[41,    99] loss: 0.706047\n",
      "[42,    99] loss: 0.706047\n",
      "[43,    99] loss: 0.706047\n",
      "[44,    99] loss: 0.706047\n",
      "[45,    99] loss: 0.706047\n",
      "[46,    99] loss: 0.706047\n",
      "[47,    99] loss: 0.706047\n",
      "[48,    99] loss: 0.706047\n",
      "[49,    99] loss: 0.706047\n",
      "[50,    99] loss: 0.706047\n",
      "[51,    99] loss: 0.706047\n",
      "[52,    99] loss: 0.706047\n",
      "[53,    99] loss: 0.706047\n",
      "[54,    99] loss: 0.706047\n",
      "[55,    99] loss: 0.706047\n",
      "[56,    99] loss: 0.706047\n",
      "[57,    99] loss: 0.706047\n",
      "[58,    99] loss: 0.706047\n",
      "[59,    99] loss: 0.706047\n",
      "[60,    99] loss: 0.706047\n",
      "[61,    99] loss: 0.706047\n",
      "[62,    99] loss: 0.706047\n",
      "[63,    99] loss: 0.706047\n",
      "[64,    99] loss: 0.706047\n",
      "[65,    99] loss: 0.706047\n",
      "[66,    99] loss: 0.706047\n",
      "[67,    99] loss: 0.706047\n",
      "[68,    99] loss: 0.706047\n",
      "[69,    99] loss: 0.706047\n",
      "[70,    99] loss: 0.706047\n",
      "[71,    99] loss: 0.706047\n",
      "[72,    99] loss: 0.706047\n",
      "[73,    99] loss: 0.706047\n",
      "[74,    99] loss: 0.706047\n",
      "[75,    99] loss: 0.706047\n",
      "[76,    99] loss: 0.706047\n",
      "[77,    99] loss: 0.706047\n",
      "[78,    99] loss: 0.706047\n",
      "[79,    99] loss: 0.706047\n",
      "[80,    99] loss: 0.706047\n",
      "[81,    99] loss: 0.706047\n",
      "[82,    99] loss: 0.706047\n",
      "[83,    99] loss: 0.706047\n",
      "[84,    99] loss: 0.706047\n",
      "[85,    99] loss: 0.706047\n",
      "[86,    99] loss: 0.706047\n",
      "[87,    99] loss: 0.706047\n",
      "[88,    99] loss: 0.706047\n",
      "[89,    99] loss: 0.706047\n",
      "[90,    99] loss: 0.706047\n",
      "[91,    99] loss: 0.706047\n",
      "[92,    99] loss: 0.706047\n",
      "[93,    99] loss: 0.706047\n",
      "[94,    99] loss: 0.706047\n",
      "[95,    99] loss: 0.706047\n",
      "[96,    99] loss: 0.706047\n",
      "[97,    99] loss: 0.706047\n",
      "[98,    99] loss: 0.706047\n",
      "[99,    99] loss: 0.706047\n",
      "[100,    99] loss: 0.706047\n",
      "Finished Training\n",
      "[1,    99] loss: 0.690791\n",
      "[2,    99] loss: 0.609645\n",
      "[3,    99] loss: 0.594676\n",
      "[4,    99] loss: 0.477921\n",
      "[5,    99] loss: 0.447731\n",
      "[6,    99] loss: 0.433665\n",
      "[7,    99] loss: 0.392395\n",
      "[8,    99] loss: 0.379541\n",
      "[9,    99] loss: 0.421319\n",
      "[10,    99] loss: 0.368516\n",
      "[11,    99] loss: 0.315957\n",
      "[12,    99] loss: 0.293274\n",
      "[13,    99] loss: 0.270190\n",
      "[14,    99] loss: 0.297710\n",
      "[15,    99] loss: 0.270573\n",
      "[16,    99] loss: 0.313621\n",
      "[17,    99] loss: 0.217236\n",
      "[18,    99] loss: 0.189818\n",
      "[19,    99] loss: 0.213172\n",
      "[20,    99] loss: 0.198358\n",
      "[21,    99] loss: 0.165567\n",
      "[22,    99] loss: 0.128965\n",
      "[23,    99] loss: 0.226922\n",
      "[24,    99] loss: 0.114983\n",
      "[25,    99] loss: 0.173913\n",
      "[26,    99] loss: 0.215067\n",
      "[27,    99] loss: 0.202245\n",
      "[28,    99] loss: 0.155568\n",
      "[29,    99] loss: 0.140045\n",
      "[30,    99] loss: 0.085466\n",
      "[31,    99] loss: 0.096575\n",
      "[32,    99] loss: 0.130565\n",
      "[33,    99] loss: 0.283695\n",
      "[34,    99] loss: 0.186122\n",
      "[35,    99] loss: 0.135106\n",
      "[36,    99] loss: 0.111588\n",
      "[37,    99] loss: 0.114291\n",
      "[38,    99] loss: 0.108937\n",
      "[39,    99] loss: 0.128446\n",
      "[40,    99] loss: 0.075405\n",
      "[41,    99] loss: 0.114314\n",
      "[42,    99] loss: 0.125316\n",
      "[43,    99] loss: 0.059234\n",
      "[44,    99] loss: 0.080449\n",
      "[45,    99] loss: 0.097535\n",
      "[46,    99] loss: 0.101289\n",
      "[47,    99] loss: 0.191372\n",
      "[48,    99] loss: 0.092490\n",
      "[49,    99] loss: 0.077625\n",
      "[50,    99] loss: 0.102428\n",
      "[51,    99] loss: 0.117108\n",
      "[52,    99] loss: 0.133084\n",
      "[53,    99] loss: 0.043996\n",
      "[54,    99] loss: 0.070952\n",
      "[55,    99] loss: 0.184976\n",
      "[56,    99] loss: 0.107855\n",
      "[57,    99] loss: 0.071328\n",
      "[58,    99] loss: 0.146979\n",
      "[59,    99] loss: 0.056016\n",
      "[60,    99] loss: 0.092052\n",
      "[61,    99] loss: 0.109699\n",
      "[62,    99] loss: 0.624720\n",
      "[63,    99] loss: 0.224947\n",
      "[64,    99] loss: 0.171361\n",
      "[65,    99] loss: 0.124390\n",
      "[66,    99] loss: 0.059233\n",
      "[67,    99] loss: 0.099907\n",
      "[68,    99] loss: 0.046129\n",
      "[69,    99] loss: 0.110122\n",
      "[70,    99] loss: 0.098421\n",
      "[71,    99] loss: 0.080804\n",
      "[72,    99] loss: 0.110093\n",
      "[73,    99] loss: 0.057697\n",
      "[74,    99] loss: 0.044059\n",
      "[75,    99] loss: 0.082397\n",
      "[76,    99] loss: 0.077701\n",
      "[77,    99] loss: 0.083078\n",
      "[78,    99] loss: 0.022124\n",
      "[79,    99] loss: 0.075931\n",
      "[80,    99] loss: 0.148451\n",
      "[81,    99] loss: 0.157178\n",
      "[82,    99] loss: 0.106749\n",
      "[83,    99] loss: 0.042923\n",
      "[84,    99] loss: 0.057203\n",
      "[85,    99] loss: 0.063899\n",
      "[86,    99] loss: 0.059497\n",
      "[87,    99] loss: 0.075397\n",
      "[88,    99] loss: 0.112130\n",
      "[89,    99] loss: 0.054405\n",
      "[90,    99] loss: 0.049413\n",
      "[91,    99] loss: 0.028451\n",
      "[92,    99] loss: 0.020444\n",
      "[93,    99] loss: 0.204636\n",
      "[94,    99] loss: 0.060244\n",
      "[95,    99] loss: 0.348773\n",
      "[96,    99] loss: 0.111941\n",
      "[97,    99] loss: 0.054788\n",
      "[98,    99] loss: 0.052394\n",
      "[99,    99] loss: 0.231522\n",
      "[100,    99] loss: 0.144620\n",
      "Finished Training\n",
      "[1,    99] loss: 0.669885\n",
      "[2,    99] loss: 0.583440\n",
      "[3,    99] loss: 0.500468\n",
      "[4,    99] loss: 0.441900\n",
      "[5,    99] loss: 0.406684\n",
      "[6,    99] loss: 0.352819\n",
      "[7,    99] loss: 0.337550\n",
      "[8,    99] loss: 0.339822\n",
      "[9,    99] loss: 0.302848\n",
      "[10,    99] loss: 0.315942\n",
      "[11,    99] loss: 0.249601\n",
      "[12,    99] loss: 0.242468\n",
      "[13,    99] loss: 0.265868\n",
      "[14,    99] loss: 0.254268\n",
      "[15,    99] loss: 0.232247\n",
      "[16,    99] loss: 0.218073\n",
      "[17,    99] loss: 0.183059\n",
      "[18,    99] loss: 0.195678\n",
      "[19,    99] loss: 0.190279\n",
      "[20,    99] loss: 0.147728\n",
      "[21,    99] loss: 0.220776\n",
      "[22,    99] loss: 0.172655\n",
      "[23,    99] loss: 0.192588\n",
      "[24,    99] loss: 0.114861\n",
      "[25,    99] loss: 0.100701\n",
      "[26,    99] loss: 0.122887\n",
      "[27,    99] loss: 0.140587\n",
      "[28,    99] loss: 0.125372\n",
      "[29,    99] loss: 0.104802\n",
      "[30,    99] loss: 0.068256\n",
      "[31,    99] loss: 0.080792\n",
      "[32,    99] loss: 0.241608\n",
      "[33,    99] loss: 0.083671\n",
      "[34,    99] loss: 0.130292\n",
      "[35,    99] loss: 0.062868\n",
      "[36,    99] loss: 0.141372\n",
      "[37,    99] loss: 0.047857\n",
      "[38,    99] loss: 0.156335\n",
      "[39,    99] loss: 0.143744\n",
      "[40,    99] loss: 0.050705\n",
      "[41,    99] loss: 0.043804\n",
      "[42,    99] loss: 0.126540\n",
      "[43,    99] loss: 0.265984\n",
      "[44,    99] loss: 0.134091\n",
      "[45,    99] loss: 0.090598\n",
      "[46,    99] loss: 0.042757\n",
      "[47,    99] loss: 0.059910\n",
      "[48,    99] loss: 0.074544\n",
      "[49,    99] loss: 0.063841\n",
      "[50,    99] loss: 0.072025\n",
      "[51,    99] loss: 0.060061\n",
      "[52,    99] loss: 0.024482\n",
      "[53,    99] loss: 0.023167\n",
      "[54,    99] loss: 0.015053\n",
      "[55,    99] loss: 0.114841\n",
      "[56,    99] loss: 0.083086\n",
      "[57,    99] loss: 0.207155\n",
      "[58,    99] loss: 0.081992\n",
      "[59,    99] loss: 0.036267\n",
      "[60,    99] loss: 0.034760\n",
      "[61,    99] loss: 0.043083\n",
      "[62,    99] loss: 0.059910\n",
      "[63,    99] loss: 0.099300\n",
      "[64,    99] loss: 0.091354\n",
      "[65,    99] loss: 0.168855\n",
      "[66,    99] loss: 0.072057\n",
      "[67,    99] loss: 0.033024\n",
      "[68,    99] loss: 0.018631\n",
      "[69,    99] loss: 0.012444\n",
      "[70,    99] loss: 0.017137\n",
      "[71,    99] loss: 0.017448\n",
      "[72,    99] loss: 0.056774\n",
      "[73,    99] loss: 0.144438\n",
      "[74,    99] loss: 0.136145\n",
      "[75,    99] loss: 0.069290\n",
      "[76,    99] loss: 0.023589\n",
      "[77,    99] loss: 0.029463\n",
      "[78,    99] loss: 0.020936\n",
      "[79,    99] loss: 0.116366\n",
      "[80,    99] loss: 0.079361\n",
      "[81,    99] loss: 0.054804\n",
      "[82,    99] loss: 0.060333\n",
      "[83,    99] loss: 0.038464\n",
      "[84,    99] loss: 0.023139\n",
      "[85,    99] loss: 0.018280\n",
      "[86,    99] loss: 0.071776\n",
      "[87,    99] loss: 0.084441\n",
      "[88,    99] loss: 0.178510\n",
      "[89,    99] loss: 0.061587\n",
      "[90,    99] loss: 0.038755\n",
      "[91,    99] loss: 0.061634\n",
      "[92,    99] loss: 0.101776\n",
      "[93,    99] loss: 0.067051\n",
      "[94,    99] loss: 0.046627\n",
      "[95,    99] loss: 0.020570\n",
      "[96,    99] loss: 0.012914\n",
      "[97,    99] loss: 0.011901\n",
      "[98,    99] loss: 0.002314\n",
      "[99,    99] loss: 0.063314\n",
      "[100,    99] loss: 0.106976\n",
      "Finished Training\n",
      "[1,    99] loss: 0.686545\n",
      "[2,    99] loss: 0.614823\n",
      "[3,    99] loss: 0.559715\n",
      "[4,    99] loss: 0.468420\n",
      "[5,    99] loss: 0.435212\n",
      "[6,    99] loss: 0.385785\n",
      "[7,    99] loss: 0.362195\n",
      "[8,    99] loss: 0.345867\n",
      "[9,    99] loss: 0.329372\n",
      "[10,    99] loss: 0.269311\n",
      "[11,    99] loss: 0.309783\n",
      "[12,    99] loss: 0.279970\n",
      "[13,    99] loss: 0.263403\n",
      "[14,    99] loss: 0.165780\n",
      "[15,    99] loss: 0.164770\n",
      "[16,    99] loss: 0.172292\n",
      "[17,    99] loss: 0.163606\n",
      "[18,    99] loss: 0.280251\n",
      "[19,    99] loss: 0.134301\n",
      "[20,    99] loss: 0.128681\n",
      "[21,    99] loss: 0.083806\n",
      "[22,    99] loss: 0.177990\n",
      "[23,    99] loss: 0.115683\n",
      "[24,    99] loss: 0.164641\n",
      "[25,    99] loss: 0.175798\n",
      "[26,    99] loss: 0.123129\n",
      "[27,    99] loss: 0.080851\n",
      "[28,    99] loss: 0.088456\n",
      "[29,    99] loss: 0.114387\n",
      "[30,    99] loss: 0.063716\n",
      "[31,    99] loss: 0.157525\n",
      "[32,    99] loss: 0.116497\n",
      "[33,    99] loss: 0.151094\n",
      "[34,    99] loss: 0.060592\n",
      "[35,    99] loss: 0.050063\n",
      "[36,    99] loss: 0.114389\n",
      "[37,    99] loss: 0.078594\n",
      "[38,    99] loss: 0.066701\n",
      "[39,    99] loss: 0.042314\n",
      "[40,    99] loss: 0.031718\n",
      "[41,    99] loss: 0.062796\n",
      "[42,    99] loss: 0.123576\n",
      "[43,    99] loss: 0.159443\n",
      "[44,    99] loss: 0.487046\n",
      "[45,    99] loss: 0.056862\n",
      "[46,    99] loss: 0.036209\n",
      "[47,    99] loss: 0.018015\n",
      "[48,    99] loss: 0.022397\n",
      "[49,    99] loss: 0.011731\n",
      "[50,    99] loss: 0.047894\n",
      "[51,    99] loss: 0.026271\n",
      "[52,    99] loss: 0.167081\n",
      "[53,    99] loss: 0.062413\n",
      "[54,    99] loss: 0.066552\n",
      "[55,    99] loss: 0.050993\n",
      "[56,    99] loss: 0.072016\n",
      "[57,    99] loss: 0.032778\n",
      "[58,    99] loss: 0.140201\n",
      "[59,    99] loss: 0.123823\n",
      "[60,    99] loss: 0.134866\n",
      "[61,    99] loss: 0.082212\n",
      "[62,    99] loss: 0.099411\n",
      "[63,    99] loss: 0.056889\n",
      "[64,    99] loss: 0.025874\n",
      "[65,    99] loss: 0.017658\n",
      "[66,    99] loss: 0.014608\n",
      "[67,    99] loss: 0.069155\n",
      "[68,    99] loss: 0.051539\n",
      "[69,    99] loss: 0.029170\n",
      "[70,    99] loss: 0.017830\n",
      "[71,    99] loss: 0.007286\n",
      "[72,    99] loss: 0.004675\n",
      "[73,    99] loss: 0.004484\n",
      "[74,    99] loss: 0.005504\n",
      "[75,    99] loss: 0.008745\n",
      "[76,    99] loss: 0.005141\n",
      "[77,    99] loss: 0.009281\n",
      "[78,    99] loss: 0.004061\n",
      "[79,    99] loss: 0.010168\n",
      "[80,    99] loss: 0.003433\n",
      "[81,    99] loss: 0.009861\n",
      "[82,    99] loss: 0.005400\n",
      "[83,    99] loss: 0.011921\n",
      "[84,    99] loss: 0.531918\n",
      "[85,    99] loss: 0.293801\n",
      "[86,    99] loss: 0.172523\n",
      "[87,    99] loss: 0.050170\n",
      "[88,    99] loss: 0.096966\n",
      "[89,    99] loss: 0.081195\n",
      "[90,    99] loss: 0.013711\n",
      "[91,    99] loss: 0.044586\n",
      "[92,    99] loss: 0.110467\n",
      "[93,    99] loss: 0.008978\n",
      "[94,    99] loss: 0.007611\n",
      "[95,    99] loss: 0.010983\n",
      "[96,    99] loss: 0.009451\n",
      "[97,    99] loss: 0.004687\n",
      "[98,    99] loss: 0.046188\n",
      "[99,    99] loss: 0.082236\n",
      "[100,    99] loss: 0.150932\n",
      "Finished Training\n",
      "[1,    99] loss: 0.698987\n",
      "[2,    99] loss: 0.622336\n",
      "[3,    99] loss: 0.509987\n",
      "[4,    99] loss: 0.439407\n",
      "[5,    99] loss: 0.366700\n",
      "[6,    99] loss: 0.358186\n",
      "[7,    99] loss: 0.286299\n",
      "[8,    99] loss: 0.270302\n",
      "[9,    99] loss: 0.238491\n",
      "[10,    99] loss: 0.227965\n",
      "[11,    99] loss: 0.245587\n",
      "[12,    99] loss: 0.210144\n",
      "[13,    99] loss: 0.187175\n",
      "[14,    99] loss: 0.175037\n",
      "[15,    99] loss: 0.234348\n",
      "[16,    99] loss: 0.153909\n",
      "[17,    99] loss: 0.133634\n",
      "[18,    99] loss: 0.116537\n",
      "[19,    99] loss: 0.282419\n",
      "[20,    99] loss: 0.107977\n",
      "[21,    99] loss: 0.169611\n",
      "[22,    99] loss: 0.107285\n",
      "[23,    99] loss: 0.088494\n",
      "[24,    99] loss: 0.238861\n",
      "[25,    99] loss: 0.118304\n",
      "[26,    99] loss: 0.112528\n",
      "[27,    99] loss: 0.081963\n",
      "[28,    99] loss: 0.064597\n",
      "[29,    99] loss: 0.101504\n",
      "[30,    99] loss: 0.075601\n",
      "[31,    99] loss: 0.068051\n",
      "[32,    99] loss: 0.079665\n",
      "[33,    99] loss: 0.184245\n",
      "[34,    99] loss: 0.264201\n",
      "[35,    99] loss: 0.111086\n",
      "[36,    99] loss: 0.061896\n",
      "[37,    99] loss: 0.035892\n",
      "[38,    99] loss: 0.041751\n",
      "[39,    99] loss: 0.055183\n",
      "[40,    99] loss: 0.064774\n",
      "[41,    99] loss: 0.035590\n",
      "[42,    99] loss: 0.041855\n",
      "[43,    99] loss: 0.052926\n",
      "[44,    99] loss: 0.102225\n",
      "[45,    99] loss: 0.173270\n",
      "[46,    99] loss: 0.104457\n",
      "[47,    99] loss: 0.038018\n",
      "[48,    99] loss: 0.021911\n",
      "[49,    99] loss: 0.006878\n",
      "[50,    99] loss: 0.188391\n",
      "[51,    99] loss: 0.091084\n",
      "[52,    99] loss: 0.039825\n",
      "[53,    99] loss: 0.040466\n",
      "[54,    99] loss: 0.035381\n",
      "[55,    99] loss: 0.086607\n",
      "[56,    99] loss: 0.045650\n",
      "[57,    99] loss: 0.036565\n",
      "[58,    99] loss: 0.047510\n",
      "[59,    99] loss: 0.284049\n",
      "[60,    99] loss: 0.057448\n",
      "[61,    99] loss: 0.100053\n",
      "[62,    99] loss: 0.046820\n",
      "[63,    99] loss: 0.006494\n",
      "[64,    99] loss: 0.006281\n",
      "[65,    99] loss: 0.019182\n",
      "[66,    99] loss: 0.486006\n",
      "[67,    99] loss: 0.101145\n",
      "[68,    99] loss: 0.055174\n",
      "[69,    99] loss: 0.046226\n",
      "[70,    99] loss: 0.008483\n",
      "[71,    99] loss: 0.004489\n",
      "[72,    99] loss: 0.002825\n",
      "[73,    99] loss: 0.002126\n",
      "[74,    99] loss: 0.001814\n",
      "[75,    99] loss: 0.003269\n",
      "[76,    99] loss: 0.002459\n",
      "[77,    99] loss: 0.002413\n",
      "[78,    99] loss: 0.286612\n",
      "[79,    99] loss: 0.243622\n",
      "[80,    99] loss: 0.073233\n",
      "[81,    99] loss: 0.021904\n",
      "[82,    99] loss: 0.033178\n",
      "[83,    99] loss: 0.019250\n",
      "[84,    99] loss: 0.037122\n",
      "[85,    99] loss: 0.014965\n",
      "[86,    99] loss: 0.012393\n",
      "[87,    99] loss: 0.031171\n",
      "[88,    99] loss: 0.181415\n",
      "[89,    99] loss: 0.131070\n",
      "[90,    99] loss: 0.043584\n",
      "[91,    99] loss: 0.031221\n",
      "[92,    99] loss: 0.037365\n",
      "[93,    99] loss: 0.025074\n",
      "[94,    99] loss: 0.019063\n",
      "[95,    99] loss: 0.051211\n",
      "[96,    99] loss: 0.055803\n",
      "[97,    99] loss: 0.040654\n",
      "[98,    99] loss: 0.015375\n",
      "[99,    99] loss: 0.001798\n",
      "[100,    99] loss: 0.085354\n",
      "Finished Training\n",
      "[1,    99] loss: 0.671378\n",
      "[2,    99] loss: 0.580407\n",
      "[3,    99] loss: 0.509823\n",
      "[4,    99] loss: 0.447713\n",
      "[5,    99] loss: 0.370554\n",
      "[6,    99] loss: 0.310349\n",
      "[7,    99] loss: 0.289750\n",
      "[8,    99] loss: 0.320069\n",
      "[9,    99] loss: 0.292600\n",
      "[10,    99] loss: 0.230556\n",
      "[11,    99] loss: 0.211365\n",
      "[12,    99] loss: 0.184618\n",
      "[13,    99] loss: 0.178095\n",
      "[14,    99] loss: 0.179671\n",
      "[15,    99] loss: 0.181616\n",
      "[16,    99] loss: 0.186845\n",
      "[17,    99] loss: 0.136207\n",
      "[18,    99] loss: 0.186716\n",
      "[19,    99] loss: 0.182216\n",
      "[20,    99] loss: 0.148969\n",
      "[21,    99] loss: 0.126717\n",
      "[22,    99] loss: 0.090421\n",
      "[23,    99] loss: 0.076210\n",
      "[24,    99] loss: 0.212589\n",
      "[25,    99] loss: 0.229055\n",
      "[26,    99] loss: 0.152196\n",
      "[27,    99] loss: 0.074965\n",
      "[28,    99] loss: 0.066343\n",
      "[29,    99] loss: 0.083967\n",
      "[30,    99] loss: 0.069175\n",
      "[31,    99] loss: 0.086634\n",
      "[32,    99] loss: 0.114749\n",
      "[33,    99] loss: 0.060980\n",
      "[34,    99] loss: 0.139311\n",
      "[35,    99] loss: 0.075884\n",
      "[36,    99] loss: 0.065330\n",
      "[37,    99] loss: 0.072341\n",
      "[38,    99] loss: 0.028108\n",
      "[39,    99] loss: 0.086464\n",
      "[40,    99] loss: 0.108374\n",
      "[41,    99] loss: 0.121164\n",
      "[42,    99] loss: 0.078974\n",
      "[43,    99] loss: 0.104344\n",
      "[44,    99] loss: 0.105200\n",
      "[45,    99] loss: 0.060019\n",
      "[46,    99] loss: 0.050833\n",
      "[47,    99] loss: 0.036821\n",
      "[48,    99] loss: 0.067825\n",
      "[49,    99] loss: 0.099751\n",
      "[50,    99] loss: 0.098030\n",
      "[51,    99] loss: 0.026602\n",
      "[52,    99] loss: 0.074305\n",
      "[53,    99] loss: 0.013849\n",
      "[54,    99] loss: 0.010977\n",
      "[55,    99] loss: 0.013875\n",
      "[56,    99] loss: 0.101109\n",
      "[57,    99] loss: 0.305713\n",
      "[58,    99] loss: 0.124884\n",
      "[59,    99] loss: 0.119045\n",
      "[60,    99] loss: 0.046859\n",
      "[61,    99] loss: 0.024813\n",
      "[62,    99] loss: 0.047267\n",
      "[63,    99] loss: 0.028281\n",
      "[64,    99] loss: 0.065370\n",
      "[65,    99] loss: 0.037453\n",
      "[66,    99] loss: 0.045211\n",
      "[67,    99] loss: 0.101570\n",
      "[68,    99] loss: 0.024885\n",
      "[69,    99] loss: 0.014303\n",
      "[70,    99] loss: 0.014781\n",
      "[71,    99] loss: 0.038308\n",
      "[72,    99] loss: 0.018637\n",
      "[73,    99] loss: 0.013004\n",
      "[74,    99] loss: 0.014146\n",
      "[75,    99] loss: 0.008929\n",
      "[76,    99] loss: 0.025586\n",
      "[77,    99] loss: 0.015234\n",
      "[78,    99] loss: 0.151430\n",
      "[79,    99] loss: 0.096479\n",
      "[80,    99] loss: 0.084327\n",
      "[81,    99] loss: 0.063044\n",
      "[82,    99] loss: 0.132886\n",
      "[83,    99] loss: 0.016637\n",
      "[84,    99] loss: 0.006114\n",
      "[85,    99] loss: 0.067612\n",
      "[86,    99] loss: 0.005421\n",
      "[87,    99] loss: 0.003615\n",
      "[88,    99] loss: 0.002395\n",
      "[89,    99] loss: 0.002324\n",
      "[90,    99] loss: 0.002559\n",
      "[91,    99] loss: 0.002533\n",
      "[92,    99] loss: 0.002544\n",
      "[93,    99] loss: 0.002367\n",
      "[94,    99] loss: 0.002509\n",
      "[95,    99] loss: 0.003412\n",
      "[96,    99] loss: 0.003568\n",
      "[97,    99] loss: 0.001206\n",
      "[98,    99] loss: 0.103461\n",
      "[99,    99] loss: 0.296525\n",
      "[100,    99] loss: 0.117135\n",
      "Finished Training\n",
      "[1,    99] loss: 0.687471\n",
      "[2,    99] loss: 0.599723\n",
      "[3,    99] loss: 0.521898\n",
      "[4,    99] loss: 0.445501\n",
      "[5,    99] loss: 0.385927\n",
      "[6,    99] loss: 0.333724\n",
      "[7,    99] loss: 0.292824\n",
      "[8,    99] loss: 0.272385\n",
      "[9,    99] loss: 0.246531\n",
      "[10,    99] loss: 0.205959\n",
      "[11,    99] loss: 0.208734\n",
      "[12,    99] loss: 0.173311\n",
      "[13,    99] loss: 0.171891\n",
      "[14,    99] loss: 0.148125\n",
      "[15,    99] loss: 0.135608\n",
      "[16,    99] loss: 0.114224\n",
      "[17,    99] loss: 0.118191\n",
      "[18,    99] loss: 0.105640\n",
      "[19,    99] loss: 0.093993\n",
      "[20,    99] loss: 0.108960\n",
      "[21,    99] loss: 0.079153\n",
      "[22,    99] loss: 0.076353\n",
      "[23,    99] loss: 0.084567\n",
      "[24,    99] loss: 0.079135\n",
      "[25,    99] loss: 0.080051\n",
      "[26,    99] loss: 0.076652\n",
      "[27,    99] loss: 0.054192\n",
      "[28,    99] loss: 0.059656\n",
      "[29,    99] loss: 0.048100\n",
      "[30,    99] loss: 0.051013\n",
      "[31,    99] loss: 0.046415\n",
      "[32,    99] loss: 0.043878\n",
      "[33,    99] loss: 0.042822\n",
      "[34,    99] loss: 0.035979\n",
      "[35,    99] loss: 0.051291\n",
      "[36,    99] loss: 0.079729\n",
      "[37,    99] loss: 0.043764\n",
      "[38,    99] loss: 0.033113\n",
      "[39,    99] loss: 0.029135\n",
      "[40,    99] loss: 0.024755\n",
      "[41,    99] loss: 0.023193\n",
      "[42,    99] loss: 0.024740\n",
      "[43,    99] loss: 0.021217\n",
      "[44,    99] loss: 0.025171\n",
      "[45,    99] loss: 0.026621\n",
      "[46,    99] loss: 0.051216\n",
      "[47,    99] loss: 0.110063\n",
      "[48,    99] loss: 0.044132\n",
      "[49,    99] loss: 0.019605\n",
      "[50,    99] loss: 0.016486\n",
      "[51,    99] loss: 0.013278\n",
      "[52,    99] loss: 0.016545\n",
      "[53,    99] loss: 0.017151\n",
      "[54,    99] loss: 0.020162\n",
      "[55,    99] loss: 0.019085\n",
      "[56,    99] loss: 0.017210\n",
      "[57,    99] loss: 0.022214\n",
      "[58,    99] loss: 0.022025\n",
      "[59,    99] loss: 0.021272\n",
      "[60,    99] loss: 0.013416\n",
      "[61,    99] loss: 0.021679\n",
      "[62,    99] loss: 0.116592\n",
      "[63,    99] loss: 0.044161\n",
      "[64,    99] loss: 0.052253\n",
      "[65,    99] loss: 0.020615\n",
      "[66,    99] loss: 0.017891\n",
      "[67,    99] loss: 0.028164\n",
      "[68,    99] loss: 0.016545\n",
      "[69,    99] loss: 0.027957\n",
      "[70,    99] loss: 0.020774\n",
      "[71,    99] loss: 0.022275\n",
      "[72,    99] loss: 0.151304\n",
      "[73,    99] loss: 0.018461\n",
      "[74,    99] loss: 0.021912\n",
      "[75,    99] loss: 0.017103\n",
      "[76,    99] loss: 0.020673\n",
      "[77,    99] loss: 0.014455\n",
      "[78,    99] loss: 0.018085\n",
      "[79,    99] loss: 0.015762\n",
      "[80,    99] loss: 0.019626\n",
      "[81,    99] loss: 0.017191\n",
      "[82,    99] loss: 0.023974\n",
      "[83,    99] loss: 0.018864\n",
      "[84,    99] loss: 0.017393\n",
      "[85,    99] loss: 0.016443\n",
      "[86,    99] loss: 0.007055\n",
      "[87,    99] loss: 0.024209\n",
      "[88,    99] loss: 0.010912\n",
      "[89,    99] loss: 0.065167\n",
      "[90,    99] loss: 0.163701\n",
      "[91,    99] loss: 0.011270\n",
      "[92,    99] loss: 0.009793\n",
      "[93,    99] loss: 0.014144\n",
      "[94,    99] loss: 0.013127\n",
      "[95,    99] loss: 0.010789\n",
      "[96,    99] loss: 0.006066\n",
      "[97,    99] loss: 0.011170\n",
      "[98,    99] loss: 0.016595\n",
      "[99,    99] loss: 0.008647\n",
      "[100,    99] loss: 0.015098\n",
      "Finished Training\n",
      "[1,    99] loss: 0.690133\n",
      "[2,    99] loss: 0.633536\n",
      "[3,    99] loss: 0.567880\n",
      "[4,    99] loss: 0.494300\n",
      "[5,    99] loss: 0.421578\n",
      "[6,    99] loss: 0.360913\n",
      "[7,    99] loss: 0.309682\n",
      "[8,    99] loss: 0.274903\n",
      "[9,    99] loss: 0.247098\n",
      "[10,    99] loss: 0.220170\n",
      "[11,    99] loss: 0.204605\n",
      "[12,    99] loss: 0.176270\n",
      "[13,    99] loss: 0.164085\n",
      "[14,    99] loss: 0.136622\n",
      "[15,    99] loss: 0.130158\n",
      "[16,    99] loss: 0.106622\n",
      "[17,    99] loss: 0.102428\n",
      "[18,    99] loss: 0.091851\n",
      "[19,    99] loss: 0.084068\n",
      "[20,    99] loss: 0.077776\n",
      "[21,    99] loss: 0.065252\n",
      "[22,    99] loss: 0.059137\n",
      "[23,    99] loss: 0.056669\n",
      "[24,    99] loss: 0.055950\n",
      "[25,    99] loss: 0.054542\n",
      "[26,    99] loss: 0.089515\n",
      "[27,    99] loss: 0.071373\n",
      "[28,    99] loss: 0.046689\n",
      "[29,    99] loss: 0.041508\n",
      "[30,    99] loss: 0.070824\n",
      "[31,    99] loss: 0.053325\n",
      "[32,    99] loss: 0.042854\n",
      "[33,    99] loss: 0.038605\n",
      "[34,    99] loss: 0.058227\n",
      "[35,    99] loss: 0.037402\n",
      "[36,    99] loss: 0.028645\n",
      "[37,    99] loss: 0.029147\n",
      "[38,    99] loss: 0.027928\n",
      "[39,    99] loss: 0.027814\n",
      "[40,    99] loss: 0.029242\n",
      "[41,    99] loss: 0.193474\n",
      "[42,    99] loss: 0.051457\n",
      "[43,    99] loss: 0.021112\n",
      "[44,    99] loss: 0.019856\n",
      "[45,    99] loss: 0.017630\n",
      "[46,    99] loss: 0.016460\n",
      "[47,    99] loss: 0.015579\n",
      "[48,    99] loss: 0.018926\n",
      "[49,    99] loss: 0.017735\n",
      "[50,    99] loss: 0.018832\n",
      "[51,    99] loss: 0.168869\n",
      "[52,    99] loss: 0.057976\n",
      "[53,    99] loss: 0.016140\n",
      "[54,    99] loss: 0.012036\n",
      "[55,    99] loss: 0.009882\n",
      "[56,    99] loss: 0.008502\n",
      "[57,    99] loss: 0.008380\n",
      "[58,    99] loss: 0.007873\n",
      "[59,    99] loss: 0.011193\n",
      "[60,    99] loss: 0.011556\n",
      "[61,    99] loss: 0.014339\n",
      "[62,    99] loss: 0.015091\n",
      "[63,    99] loss: 0.019541\n",
      "[64,    99] loss: 0.020226\n",
      "[65,    99] loss: 0.079346\n",
      "[66,    99] loss: 0.027623\n",
      "[67,    99] loss: 0.038431\n",
      "[68,    99] loss: 0.018259\n",
      "[69,    99] loss: 0.093301\n",
      "[70,    99] loss: 0.008561\n",
      "[71,    99] loss: 0.006204\n",
      "[72,    99] loss: 0.007238\n",
      "[73,    99] loss: 0.015938\n",
      "[74,    99] loss: 0.007661\n",
      "[75,    99] loss: 0.004602\n",
      "[76,    99] loss: 0.003425\n",
      "[77,    99] loss: 0.003149\n",
      "[78,    99] loss: 0.002728\n",
      "[79,    99] loss: 0.003643\n",
      "[80,    99] loss: 0.127738\n",
      "[81,    99] loss: 0.036020\n",
      "[82,    99] loss: 0.039434\n",
      "[83,    99] loss: 0.003798\n",
      "[84,    99] loss: 0.002953\n",
      "[85,    99] loss: 0.002549\n",
      "[86,    99] loss: 0.002315\n",
      "[87,    99] loss: 0.002220\n",
      "[88,    99] loss: 0.002141\n",
      "[89,    99] loss: 0.002031\n",
      "[90,    99] loss: 0.002052\n",
      "[91,    99] loss: 0.001915\n",
      "[92,    99] loss: 0.001969\n",
      "[93,    99] loss: 0.001584\n",
      "[94,    99] loss: 0.001715\n",
      "[95,    99] loss: 0.001439\n",
      "[96,    99] loss: 0.001604\n",
      "[97,    99] loss: 0.059804\n",
      "[98,    99] loss: 0.121895\n",
      "[99,    99] loss: 0.015656\n",
      "[100,    99] loss: 0.004703\n",
      "Finished Training\n",
      "[1,    99] loss: 0.670000\n",
      "[2,    99] loss: 0.579865\n",
      "[3,    99] loss: 0.510464\n",
      "[4,    99] loss: 0.439541\n",
      "[5,    99] loss: 0.368026\n",
      "[6,    99] loss: 0.313316\n",
      "[7,    99] loss: 0.268046\n",
      "[8,    99] loss: 0.237688\n",
      "[9,    99] loss: 0.200651\n",
      "[10,    99] loss: 0.166550\n",
      "[11,    99] loss: 0.139294\n",
      "[12,    99] loss: 0.121618\n",
      "[13,    99] loss: 0.104291\n",
      "[14,    99] loss: 0.092633\n",
      "[15,    99] loss: 0.082510\n",
      "[16,    99] loss: 0.104829\n",
      "[17,    99] loss: 0.069619\n",
      "[18,    99] loss: 0.060923\n",
      "[19,    99] loss: 0.052762\n",
      "[20,    99] loss: 0.067579\n",
      "[21,    99] loss: 0.071600\n",
      "[22,    99] loss: 0.036594\n",
      "[23,    99] loss: 0.035756\n",
      "[24,    99] loss: 0.045074\n",
      "[25,    99] loss: 0.051912\n",
      "[26,    99] loss: 0.037619\n",
      "[27,    99] loss: 0.032806\n",
      "[28,    99] loss: 0.030850\n",
      "[29,    99] loss: 0.024996\n",
      "[30,    99] loss: 0.022329\n",
      "[31,    99] loss: 0.024082\n",
      "[32,    99] loss: 0.038878\n",
      "[33,    99] loss: 0.016545\n",
      "[34,    99] loss: 0.010404\n",
      "[35,    99] loss: 0.010083\n",
      "[36,    99] loss: 0.010396\n",
      "[37,    99] loss: 0.018541\n",
      "[38,    99] loss: 0.026278\n",
      "[39,    99] loss: 0.008546\n",
      "[40,    99] loss: 0.026813\n",
      "[41,    99] loss: 0.017785\n",
      "[42,    99] loss: 0.005608\n",
      "[43,    99] loss: 0.004575\n",
      "[44,    99] loss: 0.004271\n",
      "[45,    99] loss: 0.005377\n",
      "[46,    99] loss: 0.006777\n",
      "[47,    99] loss: 0.008577\n",
      "[48,    99] loss: 0.008003\n",
      "[49,    99] loss: 0.016576\n",
      "[50,    99] loss: 0.069769\n",
      "[51,    99] loss: 0.021611\n",
      "[52,    99] loss: 0.004467\n",
      "[53,    99] loss: 0.002345\n",
      "[54,    99] loss: 0.002062\n",
      "[55,    99] loss: 0.001855\n",
      "[56,    99] loss: 0.001801\n",
      "[57,    99] loss: 0.176145\n",
      "[58,    99] loss: 0.037603\n",
      "[59,    99] loss: 0.010185\n",
      "[60,    99] loss: 0.003540\n",
      "[61,    99] loss: 0.002790\n",
      "[62,    99] loss: 0.002485\n",
      "[63,    99] loss: 0.039605\n",
      "[64,    99] loss: 0.003367\n",
      "[65,    99] loss: 0.002272\n",
      "[66,    99] loss: 0.001874\n",
      "[67,    99] loss: 0.001647\n",
      "[68,    99] loss: 0.001529\n",
      "[69,    99] loss: 0.001451\n",
      "[70,    99] loss: 0.002607\n",
      "[71,    99] loss: 0.115960\n",
      "[72,    99] loss: 0.017739\n",
      "[73,    99] loss: 0.006566\n",
      "[74,    99] loss: 0.002907\n",
      "[75,    99] loss: 0.002051\n",
      "[76,    99] loss: 0.001772\n",
      "[77,    99] loss: 0.001566\n",
      "[78,    99] loss: 0.001401\n",
      "[79,    99] loss: 0.001271\n",
      "[80,    99] loss: 0.001160\n",
      "[81,    99] loss: 0.001060\n",
      "[82,    99] loss: 0.000979\n",
      "[83,    99] loss: 0.000904\n",
      "[84,    99] loss: 0.000837\n",
      "[85,    99] loss: 0.000778\n",
      "[86,    99] loss: 0.000715\n",
      "[87,    99] loss: 0.000676\n",
      "[88,    99] loss: 0.000632\n",
      "[89,    99] loss: 0.000582\n",
      "[90,    99] loss: 0.000530\n",
      "[91,    99] loss: 0.000493\n",
      "[92,    99] loss: 0.000458\n",
      "[93,    99] loss: 0.002108\n",
      "[94,    99] loss: 0.093331\n",
      "[95,    99] loss: 0.029380\n",
      "[96,    99] loss: 0.006248\n",
      "[97,    99] loss: 0.002316\n",
      "[98,    99] loss: 0.001792\n",
      "[99,    99] loss: 0.001457\n",
      "[100,    99] loss: 0.001240\n",
      "Finished Training\n",
      "[1,    99] loss: 0.687248\n",
      "[2,    99] loss: 0.614705\n",
      "[3,    99] loss: 0.514297\n",
      "[4,    99] loss: 0.415749\n",
      "[5,    99] loss: 0.339335\n",
      "[6,    99] loss: 0.278048\n",
      "[7,    99] loss: 0.225630\n",
      "[8,    99] loss: 0.183012\n",
      "[9,    99] loss: 0.154760\n",
      "[10,    99] loss: 0.130135\n",
      "[11,    99] loss: 0.112304\n",
      "[12,    99] loss: 0.112642\n",
      "[13,    99] loss: 0.088838\n",
      "[14,    99] loss: 0.089054\n",
      "[15,    99] loss: 0.074299\n",
      "[16,    99] loss: 0.093073\n",
      "[17,    99] loss: 0.065233\n",
      "[18,    99] loss: 0.051758\n",
      "[19,    99] loss: 0.043064\n",
      "[20,    99] loss: 0.041692\n",
      "[21,    99] loss: 0.035532\n",
      "[22,    99] loss: 0.036961\n",
      "[23,    99] loss: 0.031485\n",
      "[24,    99] loss: 0.031253\n",
      "[25,    99] loss: 0.025539\n",
      "[26,    99] loss: 0.028890\n",
      "[27,    99] loss: 0.148146\n",
      "[28,    99] loss: 0.102410\n",
      "[29,    99] loss: 0.023669\n",
      "[30,    99] loss: 0.029122\n",
      "[31,    99] loss: 0.013121\n",
      "[32,    99] loss: 0.011357\n",
      "[33,    99] loss: 0.008746\n",
      "[34,    99] loss: 0.009225\n",
      "[35,    99] loss: 0.006758\n",
      "[36,    99] loss: 0.006300\n",
      "[37,    99] loss: 0.007442\n",
      "[38,    99] loss: 0.110021\n",
      "[39,    99] loss: 0.065829\n",
      "[40,    99] loss: 0.064918\n",
      "[41,    99] loss: 0.035829\n",
      "[42,    99] loss: 0.010206\n",
      "[43,    99] loss: 0.038241\n",
      "[44,    99] loss: 0.006128\n",
      "[45,    99] loss: 0.005165\n",
      "[46,    99] loss: 0.003799\n",
      "[47,    99] loss: 0.004148\n",
      "[48,    99] loss: 0.003158\n",
      "[49,    99] loss: 0.003808\n",
      "[50,    99] loss: 0.004470\n",
      "[51,    99] loss: 0.175707\n",
      "[52,    99] loss: 0.069016\n",
      "[53,    99] loss: 0.076301\n",
      "[54,    99] loss: 0.007593\n",
      "[55,    99] loss: 0.004512\n",
      "[56,    99] loss: 0.003705\n",
      "[57,    99] loss: 0.003271\n",
      "[58,    99] loss: 0.002809\n",
      "[59,    99] loss: 0.002489\n",
      "[60,    99] loss: 0.002165\n",
      "[61,    99] loss: 0.002010\n",
      "[62,    99] loss: 0.095624\n",
      "[63,    99] loss: 0.091503\n",
      "[64,    99] loss: 0.023477\n",
      "[65,    99] loss: 0.005911\n",
      "[66,    99] loss: 0.003668\n",
      "[67,    99] loss: 0.002987\n",
      "[68,    99] loss: 0.002522\n",
      "[69,    99] loss: 0.002188\n",
      "[70,    99] loss: 0.001940\n",
      "[71,    99] loss: 0.001716\n",
      "[72,    99] loss: 0.001533\n",
      "[73,    99] loss: 0.001374\n",
      "[74,    99] loss: 0.001242\n",
      "[75,    99] loss: 0.001134\n",
      "[76,    99] loss: 0.001023\n",
      "[77,    99] loss: 0.002183\n",
      "[78,    99] loss: 0.199578\n",
      "[79,    99] loss: 0.107930\n",
      "[80,    99] loss: 0.016885\n",
      "[81,    99] loss: 0.005044\n",
      "[82,    99] loss: 0.002721\n",
      "[83,    99] loss: 0.002172\n",
      "[84,    99] loss: 0.001904\n",
      "[85,    99] loss: 0.001674\n",
      "[86,    99] loss: 0.001503\n",
      "[87,    99] loss: 0.001352\n",
      "[88,    99] loss: 0.001234\n",
      "[89,    99] loss: 0.001114\n",
      "[90,    99] loss: 0.001016\n",
      "[91,    99] loss: 0.000932\n",
      "[92,    99] loss: 0.000851\n",
      "[93,    99] loss: 0.000784\n",
      "[94,    99] loss: 0.000714\n",
      "[95,    99] loss: 0.000669\n",
      "[96,    99] loss: 0.000619\n",
      "[97,    99] loss: 0.000569\n",
      "[98,    99] loss: 0.000514\n",
      "[99,    99] loss: 0.000474\n",
      "[100,    99] loss: 0.000427\n",
      "Finished Training\n",
      "[1,    99] loss: 0.682489\n",
      "[2,    99] loss: 0.629202\n",
      "[3,    99] loss: 0.576920\n",
      "[4,    99] loss: 0.512541\n",
      "[5,    99] loss: 0.439552\n",
      "[6,    99] loss: 0.367240\n",
      "[7,    99] loss: 0.307044\n",
      "[8,    99] loss: 0.255532\n",
      "[9,    99] loss: 0.218294\n",
      "[10,    99] loss: 0.183025\n",
      "[11,    99] loss: 0.158827\n",
      "[12,    99] loss: 0.131765\n",
      "[13,    99] loss: 0.115753\n",
      "[14,    99] loss: 0.098799\n",
      "[15,    99] loss: 0.088821\n",
      "[16,    99] loss: 0.081748\n",
      "[17,    99] loss: 0.076397\n",
      "[18,    99] loss: 0.073200\n",
      "[19,    99] loss: 0.065076\n",
      "[20,    99] loss: 0.059768\n",
      "[21,    99] loss: 0.063399\n",
      "[22,    99] loss: 0.059048\n",
      "[23,    99] loss: 0.048038\n",
      "[24,    99] loss: 0.039770\n",
      "[25,    99] loss: 0.038340\n",
      "[26,    99] loss: 0.033337\n",
      "[27,    99] loss: 0.023722\n",
      "[28,    99] loss: 0.029636\n",
      "[29,    99] loss: 0.035696\n",
      "[30,    99] loss: 0.063785\n",
      "[31,    99] loss: 0.023185\n",
      "[32,    99] loss: 0.014785\n",
      "[33,    99] loss: 0.016565\n",
      "[34,    99] loss: 0.034503\n",
      "[35,    99] loss: 0.033814\n",
      "[36,    99] loss: 0.108001\n",
      "[37,    99] loss: 0.030519\n",
      "[38,    99] loss: 0.019585\n",
      "[39,    99] loss: 0.013899\n",
      "[40,    99] loss: 0.010106\n",
      "[41,    99] loss: 0.009517\n",
      "[42,    99] loss: 0.012379\n",
      "[43,    99] loss: 0.019897\n",
      "[44,    99] loss: 0.019665\n",
      "[45,    99] loss: 0.021312\n",
      "[46,    99] loss: 0.011894\n",
      "[47,    99] loss: 0.011916\n",
      "[48,    99] loss: 0.007314\n",
      "[49,    99] loss: 0.003980\n",
      "[50,    99] loss: 0.002841\n",
      "[51,    99] loss: 0.002388\n",
      "[52,    99] loss: 0.002116\n",
      "[53,    99] loss: 0.001909\n",
      "[54,    99] loss: 0.001816\n",
      "[55,    99] loss: 0.001720\n",
      "[56,    99] loss: 0.001927\n",
      "[57,    99] loss: 0.002089\n",
      "[58,    99] loss: 0.050259\n",
      "[59,    99] loss: 0.093768\n",
      "[60,    99] loss: 0.010838\n",
      "[61,    99] loss: 0.004624\n",
      "[62,    99] loss: 0.003002\n",
      "[63,    99] loss: 0.002559\n",
      "[64,    99] loss: 0.002385\n",
      "[65,    99] loss: 0.002191\n",
      "[66,    99] loss: 0.002060\n",
      "[67,    99] loss: 0.001927\n",
      "[68,    99] loss: 0.001823\n",
      "[69,    99] loss: 0.001700\n",
      "[70,    99] loss: 0.001619\n",
      "[71,    99] loss: 0.001559\n",
      "[72,    99] loss: 0.001423\n",
      "[73,    99] loss: 0.001331\n",
      "[74,    99] loss: 0.001229\n",
      "[75,    99] loss: 0.001128\n",
      "[76,    99] loss: 0.001100\n",
      "[77,    99] loss: 0.001109\n",
      "[78,    99] loss: 0.004383\n",
      "[79,    99] loss: 0.148885\n",
      "[80,    99] loss: 0.018648\n",
      "[81,    99] loss: 0.011721\n",
      "[82,    99] loss: 0.003280\n",
      "[83,    99] loss: 0.002628\n",
      "[84,    99] loss: 0.002311\n",
      "[85,    99] loss: 0.002037\n",
      "[86,    99] loss: 0.001830\n",
      "[87,    99] loss: 0.001651\n",
      "[88,    99] loss: 0.001507\n",
      "[89,    99] loss: 0.001367\n",
      "[90,    99] loss: 0.001254\n",
      "[91,    99] loss: 0.001152\n",
      "[92,    99] loss: 0.001065\n",
      "[93,    99] loss: 0.000976\n",
      "[94,    99] loss: 0.000917\n",
      "[95,    99] loss: 0.000848\n",
      "[96,    99] loss: 0.000785\n",
      "[97,    99] loss: 0.000724\n",
      "[98,    99] loss: 0.000663\n",
      "[99,    99] loss: 0.000623\n",
      "[100,    99] loss: 0.000572\n",
      "Finished Training\n",
      "[1,    99] loss: 0.681820\n",
      "[2,    99] loss: 0.667324\n",
      "[3,    99] loss: 0.655870\n",
      "[4,    99] loss: 0.644803\n",
      "[5,    99] loss: 0.633570\n",
      "[6,    99] loss: 0.622723\n",
      "[7,    99] loss: 0.611893\n",
      "[8,    99] loss: 0.601393\n",
      "[9,    99] loss: 0.591006\n",
      "[10,    99] loss: 0.580890\n",
      "[11,    99] loss: 0.570998\n",
      "[12,    99] loss: 0.561357\n",
      "[13,    99] loss: 0.551919\n",
      "[14,    99] loss: 0.542449\n",
      "[15,    99] loss: 0.532943\n",
      "[16,    99] loss: 0.523346\n",
      "[17,    99] loss: 0.513719\n",
      "[18,    99] loss: 0.504247\n",
      "[19,    99] loss: 0.494876\n",
      "[20,    99] loss: 0.485624\n",
      "[21,    99] loss: 0.476471\n",
      "[22,    99] loss: 0.467232\n",
      "[23,    99] loss: 0.458218\n",
      "[24,    99] loss: 0.449170\n",
      "[25,    99] loss: 0.440300\n",
      "[26,    99] loss: 0.431432\n",
      "[27,    99] loss: 0.422589\n",
      "[28,    99] loss: 0.413346\n",
      "[29,    99] loss: 0.404221\n",
      "[30,    99] loss: 0.395516\n",
      "[31,    99] loss: 0.386995\n",
      "[32,    99] loss: 0.378674\n",
      "[33,    99] loss: 0.370700\n",
      "[34,    99] loss: 0.362640\n",
      "[35,    99] loss: 0.354819\n",
      "[36,    99] loss: 0.347252\n",
      "[37,    99] loss: 0.339768\n",
      "[38,    99] loss: 0.332552\n",
      "[39,    99] loss: 0.325346\n",
      "[40,    99] loss: 0.318478\n",
      "[41,    99] loss: 0.311740\n",
      "[42,    99] loss: 0.305219\n",
      "[43,    99] loss: 0.298935\n",
      "[44,    99] loss: 0.292767\n",
      "[45,    99] loss: 0.286796\n",
      "[46,    99] loss: 0.280922\n",
      "[47,    99] loss: 0.275269\n",
      "[48,    99] loss: 0.269601\n",
      "[49,    99] loss: 0.264110\n",
      "[50,    99] loss: 0.258947\n",
      "[51,    99] loss: 0.253566\n",
      "[52,    99] loss: 0.248560\n",
      "[53,    99] loss: 0.243441\n",
      "[54,    99] loss: 0.238728\n",
      "[55,    99] loss: 0.233885\n",
      "[56,    99] loss: 0.229351\n",
      "[57,    99] loss: 0.224787\n",
      "[58,    99] loss: 0.220396\n",
      "[59,    99] loss: 0.216146\n",
      "[60,    99] loss: 0.211774\n",
      "[61,    99] loss: 0.207576\n",
      "[62,    99] loss: 0.203286\n",
      "[63,    99] loss: 0.199268\n",
      "[64,    99] loss: 0.195105\n",
      "[65,    99] loss: 0.191211\n",
      "[66,    99] loss: 0.187158\n",
      "[67,    99] loss: 0.183514\n",
      "[68,    99] loss: 0.179711\n",
      "[69,    99] loss: 0.176057\n",
      "[70,    99] loss: 0.172617\n",
      "[71,    99] loss: 0.168966\n",
      "[72,    99] loss: 0.165679\n",
      "[73,    99] loss: 0.162185\n",
      "[74,    99] loss: 0.158811\n",
      "[75,    99] loss: 0.155785\n",
      "[76,    99] loss: 0.152483\n",
      "[77,    99] loss: 0.149427\n",
      "[78,    99] loss: 0.146393\n",
      "[79,    99] loss: 0.143352\n",
      "[80,    99] loss: 0.140449\n",
      "[81,    99] loss: 0.137552\n",
      "[82,    99] loss: 0.134760\n",
      "[83,    99] loss: 0.132051\n",
      "[84,    99] loss: 0.129466\n",
      "[85,    99] loss: 0.126754\n",
      "[86,    99] loss: 0.124147\n",
      "[87,    99] loss: 0.121680\n",
      "[88,    99] loss: 0.119263\n",
      "[89,    99] loss: 0.116881\n",
      "[90,    99] loss: 0.114480\n",
      "[91,    99] loss: 0.112247\n",
      "[92,    99] loss: 0.109923\n",
      "[93,    99] loss: 0.107850\n",
      "[94,    99] loss: 0.105580\n",
      "[95,    99] loss: 0.103439\n",
      "[96,    99] loss: 0.101441\n",
      "[97,    99] loss: 0.099271\n",
      "[98,    99] loss: 0.097326\n",
      "[99,    99] loss: 0.095446\n",
      "[100,    99] loss: 0.093741\n",
      "Finished Training\n",
      "[1,    99] loss: 0.734788\n",
      "[2,    99] loss: 0.700191\n",
      "[3,    99] loss: 0.678845\n",
      "[4,    99] loss: 0.664039\n",
      "[5,    99] loss: 0.653355\n",
      "[6,    99] loss: 0.643664\n",
      "[7,    99] loss: 0.634080\n",
      "[8,    99] loss: 0.624954\n",
      "[9,    99] loss: 0.615916\n",
      "[10,    99] loss: 0.607084\n",
      "[11,    99] loss: 0.598458\n",
      "[12,    99] loss: 0.589910\n",
      "[13,    99] loss: 0.581515\n",
      "[14,    99] loss: 0.573303\n",
      "[15,    99] loss: 0.565460\n",
      "[16,    99] loss: 0.557638\n",
      "[17,    99] loss: 0.549789\n",
      "[18,    99] loss: 0.542069\n",
      "[19,    99] loss: 0.534869\n",
      "[20,    99] loss: 0.527402\n",
      "[21,    99] loss: 0.520247\n",
      "[22,    99] loss: 0.512987\n",
      "[23,    99] loss: 0.505719\n",
      "[24,    99] loss: 0.498481\n",
      "[25,    99] loss: 0.490995\n",
      "[26,    99] loss: 0.483633\n",
      "[27,    99] loss: 0.476138\n",
      "[28,    99] loss: 0.468566\n",
      "[29,    99] loss: 0.460962\n",
      "[30,    99] loss: 0.453311\n",
      "[31,    99] loss: 0.445505\n",
      "[32,    99] loss: 0.437838\n",
      "[33,    99] loss: 0.430123\n",
      "[34,    99] loss: 0.422231\n",
      "[35,    99] loss: 0.414481\n",
      "[36,    99] loss: 0.406855\n",
      "[37,    99] loss: 0.399139\n",
      "[38,    99] loss: 0.391612\n",
      "[39,    99] loss: 0.384005\n",
      "[40,    99] loss: 0.376750\n",
      "[41,    99] loss: 0.369424\n",
      "[42,    99] loss: 0.362303\n",
      "[43,    99] loss: 0.355168\n",
      "[44,    99] loss: 0.348500\n",
      "[45,    99] loss: 0.341835\n",
      "[46,    99] loss: 0.335113\n",
      "[47,    99] loss: 0.328823\n",
      "[48,    99] loss: 0.322669\n",
      "[49,    99] loss: 0.316284\n",
      "[50,    99] loss: 0.310171\n",
      "[51,    99] loss: 0.304173\n",
      "[52,    99] loss: 0.298323\n",
      "[53,    99] loss: 0.292582\n",
      "[54,    99] loss: 0.286610\n",
      "[55,    99] loss: 0.280839\n",
      "[56,    99] loss: 0.275281\n",
      "[57,    99] loss: 0.269890\n",
      "[58,    99] loss: 0.264508\n",
      "[59,    99] loss: 0.259247\n",
      "[60,    99] loss: 0.254141\n",
      "[61,    99] loss: 0.249284\n",
      "[62,    99] loss: 0.244597\n",
      "[63,    99] loss: 0.239836\n",
      "[64,    99] loss: 0.235434\n",
      "[65,    99] loss: 0.230899\n",
      "[66,    99] loss: 0.226521\n",
      "[67,    99] loss: 0.222257\n",
      "[68,    99] loss: 0.217992\n",
      "[69,    99] loss: 0.214075\n",
      "[70,    99] loss: 0.210079\n",
      "[71,    99] loss: 0.206267\n",
      "[72,    99] loss: 0.202525\n",
      "[73,    99] loss: 0.198864\n",
      "[74,    99] loss: 0.195395\n",
      "[75,    99] loss: 0.191810\n",
      "[76,    99] loss: 0.188375\n",
      "[77,    99] loss: 0.184986\n",
      "[78,    99] loss: 0.181496\n",
      "[79,    99] loss: 0.178169\n",
      "[80,    99] loss: 0.174991\n",
      "[81,    99] loss: 0.171645\n",
      "[82,    99] loss: 0.168695\n",
      "[83,    99] loss: 0.165491\n",
      "[84,    99] loss: 0.162514\n",
      "[85,    99] loss: 0.159467\n",
      "[86,    99] loss: 0.156489\n",
      "[87,    99] loss: 0.153403\n",
      "[88,    99] loss: 0.150248\n",
      "[89,    99] loss: 0.147437\n",
      "[90,    99] loss: 0.144495\n",
      "[91,    99] loss: 0.141625\n",
      "[92,    99] loss: 0.138963\n",
      "[93,    99] loss: 0.136167\n",
      "[94,    99] loss: 0.133481\n",
      "[95,    99] loss: 0.130995\n",
      "[96,    99] loss: 0.128387\n",
      "[97,    99] loss: 0.125866\n",
      "[98,    99] loss: 0.123346\n",
      "[99,    99] loss: 0.121014\n",
      "[100,    99] loss: 0.118621\n",
      "Finished Training\n",
      "[1,    99] loss: 0.691560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    99] loss: 0.683114\n",
      "[3,    99] loss: 0.675001\n",
      "[4,    99] loss: 0.666599\n",
      "[5,    99] loss: 0.657027\n",
      "[6,    99] loss: 0.646466\n",
      "[7,    99] loss: 0.634835\n",
      "[8,    99] loss: 0.622502\n",
      "[9,    99] loss: 0.610047\n",
      "[10,    99] loss: 0.597491\n",
      "[11,    99] loss: 0.585069\n",
      "[12,    99] loss: 0.572636\n",
      "[13,    99] loss: 0.560595\n",
      "[14,    99] loss: 0.549005\n",
      "[15,    99] loss: 0.537730\n",
      "[16,    99] loss: 0.526405\n",
      "[17,    99] loss: 0.514845\n",
      "[18,    99] loss: 0.503527\n",
      "[19,    99] loss: 0.492299\n",
      "[20,    99] loss: 0.481191\n",
      "[21,    99] loss: 0.470139\n",
      "[22,    99] loss: 0.459069\n",
      "[23,    99] loss: 0.447886\n",
      "[24,    99] loss: 0.436956\n",
      "[25,    99] loss: 0.425872\n",
      "[26,    99] loss: 0.414967\n",
      "[27,    99] loss: 0.404250\n",
      "[28,    99] loss: 0.393642\n",
      "[29,    99] loss: 0.383273\n",
      "[30,    99] loss: 0.373080\n",
      "[31,    99] loss: 0.362947\n",
      "[32,    99] loss: 0.353164\n",
      "[33,    99] loss: 0.343586\n",
      "[34,    99] loss: 0.334233\n",
      "[35,    99] loss: 0.325025\n",
      "[36,    99] loss: 0.316079\n",
      "[37,    99] loss: 0.307358\n",
      "[38,    99] loss: 0.298873\n",
      "[39,    99] loss: 0.290492\n",
      "[40,    99] loss: 0.282432\n",
      "[41,    99] loss: 0.274628\n",
      "[42,    99] loss: 0.267136\n",
      "[43,    99] loss: 0.259903\n",
      "[44,    99] loss: 0.252990\n",
      "[45,    99] loss: 0.246321\n",
      "[46,    99] loss: 0.239966\n",
      "[47,    99] loss: 0.233734\n",
      "[48,    99] loss: 0.227761\n",
      "[49,    99] loss: 0.222031\n",
      "[50,    99] loss: 0.216425\n",
      "[51,    99] loss: 0.211025\n",
      "[52,    99] loss: 0.205807\n",
      "[53,    99] loss: 0.200593\n",
      "[54,    99] loss: 0.195688\n",
      "[55,    99] loss: 0.190844\n",
      "[56,    99] loss: 0.186202\n",
      "[57,    99] loss: 0.181528\n",
      "[58,    99] loss: 0.177062\n",
      "[59,    99] loss: 0.172776\n",
      "[60,    99] loss: 0.168593\n",
      "[61,    99] loss: 0.164500\n",
      "[62,    99] loss: 0.160593\n",
      "[63,    99] loss: 0.156734\n",
      "[64,    99] loss: 0.152844\n",
      "[65,    99] loss: 0.149091\n",
      "[66,    99] loss: 0.145561\n",
      "[67,    99] loss: 0.142049\n",
      "[68,    99] loss: 0.138589\n",
      "[69,    99] loss: 0.135381\n",
      "[70,    99] loss: 0.132065\n",
      "[71,    99] loss: 0.129071\n",
      "[72,    99] loss: 0.126001\n",
      "[73,    99] loss: 0.123045\n",
      "[74,    99] loss: 0.120124\n",
      "[75,    99] loss: 0.117453\n",
      "[76,    99] loss: 0.114596\n",
      "[77,    99] loss: 0.111930\n",
      "[78,    99] loss: 0.109390\n",
      "[79,    99] loss: 0.106785\n",
      "[80,    99] loss: 0.104457\n",
      "[81,    99] loss: 0.102078\n",
      "[82,    99] loss: 0.099836\n",
      "[83,    99] loss: 0.097480\n",
      "[84,    99] loss: 0.095411\n",
      "[85,    99] loss: 0.093289\n",
      "[86,    99] loss: 0.091218\n",
      "[87,    99] loss: 0.089302\n",
      "[88,    99] loss: 0.087450\n",
      "[89,    99] loss: 0.085572\n",
      "[90,    99] loss: 0.083743\n",
      "[91,    99] loss: 0.081876\n",
      "[92,    99] loss: 0.080098\n",
      "[93,    99] loss: 0.078404\n",
      "[94,    99] loss: 0.076638\n",
      "[95,    99] loss: 0.075005\n",
      "[96,    99] loss: 0.073391\n",
      "[97,    99] loss: 0.071890\n",
      "[98,    99] loss: 0.070294\n",
      "[99,    99] loss: 0.068602\n",
      "[100,    99] loss: 0.067037\n",
      "Finished Training\n",
      "[1,    99] loss: 0.678970\n",
      "[2,    99] loss: 0.671591\n",
      "[3,    99] loss: 0.664127\n",
      "[4,    99] loss: 0.655558\n",
      "[5,    99] loss: 0.646081\n",
      "[6,    99] loss: 0.636018\n",
      "[7,    99] loss: 0.624933\n",
      "[8,    99] loss: 0.613229\n",
      "[9,    99] loss: 0.601077\n",
      "[10,    99] loss: 0.588691\n",
      "[11,    99] loss: 0.576349\n",
      "[12,    99] loss: 0.563802\n",
      "[13,    99] loss: 0.551126\n",
      "[14,    99] loss: 0.538357\n",
      "[15,    99] loss: 0.525716\n",
      "[16,    99] loss: 0.512968\n",
      "[17,    99] loss: 0.500076\n",
      "[18,    99] loss: 0.486901\n",
      "[19,    99] loss: 0.473628\n",
      "[20,    99] loss: 0.460278\n",
      "[21,    99] loss: 0.446942\n",
      "[22,    99] loss: 0.433742\n",
      "[23,    99] loss: 0.420478\n",
      "[24,    99] loss: 0.407415\n",
      "[25,    99] loss: 0.394854\n",
      "[26,    99] loss: 0.382674\n",
      "[27,    99] loss: 0.370753\n",
      "[28,    99] loss: 0.359255\n",
      "[29,    99] loss: 0.348041\n",
      "[30,    99] loss: 0.337018\n",
      "[31,    99] loss: 0.326475\n",
      "[32,    99] loss: 0.316328\n",
      "[33,    99] loss: 0.306642\n",
      "[34,    99] loss: 0.297291\n",
      "[35,    99] loss: 0.288268\n",
      "[36,    99] loss: 0.279566\n",
      "[37,    99] loss: 0.271196\n",
      "[38,    99] loss: 0.263241\n",
      "[39,    99] loss: 0.255672\n",
      "[40,    99] loss: 0.248327\n",
      "[41,    99] loss: 0.241373\n",
      "[42,    99] loss: 0.234715\n",
      "[43,    99] loss: 0.228289\n",
      "[44,    99] loss: 0.222161\n",
      "[45,    99] loss: 0.216139\n",
      "[46,    99] loss: 0.210425\n",
      "[47,    99] loss: 0.204848\n",
      "[48,    99] loss: 0.199519\n",
      "[49,    99] loss: 0.194318\n",
      "[50,    99] loss: 0.189412\n",
      "[51,    99] loss: 0.184730\n",
      "[52,    99] loss: 0.180121\n",
      "[53,    99] loss: 0.175619\n",
      "[54,    99] loss: 0.171218\n",
      "[55,    99] loss: 0.167029\n",
      "[56,    99] loss: 0.162957\n",
      "[57,    99] loss: 0.159051\n",
      "[58,    99] loss: 0.155222\n",
      "[59,    99] loss: 0.151427\n",
      "[60,    99] loss: 0.147812\n",
      "[61,    99] loss: 0.144241\n",
      "[62,    99] loss: 0.140845\n",
      "[63,    99] loss: 0.137576\n",
      "[64,    99] loss: 0.134356\n",
      "[65,    99] loss: 0.131192\n",
      "[66,    99] loss: 0.128237\n",
      "[67,    99] loss: 0.125249\n",
      "[68,    99] loss: 0.122269\n",
      "[69,    99] loss: 0.119399\n",
      "[70,    99] loss: 0.116709\n",
      "[71,    99] loss: 0.113925\n",
      "[72,    99] loss: 0.111340\n",
      "[73,    99] loss: 0.108758\n",
      "[74,    99] loss: 0.106273\n",
      "[75,    99] loss: 0.103921\n",
      "[76,    99] loss: 0.101483\n",
      "[77,    99] loss: 0.099251\n",
      "[78,    99] loss: 0.096949\n",
      "[79,    99] loss: 0.094775\n",
      "[80,    99] loss: 0.092474\n",
      "[81,    99] loss: 0.090393\n",
      "[82,    99] loss: 0.088359\n",
      "[83,    99] loss: 0.086207\n",
      "[84,    99] loss: 0.084251\n",
      "[85,    99] loss: 0.082243\n",
      "[86,    99] loss: 0.080418\n",
      "[87,    99] loss: 0.078453\n",
      "[88,    99] loss: 0.076699\n",
      "[89,    99] loss: 0.074751\n",
      "[90,    99] loss: 0.073058\n",
      "[91,    99] loss: 0.071348\n",
      "[92,    99] loss: 0.069705\n",
      "[93,    99] loss: 0.068067\n",
      "[94,    99] loss: 0.066475\n",
      "[95,    99] loss: 0.064882\n",
      "[96,    99] loss: 0.063342\n",
      "[97,    99] loss: 0.061902\n",
      "[98,    99] loss: 0.060460\n",
      "[99,    99] loss: 0.058981\n",
      "[100,    99] loss: 0.057594\n",
      "Finished Training\n",
      "[1,    99] loss: 0.696196\n",
      "[2,    99] loss: 0.687358\n",
      "[3,    99] loss: 0.679755\n",
      "[4,    99] loss: 0.672438\n",
      "[5,    99] loss: 0.664832\n",
      "[6,    99] loss: 0.656489\n",
      "[7,    99] loss: 0.647434\n",
      "[8,    99] loss: 0.638246\n",
      "[9,    99] loss: 0.628773\n",
      "[10,    99] loss: 0.618848\n",
      "[11,    99] loss: 0.608753\n",
      "[12,    99] loss: 0.598306\n",
      "[13,    99] loss: 0.587761\n",
      "[14,    99] loss: 0.576903\n",
      "[15,    99] loss: 0.565837\n",
      "[16,    99] loss: 0.554688\n",
      "[17,    99] loss: 0.543609\n",
      "[18,    99] loss: 0.532541\n",
      "[19,    99] loss: 0.521337\n",
      "[20,    99] loss: 0.510028\n",
      "[21,    99] loss: 0.498941\n",
      "[22,    99] loss: 0.488046\n",
      "[23,    99] loss: 0.477207\n",
      "[24,    99] loss: 0.466508\n",
      "[25,    99] loss: 0.456051\n",
      "[26,    99] loss: 0.445684\n",
      "[27,    99] loss: 0.435608\n",
      "[28,    99] loss: 0.425850\n",
      "[29,    99] loss: 0.416370\n",
      "[30,    99] loss: 0.407002\n",
      "[31,    99] loss: 0.397819\n",
      "[32,    99] loss: 0.388799\n",
      "[33,    99] loss: 0.379956\n",
      "[34,    99] loss: 0.371292\n",
      "[35,    99] loss: 0.362853\n",
      "[36,    99] loss: 0.354608\n",
      "[37,    99] loss: 0.346309\n",
      "[38,    99] loss: 0.338273\n",
      "[39,    99] loss: 0.330373\n",
      "[40,    99] loss: 0.322488\n",
      "[41,    99] loss: 0.314870\n",
      "[42,    99] loss: 0.307428\n",
      "[43,    99] loss: 0.300227\n",
      "[44,    99] loss: 0.293088\n",
      "[45,    99] loss: 0.286206\n",
      "[46,    99] loss: 0.279546\n",
      "[47,    99] loss: 0.273018\n",
      "[48,    99] loss: 0.266536\n",
      "[49,    99] loss: 0.260209\n",
      "[50,    99] loss: 0.254080\n",
      "[51,    99] loss: 0.248047\n",
      "[52,    99] loss: 0.242200\n",
      "[53,    99] loss: 0.236493\n",
      "[54,    99] loss: 0.230838\n",
      "[55,    99] loss: 0.225310\n",
      "[56,    99] loss: 0.219889\n",
      "[57,    99] loss: 0.214479\n",
      "[58,    99] loss: 0.209367\n",
      "[59,    99] loss: 0.204347\n",
      "[60,    99] loss: 0.199267\n",
      "[61,    99] loss: 0.194318\n",
      "[62,    99] loss: 0.189539\n",
      "[63,    99] loss: 0.184658\n",
      "[64,    99] loss: 0.179954\n",
      "[65,    99] loss: 0.175498\n",
      "[66,    99] loss: 0.171156\n",
      "[67,    99] loss: 0.166963\n",
      "[68,    99] loss: 0.162927\n",
      "[69,    99] loss: 0.158922\n",
      "[70,    99] loss: 0.155090\n",
      "[71,    99] loss: 0.151370\n",
      "[72,    99] loss: 0.147587\n",
      "[73,    99] loss: 0.144060\n",
      "[74,    99] loss: 0.140670\n",
      "[75,    99] loss: 0.137354\n",
      "[76,    99] loss: 0.134064\n",
      "[77,    99] loss: 0.130943\n",
      "[78,    99] loss: 0.127810\n",
      "[79,    99] loss: 0.124771\n",
      "[80,    99] loss: 0.121904\n",
      "[81,    99] loss: 0.119100\n",
      "[82,    99] loss: 0.116368\n",
      "[83,    99] loss: 0.113643\n",
      "[84,    99] loss: 0.110924\n",
      "[85,    99] loss: 0.108359\n",
      "[86,    99] loss: 0.105788\n",
      "[87,    99] loss: 0.103221\n",
      "[88,    99] loss: 0.100691\n",
      "[89,    99] loss: 0.098293\n",
      "[90,    99] loss: 0.095999\n",
      "[91,    99] loss: 0.093747\n",
      "[92,    99] loss: 0.091506\n",
      "[93,    99] loss: 0.089248\n",
      "[94,    99] loss: 0.087128\n",
      "[95,    99] loss: 0.085085\n",
      "[96,    99] loss: 0.083024\n",
      "[97,    99] loss: 0.080989\n",
      "[98,    99] loss: 0.079124\n",
      "[99,    99] loss: 0.077220\n",
      "[100,    99] loss: 0.075343\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utgoer\\Anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#Here we use all 14 features\n",
    "#Due to concatanation it comes out as 28 features per sample\n",
    "final_stat_e=[]\n",
    "epoch_stat_e=[]\n",
    "ms_arr_e=[]\n",
    "for batch_size,lr in product([1,2,4,8,16], [0.1,0.01,0.001,0.0001]):\n",
    "    final_stat,epoch_stat, ms_arr = cross_validation(28,labels, features_e, 5, NO_EPOCH, batch_size,lr,cuda_is_available,True,None)\n",
    "    final_stat_e.append(final_stat)\n",
    "    epoch_stat_e.append(epoch_stat)\n",
    "    ms_arr_e.append(ms_arr)\n",
    "np.save('qB_final_stat_e.npy', np.array(final_stat_e))\n",
    "np.save('qB_epoch_stat_e.npy', np.array(epoch_stat_e))\n",
    "np.save('qB_ms_arr_e.npy', np.array(ms_arr_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the saved results\n",
    "final_stat_s = np.load('qB_final_stat_s.npy')\n",
    "epoch_stat_s = np.load('qB_epoch_stat_s.npy')\n",
    "ms_arr_s = np.load('qB_ms_arr_s.npy')\n",
    "final_stat_e = np.load('qB_final_stat_e.npy')\n",
    "epoch_stat_e = np.load('qB_epoch_stat_e.npy')\n",
    "ms_arr_e = np.load('qB_ms_arr_e.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Some Statistics and Plots about NN***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the F1-score vs Epoch values for the various Grid search parameters we used above.\n",
    "These plots are only for demonstration purposes as they tell us which hyper-parameters produced the best results in their respective model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking some of the graphs it is important to note that at some point due to the overfitting validation loss decreases while the training loss increases. It is important to early stop the training at that point and we are providing the result of the early stoping reasults. You can see this clearly by looking the last plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of all hyper-parameter combinations\n",
    "combinations = list(product([1,2,4,8,16], [0.1,0.01,0.001,0.0001]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'F1-score')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#By looking this graph we can say that which model gives a good f1-score. We are aware of that this plot not good at differentiate the every value.\n",
    "#However, we are not using this graph to differentiate every value from the each other. Please note that we will explain the strange behaviour (90% f1-score lines ie.brown line)\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "x = np.arange(NO_EPOCH)+1\n",
    "\n",
    "colors = ['#e6194B', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#42d4f4', '#f032e6', '#bfef45', '#fabed4', '#469990', '#dcbeff', '#9A6324', '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1', '#000075', '#a9a9a9', '#ffffff', '#000000']\n",
    "best_idx_cvs = []\n",
    "for idx in range(final_stat_s.shape[0]):\n",
    "    best_idx_cvs.append(np.argmax(final_stat_s[idx][2]))\n",
    "    ax.plot(x, epoch_stat_s[idx][2][best_idx_cvs[-1]], label=f'{combinations[idx]}',color=colors[idx]);\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.title('F1-score vs epoch for each different parameters(for best fold)\\n without including claim and temporal rest')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"F1-score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean results for each combination(validation accuracy, training accuracy, f1 score, matthews_corrcoef):\n",
      "[[ 0.59968864  0.5         0.5220881  -0.0326965 ]\n",
      " [ 0.71772894  0.94811339  0.74441785  0.09106385]\n",
      " [ 0.79274725  0.98544818  0.79015584  0.11697103]\n",
      " [ 0.81194139  0.99471422  0.79906093  0.12912181]\n",
      " [ 0.70608059  0.5         0.63417588  0.        ]\n",
      " [ 0.77161172  0.99075892  0.77347939  0.07805497]\n",
      " [ 0.78503663  0.98822098  0.7889871   0.14222782]\n",
      " [ 0.78315018  0.98936684  0.782632    0.10489405]\n",
      " [ 0.14007326  0.5         0.03580806  0.        ]\n",
      " [ 0.77157509  0.98991098  0.77056822  0.05460504]\n",
      " [ 0.79653846  0.97975319  0.78478109  0.05798395]\n",
      " [ 0.76393773  0.97176871  0.76726435  0.05612201]\n",
      " [ 0.55608059  0.5         0.47639811  0.        ]\n",
      " [ 0.74467033  0.97024633  0.75280753  0.01701545]\n",
      " [ 0.79078755  1.          0.78937166  0.10668594]\n",
      " [ 0.72937729  0.94805899  0.749361    0.05187575]\n",
      " [ 0.39838828  0.5         0.31158511  0.        ]\n",
      " [ 0.79269231  0.99971989  0.79010546  0.11044405]\n",
      " [ 0.79847985  0.99944444  0.79139399  0.09250474]\n",
      " [ 0.72935897  0.90390582  0.74715084  0.03722028]]\n"
     ]
    }
   ],
   "source": [
    "#Calculate mean result for the each different hyper parameter combination overall is 20\n",
    "final_mean_s = np.mean(final_stat_s,axis=2)\n",
    "print(f'Mean results for each combination(validation accuracy, training accuracy, f1 score, matthews_corrcoef):\\n{final_mean_s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14aa6939520>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#we are selecting the overall best model by looking the graph\n",
    "overall_best_s =3\n",
    "#We are ploting the best fold result with the best parameters\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "#found best fold result\n",
    "best_val_s =np.argmax(final_stat_s[overall_best_s][0])\n",
    "y_v = epoch_stat_s[overall_best_s][0][best_val_s]\n",
    "y_t = epoch_stat_s[overall_best_s][1][best_val_s]\n",
    "x = np.arange(len(y_v))+1\n",
    "\n",
    "ax.plot(x, y_v, label='validation');\n",
    "ax.plot(x, y_t, label='training');\n",
    "\n",
    "plt.title('Accuracy vs epoch for best fold of model with best parameters\\n without including claim and temporal rest')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Explanation: Example of on of the straight f1-score lines.This is for the brown line.*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14aaaf29940>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "best_val_s =np.argmax(final_stat_s[12][2])\n",
    "y_v = epoch_stat_s[12][0][best_val_s]\n",
    "y_t = epoch_stat_s[12][1][best_val_s]\n",
    "x = np.arange(len(y_v))+1\n",
    "\n",
    "ax.plot(x, y_v, label='validation');\n",
    "ax.plot(x, y_t, label='training');\n",
    "\n",
    "plt.title('Accuracy vs epoch for best fold of brown model\\n without including claim and temporal rest')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network is basically a  network that gives 0 everytime. The network is stuck to 50 accuracy for the training set. And we are balancing the data with smote (50% class 0 and 50% class 1), every time give all zeros wont change the loss value and model will stay at the same point.\n",
    "\n",
    "Note that we are not balancing the validation data with smote(most of the validation set is 0) so this anomaly occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the best epoch result\n",
    "maxIndx_s = np.argmax(epoch_stat_s[overall_best_s][0][best_val_s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our best result epoch(#90)(validation accuracy, training accuracy, f1 score, matthews_corrcoef):[0.80769231 0.9971831  0.81465998 0.05908581]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Our best result epoch(#{maxIndx_s})(validation accuracy, training accuracy, f1 score, matthews_corrcoef):{epoch_stat_s[overall_best_s,:,best_val_s,maxIndx_s]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our mean result(validation accuracy, training accuracy, f1 score, matthews_corrcoef):[0.81194139 1.         0.79906093 0.14222782]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Our mean result(validation accuracy, training accuracy, f1 score, matthews_corrcoef):{np.amax(final_mean_s, axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'F1-score')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAHWCAYAAAB0Vk+zAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOydZ3gUVReA39m+6b2HJPReBCmh9yKgIoqiCKKIFEUQCygCKqKICoKCBbEhICCo9N5Dk94JJJT0Xnez7X4/liwsKQSED8u8z5MH9s4tZ+7cuXPmzLnnSkIIgYyMjIyMjIyMjMx/HMW9FkBGRkZGRkZGRkbm74CsGMvIyMjIyMjIyMggK8YyMjIyMjIyMjIygKwYy8jIyMjIyMjIyACyYiwjIyMjIyMjIyMDyIqxjIyMjIyMjIyMDCArxjIyMjIyMjIyMjKArBjLyMjIyMjIyMjIALJiLCMjIyMjIyMjIwP8CxXj7777DkmSSv0bO3asI9/KlSt5+umnqVevHmq1GkmS7qHUMveKrVu3IkkSS5cuve06Fi9eTJ06ddDr9UiSxOHDh++cgH8T2rVrR926de94vZIkMWnSJMfv4vs3Pj7eKd9bb71FpUqVUKlUeHl5AWAymXjhhRcIDg5GqVTSsGHDOy7fnWL37t1MmjSJ7Ozsey3KP4LCwkImTZrE1q1b77UoDB48mG7dujmlHTp0iLZt2+Lp6YkkScyYMeOutR8fH48kSUyfPv2utVEatzNmZ82aRdWqVdFoNEiSdEtlJ02aVOHncGRkJIMGDXL83rRpE25ubiQkJFS4PRmZslDdawHuFvPnz6dmzZpOaSEhIY7/L1++nD179tCoUSO0Wi1//vnn/1tEmX8BaWlpDBgwgG7duvHFF1+g1WqpXr36vRbrH8sDDzxATEwMwcHBjrTffvuNKVOm8Oabb9K9e3e0Wi0Ac+bM4csvv2TWrFk0btwYNze3eyX2Tdm9ezeTJ09m0KBBDsVepmwKCwuZPHkyYH8pu1ccOnSI77//nr179zqlDx48mIKCAhYtWoS3tzeRkZH3RsC7yK2O2cOHD/PSSy/x3HPPMXDgQFQqFe7u7ndfUKBjx440bdqU8ePH8/333/9f2pT59/KvVYzr1q1LkyZNyjz+9ddfo1DYDeYjR478RyrGZrMZSZJQqf61l/Fvz9mzZzGbzTz11FO0bdv2jtRZWFiIi4vLHanrn4a/vz/+/v5OacePHwfgpZdeIiAgwCldr9czcuTIO9b+f63v/2vne6tz5gcffEDTpk1LPEuOHz/OkCFD6N69+z2R6+/IiRMnABgyZAhNmzb9v7c/YsQI+vXrx3vvvUd4ePj/vX2Zfw//OleKilKsFN8uNpuN9957jxo1aqDX6/Hy8qJ+/frMnDnTKd/p06d54oknCAwMRKvVUqlSJZ5++mmKiooceY4fP86DDz6It7c3Op2Ohg0blnjrLf7k/+OPP/LKK68QGhqKVqslNjYWgI0bN9KxY0c8PDxwcXGhZcuWbNq0qdxzSEtLQ6PRMGHChBLHTp8+jSRJfPbZZ4D9ATp27FiioqLQ6XT4+PjQpEkTFi5ceNO+Sk5OZujQoYSFhaHRaIiKimLy5MlYLBZHnuLPhdOmTWPKlClUqlQJnU5HkyZNSj2PnTt30rFjR9zd3XFxcSE6OppVq1aVyJeQkMDzzz9PeHg4Go2GkJAQ+vbtS0pKilM+s9nMm2++SUhICB4eHnTq1IkzZ86Ue16DBg2iVatWAPTr1w9JkpysW7///jstWrTAxcUFd3d3OnfuTExMjFMdxZ8PDx48SN++ffH29qZKlSp/uT8BJk+eTLNmzfDx8cHDw4P77ruPefPmIYQoUefPP/9MixYtcHNzw83NjYYNGzJv3rwS+fbv30/r1q1xcXGhcuXKfPDBB9hstnLlBcjNzWXIkCH4+vri5uZGt27dOHv2bIl8N7pSREZG8tZbbwEQGBjocL2QJIlvvvkGg8HgcJX67rvvABBC8MUXX9CwYUP0ej3e3t707duXCxcuOLVV7B6yfft2oqOjcXFxYfDgwQ55i8e7RqMhNDSUl19+mYKCAqc6JEli5MiR/Pjjj9SqVQsXFxcaNGjAypUrHXkmTZrEq6++CkBUVJRD3vLcBAYNGoSbmxsnTpygY8eOuLq64u/vz8iRIyksLHTK+/nnn9OmTRsCAgJwdXWlXr16TJs2DbPZXOHzXbx4MV26dCE4OBi9Xk+tWrV44403SpxvsVynT5+ma9euuLq6EhwczAcffADAnj17aNWqFa6urlSvXr1U693Nxm98fLzj5Wjy5MmO/rr+0/m5c+fo378/AQEBaLVaatWqxeeff+7UTnlzZkXms5SUFJYvX86AAQMcacXj02KxMGfOHIdsxdyJubwsbDZbhebGivTNzZ5ftzpm27Vrx1NPPQVAs2bNSlyvb7/9lgYNGjj6+uGHH+bUqVPlni/Y5+XXXnuNoKAgXFxcaNWqFfv27Ss1b69evXBzc+Prr7++ab0yMuUi/mXMnz9fAGLPnj3CbDY7/ZXFiBEjxK12xdSpU4VSqRQTJ04UmzZtEmvXrhUzZswQkyZNcuQ5fPiwcHNzE5GRkWLu3Lli06ZN4qeffhKPPfaYyM3NFUIIcfr0aeHu7i6qVKkifvjhB7Fq1SrxxBNPCEB8+OGHjrq2bNkiABEaGir69u0rfv/9d7Fy5UqRkZEhfvzxRyFJknjooYfEr7/+Kv744w/Rs2dPoVQqxcaNG8s9j4cffliEh4cLq9XqlP7aa68JjUYj0tPThRBCDB06VLi4uIhPPvlEbNmyRaxcuVJ88MEHYtasWeXWn5SUJMLDw0VERIT48ssvxcaNG8W7774rtFqtGDRokCNfXFycAER4eLho1aqVWLZsmViyZIm4//77hVqtFrt373bk3bp1q1Cr1aJx48Zi8eLFYsWKFaJLly5CkiSxaNEiR74rV66I4OBg4efnJz755BOxceNGsXjxYjF48GBx6tQpp36NjIwUTz75pFi1apVYuHChqFSpkqhWrZqwWCxlnltsbKz4/PPPBSDef/99ERMTI06cOCGEEGLBggUCEF26dBErVqwQixcvFo0bNxYajUbs2LHDUcfEiRMFICIiIsTrr78uNmzYIFasWPGX+1MIIQYNGiTmzZsnNmzYIDZs2CDeffddodfrxeTJk53yTZgwQQCiT58+YsmSJWL9+vXik08+ERMmTHDkadu2rfD19RXVqlUTc+fOFRs2bBDDhw8XgPj+++/LlFcIIWw2m2jfvr3QarViypQpYv369WLixImicuXKAhATJ0505C2+f+Pi4oQQQhw8eFA8++yzAhBr164VMTEx4vLlyyImJkb06NFD6PV6ERMTI2JiYkRqaqoQQoghQ4YItVotXnnlFbF27Vrx888/i5o1a4rAwECRnJzsdE4+Pj4iPDxczJo1S2zZskVs27ZNFBQUiIYNGzqNm5kzZwpPT0/RoUMHYbPZHHUUj52mTZuKX375RaxevVq0a9dOqFQqcf78eSGEEJcvXxYvvviiAMSvv/7qkDcnJ6fMPhs4cKDQaDSiUqVKjj6bNGmSUKlUomfPnk55R48eLebMmSPWrl0rNm/eLD799FPh5+cnnnnmGad8ZZ2vEEK8++674tNPPxWrVq0SW7duFXPnzhVRUVGiffv2pcpVq1YtMXPmTLFhwwbxzDPPCECMGzdOVK9eXcybN0+sW7dO9OzZUwDiwIEDjvIVGb9Go1GsXbtWAOLZZ5919FdsbKwQQogTJ04IT09PUa9ePfHDDz+I9evXi1deeUUoFAqn+be8ObMi89kPP/wgAHHy5ElHWmpqqoiJiRGA6Nu3r0M2Ie7MXF4atzI3VrRvbvb8utUxe+LECfHWW28JQMyfP9/per3//vsCEE888YRYtWqV+OGHH0TlypWFp6enOHv2rKOO4rnwxvEmSZJ49dVXHfNSaGio8PDwEAMHDiwhR/fu3cV9991XqowyMhXlX6sYl/ZXlnJ8O4pxz549RcOGDcvN06FDB+Hl5eV4YJfG448/LrRarbh06ZJTevfu3YWLi4vIzs4WQlybTNu0aeOUr6CgQPj4+IhevXo5pVutVtGgQQPRtGnTcmX8/fffBSDWr1/vSLNYLCIkJEQ88sgjjrS6deuKhx56qNy6SmPo0KHCzc1NXLx40Sl9+vTpAnAoksWTf0hIiDAYDI58ubm5wsfHR3Tq1MmR1rx5cxEQECDy8vKcZK5bt64ICwtzKC6DBw8WarXa6cF2I8X92qNHD6f0X375RQCOh97Nyi9ZssSRZrVaRUhIiKhXr57TC0deXp4ICAgQ0dHRjrTih8Hbb79dbjvFVLQ/b8RqtQqz2Szeeecd4evr6+ijCxcuCKVSKZ588sly223btq0AxN69e53Sa9euLbp27Vpu2TVr1ghAzJw50yl9ypQpN1WMhbjWR2lpaU7lBw4cKFxdXZ3SipWWjz/+2Cn98uXLQq/Xi9dee63EOW3atMkp79SpU4VCoRD79+93Sl+6dKkAxOrVqx1pgAgMDHS86AohRHJyslAoFGLq1KmOtI8++qjEeZXHwIEDy+2znTt3llqu+Dr/8MMPQqlUiszMzJue743YbDZhNpvFtm3bBCCOHDlSQq5ly5Y50sxms/D39xeAOHjwoCM9IyNDKJVKMWbMGEdaRcdvWlpaibFRTNeuXUVYWFgJJW3kyJFCp9M5zrmsOVOIis1nw4YNE3q93ulFqBhAjBgxwintr87lZXErc2NF+6Yiz69bHbPF9+71901WVpbQ6/Ul5tdLly4JrVYr+vfv70i7UTE+deqUAMTo0aOdyhYbHUpTjN98802hUChEfn5+hWSWkSmNf60rxQ8//MD+/fud/m7Hf8tisTj9iaufoZs2bcqRI0cYPnw469atIzc316lcYWEh27Zt47HHHivhM3k9mzdvpmPHjiV8ogYNGkRhYWGJT++PPPKI0+/du3eTmZnJwIEDneS02Wx069aN/fv3l/gcej3du3cnKCiI+fPnO9LWrVtHYmKi4zNr8fmuWbOGN954g61bt2IwGMqs83pWrlxJ+/btCQkJcZKv2Ddv27ZtTvn79OmDTqdz/HZ3d6dXr15s374dq9VKQUEBe/fupW/fvk6LrZRKJQMGDODKlSsOF4g1a9bQvn17atWqdVM5e/fu7fS7fv36AFy8eLFC53k9Z86cITExkQEDBji57Li5ufHII4+wZ8+eEp/Db7yuZXEr/bl582Y6deqEp6cnSqUStVrN22+/TUZGBqmpqQBs2LABq9XKiBEjbtp2UFBQCd/B+vXr37SPtmzZAsCTTz7plN6/f/+bn/AtsnLlSiRJ4qmnnnLqn6CgIBo0aFDiU7C3tzcdOnQoUUfdunVp2LChUx1du3Yt9XNy+/btnRYZBQYGEhAQcFtj50bK6rPiPgX7ArHevXvj6+vruM5PP/00Vqu1hLtKaecLcOHCBfr3709QUJCjjmKf+Rs/eUuSRI8ePRy/VSoVVatWJTg4mEaNGjnSfXx8SvTDrc4HN2I0Gtm0aRMPP/wwLi4uTnX06NEDo9HInj17nMqUdm9VZD5LTEzE39+/wpES/upcfjNuNjfeSt/c7Pl1p4iJicFgMDi5VQCEh4fToUOHct39ypo3HnvssTKf5QEBAdhsNpKTk/+a4DL/af65nv43oVatWuUuvqsoarXa6ff8+fMZNGgQ48aNw9XVlZ9++om5c+eiVCpp06YNH374IU2aNCErKwur1UpYWFi59WdkZDitwC+mOIJGRkaGU/qNeYt9Zfv27VtmG5mZmbi6upZ6TKVSMWDAAGbNmkV2djZeXl589913BAcH07VrV0e+zz77jLCwMBYvXsyHH36ITqeja9eufPTRR1SrVq3MtlNSUvjjjz9K9GMx6enpTr+DgoJK5AkKCsJkMpGfn09eXh5CiAr1WVpa2k37vxhfX1+n38WRDyr6AnA9xe2XJaPNZiMrK8tp0VNpeUujov25b98+unTpQrt27fj6668d/pwrVqxgypQpjvNKS0sDqFA/3dhHYO+nm/VRRkYGKpWqRPnSrvVfJSUlBSEEgYGBpR6vXLmy0+/S+j0lJYXY2NgKj9nb7ZebUV6fFY+xS5cu0bp1a2rUqMHMmTOJjIxEp9Oxb98+RowYUUKG0s43Pz+f1q1bo9PpeO+996hevTouLi5cvnyZPn36lKjDxcXFSUED0Gg0+Pj4lKhbo9FgNBodv291PriRjIwMLBYLs2bNYtasWRWqo7Rzrsh8ZjAYSpznzWT7K3P5zbjZ3Jifn1/hvrnZ8+tOcbO5cMOGDTcte+N5l3ZfFFN8vf7qvSfz3+ZfqxjfKfbv3+/0OyoqCrDfnGPGjGHMmDFkZ2ezceNGxo8fT9euXbl8+TI+Pj4olUquXLlSbv2+vr4kJSWVSE9MTATAz8/PKf1G60Xx8VmzZtG8efNS2yhLSSjmmWee4aOPPmLRokX069eP33//nZdffhmlUunI4+rqyuTJk5k8eTIpKSkOa0uvXr04ffp0mXX7+flRv359pkyZUurx60PoAaW+6ScnJ6PRaHBzc0OlUqFQKCrUZ/7+/jft/7tB8aRdlowKhQJvb2+n9IpapSran4sWLUKtVrNy5Uqnh/uKFSuc8hd/zbhy5cpdW8nt6+uLxWIhIyPD6YF2N6w6fn5+SJLEjh07HC8313NjWmn97ufnh16v59tvvy2zjf8H5fVZcdqKFSsoKCjg119/JSIiwpGvrFjapZ3v5s2bSUxMZOvWrU6RVe5GzOVbnQ9uxNvb2/F1qKyvHMVzdDGlnXNF5jM/Pz8OHjxYkdMC/vpcfjNuNjeq1eoK983Nnl93KlLJzebC8u6l4rLJycmEhoY60ovvi9LIzMwE/n/3qMy/E1kxvgkVeXv28vKib9++JCQk8PLLLxMfH0/t2rVp27YtS5YsYcqUKWXeqB07dmT58uUkJiY6PRR++OEHXFxcylR2i2nZsiVeXl6cPHnytsNW1apVi2bNmjF//nysVitFRUU888wzZeYPDAxk0KBBHDlyhBkzZpQb8qlnz56sXr2aKlWqlFAGS+PXX3/lo48+cihzeXl5/PHHH7Ru3RqlUomrqyvNmjXj119/Zfr06ej1esC+yvqnn34iLCzMEUe4e/fu/Pjjj5w5c4YaNWrcarfcNjVq1CA0NJSff/6ZsWPHOh6ABQUFLFu2zBGp4naoaH8Wh366/uXGYDDw448/OuXr0qULSqWSOXPm0KJFi9uS6Wa0b9+eadOmsWDBAl566SVH+s8//3zH2+rZsycffPABCQkJPPbYY7ddx/vvv4+vr28JJet2ud0vEGX1WXH0k+Kxdb3CL4S4pZX5pdUB8OWXX96SrBWhouO3rP5ycXGhffv2HDp0iPr166PRaP6yTGXNZzVr1mThwoXk5OTg6el503r+6lx+M242N95u35T1/PorX82KadGiBXq9np9++olHH33UkX7lyhU2b95c7pfO4jG+YMECGjdu7Ej/5ZdfSkTgKebChQv4+vri5+fn9KVCRkaj0VQ4Gtl/VjG+ePGiwxp8/vx5AMfuZ5GRkTdViHv16uWIlezv78/FixeZMWMGERERjk9xn3zyCa1ataJZs2a88cYbVK1alZSUFH7//Xe+/PJL3N3dmThxosPv7u2338bHx4cFCxawatUqpk2bdtMJ2c3NjVmzZjFw4EAyMzPp27cvAQEBpKWlceTIEdLS0pgzZ85N+2Pw4MEMHTqUxMREoqOjSyiSzZo1o2fPntSvXx9vb29OnTrFjz/+eFMl75133mHDhg1ER0fz0ksvUaNGDYxGI/Hx8axevZq5c+c6fcZXKpV07tyZMWPGYLPZ+PDDD8nNzXUE+weYOnUqnTt3pn379owdOxaNRsMXX3zB8ePHWbhwoeNB/84777BmzRratGnD+PHjqVevHtnZ2axdu5YxY8aU2ADmTqFQKJg2bRpPPvkkPXv2ZOjQoRQVFfHRRx+RnZ3tCG11O1S0Px944AE++eQT+vfvz/PPP09GRgbTp08vofxERkYyfvx43n33XQwGA0888QSenp6cPHmS9PR0p36/Xbp06UKbNm147bXXKCgooEmTJuzatauEkn4naNmyJc8//zzPPPMMBw4coE2bNri6upKUlMTOnTupV68ew4YNK7eOl19+mWXLltGmTRtGjx5N/fr1sdlsXLp0ifXr1/PKK6/QrFmzW5KrXr16AMycOZOBAweiVqupUaNGuRsgaDQaPv74Y/Lz87n//vvZvXs37733Ht27d3eECezcuTMajYYnnniC1157DaPRyJw5c8jKyqqwbNHR0Xh7e/PCCy8wceJE1Go1CxYs4MiRI7d0jhWhouPX3d2diIgIfvvtNzp27IiPjw9+fn5ERkYyc+ZMWrVqRevWrRk2bBiRkZHk5eURGxvLH3/8webNm28qR0Xms3bt2iGEYO/evXTp0uWmdf7VufxmVGRurGjfVOT5dTtj9ka8vLyYMGEC48eP5+mnn+aJJ54gIyODyZMno9PpmDhxYplla9WqxVNPPcWMGTNQq9V06tSJ48ePM336dDw8PEots3fvXsaPH8+5c+cqLKPMfwOFQuEIv3lT7unSv7tAaStjy8tX2l9pq11v5OOPPxbR0dHCz8/PEVbp2WefFfHx8U75Tp48KR599FHh6+vryDdo0CBhNBodeY4dOyZ69eolPD09hUajEQ0aNBDz5893qqe06AfXs23bNvHAAw8IHx8foVarRWhoqHjggQfKzH8jOTk5Qq/XC0B8/fXXJY6/8cYbokmTJsLb21totVpRuXJlMXr0aEc4t/JIS0sTL730koiKihJqtVr4+PiIxo0bizfffNOxerh45fWHH34oJk+eLMLCwoRGoxGNGjUS69atK1Hnjh07RIcOHYSrq6vQ6/WiefPm4o8//iiR7/Lly2Lw4MEiKChIqNVqERISIh577DGRkpIihCi7X4vlufE63Eh512XFihWiWbNmQqfTCVdXV9GxY0exa9cupzxlRVwoj4r0pxBCfPvtt6JGjRqO6zV16lQxb968Ulea//DDD+L+++8XOp1OuLm5iUaNGjmde9u2bUWdOnVKyDJw4EARERFxU5mzs7PF4MGDhZeXl3BxcRGdO3cWp0+fvuNRKa4/92bNmjnGR5UqVcTTTz/tFDqsrHMSQoj8/Hzx1ltviRo1agiNRuMIgTV69GinkG+UEp1ACCEiIiJKzCPjxo0TISEhQqFQCEBs2bKljN66dm5Hjx4V7dq1E3q9Xvj4+Ihhw4aVWHH/xx9/iAYNGgidTidCQ0PFq6++6ogEcn0b5Z3v7t27RYsWLYSLi4vw9/cXzz33nDh48GCJe6CsPi+r7oiICPHAAw84pVV0/G7cuFE0atRIaLXaEvNyXFycGDx4sAgNDRVqtVr4+/uL6Oho8d577znylHdvVmQ+s1qtIjIyUgwfPrxE+bKu+52Yy2/kVufGivRNRZ9ftzJmy3v2fvPNN6J+/fqOe+nBBx8sEUGntHBtRUVF4pVXXhEBAQFCp9OJ5s2bi5iYmFLvr9jYWDF48GDx559/ivT0dFFYWCgMBoP8J/+JgoICce7cOREfH19qlJkbkYQoJdq/jMz/mfj4eKKiovjoo48YO3bsvRZHRuaeMmjQIJYuXUp+fv69FuU/zccff8yUKVNISEhwuG3J/D2ZPHky999/P02bNpV9jGVKkJOTQ2JiIlWrVi1z8W8x/9pwbTIyMjIyMn+FESNG4OnpWWLnOJm/F9nZ2SxduhR/f/8yIzDJ/LcpdqGwWq03zSsrxjIyMjIyMqWg0+n48ccfS41wIvP3IS4ujhdeeAE3N7dbjvYh89/gVsaF7EohIyMjIyMj84/GaDQSFxdHVFTULcWflvlvcCvjQ7YYy8jIyMjIyMjIyCArxjIyMleZNGlSic9NX3zxBd99912JvFu3bkWSJEeIw7tFfHw8kiQ5yfDdd98hSRLx8fE3Lb948WLq1KmDXq9HkqQyN774KxQWFjJp0qQSW0XLyMjIVJSMjAwCAgIqNK/9HZg9eza9e/e+12LcFWTFWEZGBoDnnnuOmJgYp7SyFON/AmlpaQwYMIAqVaqwdu1aYmJiHJu/3EkKCwuZPHmyrBjLyMjcNlOnTqVXr15ERkY60kaNGkXjxo3RarU0bNjwtutetmyZY9OW2rVrs3z58nLzG41GBg0aRL169VCpVDz00EMl8gwZMoT9+/ezc+fO25br74qsGMvIyAAQFhb2l3fn+jtx9uxZzGYzTz31FG3btqV58+Z3bKvb/wdCiL+065iMjMw/A4PBwLx583juueec0oUQDB48mH79+t123TExMfTr148BAwZw5MgRBgwYwGOPPcbevXvLLGO1WtHr9bz00kt06tSp1DxarZb+/fsza9as25bt74qsGMvI/IsQQhAYGMiIESMcaVarFW9vbxQKBSkpKY70Tz75BJVKRXZ2NlDSlSIyMpITJ06wbds2JElCkiQnawaA2WzmzTffJCQkBA8PDzp16sSZM2duKmdsbCzPPPMM1apVw8XFhdDQUHr16sWxY8f+WgdcZdCgQY7d4fr164ckSY4tZgEOHDhA79698fHxQafT0ahRI3755RenOtLS0hg+fDi1a9fGzc2NgIAAOnTowI4dOxx54uPj8ff3B+xxVIv7adCgQQ45buwzKN1tRZIkRo4cydy5c6lVqxZarZbvv/8egHPnztG/f38CAgLQarXUqlWrRAgxm83Ge++9R40aNdDr9Xh5eVG/fn1mzpx5W30oI/NPRwiBrdB4T/5uJa7BmjVrUKlUtGjRwin9s88+Y8SIEVSuXPm2+2DGjBl07tyZcePGUbNmTcaNG0fHjh2ZMWNGmWVcXV2ZM2cOQ4YMISgoqMx8vXv3ZsWKFf+6F/j/7JbQMjL/RiRJokOHDmzcuNGRduDAAbKzs9Hr9WzatIn+/fsDsHHjRho3boyXl1epdS1fvpy+ffvi6enJF198AVAibNX48eNp2bIl33zzDbm5ubz++uv06tWLU6dOoVQqy5QzMTERX19fPvjgA/z9/cnMzOT777+nWbNmHDp0qMSW5LfKhAkTaNq0KSNGjOD999+nffv2jm1kt2zZQrdu3WjWrBlz587F09OTRYsW0a9fPwoLCx1KbWZmJmDf6jcoKIj8/HyWL19Ou3bt2LRpE+3atSM4OJi1a9fSrVs3nn32WYfFp1hZvlVWrFjBjh07ePvttwkKCiIgIICTJ08SHR1NpUqV+PjjjwkKCmLdunW89NJLpKenO7bVnTZtGpMmTeKtt96iTZs2mM1mTp8+7XjxkZH5ryEMRaRU7XtP2g6MXYrkUrHoGNu3b6dJkyZ3RY6YmBhGjx7tlNa1a9dyFeOK0qRJE8xmM/v27aNt27Z/ub6/C7JiLCPzL6NTp04sWrSIy5cvEx4ezsaNG6lZsybVq1dn48aN9O/fH7PZzPbt2xk1alSZ9TRq1Ai9Xo+Hh0eZLha1a9fmp59+cvxWKpU89thj7N+/v1y3jDZt2tCmTRvHb6vVygMPPECdOnX48ssv+eSTT27jzK9RpUoVateuDUC1atWcZBk+fDh16tRh8+bNqFT2KbBr166kp6czfvx4nn76aRQKBTVq1HC8EBTL2LVrV+Lj4/nss89o164dWq2Wxo0bA3fGFSU/P59jx47h7e3tSOvWrRvu7u7s3LnTodx37tyZoqIiPvjgA1566SW8vb3ZtWsX9erVY9KkSY6yXbt2/UvyyMjI3H3i4+MJCQm5K3UnJycTGBjolBYYGEhycvJfrtvV1RUvLy/i4+NlxVhGRubvS7FP2MaNG3nmmWfYsGEDnTt3plq1akybNg2wWxEKCgrK9B+rKDeuSq5fvz4AFy9eLFdJtFgsTJs2jZ9++onY2FjMZrPj2KlTp/6STOURGxvL6dOnmT59ukOOYnr06MHKlSs5c+YMtWrVAmDu3Ll89dVXnDx5kqKiIkfemjVr3hX5OnTo4KQUG41GNm3axLBhw3BxcSkh7+zZs9mzZw/du3enadOmrFq1iuHDh/Pggw/SokULhyItI/NfRNJrCYy9u5Fzymu7ohgMhrsae/lGty0hxB3bCEWv11NYWHhH6vq7IPsYy8j8y4iIiKBKlSps3LiRwsJCYmJi6Ny5M506deLKlSucOXOGjRs3otfriY6O/ktt+fr6Ov0udrW4mc/ZmDFjmDBhAg899BB//PEHe/fuZf/+/TRo0OCu+qsV+1iPHTsWtVrt9Dd8+HAA0tPTAbsP9rBhw2jWrBnLli1jz5497N+/n27dut01GYODg51+Z2RkYLFYmDVrVgl5e/To4STvuHHjmD59ukNR9vX1pWPHjhw4cOCuyCoj83dHkiQULrp78ncriqefnx9ZWVl3pQ+CgoJKWIdTU1NLWJFvl8zMzNt2Hfu7IluMZWT+hXTs2JHffvuNbdu2YbPZaNeuHe7u7oSEhLBhwwY2btxI69at79lWtz/99BNPP/0077//vlN6enp6mT7PdwI/Pz/ArkT26dOn1DzF/s0//fQT7dq1Y86cOU7H8/LyKtyeTqdzsjQXU6zM3siND1Nvb2+USiUDBgxwWlB5PVFRUQCoVCrGjBnDmDFjyM7OZuPGjYwfP56uXbty+fLlf1REDhmZ/xKNGjVyckm7k7Ro0YINGzY4+RmvX7/+LxtFAM6fP4/RaKRRo0Z/ua6/E7JiLCPzL6RTp0589dVXzJgxg+bNm+Pu7g7YFebly5ezf//+EkppaWi12rtiHZUkqYRSvmrVKhISEqhateodb6+YGjVqUK1aNY4cOXLT8y9NxqNHjxITE0N4eLgjrTwreWRkJKmpqaSkpDgsNCaTiXXr1lVIXhcXF9q3b8+hQ4eoX78+Go2mQuW8vLzo27cvCQkJvPzyy8THxzt8rmVkZP5edO3alXHjxpGVleXkShUbG0t+fj7JyckYDAbHBkW1a9eu8FwwatQo2rRpw4cffsiDDz7Ib7/9xsaNG53iD8+ePZvly5ezadMmR9rJkycxmUxkZmaSl5fnaPv6eMo7duygcuXKVKlS5fZP/m+IrBjLyPwL6dChA5IksX79eiZPnuxI79SpEwMHDnT8/2bUq1ePRYsWsXjxYipXroxOp6NevXp/Wb6ePXvy3XffUbNmTerXr8+ff/7JRx99RFhY2F+u+2Z8+eWXdO/ena5duzJo0CBCQ0PJzMzk1KlTHDx4kCVLljhkfPfdd5k4cSJt27blzJkzvPPOO0RFRTn5+rq7uxMREcFvv/1Gx44d8fHxwc/Pj8jISPr168fbb7/N448/zquvvorRaOSzzz7DarVWWN6ZM2fSqlUrWrduzbBhw4iMjCQvL4/Y2Fj++OMPNm/eDECvXr2oW7cuTZo0wd/fn4sXLzJjxgwiIiKoVq3ane1EGRmZO0a9evVo0qQJv/zyC0OHDnWkP/fcc2zbts3xu9gyGxcX5wgDKUkS8+fPd0TTuZHo6GgWLVrEW2+9xYQJE6hSpQqLFy+mWbNmjjzp6emcP3/eqVyPHj24ePFiibavD0O3cOFChgwZcnsn/XdGyMjI/Ctp1KiRAMSuXbscaQkJCQIQvr6+wmazOeWfOHGiuHFKiI+PF126dBHu7u4CEBEREUIIIbZs2SIAsWTJEqf8cXFxAhDz588vV7asrCzx7LPPioCAAOHi4iJatWolduzYIdq2bSvatm1bbn3z588XgIiLiyu3jbJkFEKII0eOiMcee0wEBAQItVotgoKCRIcOHcTcuXMdeYqKisTYsWNFaGio0Ol04r777hMrVqwQAwcOdPRDMRs3bhSNGjUSWq1WAGLgwIGOY6tXrxYNGzYUer1eVK5cWcyePbvUvgbEiBEjSj2XuLg4MXjwYBEaGirUarXw9/cX0dHR4r333nPk+fjjj0V0dLTw8/MTGo1GVKpUSTz77LMiPj6+3H6Skfk3YDAYxMmTJ4XBYLjXotwWq1atErVq1RJWq7XCZeLi4oRKpRJnz569i5KVzrFjx0RAQIDIzs7+v7d9O9zK+JCEuIUo1DIyMjIyMjIyfzOMRiNxcXFERUXd1QgPd5OZM2fSp08fJ1et8pg7dy7Hjh0rsdnP/4P169cjhPjHhIS8lfEhK8YyMjIyMjIy/2j+DYqxzN3jVsaHHK5NRkZGRkZGRkZGBlkxlpGRkZGRkZGRkQFkxVhGRkZGRkZGRkYGkBVjGRkZGRkZGRkZGUBWjGVkZGRkZGRkZGSA/+AGHzabjcTERNzd3W9pL3MZGRkZGRmZe4cQgry8PEJCQlAoZLuezN3hP6cYJyYmVjhGoIyMjIyMjMzfi8uXL/9fdsmU+W/yn1OM3d3dAfuN5eHhcY+lkZGRkZGRkakIubm5hIeHO57j/yYyMjKoVasW+/btc2z3/E9n7NixmEwmPvvss3styi3xn1OMi90nPDw8ZMVYRkZGRkbmH8a/0Q1y6tSp9OrVy0kpHjVqFDt37uT48ePUqlWLw4cP31bdy5YtY8KECZw/f54qVaowZcoUHn744XLLHDt2jJEjR7Jv3z58fHwYOnQoEyZMcPR9UlISr7zyCn/++Sfnzp3jpZdeYsaMGU51vPbaa1SpUoXRo0cTFRV1W7LfC2QnHRkZGRkZGRmZe4TBYGDevHk899xzTulCCAYPHky/fv1uu+6YmBj69evHgAEDOHLkCAMGDOCxxx5j7969ZZbJzc2lc+fOhISEsH//fmbNmsX06dP55JNPHHmKiorw9/fnzTffpEGDBqXWExAQQJcuXZg7d+5ty38v+M9ZjGVkZGRkZGT+/QghMFqL7knbOqW2wpbtNWvWoFKpaNGihVN6sQtCWloaR48evS05ZsyYQefOnRk3bhwA48aNY9u2bcyYMYOFCxeWWmbBggUYjUa+++47tFotdevW5ezZs3zyySeMGTMGSZKIjIxk5syZAHz77bdltt+7d28mTJjAhx9+eFvy3wtkxVhGRkZGRkbmX4fRWkSXdX3vSdvruy5Fr9JVKO/27dtp0qTJXZEjJiaG0aNHO6V17dq1hNvDjWXatm2LVqt1KjNu3Dji4+NvyS2iadOmXL58mYsXLxIREXHL8t8LZFcKGRkZGRkZGZl7RHx8PCEhIXel7uTkZAIDA53SAgMDSU5OvuUyxcduhdDQUMB+jv8UZIuxjIyMjIyMzL8OnVLL+q5L71nbFcVgMKDTVcy6fDvc6NIhhLipm0dpZUpLvxl6vR6AwsLCWyp3L5EVYxkZGRkZGZl/HZIkVdid4V7i5+dHVlbWXak7KCiohJU3NTW1hEW4ImWAcsuVRmZmJgD+/v63VO5eIrtSyMjIyMjIyMjcIxo1asTJkyfvSt0tWrRgw4YNTmnr168nOjq63DLbt2/HZDI5lQkJCbnlGMvHjx9HrVZTp06dWyp3L5EVYxkZGRkZGRmZe0TXrl05ceJECatxbGwshw8fJjk5GYPBwOHDhzl8+LCTwnozRo0axfr16/nwww85ffo0H374IRs3buTll1925Jk9ezYdO3Z0/O7fvz9arZZBgwZx/Phxli9fzvvvv++ISFFMsTz5+fmkpaVx+PDhEgr+jh07aN26tcOl4h+B+I+Rk5MjAJGTk3OvRZGRkZGRkZGpIOU9vw0Ggzh58qQwGAz3QLK/TvPmzcXcuXOd0tq2bSuAEn9xcXGOPICYP39+uXUvWbJE1KhRQ6jValGzZk2xbNkyp+MTJ04UERERTmlHjx4VrVu3FlqtVgQFBYlJkyYJm83mlKc02W6sp3r16mLhwoUV6oO7ya2MD0mIqx7V/xFyc3Px9PQkJydH3vlORkZGRkbmH0J5z2+j0UhcXBxRUVF3dSHb3WL16tWMHTuW48ePo1BU7GN+fHw81apV4+TJk1SrVu0uS3jrrFq1ildffZWjR4+iUt3bJW23Mj7kxXcyMjIyMjIyMveQHj16cO7cORISEggPD69QmbVr1/L888//LZVigIKCAubPn3/PleJbRbYYy8jIyMjIyPzt+TdbjGXuLrLFWEZG5l9NXp4Rg8HilObtrUetVt4jiWT+KwghEFaBQiWvXZeR+TciK8YyMjL/GIxGM2+8sYZZs3Zhszl/7AoP92LDhueoUSPgHkkn82/HaraxsPsOFGoF/X5viVItK8cyMv825LtaRkbmH8Hx48k0bTqLmTN3llCKAS5fzqZPnx/Jzy+6B9LJ/BfIjisg81w+6SdzSdiTca/FkZGRuQvIirGMjMzfGiEEs2fvokmTzzh2LJmAADdWrXoGIaY5/pKSJhAS4sHJkykMHryE/9jSCZn/E1nn8wmuriWoqpbY1ck3LyAjI/OPQ3alkJGRuScUFpp48smFnDmTVm4+g8FMfLw98H2PHjX59ttHCQx0d8oTFOTOkiVP0a7dlyxZcpSmTcMZO7ZtufUmJ+cxfPhyWreOZPToNqXmycsz8sILv3LoUKJTuo+PC9OnP0Dz5hGlltu37xJvv72eUaNa0b17zVLznDmTysiRv5GQkFOunNYiGwqVhKS8Flg/JMSD2bMfombNirmNmM1WRo36na1bz980b8OGIXz5ZR/c3UtfoDJz5k62bj3PF188THBwxRYw5+YaGTp0GUeOJFUo//W4uWl5772udOlSvcJlPv10O/Pm7Xf6sqBUKhg6tBkjR7a8ZRmKKbycR+83ghA2WP5BKjaLrYSvsRCCFQP2kXu5kMeWt0Tvo7nt9mRkZP7/yFEp7hLZyRc4vHouF/avxmqp+C41MjL/FRbsbMC201EVyqtSWunb9Djta8dx3cZLJdh6MoqfdzdAkgSju++iZkh6qfksVomPV7fifIovAM+0/ZMW1S475REC5m5qyqH4kFLrcNcVMf6hrfi6GZzSswp0vLe8HXlGHRqVhdd7bSfcN9cpT6FJxdTf2pKS46zg3woBHvmMf3AbLlrzTfP+vLs+W09WrnDdjSISGdppH4ob+jrmXDjztzUGoHJABq88sAu10lZuXTYBczY048il4Aq3fyNalYU3em8j1Cfvpnl3nw3nu+2Nyzz+XPv9NK2ScHuClPa0vHE8CvvYAexjtZzx+m/GxTOAJ6fvvKN1ylEpZG4XOSrFPSTj0kkOrZ5L3J9rr82OMn9bVGoNbh7eZGek3GtRykSl1qB3dScv+5/l0+jlE0BhQR6mIkOJY4cvBjmU4qdbHcTfI7/cugI98/Fyueo7XM5t1bbmBeJSvYmJrcRXm+/nrQe34ONWsv3FMfU5n+KLJAmEkPhxZ0OCPXOJ9M925Fl9uDqH4kNQKawManMQT5fieiR+2VOPy5lezN3YlFcf2I5GZVcOzRYFczY0Jc+oQ5IEJouKORubMb73Vtx09hdkm4B5W5qQkuOOt2shA1sfRKkoX7m8HqtNwQ877iM1141vtjRmZOcYytsPYOfZCIdS/GTLQwR5lq1c5hTq+G57Yw5dDGHNoeo80OiM49jFdC9+2tnQ3gOS4EKqL4t212NAq8PlyrvyYE2OXApGpbTyTJs/8dAbK3yuAKsO1eR0UgBfbGjG+Ae34lrOi0B8mhc/7bLL2KlOLA0irln6D8aHsuVkFb7f3ohgzzzCfcu31FeYUsaj08vbf/UxID//bomMjAxq1arFvn37iIyMvNfi/N/o27cv0dHRjBkz5l6L4kC2GN8hclIusmfxFC4d3eJIi2jYiQbdn8fdr2LBumX+zwgruozjKCwFGL1rYdN632uJSkWbeRKFKRujb32E2u1ei1MhstMy+Pzj9dSr4c5D/Zpi0/s7tIWk5Hyat5xPeoaBF0c04YMpHcqtK+1UDlgF/nW9KtS2wWCmQ5cFHD2WSkiIG3Nmd6dTh2uW6W+/O8yLL69HkmDJwj7Mm3+ENevOExrqzo4tTxMY4MqatbE8+sSvCAGff9aVQU83cGrj4sUcWrf/gYxMA48/VptvvnwAgKHD17Bg4XF8vHX8vvwxBgz6nbj4bNq3i2DF0kdRqRS8894OPpweg06nYuPa/jRqGFTqecSuSWLrhBOO332XNMcryn79Dx1OplO3nzEaLbw2tgXPd6+DzluDd2Xn8bH/QCJdeizEZLLy1riWjHv95m4E3/9wlOEvrUWS4Jef+9Cje1VS0wpo3f4HrlzJo1vXygwZ3Ii+jy9DCPjs0y48+0zDUutaueoc/Z5cDsDcz7sz4Ml6N23/emzxqaSdTKbdKzu4lFRAp45R/PrLIyiVJd8EUlLtMiYk5NGjWxUW/9wHxXUmb6vVRp/HlrFxUxwRlTzZvmUAfr4ujuOi0Ij18CVQK1A2jERSO9uNrOeSEKm5HFJpcUFQw2Li7J4Cao1uhHS1nYJkI4t670TYwLeGGxln8olo60fnj0vvn2LyrIJvUorYlVexFyRvIZhR3QXXG036fwGLwcL59SmY853DILr4a4nqGIBUSp8LID8ZCjNK6sFKtUREU987Jh/8uy3GY8eOJSsri3nz5jnSRo0axc6dOzl+/Di1atXi8OHDt1X3smXLmDBhAufPn6dKlSpMmTKFhx9+uNwyx44dY+TIkezbtw8fHx+GDh3KhAkTkK5769u2bRtjxozhxIkThISE8Nprr/HCCy84jp84cYK3336bP//8k4sXL/Lpp5/y8ssvO7Vz9OhR2rdvT1xc3F39ii9bjO8BSrWGKyd2IkkKKt/fnYY9huETVuNeiyVTHslHwFIAgM6QBP5VKfc7/b3AlA+mbAD0kgk8/e6tPBVg06ZzDBywkISkQgAeWZPClx+3xLfm/dgUaoY/toL0DAMNG4bw0cd90GrLnoYKM4pY+fR+hIBBO9vjFnjzB56LJ/z2+2C6dv2Gs2fTebDPEoYPb8G0aQ9w5EgiY17dBMB773XjkX7N6dStAc2azebMmTQGPbeazz9/mMHPr0YIGDasBcNf7FiijVr1/fhlyQC6dPmGRb+cpFmLKiiVChYsPI5CIbH4lwG0bFuN3373pXnz2WzZepF3pu4jOjqCD6fHAPDVV4/Qsm3dUs/BarJx8PNjYLrmapF/WUNIQ/v1b9nWj6+/7suAAYuYNj2G9O9zuD8wmIHb2jt8WpOT8+j/9O+YTFYeeqgOk9/rVaGtZoe92IHjp3P44osYnh26ml27hjNixGquXMmjenU/Fi4aiJeXninnCxg/fi2vvLaJ++6vSsuWkU71nDqVwrNDVwHw4ostGTq8/U3bvh5bWi7WTEFYUCBL3+lA25fWsnFTHFOmHeCDD3o45TWZLAx8dgkJCXnUqOHPz4uexs1TX6LOxb8MpGnTWZw/n8EzQ9aybt2zqFT22NeWhCsInScA0hUjygYRDiVAGEyY81KQ9F4s9g7G1Wbj/ZwUakd7kH0WQprZr8vhL08jjO6ERfvS7p06LOi6g4sbisg8JRHWvHQlcW+ehY+TTWTYXFC6QlW9okzvC2OOmUSDjWRPNe9vz2VqOz90nupb6tfSiN+cypYJJ8m7UvLrCkBAvWw6fFCPgLqejjSzAdJOgyG79Dr/Uxa3v4jBYGDevHmsXr3aKV0IweDBg9m7dy9Hjx69rbpjYmLo168f7777Lg8//DDLly/nscceY+fOnTRr1qzUMrm5uXTu3Jn27duzf/9+zp49y6BBg3B1deWVV14BIC4ujh49ejBkyBB++ukndu3axfDhw/H39+eRRx4BoLCwkMqVK/Poo48yevToUtuqX78+kZGRLFiwgGHDht3WOd5pZIvxHeTsrl8JqNIIr6CK+U3K3ENyr0DSQfv/JQUIG4Q2BbfSrXf3jLRTkHnO/n/XQAgrfSL7O2AwmBk/fg0zZtj9CiuFaElMNWGxCIL9NXz7QS1OpXgyZvx2dDoVBw+OolatwBL1mK1WbFenpWM/xLNjyikUFonW42tx39AqFZansNDE66+vZvbs3QBUrepLfr6J5OQ8+vatxy+/POVQfE6fTqVp01nk5RWh06kwGi20ahXJpk3Po9GUrbjPmLGD0aP/cFgwrVYbH3/ckzFjri3mW7r0KI8++hMAWq2KoiILL7/cik8/7V1mvUd/vMjWt47j4q8lvKUvZ1Yk0mREFaJfc17IN2bMH3z66Q40koLn/OvS7LEoGr9QBSFg6NBl7N59kVq1Ati7d2SZi+lKw2Sy0LHjV+zcGe/oD3d3LXv3jnRcMyEEjz32E0uXHiMoyJ0VKwbi5mZXys1mG/36/cTZs+m0bVuZDRuGlNh8RQgBRjPo1E5WKLAropYD58FiAzVgFiw5msmTL68E7C8V0dHXFj5+9tkuvvpqL+7uWvbte7HcRYnHjyfTvPlsCgpMjBwZzQsvNEcUmbEcuWjX5hQS2ASKMF+Uod54eOgILihAJGXzp0bHRL0/Fo2CzzKTqG41ceUiRA2qg8Vo5dsWmzFmmnjgy8ZU6RbEljePceynS/jX9eDxP1o5LMsABqtgToqJVVl2C20lrcSb/gqquGlKtc4W5Zn5qdN2Lvlo2DmtESgk2n58iscfCqFar+ASfVgRClKNbH/nJOf+sC+KdA/VE9Lk2pczISB+ayqmXAuSAho+G0Wz0dUx5qhIjwVhBUkhcA2z4eLmfH0VCnD1v2WRyuXfajH+9ddfGTp0KGlppS9EnjRpEitWrLgti3G/fv3Izc1lzZo1jrRu3brh7e3NwoULSy0zZ84cxo0bR0pKClqtFoAPPviAWbNmceXKFSRJ4vXXX+f333/n1KlTjnIvvPACR44cISYmpkSdkZGRvPzyyyUsxgCTJ09m06ZNbN++/ZbPr6LIFuN7gM1mo3ITu0XEUpR1R+u2mCQyzrni6mfCLVBeyPeXMReiTD6CBNg8w0EIFLlXEGknsao0d89qLAQU5YFaD8oKWHmEQJlz0WE9EoZMrMbMUuXLvlRI/JYM6vYLQaX7/+/+tm9/IkOeX8XJU/bFbsOeCGLaq1GcLKzCoGdXcepMFt2fPYLyqmgfTetItcqaEvfKytOnmXfgT0xW67XE18ErSYPHWiX1BnpXWAHQKOHT6W3p2b0Szz2/ithYu492ndq+fD23C9arlniAqlFqvp/fiz59l2I0WggNdWfhT71QiDws5YRFHvFCHQ7sj2PBz8cBeOLxOrw4vK7TeT3UK5zXX23Bhx/FUFRkoX27CKa+17LMecJssLL/y+NIejNNXrQrf2fXmck4n4alyPlF4v13o9m24gwH41L5IvUoX8w+CrOvHff01LL0l4fQawxYSvH1LgsFsGhBb5pFzychwe6T/P38XiWu2ddzu3D6dCLHj2fQvPnsEvWEh3nw8489kWy5JfpRXM6Dy3ngpYUqnkhaFRg2Iaz5cL4FWGxIYQJVZAHWCxoeVfrx58v388mM/Tz//LJS5f7hu15UjVKXOwfXrKbl228eoN8Ty5k9e7fjxak8Fr/TjodbRbBYr+fhP85yqH8Ui91cmJBjIjDIhjkvnXPr0ygyFOAeqSG8tV2GxiMDOLMmnvTzGZxafobqPa+9VExMFBw1gkaC3p4wUG1GfSgDi6cWavmUGOcxn8RSmJNHFXcdbsYcNrnqOPhMCJVnXyQ3TYnW/RYtxwLyk4twjwqk8UuBeEbo8a7i6uR+AlDn6VpknMknP8V+AU/8mo9HmBcAeQX55Lml0+RSAdvOW9ElXLvIalcFLcY0qtBXiruGECAqPu7vKJK+ws+S7du306RJk7siRkxMTAlrbdeuXZkxY0a5Zdq2betQiovLjBs3jvj4eKKiooiJiaFLly4l6p03bx5msxm1uuLjsWnTpkydOpWioiKnNu8VsmJ8h7CZc9hp6HdX6va+OAa3nG4UFORy2P2J/+wq5zuBQii5L7MvbsKfbHUCR7SfoxJamktPozTlcyrnDTK08Xel7SBDLWrmdsQimUjUH+eKyxFMyoIy8/sUVaK+tTdmyYhSqFHY4ED+8xhVuSUz+wOPwR4B/B+fA3GndMyfGsSOP7wA8A4w88F0ieebViVHnUxh1Bw+3SLx1aRQfv3KD6sVenXwpnm/+ew0fOhU18VUXxbua4YQpSj+wSYONtlOpOHTW35v0UbDt9u8WDKuGcfOFvLuF6kcVg4o0U/eHWHUR76sW+TDyx+dIdZzB7EV6MsB0yUSDJUQNomnP/6ZXcYFJfJ0fh1OZYSRGKdh1Ncr2WP+DcoJJlHFbhgl++rveg/a/91Zijxvb1Dy3pAIYo8Vuw5IqGxafD01THpPQWrYcFJvZ0x4wISf9MwYG0aXfll4d3yrZPtKeOMHDVOHRpAQ5xyWzC/YzGuzz3DWfTtnS2m/btYIPKkK2UVYDl0iPvQ3Unz3EJX0ECEFFszKAowh5/ChKlKoERLVPDfkLGez0tm5ytOpLrVG0H90Cl4dSpGxFAK6wcgP/Fj0WQAWkwK1xRWQsCgNCMmC0qpDIdQUGM0UGq3sOJxC+25FPFh5DoyCmgB+kH9mLG6EcunK96R2XEe9q143u83Yr68eam62p6WC03Xo4QPXO4QUnBuGl6gO2UUcT32bHI+zzkKPgnqj7P+tBDS1uuBleR63F5zdSm4FlxsM68bs0vO5h+pwD7322yYVkRPyHTa33TQ/8xoA9Zsc5mzfnxx5zIDNvBjFvVy7IQxwpeq9aTssFiSXm+cD4uPjCQkpPfrNXyU5OZnAQOcX6sDAQJKTy47DnZycXGIBYHEdycnJREVFlVmvxWIhPT2d4OCKR6EJDQ2lqKiI5ORkIiJKD4H5/0RWjP/mqIpCcM3sDIDS4ovaUA2zy7l7LNU/l6p5rXGz+GOSCjnpuR4hCcySkQT9MSoVNiYyvykZmvi78vIRYKwGgEpoqFR4H2GFDUjRneaS6yEMquwS+YMMtQBI0Z3FwxKAhzkID3NQ6YoxYLNRbnSC20UIyM1ytkJnpqhYODOQjb94I4SEQiHo3C+LF95JoJWyG5ggTR1PYZEaFPDsOyk06ZxP6pa6vD2wBrqccP70XYxFYbcw5Rm0rIhphBAS9SIv06XRtUVnqTnuLNjagrMJQfwZG0mTavG3fA7VtNX56l17/yfpTlAca0ESCgQ2x/V+6LkMHnru1qJ/aPWCid9eLJEuxDWDkVIJoz++UqH6JKFASBWPUuHpa+WjXy84ytbNfgBfk/3hIrCx33KSQlUpFlQBWpMPRZoskIQjDSTH7xoNDczZWP58ExplYvb6W5yTBLgW2jWtQl0yLsYgql7uR1B6NG4G+2LlcxELqa22u5sotApsnlbCM9sx9pOdvDKjYn1ZHo8MTeeBZ7IJSe5EaGp78vUJnKgyByRQWDXUPf8Ci5bm8OpnB7iQmMfloH3OFUhwJXADNeIGIp2+H4X/Vmwq+3gWAgymilvM3AsiUOREkov9i6D3lc4kVY4rcx5yyW9IYOIo1Ba7ZpvtvZoibVy5bSgkBUqFEoUkoZAUSJKEyWLGYrOUW64Ekg2r9wGs2iSqxz/lSPbJrofSqsOqNJJXqMVsVUJJN2+ZUjAYDHfV/aOEq5IQN/3yVlqZG9Mrkqci6PX2gVJYWHhL5e4WsmJ8h5BUHkTz/R2vNyPJk0KuKSXVcz7A06X80FYypSOZclEbziAAybMhTZTXbQDhakYYjuJuCaBl0QyErjwrh0Aq/Aqh8AJdBb8S2KyoTYcAgcU9AoUxA4U5n2BjHYKMdbB410BorvOZs1lQFx0GBIH6x1EYM8CcQg3zU1TVO79RG3PNTBi/hXPNc2i0xo9enapz3zOhVATzFivWw1bnRI2EprcSRbiCAweTeX7kek6cKltZfLh3VSaOi6ZWTV8QNtSphwAbX++pwuEsZ4uCW0MFViGht3kQnfsqFs+qWIRgfMxWCovSifT05O37+qBVKvn5wUMUZpoZvDmUbg+aGPjbn2w6UIdu3qOo7udTofMDQAjUhqNwVekItNyPj/VpbFsNKN2KsOUqEBEuKKs7WzwFAssmK5bNRYhEBbbUir11mJRWFt53kk3V4xlwoC6dz1R8zYH2oSLUdS3ErSui0puBKNX2Nhf0Pkh+qpmeX9bmuzBv9hYpHOfWZreZJ5eYyHMX5L6ahK93GkahIA4Xakn52NJHsuFgNQb9XIRv1tUHl6cN3YMmVNWt2LIViNpuKAKUqLLOIFmNmL1rkqvQ8VWWme1FrgB4SnlUUiRQSUqkFptpq/gDJDVCPxjM/UGdjGSegmSxLxISyghQ2K9/ks2flwonYsT+mTTQaqGlLR0z8KRHAx5QFTIgP8+hFC93cWGL+VXmSNfFlg4qRHvGixYZU8HfXu+xRUnsnnEJv6pF6NziuHK4Jl6VNJyc1YRD1vJdisSFA5B4+uqvq76NJ67/NHyaDMkeWm7f5Qx2juxNpQtaWoUGoci7agmUBD/ff5ZnZmzi7QEv0qd9QzS1VZzKyKDQfPP40sVkAk6vVgXVIO2jUvO6KnTUcLOH30szZfNT6kbOnSs/LnP7yr681qYqihsUFpPVxs+Hr/DLsSSst7LcyL0rlSo35vNCu1Jty5NQumuoP3k663MTWdDkBCEFbvQcc4+j6Eh6u+X2XrVdQfz8/MjKurMumMUEBQWVsA6npqaWsPZWpAxcsxyXlUelUuHre2vRSDIzMwHw97/DTum3iawY3yGkIjMZtYfc0TptwWEYp30OClBtWImlc0/ydyVhefvvE+/vn4TX2x1Rt69C4e8nyf30qxLH3Z+7H7cnG8GBPWQ8/2uZ9agiDfgvsi84SB/wG+YTrjdtW9cmCu/JnbFcyiZtoL1tbbvK+EztjmQ0o7xyjNT+CxG5douTy4O10bzcCvP5DNLbv4yufRW83+6I9eBxMoa/51R3mhRM4tDGWDWCw93S8ZonEfrRe6go3xKk1DVF6z0EKKlA5CzOYGr858zOc8NaitlKkqBLKy86e6TTf//v0Od3MgBts3B8PuhOeqGJw1klX+DyhY2J55OZ0TAYdVE2xkmz+CaniFPREeiNZoZ9toqC0UuJk0LJU/WmajsNem8belS0MfmyWZXOlKWrmfLlTvRF1xR6ExrMaHGlZIxezf1h+E7rgSiyIGlVSMZ8xJp0VKH26U/pZ0Pk5WOankT+z18hjIVIGn9cOz+HposPmr42RIGEYYoXmMq3hFzwy2RWh30keNut+gsbnaLV6SjciirgN6cUqBsUIKmh8oNaTF+mkjP/a4ThEm7K7uQpIlmw8iw7B7VHabFQ9Vw2Ty5TU/esBGgIjE5C552GEDAzpTqJ3jY+0ZyluZRF3TU5WJM8QBKomhehfsCAdNVApfCyIS7lYll7Ck03+8uB4fg+RqijSffyRcKGQEG60JFu8+cgDVlBDxRXoO7b59Dc54LrY0Yslwxkj5fQ9w7DY0QCCo84wG7F/LnoQ/KEJy7koc80Usdiv3ZXUOCSWsBWnY0zvmoez7NiMClYXijRxdeuKKSZVfirLQgfJSgF1v05ZL86ASEEx1SPISRfwo7tpuE3q1ky/nVSL/mzv0iPUCrwTs3AggYLN1hvrdmYE89wM/T+9jGSmWJgZ6uLDJOaor5sf2kWCjC0d2PV0f0A/LLrBE8/0wUKoYHe565bS7dmH2ZF+i5Movz7XKWQeKZxJRSShNUmMFltmK02bAK89GoGNa5Eq0hfPt55nguZFbTY5aWRcHgdi3yjeDi1GorzGtK6ZDCr7imOY79uUqYgPy8fH5976EohSRV2Z7iXNGrUiJ9++unmGW+DFi1asGHDBic/4/Xr1xMdHV1umfHjx2MymdBoNI4yISEhDheLFi1a8McffziVW79+PU2aNLkl/2KA48ePExYWhp/f3yPqkqwY/40x93kCFEqUB2JQL1+EpXNPbFWqI7y8kbLvztvlvwmjTovBRY93ZjaSuxbd1XBShX+cKjV//i9HcXm4DupqfmhbRlC0q+TncQBV5LUNCtxHJJA5vBo3fvMUQIFejc5kQWUVaJtXssu095IjjzLSF4K8ICEThasGrzc7kPXGGhCg72bf/rZwjf3hbT5p34BEXc3PvqrMdE0pTFf5kudvV6gtWsHevtk0mlebOkVlh/eRlIFoPAdgVlhJU8Zgs1zbCCFWW5nXzxznTIE9VFhXj3yaP6AnpnUY9/m48F49e+QOpVJifWIu8WOTiEzKR1J6o422hyiMyTLik22hybwqqIpU1LfuprrtKEtqdmBzDytz3TN5sbofri805/KRJMgtYsjvlwnKcQWlK8mKRrgpNDR+5Np5PqpzZU9GDpk+8F3vRgz7NR4JMODCbmVXzGhoZV2N21XlWBHkjcJFh9ujdhcK4+40dNHBSFoFykgrIluFYflJ1DXCUd/vjrZjMOr73sa06zKa6AgUPgKwuzRIrgJr5NcUbTtQan/muepZ3zyc1dFhWJUKPPOK0JmspPi6sKzKDB7ddPOtmC/X7kEjdRusZoFCKaFpqcEr4kUK5uwnICGT+Lr+nOhek4A0G6Omb6dmQj0khYRF2Mhv9CcRT9jrMX5fiQFrtCR7ncHc1xtl5yx0/S+z71N/dONcqHfVcm4+G0/hskO49u6Fqo4SfSdXwIwQ4BmsZ0RhIn+kZ/Kc+WM8fzaS5B5KklcYh6OacCzyPtYkjKS+/zJc+nYFpRlVpUBUYTUwrsykaHsVcptYsCkl0twDONyjHb6KHEZr3yT4RArm8w+S3KUxir2nmfDLdjxeuYS6qpGC330xrvFlPFBpekeIiKTo9z2kd2yMnxcU+FrR2LyxDH4Q694r+CoC8RMWqtsEbGjOg2/uYM2GAbTJzybcnEf1ZRexXX3M+UReQWSpyMn35Vz9fDLCPQmy6enrUZlLu+Iwb4lDrSzAoLn2EmOxCZpKYLWAm97C8n77OGeQaBqUjJf7w6gkHRfX2q1mpy8k8UfcavwC9IRk6qiWqEKH/V4RFIH6LIkKNcda1wMbRG29jKtCS6Xqrii8BbZUBamnTBQoTERF61EoJRKOGMjPsKET+QSKa1Zh5cVL9E5MoDeQHuDPhl5dSA21W/KUZjMNjp8mNSCAK6GBNPHJI1CVSVFyASkvbyLLy5sMX28Sa1YhqKkXrUKzqeqq4YtONcjdlIhlaywK2zVXniy0/NahCxmBfmCz0WLzXi56mzgdkM8BcwKXNWlU8chif5YbZndBHauGJoezqHE6CS/d4zcd9zLXFrZlZWXh7X3tRSI2Npb8/HySk5MxGAyOqBS1a9d2KKw3Y9SoUbRp04YPP/yQBx98kN9++42NGzeyc+e1XQlnz57N8uXL2bTJHsqyf//+TJ48mUGDBjF+/HjOnTvH+++/z9tvv+1wk3jhhReYPXs2Y8aMYciQIcTExDBv3jynSBcmk4mTJ086/p+QkMDhw4dxc3OjatVrvt87duwosZDvXiKHa7tDCCEQhnKWr98ipkKJhGMaQCKkbhFaV0HicQ1FBQr8osy4B1hvWsffjfxkI+vGHiesqTfNXqp42K0SWM4iFXwAgPCYBZKzxVYIwZYCwawEExmXs5kSJOFrTEaRF4dK50qVZh2RynDGlbLPIeXFIdTuiMDmpa8qLvwcReHHjp82j29JMTVm6cnDJOblklaQT2pBPkVWC24aLc/d14xu+hQkmwmbf2PQ2T8zScrzSIp8MJkhIRME2DyqgD4ARUoMAgkR0haUGhACKXEbks2E1f1+TL/pUEQqUbVRs2jKfn6IPIRSUqNQKDFbjbhaQ2nVrRvN3JW0cLlBaS8SFAzNZQfxfNf2ELnqa+O28kX4ZloiFotA7aagVn8vghpfM3193yKKIA0IrQ9SUSZWIXjtUBZjf++Iy1klqjl/4uopmHgkhQfnReOX7MLlBvk0n1MVSZI4/VsSayYeI/6RXPr0UNA+wI0cs5Xtq7S0+aWR87XwsOK+MgHp6vxvvaLi4HANE3tvwaoUuBu0KMqavVQg6QVuKgVzmwahVki8diiVAVEe1PPSMfdMFlsyjRTveSxMNnsfXz8sikN3Sdi3q5MAVUnruklAocUKVrvC2bJSFC81a8PJtGQmb12HVqli/kNP4FUEwmRBEVBy3jHmmDn2yTHu6+HJZq0rRWpXumWkIWkFwiBR9IMbtnMlrTCZWgMHRCyPfFuEQiGwFoaR/2YIpFx1mXA34/bpURQuNgyJfqjwxIjEfDdvPBIyeapDlH0L4z3nUEdeRFgVWDIDUPkmIynA8G0Epo2lhz6T/KzoXs5GGZiO0jUXYVVStCmMc79r+LLNAc4FZjryqiUV7bwa4Kf2LLWukgge72xAp4GVu7RUdVdQs14h5gQrSmM2CsX/b/6r2uUA5y8Z2fpDPdo2LSl/QPRe0jLtbhNfTKzCsCduf+vrfxNZhRL62j3Qae9clJx/a7g2sFtgBw0axNChQx1p7dq1Y9u2bSXyxsXFOSy3kiQxf/58Bg0aVGbdS5cu5a233uLChQuODT769OnjOD5p0iS+++474uPjHWnHjh1jxIgR7Nu3D29vb1544QUnxRjsG3yMHj3ascHH66+/7rTBR3EEixtp27YtW7duBezXLTAwkHXr1tG8efObddNtI4dru0dYVHdusk67AharBRc/UHqCBVB7GyjIhZws0N+dBax3DYvRysrR+0k7nkvyyTTqvxCG2uUWh5+tEPJmQ+48KHYTEKPB93OEAUxrDBRkWdmXZyUu38SfXy8hISWDdjdU07lNAr+u6o9GU8qE7R2OOv8SkjkPiykZ4VqKUmA+B2YbKLzBlkVO2seM2/cIKXnOi+IUQKGxiLXHdtC9SSQ2SYHF1QMkKwgLWK7GrJTcUXjpUGUZkXLPI0x2f17h4odFqwTs40ql80AqTMf402UMS+3KtbKNhjhDMgpbEVZPH8xhDVGeWItBusDaswfZGFyTBdVccFVKJOzL4PL2NAKL3Piu2l4Oh9stXVqUKBQS3tkSP85IwWIRPNjRh+invNidXwBWKwE+HoxtUp8gSzJCUmIOrAOJR9FYcugcpGB21FYe8YjiPk+B0WqjzoZwwjK1KLQ2apx2IX9mFrph7gS39sAHBZ13NiLvfA7xo5OI9FHTs7eFAlUcxt8DsVkEVpMNXacCzBiwxqpRBJmRAiDSNYDH91ZlUbPjFGhv8iJqhnYB3qgVErF5Ro5lZ3I6V0k9Lx2hrpCbWMqWwDe7hcuIlqgAhFJNUI0WjG1aB5VCQWOXMGr4enIuLZXFx2IYaA20h+Bzi0Th4fx599Ci8wRWE5ishRxS6NmkEawN8eLdpHR0miLEIwbyZnoiCQmtEiR3CfUAV1a/c4T2IyQUCgU2nTfWyOrofs4mfuhWtLGNuViYRfBxPdWbFqANyCQvWcPM40XsaOeHMsiHvJF7aDGkMlUik/EGci57olZK2HLd0XrloXv6IkUpSiwXnOW1qGy4v5iCqlIWiqvbYUtKK7ouF8mon0t6bCoqkw21VUGEPohHg9rhr/W6SedeQ60vRMEJjAYF1ay10RjysCUeQm2yggIsVjU2UbrCpVRZUCitCKSb7jIhXV1kKJCwmVXYbCVfmKPCXDh/yciZeAst7rv2QBUKM/mFRQ6lGOCPLVkMfTQMmwmsBQrylAKlXuDlZu8jk5DItKiR8ixojVZc3RSotBI2K2BVIhkE2EBIoPC0LwoV+RKYK7CYSQmSi835qa4USCqBsEnYUpWgAIXL1djQYP8gUtxHKgFqkK4mCGHvP0l59bdVQuTYZZE87S+KQpFFnkWJyaZEq1DirtBhBdILwCoMqCwC3b2PvvWPYMKECYwdO5YhQ4Y4QtwVK49lER8fj0qlomXL8ne07Nu3L3379i3z+KRJk5g0aZJTWr169W4aV7ht27YcPHiwzOORkZHczPY6b948mjVrdleV4ltFthjfIUymAqZO/Wds1/tf4Pffu3DwYAOUSgt6nQWdxn5tMnOKsNmUNGhwnIceWlOqQbh9vSdpU+cxkrMu8OW6MVRkDyd/z0q0rt2XbccXk5HnvBCmXd0naFv3cU5c2sXS3dPKrKPX/SO4r8q1z0kLt7/H2cT9jt8taz1CpwZPc+LSTpbuLn1hzu1is3jz43fDiLtipk1TPZu+vQ9JsvDtpnEkZp5DkhQM6/YZ/p7hbDu+mK3HfybMtwbPdp6G1WZh9qrh1I1oTcf6AziTsI9FO6ZUqF2lQk3XRoO5v5o95NSFlCP8uvtjCopKUVrLQadxQ6d2Ibsg1Sl9aNcZBHlHsfrPL9l/bjV1KrWmb/RYLqef5tuNr99SG39H/DzCGNbtMxQKJV+te4WkrJILjVRKDSN6fI6XawCbjv7IzpNLnY43rfYA3Rs/T25hBrNWvYDlquW7b/Rr1KnUktzCDH7b9xk227W3hkaVO1E/sh0AmXlJrP7zSyoHNqB5jd4oFEoKjDlsOvoDWfkpf/kcg7yjaF+3Pxq1HrOliK3HFxJz5jeEqHjkjr/CypWdOHCgEa1bx9Cx406nY1euBPPNN0+hVFqwWlUolRZef302Gk3FF979mxk3Lh+N5uZrMCrKv9liDDBz5kz69OlDeHh4hfLPnTuXY8eO8fnnn99lye4eX331FW3btqVGjbu7U7BsMZb512E2K0tYc9Rqc6nhyU6cqM7Bgw0AwZNPLmNonw5E1+zEqSt7mDJ/OT//3IcjR+ri7Z1Nu3Yld+iJOfMbzar3JMi7MjXDmnH6yp6bytf9viFEBdbHxy2Ybza8xvXKdLUQe+D2c0ml+6cWs/rPrwj2rkKwTxXyDVmcS/rT6fiVDLu/cZjvnZ1AbDaJjWueJe6KmUohKtp0ns3ZpCHUDo/m0Zav8dW6MVQLaYy/ZziGojxizqxwyBObdIiqwY1oXftR/D3tk/n1yvzNsNrMrP7zSy6ln6JXk+FUDmzA0G4z+H7zWyVeMMqiZlhzet8/Ep3Glb1nV7L52ALMFiNB3pUJ8o7CYjVx7KLd8pGcZQ9rFuQVhSQp/m/K1d2ibd0nUCiUnLqyp1SlGMBiNbH56E/0aTGGdnUeR0Ji16lfsQkraqWW1rUfBWDHyV8cSjHA7/tmEeBZCX/PcAa0m1yiXpvNyp6zv7Pl2M9YrCbOJx/ixOVd9G46kkCvSHo3ffGOnuvF1BP8vn82mXmJN898B/H2tr+kZWZ6lTiWkWH3Bw0PTyQ724PsbC/i4ipRo8bNfcrvJenp3qxd2wGLRckTTyxHq5UV+b8Do0aNuqX817st/FN5/vnn77UIJZAtxncIIQRm81+PwScExO8GrBByH2hvMEKnn4O8JHAPAb8b4pYbsuFGEaxFkJ8OlhuC3oeHt0DlVgu8JoL67gXUvrQzjdVD/0TYoNWbtXAP07Fm2CHcgk089d1rSJKZq86bAJiNGpaPfgm9RwEPTPkShcrGnB+rMfqdxiU2foiopGdEm1Y8c6YyJrXg+7Ea3ENtvNVlHjk5RYx9tSXnBjRjvvoQ3pIZc0B9rGZf5nTfzpiDdr+tb2b1ZsDzjcAYg2X7QrK/eAFNug8uj6Tg8lA6lktast+qAkLizwZKpo+4tpuR4uIBFInHqeqmYtb91y6Gxa8We63+TEoy4YOJxbqD2AQ8nuBN7pVTaLDw44M10KuVvLbmMGfSTXzYyZ+awVFg0aDKEdjcgrCKAAo/y8G6xu4ykBpuo9aUU0gSmMJbgkrHjF1pbD+9DKtkZdrSLgTn2hfMFarNfN3mABf8nBdpaiwqmh0LpU3f2kgtL/NSYh2ss9ayZd5x9DoFS75oT7twH5Bs6APTUaitJCa64acpQuNnJv33QPI2+WOUYN99Kh58EbxyDjteAyQgz6sp30bvAmDgzva4+GqxGmz8PiObysfM7O6sJnvJCUINFgZsbufwWSsy5lNw8TBBmiKuWPQERKpB8gJVNRBFYDmKEGA54AIWe6xdi74AT1/nSBQ2i5LcLE92eal4QJ3KfvzwCKpKlOqkPXRbYh6SAHOgK0KtxCJgwmJvqs6Kx2ayodAoqNTan5AHgthby8JgP7silnLWBZ8Mic/dfNmgd6OGTsHroRoOjjlC/Ca7pTr1u6bs89Dip5KYFaXHQyVxLOYQb53ajRL4OLgpF6x5zM++QJ7pmiuIJKCrVyjBIfXwql2Ji4diWX52N0JlX+jpo9JitUBRnhWrWoFNraCKVsnM1uHYhODFPYlcLChWbmxX/xRIkgIPtUAhwbAaAUQH2K138Xlm0rJqE+lhw9/rPCaLjrikFtidQq6hVhUS6H0GlfK6Hc30BlBKWD11GEzuZFyIwFRw/URlw9fjIm76VGySjVybDavhmrXZVS3w0IDRYiPLePVbvqRytC0BAb5WFBJkZCspNEnsiPUg5oI777+UgV4D49adojWh/BFfFSlbICEY2S+HWpFmDIVKVEe1LDiRx740H5A0VPG0Uj0klW9yDoKQUFyqS5FRAo0BqcY2fuv/DiprAua8GPJS7QtlvcJSUShsrFiZR78BcTSs48HunR1Rqq9GOlCGMWnyLqZO3cFzgyMwmA+y4EdfBg8KZ8Z796HKB2WYGbNQMPpyJJ+Gx6GWBBbqoUSFZc85EAJV48pIrjqwpYM1DtCBuh4AJ/Yk45aZddNNbSw2CaOfNzXv97d/hhc2sBwHihCKcES6jstHUll+xMK+01dYtXQ/RqPdHW3iuCAaNznPZ9ljoLE7nop8ngvQ0EztyrkdCQQpjHhqBSoFSO5WFOFmzEpBhvGaUEpJwsNdiVoJyiIzNgmsOj2urk1ua6vqsvi3W4xl7h6yxfgeYDCY2bMnifT0Ah57rMFt12M2XL0oKnDzwnkxEOAZCIZUMOeAWn1tbVjWRci8UHa9apXAxWU9RUW1sVjCsVmj0Vh/h8ye4PEieIwE6RZCrFiSwZYGmnplZsmOTWDTqBNg0lHnEYn7+l3EUpCDSqGn4LKO/IQAPGrW47I0lsoBdQE4v/QKmWeOAHB27zaKail59f0vEKKk8+fFSwZe+2kDp/3rMf2TVYxtYKJN/zbk5BTRokUE70/pyc+XE/A2mzFKGnRelVBLCkat7salaAMzLuxj2KiVRLqvJPpMKOZ17+EKpPlKHBUq2poVqCoVYXoR9LNdaH4QZsbkktZlKl/saMPZfXYf3Udru/LbpgxcdGba3h+AOusC32V4Y3NzpcuZS1AHriSqabTJG33bBymoZcPT9RIpZjWXCCT52EU+TTzFQw28AQHKSlhO5GJamozIFQgJzkR7sG9UFF9Jl6lEPuqCfNLdPNikV4JSBYVqUu9TU6WSPwqFhK7ISq9fGnC6bSAmvZI2HkoqaZXEH0hjy84zXHDJ5lx9CdOms2yfZ9/O+KN3vekSGYZNspHhYUOTFYzkl0BIiD3smk0BfsMy8RuRxbNX7iPe7Eq0/gReJg2S4aqlUaOi4OJxJIsOrwjw8twHFvjT4sVXfevh8qiVnyP0/PDxcQqLJAouCXyq2ZUqY4rEyoWuPDewiBCNEYXaHVSVQOEKuCIkbyTJiNJPQ/bpInxrZiKp7cqg8K7KYZsndTOPoFZZ8PLPpOvVSCFLrGF0tmRSw0VP7EU1VivUUOTx3aUgelWyEORqpFZ3TyIe6UFnL/s9IKwWZlzO4yG3WDQWBQiBv2chKqOekapUHg5MItK9iFOLzVxcZ0HCPtHW+TyBK+/W54pJ8Fm6kgluFurbvGnoFszBwkzeSD5BoWRXSMJcAnlUV5M/Yk4RWyuH1XnpaC7sQX/mDDkkggaUFm/GNm5Ka4OEzapk3rCLRHbwpcdMNQmrUgAz+Xm+fD7owWs3RvqLULgMPMdhzXgM28V0cNWialIZ8hMRKceJdIcIt3OIq8qo1S0cD7880k/mknNJYMzVUrNPKHofP4wGT/vuMYBKV4i20jmETYEK8HCz4eETT2yCJ/4KP7gaoi9L48daEcwik4YZQWqqBl17EFlOXsGakoPG6zuU2bvwr56EMmI/KK+GahKFYDkGKPCt1Ajz4VxahVtoFQqKfAWaoHw61whj/5F8evUO5qGq3mBNBFsBJpsa3Xk9CoWCIc834nnd1espBGP/WIotT0vH6tVZWekLBAKNQkORzUSiKYOqHrXQuNbi92d3kHY8lw4ftKLuE5UI9b8AzOXsqUK07s1RKK8perGxdmtyrdp1qROykQU/+rJmXRrffKlECrC/8H+cFMZ5mxcWZSquKisay0FsKToUCh9wEai9r8Z8tWaDUg+oQG1/gWnU5jYXKdtSr+724wGqSAhXErPXxPuzfiUnxe7eUqumF6dOZ/PJrEuMfL0mtngL3YIyGda1Bm5Xz7Hpg96O/sNsRRjNYLKgdtNiVltISckjNTWf7GyjI1/WySQ8bBbigvWMfVbeplXmn8c9V4y/+OILPvroI5KSkqhTpw4zZsygdevWZeZfsGAB06ZN49y5c3h6etKtWzemT59+ywGl7zRJSXl07PgVer2avn3r3fb+8KarOwRrXEsqxQB6b3u6xWjPq3WDnIRrSrHeGxTXrUmRlODiA66qaSgKZ5KW8SW52eEYlR/gpssC4w7I+Qgsl8D305sLKEyQOxdyZ4Awgr4neE8G1bWV2DaLhePzl7F7hhJTvp6gurG0G/4xUoY9mmhow1Fc2leXi8ffZaNVyabYTbzeXkWHajU58cu1gP5bpp1kZsERzGYrffrU5ccfH+fLiwYuWPN4NzCOtyefZNbn5/k27Rhb36xEiwb+7NmbiKenlp9/fgK1WklHKQmA/YpgWl/tUEWgkmkbenOxRTbLU8/S51kNG2t0oLoOdnRSM+dRHW/6fIZS9zDkqQlpdYUifROM7+fh/rOS7wp8WTLuJMXhQ5/l2ur7utWv8M27NehYL4FLuZH0vPoZNnGzFf+FiVRfbqL+DBsEw7n1VjY9c5rcfAOHge/YfbWWku4dnIeQy9XZ/lY1ngoD26WLSIVG1OYCEg4bOLswl/XZ39OyZSTffNOXmtV9uf+RHBoYLmMSoJJAp5Co3lEQOdyCoegym6deYdd8e3+/MiSKFzr7YssEpetmQvw+xObSBGvecFQeV5VeSwxk2jexacQEtLq+ROmtdsW1WDF20eIebAIJQurshHR7/j8Ms4B6dFb9jLtUmZCmPlzekc6lHen4VHO3RxJ58zjpZ4zkD1ThZrMgDFYkDy8wHUfkr8aW1wJliAaFdxq+9XKQ0CCsSkyFIbyjjkCdVUDdvHCK3DPRuOSgUgisKj2V3d3p4G4fB9OpRBcuUYM8+vtYcfUIAesFenhm8vwlPxqbL+OTfRrJZmE0wHXr+3QAPrmogGo5UHhlKzumtgY0NO6/lkOLO5Mek8EIUx4TJDd25Vo4fTGJmkBkSH0Oxm6lULKglhQ8rI7Ab4uObl9Bm9Y1SEyw8u6xkySbDZgwgIBarrV4r1dDXJP3goeENdeX0Npa0o+fwnr5G0LrvGZftOVbDSxn7BsKKCuBJd5+q0pVsF2xj01lVACSQoFwDyM90R+d4TjuLglI2ECtRB+cgz4kl+A6YDULvu+QRdza8zz8czP86lxnmbNmgg0kpSenf1dTpEqkQXcVVUNzgBy4Og14ApFA4ysqjJvc4cnq16aQfLsSdWx1dXZ81Q7fqrm0/0BByP3FE4h9EWtRno5lT8aQfvLaotaQJir6LvKic1V/Wkb4oFWeQ5gVSFdXTa5N9KG7oQiLXoNad+1F/1DCZY4nJ6JWKgkJNiFiBbU8q6FVajmceZwzObFU9bCvnq/aPZi047mcX5NM3Scq4WW1h0UptFnIzTPi5XUtSsvZs/YFtNVr+NO22UO4uhwmKQkOHc7mvkbeWJNUpBe6M9NvGZ5WC6jqQN7XWJMe4LU559l+/ASvvpxLv2feQlIUxyO2gBAkJuXy9tvrWbXqNFbrrbr8FNelAOyxZrOzjZjNVpRqNdPf1fPiY19xf69OHDrhw5JfXYm4D7pUqeRQioUQvPHGGr7//gA227UPyzabICfHiMVSvkz+vi6MGdykxKYiMjJ/d+7CBrIVZ/Hixbz88su8+eabHDp0iNatW9O9e3cuXbpUav6dO3fy9NNP8+yzz3LixAmWLFnC/v37ee655/7PkpekUiUvlEoFBoOZpKSSmwxUlOsV49JQKO3KL0BhBuQlQ/pZ+2/vCAhpCEH1rv0F1gZ3/1QUhi8B0Pnad0wy5nuB/yLw/QxQQMFiKFhaoj0njLsgqRPkfGBXigEMKyGpDeR+BcJC6qEDLOn9A1vfc8OUryegZiIPTNuFyq0BaBqDpjGR7ey7lh04rGVTrH3nqWXHDpEVl0/i3kyQwCNCzw9xJ4mLz6JSJS+++aYvBrWKQ1dgxCYTXl4aPvu0IT8Ob0d4mDsXLsGCP+wPqW8mRxLplgoWI6Em+yfuReYgLNd5Dakra/hxRSjN3APJtZroF7+CpPe0fPq0HpNe0EC5DzTHQKGColxUnXLY8sglRj26jh9/cUFYwNVPS5UGfjRv4E7zRu74eBVx/KyRFo8fYffULXSIOU9AqL2f6t/XkD6BdWngFoRHQ4HZbOO1YTvIzTegdVfgGaWmYYgfzZv50LyJD/e7BdE0MpTKjcLxqB+KUq0kcetZhvdexxc/JyGUBgypeVx4cyOH52RSmG1/EO7aFU+DBp/y3tsrMOeko8WCu2RBjwVsZhRY2Hsqh2ZPHuLTby5jtcKTvQOZ+ulT2HLs1n+FXyJoGlNocmHrd2dJOeaGrcAdQ1w/Us70A01jmuizmRh8GZWkAMUFUF8ALOAi4RrkQ7XuGoIbWUDTmHRVJ3ZZ7Nua91QvAtNhKrWyWwcvbbdfs3N/JHFxWxpu2WbydPYICOYCAZYLiKSeWM+rEWn2UFmS1YSEBpt0nrwMPxR5Glonp/FUQTYIBRf2erFktILk8y4oAurzaHY8Sgn2prkQW6jDR9gt1K62PJB8ECgJ0Zipp81DnXkGrm6RawNQKkBVBKo80KqxqdQIs11RUqvbotapqdT8EtEjz1C59SEACr6ZzQvep2hZVEhNiwkDEtvUoRB0HwrfysyodD9PR1ShwRN2BcvFT0HVBmpmdW+Mt3ttXIoCeaNlH2Y81QW3ojQkBJLChsorjQ6jTSB8sOTZ/YLPblPgHqECkQ22JBBWsNjfkm0pEWC1gZsOyc/uYpN9EXKTtKRmN8bqFwIuWvD3A4U7SG6ACqVaov4ADwwZJn59Yi/pp66LtiLs/y/I0LJ53Gm2vZjNx0fD2JXvzkmDnuQCDbZcBfl5Kkw2iVphFmo+mImwJoAQCKsNCu1vG4eW2n3SM2I9WNo3ho2vHcWQacJ6deHln1+lkX4yF42HCv+6HgTU98RqcSPzgkCpkHDXqtCohEMpzrR6Y0qxK8Nqb+cJdPERu39/95p1+TPb7gPfNrglNTztLlBnc675Z1ftYY89fHlXOsYcM6ZEE+4Ke73nz1/bAdJms3HuXDoANWr4o/N9hM6t7eP5g6U5pCfrsF3Q8oH6MHWL3rC7SgBC1ZRp32qYseQkB09JPDHUkxbNJrFrm33L6fx8CxMnrqNatWnMm7ef5OQ80tIKbvGv6OqfwZFmNlsJiQqi2cMP06jBCZRKEx+8bT+X80fOYjXmU6vyNcv+1KlbmDZtKykp+U51Z2QUOpRiLy891av70bRpOM2bV6J580o0axpOs9r+NK7ui8FU8kufjMzfnXtqMf7kk0949tlnHYrtjBkzWLduHXPmzGHq1Kkl8u/Zs4fIyEheeuklAKKiohg6dCjTppW90v//hVqtJDLSm/PnM4iNTSc0tKLxOp25mWIM4OJrV4pzEhyhU/EMBe+ydp7N/dyuyGruQ+dRG85DUZ590ZXCta/dWpwzHTLfAE1DUN/gvGzNhKyJ9s+zAAo/8J4I6hqQOQ5Mf2JNe5dd717hyNL7EbZANK4Gao5VUvTg0+xQDHJUJUkQ1c0E07ayw+cCmqxsvI+e4Hx0MzbF2wOB3/9kEHttmRzckYoCmPvBQ3h56lk9I5OPlpjweOjaQpFGzXQcfaYBY6aeZf6vqYwaKNG3mz9knIWsOCQEscKd0zY3zhhs1HG5ak4XRbhWmszyH11pMaQlcWk59H9nIZ0+6Y32t7n8FFELZVQ+9d0lmvpBUuw+5vpdIveKmeT9doftDb8Ooqb/ObwlEwfcGhBpWkmv4ansWWtg1o+JRGxaQUO3KnRuFIh5igKlBJbe6Sh8bIx5+Sgxycm4arV0fbEm+RHpPFVQxFNPd0LysGJJCEHh5cu3iQYSDRaiD51kwqcH2HMyjRHvnGf+8lRi44rIzjchKaDvky68O8qb0W9pWbP2AhOm7OWXJS6MfL4hS0yeFNqgq5eSywcT+ObbYwDoA9wYNcjK4LY1UOZa7FYpvRpb8OscnJfOvlkXsBisnF5r4OG3ggmIVGOJG8CGNdD6HS06dT5XTBpcNE/gE6UCYcNmSUJBIs1GuSCp34Ygd9ammbBhpq46mSjFebDEU6mNP7umnubKnkwKUo1sm3wCgPpPqUhdu5Hgdk2xpiSzefpQbPne+AVYqN1eIIqsSFf9VV+19cLi5s2H2cl0LLp64ygteNc9QvKHvix9yUCth8/S/l01IGFbbGHp8zq8lIFw8TQU5QAKJIUf2FJ4Rn8Jd7OZNKFlpO1+vq98Bp1SATk/gPc0hO0sCkxYL6iRilJR60y0fkFJxEMDwOcJWrx2HPcIM0p1a7rlzafG/jCM4W1JvZRO8w/iMDxXmfV97iMtK5EISxHhre3Tb8JZJSFVrXj4Wvj+IU+sORLWwsPknT+Eq8VuvTBb8lEpPHAPMvPkV6BURWGzQlZuZSyGLNRXQ2IVpGdiy2mPMUfBle1/Et6wBZqwEKQUCbMRsuwb0eFXTaD0EODhBaq612KBWxPBdplGz/oQu0aQeiyHX5/YQ4uxNfCp7kZIwzwkCba/cxmL0UZ4S1/q1QripXgvFBJ00toYcfESGoD7wrh85BjhLdRguwK2TIQxFASYigT5mVYqtfHDLVjPycWXObn4MhfWJzNgvTt6bwVX9pip/WgY0eNq4uJ7XcwvYeOr3RvYezmerp6h+DaOpqO/nt8zFbQ22TflUfhc83k+l5bC4YTLKCSJLjWrsWTvJwC0DYrmVLbdqnDmOsXYu7IbvjXcyTiTR9zGFLLOF+Cn0pNnMnP+fAaNG4cBkJiYS2GhGZVKQWSkDyiU9OwRyop1griN+3Af2RFEClJqCoQCSvuLwIq19Zgwz76RwqOPRLF6zXn2HvKlVcc/6dE9gUOHs0lKsr9QRzdVMXmcnuDAW7BhqYJBHW6ft03XzkunjGXNIU9W7HfnUHwr2rZ5ms59u1Kv0RyOHbpI2ukjaNSNAVi+/DhvvrkWgI8/7knXrtWdmvDy0uPv74pGo8KIiVRyENctOLbmGVG76HFV3vOP0jIyt8w9G7Umk4k///yTN954wym9S5cu7N69u9Qy0dHRvPnmm6xevZru3buTmprK0qVLeeCBB8psp6ioiKKia99Dc3Nzy8z7V6la1Zfz5zM4fz6Ttm1vzzfMdHUX3fIUY1dfSMe+sA7ALcj+NbXUL1aWJMj7wf5/z1dR6SSUGrtCXZQHei/AYxQYY6BoF6S/AIF/gOLq50LjHsgYAdYkQAK3p8HrdVB42Y8H/gYFC9kx4QRHf21m74duiWS/8SAfGVwxJpfcrrSSVqJOE0FqlUJqzP0V30NH0aWls6G+H/d7BuJarYg3h20BoLtnJKpfjGRtyKDVEbtCnB1ltO+2ahNUaVCITgffftKMGd82xoM5kPkVmJ4Em70Tz2pCwQAH863XFOO8H8F6Cf+QySz/oBZtRq7m0J6LFD3/CY8en8ElDw/+/KAta7Sx/OAVTpibkkERPnw87zCgpG+7SO5XpKOSTBQWaoj72YUI9ycZ2cBM55Az/LB2HRcTjXQbcoInm+byjlSF0LF/ompWnV+WXGHmF/ZV6+Pn9WVzoAnlhXSOhieTn36atUO/o26v7lSt1I2BxZ1WJYDNMzrx9eYfePMzLQeO2b9KeFZSU+tpL6Y+eIgq/ltZ9ZU3C9eMYNQbVzh2tpChY6/dS9ffVSGP3kf9B8LQD27Lz9NsPPPjCoJDq2IJsKJXnkOlMWAxWAlu7E2bSbVx81FiPnGRgCgtZpc8dFozRTaJyYmVeCJAQQdPBUgKUk/q8Qyx4VNFhVAYsQo3VmXZx8AIUx6WhNVInvvxraPHxV9LYVoRvw3cT2FaPpLqd7ZPWYiwWamx63v0Hm7EbxNcPngYOMyBVYt5/Pu3cdNCisqVw8ZgfPVmrkiHiMiybw6i8FhAkM9PBNYaR8qpyoQ2s6FQSuQmamkxuqH95IW73R/JZgFzAaj9wZZCtSK728EqWwgdPNLsSrElFTzfBKUrkhQK1jikUDO24z4otMnU7GhBWE4iqQTe1dW0ekvFyWUxfNnlV3IuJuPi44VK9xQKZWcOHi+Crla26dy5X1WIUqUgPVvCdF6HJd9GTnWBn5sRfN0xqELIOh+Au9duhFBwOe0xlAoT/p5HcNHZrZJ5xggCmtVEobwWR7Qww8qJXzuxb+ZwDBmzcA+rRvNXviawQVtHHs9w8AwpsFuTUQLXxShWeIHtMkplHg8vaMKKAQdIOZLDljePE9hARb9lXhhzbJxblYPOS03nTxri5qJkaQ0XVBJoFBLmDB1SvhFlgY2zq905vTyNdpPcUbsUIqkvgKQj5ZwRJGg1vhZ+tTyo/WgYW946jrAWovdWYCkStHqrCSFNSnGRkxRUC4xk2YnTbDQm0yrFAgF6LuTm8aTVjAAkr2sT6OIj9ugu7avU4GzhSazCRhX3SMJcQ7BdjUoSmxuPxWZFddUPrUr3IDLO5BG7OomiPAu+Kh1xplwni/GZM/brULmyD2q1vdwDDz0Ko37hwCElmaaL+KFDGGsjlD2RdG05cugYA4ZsQwgY/nQjPv/+CZKTcnl7/JfM+yGN1Wvs6xYqRxj58PV9PNLj0k0X3pXAZxJoPSBnERSucTp0X+VCVuzvy+HL3cClChLQtFNzjh26yMmDpzl2LAmLxcZTT9l3L3vxxZaMGdOm1GYEgvMkcZR4LDcGAHcHHRrC8b9F4WVk7j33TDFOT0/HarUSGBjolB4YGEhycnKpZaKjo1mwYAH9+vXDaDRisVjo3bs3s2bNKrOdqVOnMnlyyVBDd4OqVf1Yt+4ssbHpt1Ve2MB0NapEeYqxSgcaN7sS7eoHATXKUIoBcmcBRaBtCro2SBLoPKAgHYy5VxVjSQl+s+1uEuaTkD0ZvKdA7kzI+QSwgaqy3e1Ce59z/ZKCs5vbc/RXLwDqzfFlSc0OnCm0P3Cq6hT4qq4Jd7DAyqUigeiYBVYrPqfOARC8ZTuHW7dBVz2IAe9to9BooW2DSnxo60DYJU+4ZMagg19b2WjXPI9g1JCRh05no6hQQlu5CR5qvX3DD9MpKHwXzANA3QzJNQwMgkMFVgaA3Ycx91OEOQCR34Kg8CIeHBnBgunnOXlczT4a0Sz3EJ3PJlIYeT8bjlh4qLGGyrkKDuyzb4bx9qAGKDyyAVCs9KPLSgtgoSfQkyqMerEb757az2c/JrJg32XWe33Bxydacl/lTAY/b/+sO+ypZrzQrz6bDtv9X09mhbNt8mpOLttE8pGzRH3/ABesSgxIaLZncPn0FV6a6UqvByrzwaxs1H46ztQ1oVMpCS14BSHMSOyif4cLdFndgne/TiY2WU+uVXCq0IZKglYBOnz6Vud83brUe/xBxNVFVZs/mcoT07+myJqDHiVVumhxCaxOtV7BjlXlNpdILEcuUqmlGrCw87CGVBc1hYnZWK4YwGojeb+Z2BQDrV53RbIlsL/Qk1SzwF0hiMy8uhAqpxnW/edp+oQ/W2ddIenPbRRmfYHNYu+HyLb3EX8pg5p13Wg3/BmO/7afE5vXkHT8MCI3E/x9QA2t1ApeC/XEhT5Yj+0Co0ARlA+qh2nyXD67P1dSo5fd0ugRXslpzKL1AGM2FOWCJgTMaqQiu1J1QqnnHa/DQDgogkB9dTcdyR9IQqE1YvZUoLBqUSiLkDQ5gAeJO2NZ9+YnXIqxK6oKlZLCzGxgNuhWY8mbiF9SGDGVXcDT/rKQllRAJXdfkgpDMB/WQUgyPhGX0XvmoYtKhiwosurReeQgClzIyqxLZlEiKmU2l2P9CW2ajPLqxkJ5SelsHDuBs6s2XJVXIu/KOTaMbkfNPkNo+vI0vMK98IoAbFfdvST3GyYPPaABTGjdDTz0UzMOfnWB1GM5hN5vfxNP2GsGAR0/rI/b1UV1LtctSFP4e2DLN2JLy6XO4xH88uAVLu+x8MzWACSlGcnHSvolE9V7heBXy+6/HHK/D4+vbEXKwTNALkqtZ+lK8VUah0UgIXHRVECHzHTSzX645tonT4ubDs1VRTUhJ4udF+xzzKMNGzPnvD3ea9tg+4YIYa4huKj0FFoMXMy/TBWPSACq9Qhm34xzXNqRjkqnxE9lNxRcrxifPWuf56tXv6b8BVVqwv0Nv2f/YT1rVrzO0y2HIIx1sVnfJj3VRq8+uykotNCxcTAzPn/YXibYg6++HcWLL27l08/OUb+eJ8MGZKJV3U7UJAVo7AuZUVYFt8HXDkla6t//KIpf4EqKhbRMMz5eKtKNHgRERpIaH89LL/3G+fOZFBaa6dKlOp980rPUVvIo5ACxpGM3NLmjxwXnnTw0934Jk4zMbXHPR+6NoVyEEGWGdzl58iQvvfQSb7/9Nl27diUpKYlXX32VF154gXnz5v2PvfMOj6M6v/9nZrbvSlr1LlmyZFvuRe7dFFNDx6FjwPTeTegQDCEhhB46oTebaoyNGzbuRe5F1Vavu9L2MjO/P2YlWZZcIBDyzc/nefTYu3vnTtnZuee+97zn7XGb2bNnc/vtt3e8bmtrO2rz7J+L3r017WxJSfMRWvaMkI9IpSGN/B4Oyf3B54Co1J6T9AAIV4H7A+3/MXd3DICmGI0Yd6mhICVD/PPQeCG4/wWBdRDS9L+NwgW8uWsqp/RPZtBB1U5bStwsvmcrPqvMjnsFvjEZkb0yVkngmmQDJ8fquiRf/Gmfn7VV+6nVtRBVWo1BVEkbOYB963eQMf9b3hLj2FrqINFu4vUhU0jcHoOMysqxej4418T08ir8ihdcBnD5UIHvnxI4+S0Dej3axYj/B4T/AMLzoF/GQMtbQAw7fQp+RcXU9hIoDhT37Sxrq+fFxl348mQKpuvYtSDMAqYRSysnLF/JzX+YiWA30uZq4P5nNfeGi09LpiA/FtHQjKoKuPLi+PbUzrr1g+tcFAibeeaWDGacEMWsx9axY28Mlz6+DsszEl6vzJRhKcwsyCVOJ5ASFUOz0YbS2sSWr76KXNdKPl+9nDdPuhh7RRtT39yLEjbR1HA3Of1q+Oeje9mzT8fNFcVk6mxIiolwwxx0vZcgNNpJiNXzj/s/h7jTkKNv4/w9Xpwy3Jhh5KkqN9GbVmHdvhgEEUmnY9/mtWxeuJQxj2lR/6g0kaisuC6kSYyzIeUk4QlsYMnVL9O4rZGzBZEWIHKX4WlVcFQHKFtqQJSgPmRiYFBHhqTykc8PKCAGQNGIhl5y42jcCoAtJYmT/nYzfc44EWGrAtSTM7Yfvc64gikBP9tf+ztRiXG4m5x88MdZpPQdxDzpUOVmS1CFr3j/dFXL9ld8YOjX8enoGVPIHz+A7e/8k6Kv11B49jj6TRlGZdFuJsy9ivBf3oRUFVU/FG9T5LeJgN6YiTW2GENvGcFvgdoAapuPL59YyJaXngFFQZCMJA++gnM++yOlX37B4vtfJ+Qt4/jSB+n942Y2JD6CmqstO6eoqdSRCwiEhADli+exatMGJt17EXadppMypZhIizMjV3lRSuqoLPYx969NQBPXbrahyHo2vzWfRbP/QaDVjSCJjJ1xBSMvm8WKz15n02uvsXvua1St/oaTn3sOe/Y5HVphhKiul00QIlHjBlCdGKNjGXtnxDc7vBvUVpKHZnLhgvgOUnswxMRolPIGVIeHpHHpJBRE0bTLRcNOPckDQ4jJIZqrgoz58+Au20l6kbQROu0ZKB6eFEabTBTEJ7GzuR7FWc2/GnIZFNQkToa4zqjCZ1s2oQKjsnqRFGVhQ5OmA5+SMk47VkEkP7o3WyIJeO3EOK6PDXuuFWeZBzmgkKDX7teyss5E2/bEu759u0ZFTzu1N+uLavjmhwTOHLeG0pI09m2s46+fbaey0keffBsf/vVk9LYDHvJqgEGDYnjztcLIxcgBsedS3IeF0grybsAA9nu7RUxsQH72PvZU+Nm820uvNCNur8KA8SNprtzPsmVlHef08ccX4db5aKBrsR0fQUqoQUFFQmQQ2eSRhsCxJLt/B83NzRQUFLBu3bqOcs/HoGHkyJHMnj27Sxnr3xK/GzFOSEhAkqRu0eGGhoZuUeR2zJkzh/Hjx3PXXXcBMHjwYKxWKxMnTuTxxx8nNbV7jXqj0YjR+J+pSZmXpyUU/dKIcYe+2HKYCHAEBuvho8r4V4HjfiAIxglgGtfxkSkif/a3ab7JHfsyT9Gs29qe10ixYIW4J3llhYG62hperKpl9ulnkx2nRXJC3jDzr9tIwB9mzew2vP5mhJIyEloreOK4E+gd3d3+bWyUyPp9WsS04Mc6znryVgpOHMvqt77g2adWsoQqAN68dwJpgomKPCNPFArUZhlI3+rAk1NJb1WGRm1gV2MsbKx1MGhVEznHRe4b0QqJb0HdyRDaRkbTRBKl1TTKVra7Gil0vYqq6iiqG8nf67cgo5IYl0x6UjFGSiliEB9yNqWbNzGxdBc5p/Zi884WFq1yotcJPHxzBrp4Tbunem3EpPjYG2NkbbadtO1OLr4vE50wAeovYOzEABu/P485jw5hzvtb8Xpl0lPNvPunScRZdXir2hhk0eMyx1K14DvCHk/HtXLuLIOTYEBCmJzjkyldUMf29/cz5V5twMxKCZFapyOVeNBL4A6gOsYiUA6iC8Td0LobSUxkfPT5fOsI82xtgKCqY9jf7gDAaDuRwdOTWf/ZO6z96DlGPfwvxHayqbaB0HWGpiTp+WTa3VSt3X6Ymw/Kl3T+Pw7wAuWHaCuIIoXnXMC0F67AFGslvFuPGpAIqwI6SUWwSUQnpDPuynPA28j2Jetoq2qgrWoxDYfos2d0JvXaYwXyxw/AZBbZv2I55z6uiVaWP/cBZasaaay4l0sXfUxjqR6/88A+YkkfbMMU7UY1GgkLNvSqm+zUAFsUheypMxh+9V+wJmdBuJbRN84g/9SzWPrQZ5x6+xiMNjPKi4+gH3k+cliixdEHEGiSvLS0rGD9TTehKgrlixZy8/cvakECiwDhPYjx/VBKIK2vCZ1RQG92sX/1bhbd+zIN2zVpTtqIfpx83SMk5w5AGp7D6Se+yqCLLuLrWbNoKS7m0/POI2vCBE548koyRhWA0AMBFWKBBlCcIEYeEKoCqhZltqUlY0u3dN+ufXOrUUvq8wZQaxwM+GMWyx/awZp/ODjjNSNCrEziSDuxuQeZtKvqAYT9yNHSUb1y2Nlczy53AzVNPi4IarpcMVbrt9nrYdHeXQDMGFrIqoZ1hJQwWdYMetk6VxD6xnQS41Myj9d2LwjknZzChhe165qZHA3Nh4oYJ3Q5rtPOPJ2H/vxP5n2fxbzvod0VAsBu1/P1vHHExRwcDT+o1rjaXYJ2VFAjJFaIPuQgMrSfhT0Vfop2e3G0aasN40enkm8dyauvriU21sy8ry+lwl7L3vpycIchx4Igdu0vhViG0xsrxzyDfw3MmTOH008/vQspvuWWW1i5ciXbt2+noKCAoqKiX9T3559/zgMPPEBpaSm9e/fmz3/+M2edddZht9m2bRs33ngj69atIy4ujmuuuYYHHnigS+By+fLl3H777ezYsYO0tDTuvvvubkVHjrTvH3/8kaeffpqNGzdSW1vLvHnzOPPMM7v00V4u+8wzz/zFjl8/B78bMTYYDIwYMYJFixZ1uUiLFi3ijDPO6HEbr9eLTtf1kKXIIP7fUKckL0972JWWthw28n0odBDjf6eydHg/OB4D37cAqKFkhJQHuzQx2ABB0xmH/aA3H/BhzF0QrgalGWL/zLpSP+nOLfS12gFYuegH9qWnk5mezu7XGmltbGPntV5E0YlVMKJDJtxczeNffsSVo8YzNL1rdF6q30+UtwW9qmdEnInMyaNxBxTijjuJte8mkxiSOOukbCaMSKRS9HNfrPbgTt3n5s6cJjKsHmKCEeJmMyHG2XCOr6JiaWMnMQbN/zb5C2i5ByGwhmHC9yzkbDY3r6BQ56fOeQVPVu5ARmVq7760ZIxFf83NpNNCbM5olpZ7WcsIxt22nLeS9DzxlBY9Py7LTuwBZLGpIprYWLi5rYk/f+3iqokJ6EwSMBRSvwbVj1Qay5+ubOG8mxN5+90KLrtsMmzyoo8TCeyo4rzkKCoM0SxaolVni89LoLmkCblYUwUPy0th0MUmShfUsXteNePv7YPOFIsZBw8NSGazKxkpLwV5VxWCrxr0QPwYkO6B1qfA8Scm2obzLb1wyRD/w1cYt2xD1JnoM+FKxl+Uypb5n+PcV8q2D75nyKXngerRJCcHRK1UVWX+9ddRtXY7ppgosodez7rBKdSm2jjbptK7pgklrLLiAwdTHutPmEoMgsJabywjnQqq248QvQ3RPB9sl4E4lFB1K2l9+5MyORkx1o/q1YGvhMdiRnC8msAkoVGraCPqwRtxsLjgGs7vl0nQI4DUfTIMaKROadYszIJ7I4mjIkRdC4YCzFbtHuo1egiXfP42pmgLAZ+XgZefRs2ucqrX7eCLK59hxPVvIIgg2GR2lftxtslYG5LpP8BES2MsYsDPyJwNDDlzKsWlZhLOeJhmbwjnqmoaLDJx10FcjoFTHrkCk6olhhnVara89x19pp+PVW3FQhuvepwkXH0JqqJgjoujV2E/BEHAUd2MMcaGJV4CoxOMeiRCxKVV01j5LO+fpiWsmux2Jt9/BaOuPxtlexToPYgxGnntNXky123dyoonnmDVX//K/pUreWPCSgacezzHPfkKsb0PeuAI0dq1Iog2pbFq9wMK2pBh5kiQsuKRd9egVDTQ98RMVj4h4tzpQ3FaEO0yAy/vITlZbUSzGZM6kwEPg1G9cnl74xq2eFu4zO0gQZGRBQFd5Ly/2LaZkCLTPzmVgSnpfLRRsw6cnDKuy7O5J2cK0Gzb2olxfp8E2AmVla0EAmGMRl2HxvhAKQXAsBG5FPSLZddurbhOgt1Er2QrvfPiufO+DPr0iUJVDiKTaqDrSzX0y+Kv7RML8dDJ38MKLHy8oIXNu720tGoEfGg/C8ddcgpRUUZOuCCX0uxyvOsaoUKLwtscEnEjMhAELS6cShwZJByLEv9K8Pl8vPHGG8yfP7/L+6qqcsUVV7B27Vq2bt36i/pevXo1M2bM4LHHHuOss85i3rx5nH/++axcuZLRo0f3uE1bWxsnnHACU6dOZf369ezdu5fLL78cq9XKHXdoQZXy8nJOOeUUZs2axXvvvcdPP/3E9ddfT2JiIuecc85R79vj8TBkyBBmzpzZsd3BOPXUU5k1axbff/89J5988i+6Dj8Hv2vlu48//phLLrmEV155hbFjx/Lqq6/y2muvsWPHDrKzs5k9ezbV1dX8619a8tjbb7/NrFmzeO655zqkFLfeeiuiKLJ27dqj2udvVfkOwO8PYbHcj6qqNDQ8SGLiz2O4ddvB0wjxeWA/ktrDvwp8S4iYSmlQ2sDzOZr5qoj/o1cIfDICw9kWTLdGoejh22s2YorR0//iIQTaBJIKICqlswtVUVl4WxFBf4iMa/QUl2j6vJAgoCgyxkPqNn57ZMaIDM/QYzTrICEKxWRCFFRumreNgS9ncfWSE7oMeEqrFzwBhKhF/NC4nueLzmXwwzM5/uRaPhr4NOU+D3lRsTx5zgVc+/yH9LnzMjDEc/OuUub963XueGQPTuwd/ZlMIhs/r2TV/TMYfbFAa73Kzm/0nP1AHFu+e5tdKxZz4nPP0Oe0Tl2e6vETXleKmBtg/941LLz7BUbfcjdm61QSBSdR8dpEb+uqJXxz/82EzSaGXnAv2998GMlkZPnKKv5eEMsAk8g7k5fRtt/LcX8ZTOYYK2HnMuJMOtp0sUTljEfetB1dVAUqAkLedI1MNl8H3q8ICcmc6/4RT0Cm8KxCzBWlDLrwVoaOuYjMgWbmv/wSRZ++RExWCjfuKkKnrwD0oBvWEXla+9xzLLjlFgRR5KJv/kXF8kF8atBRPCObE6Ilbt5Thl5SWfOtlzF/KeTDhv1cGl+HVzGiX2sAWUWXPw9BeUmbgMXcFrlI7QUdgGAdNF/H7d4PiVMyuF/aoc3kbCnQUkKVLp6nyecfWeXa8ekP0ry3I1wCajOIGSCmQcsd4PkIhBhIma/5/RbPB1TQW7SSkcaVkH4OxQtW8cEZd4CqMunhN2kZdSavf9lIKKxiMgjMPCuBM4+LRRIFtn34IQbnDvpOG0XYEI8uZzyqqvLhySto2uXi1Fei6T1FgspmLSIK1Owo4a2L7mP6e+8zJK4f3mCQv91zDdKW9aQMHcrMFStoWzePhPQYlj73AZvmLSP/pFF4G1txV7nxNjTiqKkCVES9jlHXX8LEB57GbKlD0LmRS/SIqQYE+8Bul6Wtqoql999J0b8+AVVFkCRMMT2RKFm7NoiRv85qekft8ikrkXMWCAVVVEXFYBZA0t7TEv962qcU+fzIcAcCKKhYRB06QUAVBARJRI18pqJi0RuQRBFXyI2Kik1nRTrgOaaoCq6wBwGBaH3XZ3agLYSqgGgQecw/kyB67oz5jFjRxf2Oy1AR+ZP9A6LFrqVFxePG4MnJJ86uYjLS8d0jqJFTO/gaqhDxdRBA+w3/ItLZPh4c+jtSgWCo67Cv1wmIAuhz07CMHAEbnOBXtICTqiKIIs4FC3B++eVRH4ktJYXrd+z4+adwGPyvVr6bO3cu11xzDY2NjT1+/vDDD/PFF1/8oojxjBkzaGtr47vvOhMxTzrpJGJjY/nwww973Obll19m9uzZ1NfXd6y4P/nkkzz//PNUVVUhCAL33HMPX331Fbt27erY7tprr2XLli2sXr36F+1bEIQeI8YAM2fORJblDj74c/F/pvLdjBkzaG5u5tFHH6W2tpaBAwcyf/58srO1EsW1tbVdPI0vv/xyXC4XL7zwAnfccQd2u51p06bx1FNP/V6n0AUmk56MjBgqK52UlDT/bGJ8NI4UWkT4EfB9d+g2xgnIDY9T804te1v+ivJcGOEtgUBf2LOiFlGfSfZxGeisCfhbuxLj4m9qKV1XScwFAYpLtIdncdDHpeIJeEfAnFVfkSLp6ROyYjaJKDrtQSwIEkZJRBAEVFUlrCiElUN4WKoCelVAp9fGC79fQY4MHGajiBwKoTMYO8YPAZWwApWtCpVtfiaMSiTNbELADHiJizKwO66RlmI38X00zaSqqMjb9kNIRsyZSl/DcAbcdBz6mv0s3waumcuxjx/HQyeeRklQJOkTTaOeOuBMYnNjuPz+62l8NZYva8eyVhiJosIN1/Wm//hoVl6wnaX/0KobmlO38+5dL9FWVQHAZzNmcMWKlaQM11wS5PIGMCo4PWV8MmM2fkcbX111FRd8/R1LXpA47ZYkJL3AD19rVngN48ew3dOX6Mxk2irrSd2wnN5Dz0YQBQZdlMVPc3az/f19+KLTeL+1gb8MSSU67ABHKVKcD0Kg+mygSAiSAHHPQKgMfWg7E3RL2PLRPswVpVjioznxqsswosldjnvmSspWf0br/jrWvfQu426ZDIQAH2ChbPFivo9o9U948kZ6Tz8de67A0ru3UTwjm80umYYqmfRskZxCK683BJnviOVsewM2KUDYLqC2GcEWDW10FKFAVUHWIqkIceB9HYBeJiOLPAnICEhBd4fP2ELSKQmYIhKgkFZwRujUd3feY5HlF8GqEfu4ORAqhuBGaLpCc14x2CDogpAXFQWHIxdLtJX8k8Yx+uY7WPuPv7L88evYfKqdUEJ/RgywcNslKaQkaNdMDgZZev/9GPQKfaeNQhdsBlcNQlQahdfnseCmzciheHBqHr4YolCDLtIG5GGJjeK7W+6gz0sfMPetF5G2rMcUG8v5n3+OwWImISMOVJmG8gbctfVsfuvrbqfY/+xJHPfnm4nLG44qxaFWVyEkgxC7DyH6xB5/etEZGZzx+qOMvvE0frjvdUoXLcfX0tJj298CvuCR2/wcSJG/UOTvQLQPbiG8hIB2YVcQZ7d+2u8gHz1fC9kPsTioJ4maVvChoCJiIIjOWU07LdZlJJH64u3YCkdA8690sgYRci0I+t82KKEGFChqhZXaNQjU1lL70ksYMzJIveYa7CedRKCxkZZvvjmq/qT/kITxcFBVFX/w94n9mQzCUa8a//jjjxQWFv4mx7F69Wpuu+22Lu9Nnz6dZ5999rDbTJ48uYsMdfr06cyePZuKigpycnJYvXo1J57Y9Tkzffp03njjDUKhEHq9/hft+1AYNWrUf8ya93dPvrv++uu5/vrre/zs7bff7vbeTTfdxE033fQbH9UvR15efIQYNzF2bPZRb6fI7Qk+PRNjVXYjuF6Atn+iRYQlsJ6teQp3QADTaMLCJJad/Ahrdv0NWY08nOuBA1YKPzvvDfqedS0DZlxDQu9sBJ1AOCCzbvFm4m/yI+ggoCgs9zoZ5e1L9FsCsSMNXHbnVJ5csoDNuBE8OlTC6BN7885ppxB/0IN7W201q/aWECoKIheH8AZCLN1WBWYDNmMTNpOOhrIWFm6TUYEP/j6I806OoWpLJRv2+zj9xKFIRu2htqUxxIaqAFGijpVrm+iVFWDIoGx0kkqC2cCuYQ7Kl9Z1EuNWD4Q0Yh4qrmbJIzdjqtmPbDQiBQLkvfsR08ZPJyk+jk+XFGFf9yOqIDLpAe3eEnVmxl6ahf+pZRw/METc5fdwzVXxYAzx47C/Ip5TTuLCZUSv1S5qVFIKUXGJ1Ozexsen/YErvliANScTtdFFONXBx2ffjd/Rhs5sJuzzMe+SCxh80ft8+WQd0WkN+NcuRxVFaqdORPIHGWwZz9a35tJv7XeYr9GWlwrOzWD1X/dQv6WV+qVeduYFeHeXiysGRKM27aI9yta2L4jsLkLKjNwb4Ueh8TLO891B8OV6wsD4C27QSLEkomYnYEuuYMpDV/PVrMdZ8cQT5E/vh94cBlHE2yLw2fnno8oyQy4+hTG3XAiCjfi+IoNjJNaEFJr0Ilu3+0nPtmBLFvisKQSCRLOShE2qQ8wIotTGIeh7accUiiiO1dbI8q+g+byGNO1yjjkGr0dHsRhPP6UJVBlVMjI3EI9fFQljQo9fI8AHE2NVBiIFaNqX5AUjJL4OdSdBaA803wqm6zViDHj9cTicZ+Ly+4nJdFA37g5a5q4nrnI5A5bezPiPV3DK9IwuA93GV1/FUVaGLSUF2ZaF5N4PdUVgjKbPH9LInJiAyRKEisgPLzELoXkf+N0MPW86Pz73Pv+4+VKUfaUgCJz9/vvE5uaCu047B52Zsz/9mk1vvEGgrQ5rvIolIQ5jYwr2rGTipsegKgFUfzmqV6taKCaDEKVGymj3AFUF1UXKkHwuXvA1zsoWQl5vD+2CEI5EgnQFWmU9FND10eQpRwnF5UPZVQUqyIqAJKqI/SVEk0uL3ut6RfYV6V/K7rSCPApsqtzHy6uXk6gz8Wj6MAJ9U5hbsp0fI04UM0eNY1yvPFbWreaVPe8wyN6fe4bc3K2fx4v+xu7WYq7pexkTU8YecLlUQt4wBquetTct5rvF+4m/9U4SU/RwbzH9+qdyw2c7UVGpiQ1QGuVC3uLsIJe/FqTdHmILEjHHH1rbjeoG1ad9P8LhgzKllX5KqzT5RnK8nvxYFcfuJpRIQY6shAR6DRiAFCE++xobKaurI/mSS5g8ezapsbFHPGZR97vTC/xBldNvKP5d9v31i/mYjUdHjCsqKkhLS/tNjqOuru5nuX+1b3NwAmB7H3V1deTk5Byy33A4TFNTE6mpqb9o34dCeno6+/fvR1GU31xn/Pvfuf8rUBVwPkpelsJSuiZpHBaBddByPyHlbOBaRB1IB47zqkpT0Qu8dfztDDjdwCmPxoBpItgfBUPfbt3Vb9vGF2eNoa60CICcSceR2L8/4U1BlPIwihqmvO0HXP5qdnz4JDs//gs59hOY/MzTbDFUYRivRdqq/QaWBSqRJT0nfapVy5PXB9lXlUFSTAENrbtQCaNa43nsuOOJF8NQuwOi0sCm/RD67Y0ne44OtVFhSds+bmxYRE1bz1UBLz5nKMNnHI+/bjkZQ/qQMQRApa2uiQVPvM7OH9ZSdfYfuPKu26msqKViv4uK/RqJSkbk3D7xlKqbid6r0qdPH5SGNpa21bLe14znjdcw/rQC2Whk2z23kjXvG+K27WDTg/cy4tTjKXntNeyAkDeJvmd2ZsoPu/x8lv/tSdj2ExdMBrO+FkVNpf/CIL5X3kbn04jjmFtuYfLDDyPXNPP68ZNxVlfy+bVXcsFf/olggS/vfoDGXeVEpaUyc8VKPpsxg5oNGyj5/k5kz0OUrX8XgObx0wgkxOOwBIktOA7emotu2Q8dx2NJMJJ3cip7v6phb20d5EFxoxmfbMMsuQGV2h2lvHpOpwtLT7CnZjD89PMRkqKR8lIQ9E6QFYZcfBarn51H444dvDT49G7bpRUO5bSX7tEcAyJL0YWX9uKz3W00D7Lzk0fi+JCKVa+QLYeYmGIl25yGGqxDjFJAEaCdGIcrtASj9mixmBIhSNrrHIu2jLFcSaQfWpJTszUTX0AkSgKdaNWK1qge4KBBOhItdnsl/jmv83cYa9CTaf0BQa4BVDLjw/SNrJY43QPwhjxsaQiw4EsfdU0hdJP/wtgF52Ns2kfdoxfS3OtNEvppzhYBl4vljz4KwOSHHkJKGwyVHvA1Q/V6yJ6IOdYAdZoGGJMeTEGwGsHvZtzVf2T5Pz/XSDEw8aGHyG/Xzrkjg4YtBb3Vyuibb9YIbXgr4EdptKL6g0AItdmKvMcIYhVEJqaCPkV7HvUoe/Kh6XhFEKzYs6N6aBNBSNDaizGgZAO6LtKao4WclIFS3rlELPVLQTSX0CKo7JN0KKoP1AwQdFri38/o394nh8JMHwqwyhxFWagBnz2W4YWj6BUbT1pyKvsFgUBaBqNzzyXDmsb+hO5JwcNSziCmrYK2qAT2xx38ufZAjh9qh8X7WdfajM2sXduEgTb2F+hxqC5aKhthURsEFQRBIDs7G71e60tx+8HpATuIlhBg7tQBqyqqUo8gwLqmMkYl5OKXw5j07YVEavB4PDQVaYRkyJAhGAw9rJKEirR+pT4gHp642pq9vP1FJUZ9mCtObqa5sh6A6OhoRo4cSXx81+TAxIIC9Fu2sGfPHvZUV+PX6Y5ITvR6PYc23DuGA+Hz+X5T+cfPcf863DYHv/9L2/zc/CsAs9mMoigEAgHM5qOfnP8SHCPGvxb8K8D1Kr1T+wPDj86yLVQGjTNBcRB0aZWFDOYGBBIAEYJboeV+1j+3GG9LmPXvhMmYeD2Dr/hLt8FDVRRWzJnD8kceQQmFMEp2TrjiaYb/80oEQaBqTTPrLt7JqPgMRln+RKVrJdutX9GwexXN/QOsoghRMhJC4qeUAkrKfkJQFUY0DCTG3fkQTvrYS80NYxFLFQRPCxdPPIlh0Sao3wptleB3InvsBD9qAtlL8MQg9760mTdKtcSBvLx4rjo7HkkNUrqqiNJB0zhnaC8uu2wEbxW3cnFLMnpjM6iw5v1vWfrSJwS9fiRFIfOzL4i76CzyJmazfkMLbl/XxVNBgB3bd2CKj+OFDUvY4mkmaeUa8n7QqkztveJihKwcRt31Zxr/dDutlWW8f8bZRO3WEutGnH8lYb92XXUmiMoeT78/TGbn3CVs+Oc/GXa+kW/u3kFo8x50QGtfO6P+/jjTT75BO4DoaP743be8MXYs+zavZfHLf8WUbWbP1z8iGQ3MmPcFsbm5zJg3j1cLC2nes524vBcIedcAUD3zNgS5jBavh6bJExD1Onzl+2guLiY+Px+AgRdmsferGlqTA4j+AIlLPuOZW+dx2duPkTG0Lxs+XojOaOq8IO23iapqclqjkRPvuBdDYV5ndbCwRjxFfTKnvPACn553HkFPe7IVgEjyoEGc/8lf0ZkMXRwDcqYlkf50Mc2D7FRMSGKLwU+hGmBCo4tV81qJGWPjjAI9UloIIbpNixBqBwTh7WirHzpNBxzQCjEgpdHLYge8LAgncLVeRFBVNkjpAPQ3SwiCVdMQt0smIlAUlV0lTQzIgS17Bb5bqWXpp9kNzJ6ehEEnQmS4NoitqGoVgVAM320T+KKoBn+k1G1inI5bL+5P9p1f8ub48VStXs3LgwYx6uabmfzgg6z5+9/xNjYSl5/PsCuv1Eho2gioWK5FoeuKIKEftFZqBxZn0yLjFqAZjDqV/OdfZu/1s1CPP5WpDzzQ+T25NZLSPsHs+C6lDJBLEBJ8CLJGShSHFzCBooIcRFVcCGIUGgHuIWrc4V9sO4zPY/vXHqvZ3CkR749unsdHBzE7EVdDA1aPgKKqhExm9koixUIAhPoD5MRBtKWtnwEJ+hZoyW8K0OuAnACAikh/UoyFQTGavKmM7tEqa2wsgyJR0AM/V91hqPSBAv0Hipx7biqpqTZMNonYcy30nxhF6Y5iaAlCrRaBjbHHMGrkKGIPiKqqqora2IZg9yEI+yLR8oh9oBqCcAhZVXh29UauGVyINxzEYtaOd9CgQWzbto3i4mLKy8s7InZdyIUaBiVy7cQqEGoOe9lURWVcv2Z6Jzcj+8MIgkDfvn0ZMGBAR0L7wRg8eDDBYJDy8nIqKioO2z+AyWRiyJAhR2z3W8JkEPj6xfzfbd9Hi4SEBBwOx29yHCkpKT/L/etw20Bn5PhQbXQ6XcfE6pfs+1BoaWnBYrH85qQYjhHjXw/myRB9K3nZmla0ZG/Z4dvLLdB4CSgO0A8gGB4DgEGYD/Ufa+WWPZ8ihxS2f+3v2OzbW18hY8q1xPXurKynqioLbruNdc89B0BuzIkcP+6vpLwwsOPhWfpdHTVWJ6tvbkDVy4CVaC4gmgs6+gnsb+LzaecSaipGCHoxBE3c/FUvAHZeZaH/617GbQiz5p+VtJjSOfO6iRyXYYGgm71Fu5m7sJFWl4zs2Q+qgKrC3OUVlNVq4umbbhrPnHsHYnXtwOto4+nPFlP56jPM7GdlnVtG8QcxifEE5RTErHjSJ2cwffxltOTGUfzoozR/9AlzL72Bq1a+xvQheQSdArq8IK6gnks/WcUfbPHYgZfnf8UWn4u4sgryPvwMgPzzr+Tycx4jLKSAIND2eAHfXT+KunWrkQBrcjZ9p1zAfo2jYoxSSR8cz4irz2Ln3CVsfmcBG16XQQWTPQrr7Wfxw9AmCnK7JoAkDxrEWe++yydnn836ue91vH/aK8+TPmoUoOk8Z8ydy9tTptBSshyAhMFDaB05CWmnD8FZxapGD0MnDKV86QZK5s8n/pZbAEgfE4c914rQvIFhb36Cy+EEYO0XG4kdcxqnfzSfUxtdyDsqCSNQHJVMgeoEd8TKKiMOMTcZQYqQIjV4QCZ7PL2mpHNXY2MkQrkRkEEaoEkS2l8LnclagiiQH6NnK9A0NJa13jYK3QGGtrj5oEpiy1ofp0frEVNDCIILrQDBULDfiEaK9VqES9BBKJKAZxiITRJI1Ak0hg2UJ44m1yiyvtkIyAywiJ0SCbVTBlBZF+SZd+o4dbyTATngcJu44qwEJAQGmGIwiCIuOYRTDkG4GMK11Hl0NHm2YYkr5sLTNXccq0XkhLExWEwiMIRri4r4/vbb2fv116x55hm2vfdeZOIA0/78Z6RIVBCdCdIKoXIVuGo0o3FUsCaDOVq7znod6PUQCnHB+cex8PhqhqfHI7RH3/wOraSlqANLVxswhDjAgiB4QacltumiL0e15aBGfYHgfwIhlA3GoRGJSU+arEP4F/cEwQ5o0XXt9S9LVhYEgXd0y/iDMoid9mYCUiuyqPWZoQjEqAJapPOXxRd31tWyvrICgIKkFIZnZKOTupL+5bWrKG4rY2TCMIbED+jWhzPQymcVX6MTJC7L/yMALSX11G2tQ5W1yVJvi47e56V3bFPY7uaxo32yAQP6D6CgoKBbNFUQBISkGI29y2i/u3ZEHCma/C5EQdN0WnQGVEVGECV0Oh3Dhg0jIyOD9evX43a72blz52GuSOthPuvEwIhjXXR0NKNGjSIuLu6w7QVBYMSIESQmJuLtSX5zEA52kPo9IAjCUcsZfk8MGzaM995778gNfwHGjh3LokWLumh9Fy5cyLhx4w67zX333UcwGOxYnVi4cCFpaWkdEouxY8fy9dddcx8WLlxIYWFhx0rJL9n3obB9+3aGDz9EsvWvjN//zv1fQsxd5BVo1btKSxsgsKl7pTjQHoRNV0K4HKR0SHqfYIM2CBqM5RDcov0BpWtH4G3+FmtSEvF9+7J/xQrmXnghM1eu7BiQl/zpTx2keFr2UwyKuxjr/fEIkRmrqqiUfF+L/YIAqj6iz1EElLCKqBdRwjKNn3xE05fzGHWFhw0ToggDpy7phTkgIQ3SM+baaLy7ZMI/BTh1cZi9KS2MTsznzTfX89Y/l/LT+gMj5FVdTjcrxcZb71/ItCk5HQa3K1/9DOegUfhUgY0embcagpwqa9ZBBksMUkw86bYm0oMWpNQcjv/Xe7xbU8e+H3/ko3Pu5opP3sWo2tHpw8Tq9VjDJooCbqboYinQm5G+XYjpiy+Qw2Hi+x5P/1P/SjiiXRSQMWXmM+qBD/hp9mmgquSeOgvJELH+U0BVvAiCSq9Jg4jL0dFSrh1b7nmjOeuZB6kyG/h4zbM0+LpnERecdRaTH3ywY6l99M2XM+Syq2mrAcc+TU8O4xh164usefpqAEZefQurDSJ19jQkZxW7dm3mjONHU750A9+/9zbfF/RGFATcXoXmuG/p/far2rkkZHD2qy8x8KxO6UOtYiTsEUmzKhS4tNm6qpPQDUhAjG4FakCxaMRJiXxvQlRXz2JB0N5TnRE/YwFtRO9qpdXYEmLJjiDiKBnFKLFF1PoYmKhyxWmxWBqaICDibjQRleQHuRzi7tU0v2oY9EO1/wMEd7CxbDjfbb+UkFBNeJAV4vU8tRRSav2sH2MAk8i6hQ4qPEFmXw6iEOQvb+zH5RXZsMNLKKxy+0WaTvLkSWmIYiz127WCNjojDCrUIxn0oBZAw4MQWK+dU+oy0PdMzOLy8rjgq68oWbCABbfeSvOePQCkjRxJ/3PP7drYEg9JA6BhO4QjSQMJ/UAMgxwhpbZ4cNShuKop9e/E7hxMUlIk8aY9WmxN6h7RFSI6bHlP5LUNVB+CsBPBHoaGbZquvp0YH4yIvljbNpoWXJRQi3xQOV8rJvqRiUGwoQ0REU/dQxTd8BFgN1X4D/bijSCsyPhSLczN3E9WYg6gYlENDJcVUlUBEDQdcw9+uCVt5SyoWsyZ2aeQYe1Zg5kbn4qvSmVYRiYDU9J7bPNm5Rusb9zIcZaR9I/P6va5bJB5uPwRfLKfmdFnUrerpsMhID4+nrBJZln5ehqXxSDpBAx6HT5fiAmnpFAlluFRvOzSlzBWriMznEW04RATjw49fIBOE3mNGNf6nQyLH4qsKkiCiDPUQqyx0wouMTGRE044gXnrv8KqWEgxH1AARGlF09VbQTz6pG+bzUZeXt4ho8QHQxTFY8UnfgO0J7Y5HI4uKw0lJSW43W7q6urw+XwdrhT9+/fvWU7TA2655RYmTZrEU089xRlnnMGXX37JDz/8wMqVKzvavPDCC8ybN4/Fi7XV1QsvvJBHHnmEyy+/nPvuu4/i4mKeeOIJHnzwwY5g27XXXssLL7zA7bffzqxZs1i9ejVvvPFGF7eJo9m32+2mpKQzAaq8vJyioiLi4uLIyur8ra5YsaJbst9vhWPE+NeEINB7+GPAozS1GHGWzMTeZy7oO6O7qCo03wmBtRrxSHwXpKTOUtBptyGXW1GqguimT2frl38FYOCFFzL2ttt4ZcgQqtetY+mDD3L8nDmseOIJVs6ZA8BxE/7CIO/F6KYa0Y/rzCat3+KEAheGXAWdpOPE6SeiGi387ZN6LklIxSuotNVsA3Uu4bf+xPbtN9NUa6aucSuvsA3RIyEUiqheFWVfGBXwt4S5NmURXq8mZxBFOGFsPAV5RhR3FEJ6IqgKCT4/1/6hL/HjsjQf2rAPr9PN+g++I3XO82wFXqgNUhdSyYgQY8Gs/eCFaDNqkwvV5UOyWzjv0095tXAoLSWVzLv5Ps772yvaDawEOW3gIN7fvY5Cnw+b2Uyyx0NLIEDSwMlMeuyziCWVTAI12NIkhD6pbMufRnHoZWJ+WkT83VeRG5Fsu1wBwk1a8oy/LZaTH89n0/vljLzYgmvS+diS4slVVAyiRIO/52Iuk++fhSpXE/b5mfzoc9RtBe9B+Th5J88i0OrEVbUXe96FzPBKvJDYB5u7FldbM+IoTe+sbtnBmr27UAwGokrKGPCV5tzQMHoSxf3+QfG6aO4e6GVAbzNfL3Py2meNDE+CByZr+9lSJ/DqNomnBtQTq7o7AoBd790eSKEQ00mM21UVByynh8Mqj79ai9MHsSUeXH1sXJtjhWIjgjfAjDEGnNs186k350nccg2AVyPCga0gh8CgleZtc8u88tEwFm5uN4d3o9okiNdT4pUpKfbBFDsoKttXtiKEVC45WSQrRcHR1sb6HdokccIwMxlJTgAk0YajUiPFCJA88AD9vmCAhNeg+Q5Ns3/gb/QQyDvpJK7bupV1L7xA8bffcuLf/tazVs6eo0WLXdWa5t4Uo8220AMhiMoCRx2qp5655V/yUdlcjk+bzC19LsXeGtFc21K699v+nQhRGsGVUjTbOXk/BLdrE20x8rvviRjjB0KEgR1CE3s59HL7PhoYJvQmQ4jRJCs9+BerqJRRx1YqCB9ErrtAhN6pmlRMVVVKqnZxZ8ZMDFQCjZGMwa6kOCiH+FfJR7xX+hmyKuMJe7lncPekOQCTXs8lhWO6vOd2u6mq6pygxzRbGR4cgK4ednt299jPVGEcjqCDbSu3aHmGOh2DBw8mNTuNmStuojqqnjVv9+dAs51nnrkKTCFe2f02zZUb+KZyISvr13JT/6s4IW1KD/dH+w3YHjrWdUSM63yt5Mfk4QkHiNabqfNWdyHGAHvdJdgzHISUZgakj8Gkj42s7mwCrCD1B/EoVgOO4b8KgwYNorCwkE8++YRrrrmm4/2rrrqK5cuXd7weNkyT15SXl3dMUARB4K233uLyyy/vse9x48bx0Ucfcf/99/PAAw/Qu3dvPv744y4exk1NTZSWlna8jomJYdGiRdxwww0UFhYSGxvL7bff3qWKcE5ODvPnz+e2227jxRdfJC0tjeeee66LF/HR7HvDhg1MnTq143X7Pi677LIOA4bq6mpWrVr1m0XVD8bv6mP8e+C39DGuqgviDypMGPUU9fUeNnwznxFDrWA9B81HK6yVafZ9C0iQ+B6YJ6OEoXyF1kf2KBXvWQ2ozQrcrPL8NbnIgQBXb9xI6vDh7PzsMz497zwQBIbOnEnRm28CMGnEwwxXrwYjRH2WiJimQ1VVmsMqG14sojW5BEHSLE+q4jJ4rjaII6Tyj0YLRgRWPLoK3dY/80PLNt7hj0d9zn1yrMw8K4Fzpw0kJiGTRPt2fMF4ah0a4UFWAC0yEh+zgxhLORs+/p5vH3qJqTtKeETtJACfOKuJDoaQhvZCjLUiVzQglzfSZs3AHYxBUUCUP+H9Uy8l7AuQPfVcciZpy3/OqjQcFXtwyrWkXXcd4dZW4koM5E2/FEEQkP0+cqeZkSQZIrZyAHVBhYqAwmibhCAIVHqquXLFrbwy8nJyoxNo2JuLtzlMWtoMDIYS/InzMelUIMjDW+eyu62Fj6a+1vWiKC0ga5nQfk82tdtSUMJaADAuRwsqtqO2IYi3TsDg14hdpU7mzegA1TqVB5Jr2Dx8Im2V9VRf+QQ1hnSGvn0zel8rUdOmMfCpf/HWJ34aW8IIAuSkGymLZJoP62fm/tNMeIMqD3zmweUJ8METbUgiVDZEEW0JEmUJIIoQlkVUaWjH8lcHOvyFxUh0sg3EbI2QAa991sjHC1qwmEVevj+LuAQDZklALqlDqWzWJjZtPmQVzvtE4o7LfEwpDEK4HhpvBOt5qHF/ZfkGFy98UI/TpSCgcOokA3nZ8ewwCiyM0pERVBjiV/g2WkdiWOVipzaBGpZfQ3qii937Eyipiic1Qc/wAhlB3gXo8bmHU1OknUpCH4jpOZj4m6DYWcKqsm8YkXU8AxMifsKqX3sGCFYoWwRhP3fXfMdqbyVGQeKVzLPIM8ShGqMRsiaCeIgonhrWiLFgh6ZZ4JsP0bdC27Pad5P0MloUtrBr1FlpoEEpZYOk4hG0mU4GCSTS+RxUUSmlDlfEgCxdjWZY2ItZSAJdbkc7Fz42UkwjWhQ8DhvZ9FzC+MPSudT5GhibNJKvir+h1lnNO5NeINeWqbmSHJRwt8Oxmye3PkeFu9Oqc4C9L6+M/9tRXXuv18vChQsJBn+5XVpSUhKFhYXYbDb+vv1l5u77lmRzIhuvyqei3AlASkoUtbUPdGyztWUHT297seO4RyeO4NHh92LRHaSJDG0EwqAbBIJFW0VRGni79EdGpfyBBKmKJJONFY2tTEzrGiFbUPkVJ6UcqD2P0e4DZR8ggm7EkbXjvzFag21cufIWekf14s8j7kd3qPv4F+B/1ccYYP78+dx5551s3779qF0XKioqyM/PZ+fOneTn/z5a6v8E7rrrLlpbW3n11Vd/cR//Z3yM/5ewq8zHvX+vwmIW6ZWTQH29h5L9uYwYtEEbsA5G3BxNl0xnxTvJAMpSn0aKge2PfogcCJDYvz8pkZli/3PPZdhVV7H59dc7SPHo9Ns1UmwVsDwQg5imoymk8GR1gG1tQc7tVUNMEPZHpfJdKJH9lRp5yjAKuFs8GONsjL5tOLrwuzx0we0QhKGmKiYlB5BVBVEvIOpEVFVF9qtIkaSuvKFJ3DhnPHJI5uO7/oE1VuXMh2di0jvQG90EvVY6jOZVMOu1pcnSFZuwpeYwJCEXa7MXjwKxokpUqD1irBG0sMFCAzkEPZ0WRemF+fzhn39i7qUPsm/pZ+xbetB1lSRSL7kcXUwMMZOHoQQVXJUNDL8qNTL2dn1IpxhEUgydD6F3ij8iWm8gNzoBWVWoczixyvlUV3+NTrcP6gcSnVJDTEo1t+ecx9YdMVSub7flB73ZTVJ+KaIIroZkGvZqJNIYBUkFXa346ptD3PL3fbi9Co9fkUmCbCYzLPGnFjPvRgVBspN/0jg2vjYP3fK1DGzZid7XSurw4Vz+1VcYrFbG9Zd5+eMGvv+pjbKqAEaDwFXnJHLGVDuiKBADvFSgULSzBEmEbSUSt/1NAszodSZ6pck4XSL+YAVTRkZz/Jho+vc2RSYOZjqW0jt0yNpgtHarm48XaCHwOy9LIT25c4VCiI+CymbUNo1ciTFm+uXreeIt+HyxGb2kg9BfQYzGI++jNHI/ZiVUcOcfXqL/2C9AEOjjk1lY5qfNLGJKMUBLmLGJeqb3sdFSDibZB7jItstEu+wQgraqOmJSwd9m7TCEsCVDdBpsaCpic/M2ruhzIZLw6w3WB8MRcHLvxsdp8DdRFGri7wmPRy6MqSPRTLYmIrVWMsHai6l55xDTXEqeIQ6n7OOVph1cmTKQRFNCzztod28AMAzCH/iJHXoRT+J9WjReai+UsY0D73dZ8NCk08KdZgwMpzdpPfgG5JLKLirZTRXVQhsNOok4vEBnGfBG2lBQkBAZSDb5pPVYkKLctY+FuxcgCRKP59/OFv1GaqlmVf16cqN6RXTTnXh9z7v8q+QTVFRiDXbO7nUqb+x9n33uqqPKZlcUhTVr1hAMBomKiupIAlpQtRgFlampEzBLPQ+K1Z5atjh20Gp0YbVF8cOeVciqwsp6LfHg3sG3MLv3+g5ifHAp6MFxA3hz4j/4qGwebxd/xNrGjdy/8QmeGvkgevHASacB7TcVBMFCWPagE6DO30ovWyatXi2S3xrsbvnW5KsBkvHJQYyiHpFWupaB/n1JMUCZq4J6XyMi4q9Kiv/Xccopp1BcXEx1dTWZmUeq8KVhwYIFXH311f/TpBi0ieqdd975H9vfMWL8KyEzxUBstERVfQhXSIsQlDbPhKhRWuRN0AM67V/DcLB0RgI6SkFbVYKvaJoKIVpg114tkW/wHy/pMiCc9Oyz7F+6kubS3YxIupYxSXcgjTWw/9J6ZHMjjcXRvOWzUCOamVy3g5igF5fexOL0QQSDGlWdkaDn0kQ9jmAYdwMYokys3VJNWTAJCZmp/m+I2afpEaNTE5g++0oc++vY/cMaqrbsRRAEzn/u7wiCwNp/fUXJ9/NAEJh+67mY7VFE2b4jZlgvVNmGf72AgIxB70ZVVMrXbiNj4h9p2iFwc4yJvxn8XGkXEeq0qlCqQY+rFpqKrZEKUDJvB14iJdbKdYYBDPrjiajkUr7sR0S1ESQVxWNGiomn34ipBFNS2O6uos69A4NLZNgVuUeVTF/lqWFR9XLOyhoBgIKVxL5lyMVeAoEhBIODIQjOykSikmqIjpIZN9JJa00VzqpUBEkmtf9eRFHB0xJDw95sECA2W/s7cMySZZUnXq3B7dUmQU98WM0Ls7PYUCExJKDjQpeBgGIjZfpYNr42j+QSreKULTWVP0ZIMYDNInHXzFQmjohi7VYPZx8fS2ZKV+2ZQScwqr92X+2vi2HSiM6JRrzJQNAFHr+CqwbmzW1jgdlNvd9PQFa59FQdI/ppExaXV+T+lxsBgfJqjcyeMc3OpMKuS7dCjAV0IkQcHqT4KB6+Po47nq5kV0UAsAHt2eoBdBJccHwdF4y4GoO1sCN6mG0UEYA2GVa5NEI3wChRu1UrVBf2WYlJAZ3Bo+W5AVGJ2o/J67CihLWJSGJfkNUwj27+K46gk/72voxPHnXkG+IXIKyEeXDTkx0Sm83N23CF3EQdVFGtWPHRD5hkyyHGkoXg9aKg8nDdUjb6qljWvJkbCq7ktMwTD0kGVVT2mYdQZPs7IenA/tt1LwdZI0a6SQmZkVsCLHMvwxls5azsU0m1dEYh28luBvFsoASH4Ka+h6IYSdgpJA9rD9rgdsyv1OwGxyeNItZoZ1zyKNY0bmBVw3ouzjuvS9utLTt4p+RjAE5Kn8aN/a/CJJl4a++HuMMemgMOEkyHTxDbvn07TU1N6PV6Jk6ciM1mwxVyc0ejpvefPepOjJKhx22rPDX8fdnrWv25g8wxzsg6icKEofTuXcoPEQfFg0tBA+hFPZfknc/w+CHctvZPrG/azONFz/DgsDs7J2OCQRsTIhKKsOJDJ4FfVrHoLLQJGon2htu69K2oCr6ITn1VQzFvla3grfF/Qo8DUI5o0fafQmmbJgfqHd3r9z2Q/4O4JZJkfbS49tprj9zofwB33XXXf3R/x4jxrwSbReKRG9K56Yn9+FWNeJSUhSD2/iNu206MdT4FeWcIDBB6zE31xNWAQH79aZT6wqQZJEyA+oXK+XFf0CztITVpJJbbY2ga7WT7ys6IzulASNKhl8OoCpi3JPL36VE4ZJVso0haJEqaVKAnOl1LCHvs9rkATB6SwdmWvyCPlNi9vIYpN2TTNyJZGH/V2QTaZDwVIeL6mAi7FGzGkZzxQi6ullqqthWTP3E46575AEtuGuNuvxBjRixqo/ZAry+pIuDykHvcNAByWiWeN1gw+2Tq6QWCgLpRiFQBFDAKXuLVKhxqMdme3A5yOfjiCxh8yUWovu0IOg/hEhNSVj/C60qQVYWSsAm/3499CojS0WUlv1vyCQoKp6WPBEAvJZIan4vqHYjPNwpVPwrsdwJGGhvz8Rs3kW23EZtZgz2jHlXVIYohFNkMujxSBgsYLKDvwV3mX183s6PUj8Uskp6op3h/gKffrkOckYS5VqBPSMK7VcI4cCSiXocSCqMzm7ngq6+ITu+uCWiNW8/mrM85O2o2cNDnqov2MuGnTsnl1KkSchiaS8BV2/O1qGkN8MyiSpZvEBgRcZXasFNiR0mnQ0rfXiauOa87ORBEASHOhtqgfedCrBWrWeIf92axcaeXUNAFLRGtWtwL5OdEkab7AFwhMHQ6BhhFgTSDQHVQpTak2c3l1UiEvNrqSnSG9jvTm4Ik9w+hqnosMdqPyRRrJTlak62IEvxUtwFH0AnAfnfVb0aMX9r9FkUt27HozETpbdT7GllVv57pGVO7tFvi3EkGduySCZo0zauYNJhb0oYyZ+s/2OXcy1+2Pc/imh+5e/BNpFm6ao49+NlICfUGHWDDHiwj3/UdgmEkWE8GxalF98VEUFVkuRYJH4ZwiEuWPkZACXf0Veut57ERs7udix0b0xhCHY6IMlnD8tpV7GzaxR35s7AeZkkyrIRZUK0l256SeQIA45JG8gyaXMIZbMVu6HQ4aSfFp2We2EVPnGpJptpbyz535WGJcW1tLbsj1ovtMgjQIvgAVp3lkKQYIMOaxt9HP85+d9fkYZPOxHGpkwDo3bszwt63b/d7vx0DYvvy+Ij7uGf9oyypXUGU3sYdA6/XJjmCIaLzD4KqohdlQEAfSZozSlYgSEjpWma6wr2fGL22MuOVZfZ5GlnaUMmJaRMjhT0OnXT3fdVS3in5iBsLrmJc8shDtvs1UOrSivf0jur1m+7nGI7ht8IxYvwrIjvNyOyrUpm1Q1tuXrfx6Dw524mxuFEjHfrpZrYs12QSmVHjMa2O5803XHiG6rnnTT/KlhBGosk6bjzmB+yIqRJ7vtN8gh0GK2FRR0KgDX0kmc2zVM/Y6Zn0s3Rf1hJEMNth0ZK97C5qRJDgnlnHMzI6B90FFiqmLqL3GC2yUbFeIK2/ijFawjg40ldLPgNmDEXKr0eQwLdPBrmJ9MF9+OzWv7Dpra+wJSQx5epzyB0/kD2LfgJg0AVTkYzQsBvkgIA/qAN0WrDLDQiaHtfkrEfXEqKvmMFks0aaVEVEaGfIejOoHgSdgry7GgCd3Ua/jH4UFRWxfft26uvbvwc1kpRk4MBqaSaTidjseL6vXkKUzkRvW2TwE2NBMCHoM7EIKyFqIMRCkzPMlU80EhTiGHHBXO4fcSpWnYwgyIAe0dgXq+nQP62i3V4++FZzg7jtkmQKcs1c80gFu8r8FFQH+DBG5f4WM7EYaHTF0vfGK2hTLWSMHUtFMEjFqlWA5hHZ7mf6bukn7HNX8uW+77ix/1WEQiF2796Ny+WKVMQKasvswlrkIPhdkQJxQHR0DJkJfZFEHbKi4nWopMUYmXN+DlXWfRDRm6alxPHw9dq10ekEhhdYMByiTK0YH4Xc0AY6ESFamxkYDSLjhtpAtUJVkbYEnNIEhnioj0zq9AO79JNjFKmOVOM6JaBDbtNkPMkDwGzXQcgE+LElerSktIgThCXOyoEr+/OrOgulVHqqD/nd/DtYVL2MT8u1yP6fhtzO3tYS3in5mBX1q7sR49WNm8i35nFCVJ72RkwW2HuRIwi8PO5pPi3/ktf2vMfG5i1c9uMN3Dv4Fo5Lm4SKSgm1bKMCGQURkYGtc8lv/QgRBXRjgcTOhEkhkXC4DB0Bwgr8aes8dKKBXlG9SDDG8VPDOtY0bsAv+zH1IDEQEUijk4w6Ak7e2vw2YTVMPFHcNejGQ16PVQ3rcAZbiTPGMjpRW4VJNieSF51DSVs5axo2clKGNkHe5dzLusZNSILIJXnnd+kn25bRQYxHJPTsi+v1elm3bh0AvXv37rIU3T4hij2AhB8KIxKGHHIfWt+dxPhgKcXBGJU4nAeG3sHDm//Cl/u/w26I4aq+FwPtCZJBIIwkaP7OMQatP6s+BmhELwpdVhu2tuwkyaSdQ7xJmygtqVnBielTD2u/92n5lzy3U8uD+Kziq/8AMa4A0KQyx3AM/wdxjBj/yhg71Mb5p2fy0DIoKWlmZ6mP/r0Pb0jdToxZog3qhvMtbD1bq4Y26LyLoAiues+P+r4fJQhYBMy3RaM/y4wQeahW+JqxAkVRvYl9xYlSFCb/ggQqVtUTrpDI/cvhDbXvvX8+AHlT7JxwbSICbSDZGD3ThM4QoKVK4qs/qURnmrlswSDU2hpUj4o4rQ/Kzj0IEqiKDnNqb6hqIn/aWEyxdhylVTjLa0j5h+ZjWLpyM6nDhxOVmgpA5kg3SrAO2SkQqgbVYEdMjccYBXoLlLtbyUDPFGkIvYxJgL8LqRXaoy8GtUPTKiREkZtmZ/fu3fj9/i7Z6YeCXLaXXH0WY3L6RFbyTZ2Z8qbJ4C4Fo5b5vnhNG/6gClhY+80Y5qc2cF7OWM2TWkrvtB/rAa2uMHNer0VV4eQJMUwZqQ1ot1+WwmOv1LBrsQPOS2RF0M94nUBrQyOMOY5ooA1oO+BcqqqqqKqqotegXPa5tUIS6xo30djYyLp16/B4DnYm8ALdTeSdTVU4g5UdXqbONh91RSJ62YSuFYrb6km3xLIhvIqLhl94yHNTVAUxMmEREqMRHB5Eu7W7FEAQQJ8Nwa18Uvwsbv14rjDv0D47IGIM0MskstIlkxMSOb0tUoGstzaZ0/o6sAJe+8RP3+UecQScrG5Y3/H6tyDGxa1lPLX1eQAuzZvBpJSxJJsTeafkY9Y2biQgBwh6gzQ3N9MWdGF06NjodZEfkjW9hyEa9u3r6G+MOJw+uTl8U7mI/e4q5m38mkR/PFViC+7IRCUKMzkkYGzTsz8UsYX0Z4KjBWQ34EHBp+lQgW+rt3JGwgyuS+qMPocbgzj9bSzbtoJ+9iPrFNc0bqB3ULNQKi4rZpOhiDijvce2q8vW0jeUy7i4kVTtr+x4f7JuDFJIYGfJLvqFtYS+r8u/o28ol8Fx/Qk2+KmgoqN9n1AOzaFmGqrqu7x/IMrKyggEAtjtdoYOHdrlM0dAO3/7IY7z56ArMT50xLgd09Im0hpy8cz2l3in5CNSzEmcltFu4RnokFM0BtrIitLIvEE0gwJ2vYV97koGxhYAmtTk3EzNPaV3tObysbZxU49SHdAcQN4s/oC3izvts7a07CAgBzBKh35G/TtQVIVy1zEpxTH838YxYvwb4IbLcnnoDgh4vdz/jwqumZFGWpKe9CRNh3wgUZCD2h+ArjaMNERPvWcLzXv2oDObCT1yPhsfkBmxOwQh2Npfh/0hO4PyOgf+j6vbsIY9qMDELTL2RAMlQdj7ThMgkTU5EWOMHllReOGnpVj0Bq4cPQExchw//ljGptU1CBJcd+sIBCUyQAt2ckdqg/DGjxRAJGNcEoItGSFfI9qqN4AQFTkByQ76WEDAYBC5eed69v00D6PRiMUejRxSGHPTfWSfOr3j2J2BrcQbJfRJYEoCVW5B0LWAmATEsFPeRwZ59JUywKBZwzlCXuI6Tj9i7WZUOvoUE6MRdDqmTJlyQLSYSGUoPyCA2OmPWFxWgrvVxUmBSSQ0RRHIkjEaD4ie2e8D2x/BoEUzF6/p1P6JTXms+LGC83onasvWB8AfUKhv7lqd7/XPG2l2hslKMXDtHxO4Z8Oj7Gkt5uq+l3LKxMHMX9EKb9exzuLEPqgaWQ0gCpCfF4PF1ukK4Pf72bt3L3V1ddQ11pOv60WptJ/UlgSWLtUyEg2ihazkVKKSHMgBPY6qTh9YcwxYEkFVFfbs2UNbWxuLFy8mLieBpxpfJEaN517THDLFXJp36nkk8Aj7A/UMiBvM0PiuUd2gHOLPW56hqGU7cwrvp7+9L4Ikois4jA2ErhcEt9Lg3sCPraVc0a8N0IO+KznLMYrYFLim1YiEgDURYjIOaNClAp7U+d4B+L56KbIqY9NZcYc9VHoOXxXs5yKsyDy4aQ4BJcDoxBFc0UebPPSJ7k2SKZEmXxNLNi7Dva+to2TqiUyAIKxzhQAnlG7ose9+9KIfvQDYvWFHl89cONlKLTAs8gcQAooOaNVpJ5hIOlV1+6mi0+1hFJolYNteB+tYd8RzFduPPYKSLXsP2TaHdHJIh0pYV9nZtwW91kcDrGvQ3u9FKr1IhTpYV9f1OKIwae1rYF3NoY9Rp9MxduzYbp68jqBGjOMM9iOe35GQl5eAzWZAr5fIzT283rkdZ2WfQkvAwdvFH/Ju6SecmjFGW8xQg7R7GNf5Wsm2aQQYQRuW7YaDiLFjJzfka99zsiWDHFsW5e79rKhbwymZx3fZp6IqPLfzNT6v0AowXNnnIr7e/z0N/ia2tOxgVOJvUyihxluHXw5gEA2kW3r2nT6GY/hvxzFi/BsgPt5KbKwZh8NHTZWTp9/qXG42GQVGDbRyz5WpGA0iAUcI0CO5wwhBFcMfrWx9V4sW9zvrLD4OmWGWl/E+B9UeK4/kRBMvh3k1rCdGJ7DZI7OiopYpgKfVyJRBCeTenkz54nqWPbADV7WP/udrTGLd/grm79KWrMOKwrVjJyEIAg89vBCA9PFWZozPo2MwdVdiMATxtcHeZZGEqMldyZ/a6kOM1Za6BdGuCTpNdvA7MJuN9PvDFHC4wOFGCNvoM2wouqSIrZOqYtNpRMHfqmK0Cgg6BdQWkJ0gjOAnbxEnoi03CwatbYmrilHt3CcSGRQskWtsM3X4IEdHR3da+qgKhB1oXrKALqdjAPrSt5Babw2jQoNpqnWxcLGXkYVWUtqf66KlgxSXVfopr/LTL8NJv4JmqsqtUG9g6Y+bSU4w0qtXLywWCz9ucPHse/W0ubv7u+p1An+6JpXFDT90RDKf3PocQ3sPI7PkQnJiK+mX0YKsgkmKZsIEG3FxetCla/ZOEWRnZ7N27VocDgcnyZPwCD6sqrY6EW/qRaZ1GL2G7MFgjqK1LotoJRVR0oil+YA8nV69erFx40aqqqpoLmvkNHEqDpOLMnEFKd4cVEVgJtfhUdxUr3LgNmxFFETirelYDHZqvE1MDJ3NRM6mcZOOClsYnXiER0v4IVCuY3JYR6FeoqoqAIIZGrpqQDMVift9ZuIUEcWkktRP6JpI2X49VC89EWNVVfkuIqO4qPe5/HPPOzQHWvCGvVh0Fn4NFLVso8pbS7Q+igeHaklWNTSzV6jm7EEzYFMbrgqNnElxRoJimLAqYxD1B7kV9IywGu5ISDSgIwYLIgdIWJQmCEZIs2kCIEUmCpqUqtrrIEof32PRCXfIw87WvUiCyPC4wYd1fehoi0CfmDx2tRYjAAPs/bpZktV466jy1hKls1Jg79Otr83N2wipYfrF5NHoa6I56CTeYKd3dE73/YY97HTuxSDoGBo/qMdjkySJPn36EBXV/RwdAW2VJNZ4ZCnFkWC1Gliz5kYkScRgOPrh88Lcc/i4bB413jp2t+6nwAYQJCi7MQB1PidjUtsn69o9EWOwsN6hRdrrfQ20+FuIN7afn4FpaRN5Y+/7LKld0YUYhxWZJ7c+y/fV2gT51gHXcE6v06nzNvBt1SLWNW76zYhxaVsFAL1smcccKY7h/yyOEePfCHl5CaxfX8ngXjL2dAs1jSEamkP4Ayo/bnRjMTdw5+UpBOr9gB695EdIFGlL349v33am3HQhwWkXsN2rcLXkRRQhI8ZLtlGgIqTy99oAN6YYeLzSz3CPRmTV9QqJp2pEMOe4ZDLHWwh76jDFaUT0ix1FHcf3xfYiEqw2UtriWLa0TPM4PieF1Cg6C0A4tSXn0tUGjBbwyTKZE7rq6lRPG2KCEiniFCGh5littK3fAVYr+CLHF7Cg+jyooTCCXgd4MUo63CE//q0mJNGKrjAFwVgByMiqm42t26nSTSFDTABjhBi3VRFvqdCW6tqXzE0qWI1IvQ6xvKm6DjgxtOV3QUuO+rZqEWFDmHOHnIlzdw0ud4AfV+4hL09m8ODBXUqbLlldz6mFpaTFaTKFpFzt38a6RhrrYPeePVS15vLVSi3ibDYK6HSdZEMnCVxxdiJxSX5eXvYWoGXsb2jaQn1LNScOXEe0YEYF+vbpS4IyEJOwF2hDVRwIUieZi46OZsq0KTz0zRMMDvTFqprRCUayowpJtKeT3N+DwewBBGIyEog5hAOQ0Whk7Nix7N+/n5XrVpKiJJLiTUT1BqilezEEj0/L2Kty7iLNMoAUSz8SpNSOz2UPhyv3EEEqkIoFsACBQORt/8HtBOIQCAgqWQO0SsldP24nwZFKYl3egz2tJZS59mEQDZyRfTIfl3+BM9hKpaeGvjF5RzzKo8GSGs2EfErqeIwGE2vYzX6lEfa40e9waVpfgwDDYpCzzOgEoePBe+TrpEmlAyE/y3f8wOWpZ3dPHJQboPpO0GVB2oMAbGj4jsLYZD7Zt5Z0ayGTU3suwaqoCq8v/oimQAtjCsYeVn/6xJZn+S7wA6dkHM9pQ05l/aanWFK7guYYF3MKO/18l9Ss4J9F7yObFGYPvpXJmZO79fXTls18V/UDjTGtrAlsQDWpvDXxefJ6IsYhD08ufAmAK8fNxKbvodT1YdAhpfgVIsYAAwYcovjKYWDWmZicMo4F1Uv4rmo5Bf0KAZVAuAWDDhxBPzGGdl9e7e6I0ZupiEiktrbsJMHUTooFQMe01Em8sfd9NjQV0RpsI8YQTVgJ81jR31hSuwJJELlvyG2aBhlN89xOjI8WsirjDwew6o9uElkW0Rf3NME5hmP4v4JjxPg3Ql5ePOvXV5KfGuauOzRGEgwpbNjh5eEXq1mwspUBeWZGGrXIj84cQDpHYNFdN3L+UzcgGfR8KvWBAEwJa2xBUFQeipK5qkViRZvMbq8fZ1gl2x2J8NYYsaV2SgB0un3ooj2gmNnXZqaouhJREDhr0DA+37qJ19euxPWxtv/0cRZOHjUAod0TMxgGnxsAvTWFy57VU7I5gCmma4RLjRj8I5vAEPnMHAeOMvC1gJoFfk1OoOjsoKqoTS6E1Fh8oSbMAuxqrWGoMFjjraZYoBHUNlp8VXjDPkqlWjJIQLBKQIiWoJt5+77lzkE30CGlEMLoR+Ye2sez/bw6EEBRLby651+E1TDD4gYxNnck4dQitu6opaTMRUlJCfX19YwePZrY2FjKKyowyxuJjlMQBInYdDtLalajqxqOGjKRm+rDiocUyx6mDbKTkjmQS/6Qil7XPQr356JncIc95Efn8uiw2WzYsoHK0v0IgkCb4GZ/Yh1nDjoDISDhKE/AEtuG7G9EMKQh6Tv729tWSqPBT7qpECEUJMGcy0/qUi4tTEEvNEYSsGIjdoGHhiAIRKfYec/0JQPDfTgn8/SODH5FATkArpCbrY7tqCrkmjIJurzUeLezO7CO/n2HkWJP4fmdrxOQg0xNndDhRNATtjd8wUA+xRHWUxM0MMDigahLwHxSt7YBRUWygc3cQzRT0KElMwWgvSTxAcS4PeluUspYovQ2Mq3pOIOtVP1KxDishPmxbjUAI7NHs4CNBFx+WOeAiIym0eJkU9xeroi9CMkt8sKuNzDrTDw87O4OTfbhICAwt+xLdldv57OArjsxlpIgdUmHx/Se1hLu2vAyCcYoLsu/7JCkGEAURCaljGXuvm9ZXvfTIYmxO+Rhaa02ATgtU5NCXdnnIpbV/sTK+rXscOxmQGw/FlUv4/GiZ1BQOCl9Wrekw3aMSxrJd1WdKyYTksf0SIoBbHorCcY4mgIt7HNXMiC236EvVg/oSL77FSLG/w6mZ0xjQfUSfqhdwW39xiIQwiAGAAH5wKE4spIVE5FSgEaMk03txNkIgkCWLZ386FyK28pYXreKkzOO45HNT7O8bhU6Qccjw+9hUsrYjm5HJAxBQKDcvZ8GXxNJ5sMnDwLcv3EO6xs388jwe47KyaU98e6YI8Ux/F/GMWL8GyEvT0vSKC1t7njPoNey8i8/M4E35zXx/Pv1vHZOCkggEeanDU8w5OQRSBGCOT5cwVdyInEHVHBKd3uZmRTH6w0hGsMqmcE2DHIQxQ/26NjOpVDF3VkWVm3jqx2aFnBsdi5Xj5mIqqq8t3Q9q5dqGtzs420cl5cF1AICRBLZVGsSqTkmQCZniBHVF+yQKqhhGdESCfVJ9s6TN0e0d4E28EY+1+kQ4xJQ2hpRGtoQU2MJhJsw62G/s4WhQECU0eskkLUqa76wRvi3mmuYYhyFYNO8eJsCblY1buHafpdj01m040VF01ceIqlEaSfGEiAjKz6e2vEuCyPLjTP7XAiqik4XYviQONLS+7Nu/RZcLheLFy8mPj5e80eVoLHNyoXnTEQxyzzi+DtSfC3GFTezZq/K8Nx6huXWk5fqxKzfyP59/btEnEGzXSrbV05fcpgZdwHLlizF6XQiIKBPNDLPP482jwvvxgBPjLgfkz0OJVyBzhCgbpeLqLRorAmaxV5zscC9Jq0kuBSt8ozrUTaH1jPOnUOBVZvYHKx9PhS2OXbgFr3Ux7UwpnB0j22qi2t4be+7iLJInjGbKYHRRMsWaveUENvfwAlJhXy+7xsW7PuKaFFgUv54zObuyadzi39gdNpSzKqAKazDqg/hj52FqYdgoLWHwhEHIiSY2S54aRIVtHtBkxUoqoolK4ULMmeSbkllEZsZN+x4BgZH02gMs4jNR7wmsqrgDDjRiwaiDd0TnDyyl1NGn4NeMtBg9cNeD2xzgayi1+sZOnQoHzjnsbdmNxurNmDTWdjXWMbU1AmkC0cmJu04O/MUPi6Zy4amIspcFd0z/vUaqQwpIZ7Y8ixhVaEgdhCnZZ3YvbODMCV1PHP3fcvK+rWElZ5lMItrfsQvB8i2ZTIwQkyzbBmcnHEc31Yt4tU9/+LkjOOYs+UfKCicmnECdw2+8ZCFVEYmDEMn6DSZCHBZ3ozDHmO2LZOmQAsVv4AYO9s1xsbf1+d3WPygDoLvCgWJ1gsYxUhhIPHAG197/pslA45AC76wn62OneTbIsT+gMTSaakTKW4rY2H1MlY3bGBl/Rr0oo7Hht/XjcjGGKLpZ89nl3Mv65s2cWrm4e+NsBJmbeMGQkqYBzY9wZOFDx5RglHaFrFqO5Z497PR3NxMQUEB69at6yj3/N+MF154gYULF/LVV1/93ofyq+P3L5PzP4r27OWSkuZun/3x5Dgm9rFydYkRQtpXULNpGTVFS+l/4jgURcWt6kgT/Nyli2TQRx6gSouL8xP0jLZJ6AWYIWj6uWCpxOBp0SiOCBlWGjr2pypulpfuAeAPAzUrolljJiJs0Rwd4vsbyc2Pp1dsJKqoWsGlEeOwGINZ0BZ8JRGatnYa36ptXgR7pFqd7oBEFJ1Js5QAaIkkOpn1iMlaxENtcaP6gxhEjfC3tGmEt16NOCZEIn4mUdtvVEIiusJcBEl7rRct+GQ/C6qWRLSX7cd9iBKwahDNkQEQNTKyqWkd31X9gCSI/GnIbQyLH4RGrLUkvpSUTKZPn05GRgaqqtLU1ISqCqwrTiFkHE5sbDSxxhh0gg45bh8XnW1GrxNJzejLpElTsdls+Hw+Nm7cyNq1a7v81e+oZXpgIicGJlK9oxKn04nBYGDcuHGcNfUMnhj9J0ySkbWNG3lw0xwsqQpKpEKZNa6Rum1QvwOq1kO6p692DaMryRopEB2vXYt9rl1oC/V6rWzsUWBLi0YoB8cNOGSbi/LOZXBsfxRBYa+unNjhiSQlJSHLMtu2bcO9t5XpgYlMD0ykdXcL3y34jpaWrhW8qj21rGouxyuLiIJKgl6LrG53//zHUS0tfC+1UKyGcTiCOBwBHA4HjhYHrQ4nceEYEuRYAi4/jhYHBp+OBDkW0QuOFscR/9ocrYheAdkd6vHzoCtAghxLjM8Cy5qhqA1kleTkZKZPn05OTg4TU7Wo3cq6NayNLGOPSvh5Gs8US1JH9O/T8kMPRO8Uf0SZqwK7IYbbBlx3VH0PjhuA3RBDW8hFUcv2Htt8U6nlIRxccOTy/AvQizo2NW/lz1v+joLCGVkncffgmw5bXdCqt0R+c1rp5CM5YmTbtFW39gjqz0FLxMfYfhR2bb8lJEHihPQpAOzzdLXyjNIfWIFQpN1rMFpvZodzN+WufSR1RIwPIMZpEwHY0rKdlfVrMIh65ox44JDR3fb7bl3jkSeFFe79hCJ+1yElzOwNj7Oxacsh2/vCfqq9dcCxiPEvwZw5czj99NM7SPGWLVu44IILyMzMxGw2U1BQwD/+8Y9f1Pfnn39O//79MRqN9O/fn3nz5h22vd/v5/LLL2fQoEHodDrOPPPMbm1mzZrF+vXrWbly5S86pv9mHIsY/0bIy9MIWE/EWP4xwK2L9NAi0WqQCLQ2s+ipW7nwn/cA8PWeeGr7xHGtVMJAoQqZDMT0eJSqZvAGEf0h/pxlxK3Ahh8bcAFRPjO9eoO8vRJhXG8EtX2/AoKgkhdnwuGPYkB9mHDLfgI5yWxfpEVkM6dYmZbXF6G97K87rOk19RI+VwAzetbXCIxMU4lyu3E3+7DFm1F9DsQoUGUBQXdQNM0cp5Una/eiMxsQzCpCrBXV4UGpa8CSLhJWFFIVLTmwNFRDcsiDLdJXgtGEWdIzwN4eIdII1MjEUSyoWc9nFV8xNqmQdKMhQn4PRYzbo8UWAooeIyAJIQyinoeH3cPElDGRdu1CVwMIYof2trKyksrKal79ykx1s5nLz9cGWFEQSTTFU+urZ+goFxed2B8pMoFJSjyRnTt34nB0tUer9dZT5alBL+oYGFuATtRhsVgYOHBgR2R1SNxAnix8kLvXP8JPDet4ZPPTPDz0elAasSW20FiWjbtB++m2KE28FXyOh8bchKjTdITL61Yhy04gLVIm9ugKnGxt2RnZ/6GJsSRIPDTsbl7c9Qbjk0dxYvpU1N4qJSUl1NRokyBVVdnTWoIQBHsommXLljFhwgSSIkmXWpRewKnYsUgaaa4OGNjgLaMwedJRHWuQMEWUsY8G1BofwoZW1IBy5A1/Y0iSxJAhQ+jdu3cHgRyVOAyjaKTWV0+trz7y3s9Pfjov5wyW1f3EwuqlXN33sm7SgN3OYt4r/RSA2wded9TSAUmQmJg8hq8rv2dZ7U8UJgzt8nlxaxm7W4vRCTqmp0/r8lmKJYkzsk7ms4j7wdnZp3LrgGuPWLoZNCmGUTJwXb+ZR2zb698gxu0FPmJ/JY3xv4Pp6dP4sGwuu1r3MciuaZUVVSXpQAcHQdMQQwi7wcK3lYtQUcmNirQ5wA4yzZJCQUw+u1qLMYpGnhz5QLfv70CMShzOOyUfsb5pM7IqH3bysqe1FIBBsf2x6a2sbljPvRse5a+jHmFI3MBu7cvd+1BRiTPaif0VrPH+f4LP5+ONN95g/vz5He9t3LiRxMRE3nvvPTIzM1m1ahVXX301kiRx442H9g8/GKtXr2bGjBk89thjnHXWWcybN4/zzz+flStXMnp0zyuDsixjNpu5+eab+fzzz3tsYzQaufDCC3n++eeZMGFCj23+r+JYxPg3QruUorLSSSCgzbrVsIr3ESfeOxzQohDuBbIgseavV5E3cQCp/XPxBQXet+XztZpOq6xDFIMIZjdicgxCtBaFVVrcCIKASQnT1KSR2z7ZkWXCsIzqqdGqNziDqJUOqGzivrw4/jYgFp1hN2J4Lx+8+AMOh4/sXrG8cMe5XDi0UJMbuP3g0Gb9RJuxxYQJhMGbmcy2JhFJhD0rqiK2U5GSsyFLd/JljjvotQFUD2KGdl1Uj0aISt319DX0AqBGbWJDUxEIBhRVhyiI9IlOZUBs30g1Ci1iPD55AtH6KKq9tVy8/Dr2tkUGS7WrNVoHFI3wh7Dx951vA5BhiePpkY90kmKgI/NL6NRpC4JAVlYWQf0AqpvNpCToGZDXKQ1INmsyhQZfUwcpBs06avDgwUyePLnjr8/IfrzOx3xp/oG+o/pz3NTjmDx5MiNHjuwmNxiRMIQnCv+EXtSxvG4Vj299FRUTgqiQMbwFYzS4Y+q4338DbZbGjuMYmaDZOaWbI0uzYjRHA2/Yy97IQHi4iDFAkjmBR4bf05HUIwgC+fn5Hec5ZcoUzp1+Dt/bV1Il1hEOh/nxxx+pqalBVdWObHlR37ujz2K/hS3NPUcrD0YNzXzPJiqCdahrHfCTAzWgYNCLmM1GzGYzRpMRl+DBJXgwmAyYzWbMZjN6kwGX4MEjeDveO/BPb9TjEX0d28o6BZ1Rh0vw4D6oL8koRfryYTabSU1NZfr06eTl5XUhhibJxMjEYR2vc2xZR6XvPBiDYgvoF5NPUAnx9f4FXT4LyiGe2PJ3ZFVhWupEpqb+vIGqXYe8on41sto1JbA9WjwxZUyPZPuy/D8yIXkMs/pcctSkGGBAbD/mFD5Ali3jiG07I8ZH9iQ/ECElhDusTc5/b40xaBKDvOgc6nzOjvcaA21k2Q7OjO10plhepxVF6mWNeNEfIKUAuKLPRQyK7c/Tox4+LCkG6G/vi01nxRVys9tZcti27c+DAfa+PDZ8NiMThuGXA9y17hF2OPZ0a18WKQV9rLDHz8d3333XYTfYjiuuuILnnnuOyZMnk5uby8UXX8zMmTOZO3fuz+r72Wef5YQTTmD27Nn069eP2bNnc9xxx/Hss88echur1crLL7/MrFmzSEk5dLLpH/7wB7744gt8Pt8h2/xfxLGI8W+EpCQbNpsBtztIRUULffIT8T3eSuhrH4hguMSK7SI96594i/qi7zn/+5cBKJHTaE61gayysiSWUwc0IkU5wWpEiLehtnpRm12QHkdjYyOqqqI4BfIL2jOWVQSlDmod4A91qDOjRQGNWMogBXnp7SIAbpzZl/EZqdC6F5wNIEeibpIBbGYEWWGzQ8dx58VRsUeE2hoGRAVZ+VMz4/tHfgxSD9q9A4mx0azpMFQPQny8Fj22aaR6u7OSqYqWBFWrtFDbsJ4pqeNxhMLEG2BsQoGWra222xWIWHU2Xhj7JC/seoN1jZsoatlDn6gxbHdspU9sPAbpgEQzVe2IGK9rLuWnhi3Q/3gSjdEk2Q6KenREjLvrlBet1sj18WOiuwz8SRFCWu9v7H4NDsIru98moAQYFjeI6ek9JyUdiNGJI3hs+H3cv/EJFtf8yMmp/Rkdn4jB1EjGiCQ+2PopXjyMSjiuY5tUSzK5UVn0t0c8hIWjI8bbHbtRUEg1J3eQ7H8H8aZYHhh+J3eseYAT/BPIlTP56aefSO2fTovHQawYjVVfgN+zC4ASdzwVjkqcbicmXc9lhoOE2M4+qmgGR0iLEvtkBEGgb34CA/pFIRmHoKLjvo2Ps7J+LUPjBvL82Cc7+gjIAY5fcA4AXx3/fjeydNPqeylq2U6mNZ3Zg29lUJzmIXvXuodY07iRUzKOZ/aQWwGYs+VZ5lf9wFnZpzJz4GWHvR6TUsaysn4N8MuixaBNQM7L+QOPFf2Nufu+pU9Mb4TIL3xl/VrK3fuJNdi5beC1P7vv4fGDsemstAScbGvZ1eFVHZADHTr80w6hSbUbYphTeP8vOqejRTsxrvXWE5CDhy3tfCDa9cWSIPVYBOP3wPT0qWxrXtXxutHvYoAtvmsjQQcqxOgtHXKGnqQUAGOSChmTVHhU+9aJEiMShrC8bhXrmjZpQYdDYG+rRpz7xuRhlAzMKbyfu9c/wqbmrTy19R+8M+nFLs/C/8ZS0KqqQqib1c1/BnrTUU8Sf/zxRwoLj/wdtra2Ehd3dP7Z7Vi9ejW33XZbl/emT59+WGJ8tCgsLCQUCrFu3TomT+7uPvN/FceI8W8EQRDo3TueLVtqKS5uIusro0aKJbA8GYt+mom6lZvY8OJtTL7+HGwJsahhPeY2GykpAkOqAvgaolALmhF0QXDXIsbHo5Q1oDo8qLJCXZ0W2Y0OaBXwMEiIthaEhmaNEAoS3ztkpvePRVFVlJ0WkOGnvVUU7fJgMopcMV2F8sWdBy5JYM9jx/4o+guVCAaVvLGJCIJATr9Y9lU1kyYFiG+uR7BFIkvGHqJfhijNW0sJgzUOCGvEWBAQ0+MQrE4AtjmrODWsB8LUqi3sayxBURVKXY3ExycyLC5S1KIjGqwHQSAnKpu/jXqUDU1FlDo1V4BabyXLG9/lhoIrDjgQH5oEQ2RpXRHOoJeQoqAXRTQngwMitWr3iDGAoy3Mhh1a1Om4MV2JZpJJO/cG3+GJ8S7nXpbUrkBA4OYBs476gTk+eRT3Dr6Fx7f8jTnb3mPe5NsQcKMqXtY1RfSqBxGt0zPGYxB1uEJBonRHV+Fqa4e+uP9RtT8aDI0fyFX9LuGVXW9xQnACfcI51Oyo4iq0kr/frQB4HIBoYCawcP7Co+5fBWw2G6NGjSIhPjJYCCKflX/Jyvq16EUdN/Wf1WUbo2Qk2ZxIva+RSk91F2IckIPsdGqRsCcPimRenn8haxo38n31Ei7L/yOJpnhWRIju0URnxyWNRBJEZFX5tzxkp6ZO4KVdb9EcaOGu9Q93+/yOgdf/Ii2tXtQzIXk0C6qXsLzuJ6L0NhZULWZhzTLcYQ8p5qQjRiN/S8QZ7QcUaKk+pIPFwThQX3w0DiD/CRyfNoWl1d93vHaHwz08D9qdKTqfTzadDlC7RYx/LtrlVusaNzEz/4Ie28iqTHEkka5PjLayY5SMPD7iPs784VLK3fvZ01rSRRve7mH8XxUxDvnxPTX+d9m1+Z6fwNA98bgnVFRUkJZ2+IIoq1ev5pNPPuHbb7/9WcdRV1dHcnLXyrfJyckd/OHfgdVqxW63U1FR8T9FjP87nhT/o2jXGe/+Vw3Bj7TkL/ODMeinmZCDQb647kris5MYO/MsAEKt8WTLYV5Nl7huQgzDUwUUt13rrHkvWAxg0IGiorZ6O6q65aXHAiq6VAeSqUmzRDOYqY4bxjNbyqkOyohmI5j0qFIML32jRVEuPDGT2IRI/wYDJEZDr0KCMfk4drehRpKhUtM7tZvpI7Ufb5+cMIIAAbfIo6828cjL1Tz2Sg3L1kd0yoIAUemafVqk1CmqB1QVMSUKwab1aXRbkAIawW4RPLQEHBS3lbG+WXPRyLa2R6Pbrbi62o4VJgzlvJxzAUg0RrGsdmVHdTGgw41CFaLY0LQVgLAa0dV1RIjbEXl9UEnn71a2oijQt5eJzJSug1KHlMLfxKGgqiov79I8i6enTyUvOveQbXvC9IypnJF1Ms1BN+uaywBoC5RT72vEIOq7VaIbnaBF4Isc+w50bj4sjibx7uegDS+r2c2I3NFMSBnD94YV7DGVIx+Vc++RIYoieXl5nHjiiSQkJGj3mSCy21nMS5FrfWPBVR2D+oHItGrR9INLQ+9u3UtQCRFntHe0aceA2L6MShyOrCr8q+QTNjZtwRVyE2eMParJRIwhmmv7zeSMrJMYHj/kl542elHPbQOupSAmn/zo3l3+Lsv742Gt2Y6EKakagZi371suX3EjH5XPoyXgIMYQzW0DrvtdiaUgCL9IZ+yMeBj/N8go2pFgiiPF0imdkNUe4lOR55w9ksScbklEFNp/zf9eOef2BLxdzj24Qu4e2+x3VxNQApglMxnWTsIWpbd1JIG2F84B7RlXdqwU9C+Gz+fDZOp5pQxgx44dnHHGGTz44IOccMKhbTAPhYMnXqqqHnVw5kgwm814vd5fpa//FhyLGP+aaKvWIqT2bAD69tVI04bFlczqNQDT3dEYTtMedMsefpisIWlMve0+5i1xkjgqi0H6eKIDfkwON2JCFKZoCLmiCZqcmHEheOo0OUWtE3dtIy6XC1RIj4lCNbkRQo2ogBBrQ3bn8NF2jezUuiA9GgS7TG2tyNyvtOXra08fTLg5Bd3QNAS2aWRWiuWbbxo4JVlGdUkQrYDqBjSSr4ux4I2xYorVkvtKSyVWbOx8uC7f4OKnzW5uviiZqOTBkDQABAnC+9AcH/wIUhBkUAMC56mTI9FtyI7PYV9DHavq17GoZiM39BmPVSdp0eIDI8YHQYwQ2URTNHW+Bio9NWTZIsRGdQLgDEFzoAWDqMcgRQOtB8gzIjgoYuwLKPzzkwa+Wa4NrieO7y5LSDJFpBS+QxPjNY0b2NyyDYOo56q+Fx+y3eFwU/9Z7HLu5cvKDYxOyMUgtCIJAoPjBmCSuj5Q08xWwMPqxj1kx1QfUcMZlEPsdGoTkcMl3h0NVFT2Us129qGgUiU0cc6wGZT9WMFC7woWWiHeGMdHx73OarbRJBydNk1RFTaVrmVXxVZGxA9mVOJw8pP7dLHCc4c8PLT5KcJqmMkp4zgr+9Qe+8q0prOhqYiqg0pDF0U0zkPiBvY4aMzMv4B1jZtYULWY2kj2/ZSU8YdNYDoQf8w966jaHQmTU8f9WwT4UChMGNYRldUJOsYljeTkzOMZkzjiyJUM/wPItmWy3bm7o+jFgShuLSPDmob5IBlOh4fxf0Hi3YEYlzyeoBLGIOrQiT0Vz9Cud7xRe+aMSxwaeV/Snqf/BlIsSWRZM9jvqWJj05aOCdGBaNcX50fndJsQnZxxHD/ULOeHmh+5oeAqDJKe5kALraE2RER62bK69fe7QW/SIre/076PFgkJCd0Stduxc+dOpk2bxqxZs7j//p8vWUpJSekWHW5oaOgWRf6laGlpITHx35ff/Tfh93/a/a/A0wC1G7XIlckOphimpWTzBLCotRzdtRaMM7SEqMoVS8nONZB32TU8/24NN/+5jPTcBn56P5doQG12o0QG5r3NOooqYrl0fDM07UGMHY5c66SuVrvRbbIJgygiRjsBEOJsKFIUm/fWsHC/5jKQZE0DHIh2mdf+uYdwWGHC+GyGFiSCJ4jibESKFVBUE//6uIkMnxOpF7g8JuyEIsS4E+Y+iSBq0WpBsnPzRVpUt7YpxOeLHCxd52J7sY97rkxlaL/IQ1+waP2ono5Irdomka1GflAmA6OTR/Bjw2rm7vs2Up2smUxrfMSPOUKMe1pGjLyXGNHgbWjarBFjVYlUvIPNLVo0Y4C9H5JoiUSSD4gYqzLtJXTByO4yH3PeqKW6XtvvuSfEctoke7ddtydRHUpKIasyr+x+G4Cze51Osjmpx3ZHglEy8NiI2Vy98jYcQQ+xBiuj4/MYerDtl6og4SWIij13OGst5Wxg/2H7NigiOr0ei2omy3rkRKhDwYWXdRTTEknKtGPFiYdSqY7rxt3AI0seJagEOTFjCquE3TTjQ68KDFOTcAZU/rb9JXSijoeG3oVe0hGSZZ7f+SoN/ibMqoF9jgo8YW9kUF6OUTQyLW0if8iazgB7P57e9gI13jpSzcncM/jmQ0ZEMiMRsIMjxu1R86E9ZNwDDIwtYGTCMNY3bWZTs7b6MC3tfycb2ygZ+NvoRyl37WN88ujf3d7sYBzKsm1+5Q/M2fosZ2SdxJ2DumbrOzoixvb/yDEeLSaljKXevZRMaxxWfXwPLbShOc2ifTY0rr2s9r8no2jHqMRh7PdUsa5xU8/EuE3TF/e04jIiYQiJpnga/c2saljHlNTxHTKKTGvaUeu//xPQJIZHJ2f4PTFs2DDee++9bu/v2LGDadOmcdlll/HnP//5F/U9duxYFi1a1EVnvHDhQsaN+/cn16Wlpfj9foYNG3bkxv+HcIwY/1qwJII1GTz1GkHOnsSo1hTskpEW2c+mfs1MJIZgXQkJxlrME4cTDoV550tNu1pd1sJxF33CojnTyBCFjvK2XrOZz5fBOSOdWHEhxDhAgAa39sDPiI4CoxtJFwRRhGgz/jIdz9Vo+tPT+w8mIxwLOAjpw7z61gYAbrxpPFLvZOTdNRDUHCKCVTIXJXfOWqPTUwAXqF6NZEYiB4LZAQqoQYl+g7IoOCBqN2lEFE++Xkt1Q4i7/lbJuSfEMvOsBAyi9QBirEUJK5zNZKJFdgWTnjGJWvJBe8JMnd8bIcbuw0aM2wcLgygRrTezvmkzZ/c6DdQ2NCWqnuX1RQAR79TIUmSXiLH2fxUd73/j5F9fN6MokBCr4+4rUhhe0HMZ2nYpRWuoDb/s7xa9/b5qKWWufUTpbVyad36PfRwt0iwp3DP4Fr6vWcMfe43ltIxhpEUdTIxdqCisFcPERmvHJnN4GzOfXuHcsRdTU7b3qJbXWvGwi0oCHRMJAJUmXCgo6JAYSg69SKaYGrZQTr3RzZ0T7+Snvcvp3WcIzbShR2KSMJA4IYosk0prazMtAQctzgaGxQ/i7bIPWbt/DXFGOy9OfgWzZGKncw9rGzfxY91qKtz7+a7qB76r+oEUcxJ1voYOO7nDJVpldBDjzohxWAmz3aGtpPRkRdWOy/MvYH2T5gEbb4xjUOyvp8n+b0B/e1/62w+dkPV7oidiHFJCvFn8PtAZ8T8QLR0R4/8ukm/WmagPWqj21VCYdFr3BhEpRX5UFtPTpzI6cRBQ3U3m9UsxKnE4n1V8zfqmzT0uq7dHjPv0UB1SEiROTJ/K+6WfsaBqsUaMj5WC/rcwffp0Zs+ejcPhIDZWCzTt2LGDqVOncuKJJ3L77bd3RH0lSfpZEdpbbrmFSZMm8dRTT3HGGWfw5Zdf8sMPP3TxH37hhReYN28eixd35hvt3LmTYDBIS0sLLpeLoqIiAIYOHdrRZsWKFeTm5tK7d/cJ1P9lHNMY/1oQBEgZCpIRgm5o2IHoUDkxRntQfP31LnBWoHfuwBxjo6Gkis1bc9i4vT5iCWantKyFE25fSGWdGzVSqKNgRCJhVce7P2nJRYJjL4rNQH1Qi+ImG2wohgiZjTaDqOOt8moawn6STRauHD0epc6D6hGZ/10t9fVuUlKiOPvsQQgpdog2I8ZoBEfXJhGSwaMzIPZJRYi2oxFR9YAqekFQtCIfgjkH4aCqbgW5Zl55sBenTopBVeHThQ5uemI/Tc5IFEH1dESgv2xZ13n5zAaSzAldMppDqrFzm0NojLX3RNrneInGKDY1byWshCPEGFQhhqKWbQAMjR/UmVx3oMY48v/9tQJvf6mR4ikjo3jt4V6HJMUANp0Vs6RFJBp8XT2rA3KAN/ZqUYBLep//q2TFT0wZgyJoD8XxiX3ItR0UgVZdVAgqdRLIisy8NR9SunMzk0IFnEJht7/jGYrf78VujaWgoJA2Dq0VU1DZRSWLKKKSJhpwHvDXioJCMnamM5wcUhAQ6EM6Q9F+A26bwujhx9Em+tCjYzKDiENzUxEEoSNSW9SynUpPNe+WfAJoMpIovQ2dqGNw3ABm9b2Ef016kZfHPc3JGcdjFI3U+bSCNtf0veywmfbQqTGu8tSgqNqkYW9bKT7ZT5TeRk7UoZeCB8f1Z0REIzw1dfx/TULX/w/oFclVqPRUE1Y0rfr8yh+oj6zWVHlrCMpdLRud7R7G/2URY4DCpMmMST0LndTTZF97nkXrTdw/9A6MYkRf/G8m3rVjaNwg9KKOOl9DB6lth6IqFLdpuQx9onsmPCdnaE44axo30BJwHCsF/W9i0KBBFBYW8sknn3S89+mnn9LY2Mj7779Pampqx9/IkV3LtguCwNtvv33IvseNG8dHH33EW2+9xeDBg3n77bf5+OOPu3gYNzU1UVpa2mW7U045hWHDhvH111+zbNkyhg0b1i0y/OGHHzJrVtcE5/8FHHuq/5rQGSE1EsFr3YeY0MDJMVqi1VfztkD9VgRBYMPH3xOIH8b8nzRd6uDhWaxYcR05OXGUVrdxwm0LqGzwgEFHdIqVUyfZ+XKznRavHsJ+GqhD5v+xd+fhUVXZwod/p4ZUKgkZIANJGBKQeTISwUAjKiZRvDgiKJ8oKiCNfQXT6DXY2oitSEvT2KDQXiPIFRFtpG2viMRWBiUXAQmSBGQMYQqQmYxVqTrfHycpUmSqCgkFuN7nqUfq1Nn77AqRrFpZZ207Pjoj7X1VTO2sWnAY4EOZVc+/Tmjf4M+E9cXbpqAWlWEv1vPB/2i/Un/kkRiMRj1HT1pYuN2G4q1is8Hq/YHYb+pF4Ige6CPbo+h0oNQEc7XlFPaTgF3bnU5puG2M2VvHs492ZO7vIgnw03P4eBUvv1OkTaOeB2xU2Cz8q+RHrKaab0Fv7R/8um2H/L06Xri2I2Pc2A8G7XhX3zDKqyvIOZ8Jdu3rm1dlo6CqCC+dl5YNc2RdKrUbFVWVA0e19R0+AT5mHS882ZEXp4bTzrfpej5FUS6UU1zUsu0f2V9wtjKPMHOIlsFuJeO6jedERSU6RUGxO9fJlqiF7K7ZIdCWf56T+cf58ujX/HZLEpnnsvDF2+nhr5r55/99TMH5PBSDnk3spZD6N+SUUM537CEDrYl/OO0ZQk+nx830ZwT98Lno5qAeRHI92v8HlVhqguL+BOH8QcERGOfv5S9738FitzIk5AZGhdff9ENRFPoH9WH2oJmsu/0Dft9/OjP7PcX4bvc2+/XraA5Dr+ix2C2cq7lpck++VkYxqH2/ZoPdF69/lid6TOCJnv+v2WuJ1hNmDsFL54XVXs3pilysdisrD10IJGyqvV55TGHNb5+utBrjZim1CYea38o4dvVsncDYbPAmLkQLsFJPbnJ67VR5LmXV5XjpvBxZ+ot19etMn8Ce2FQ7qSc3O7aC7iY33rXYSy+9xFtvvYXdrn1YnzNnDmrNz6e6j+zsbMeY7OxsDAYDw4c33Xlj7Nix7N+/H4vFwr59+7j//vudXp8zZ47TvLVzN3T9WhkZGaSnp/Pb37q2w+bVRALj1uYbAu21Fjbedx5mVFQ4RoOOXw4VceBoBd+/u5Zj+woIGhTL/27eD8B99wykS5cgNm16im5RQRw5XUr8sxvIQ4eiKIy7oz0oev57k1ZvdqJAC8AiTP5grs0Wh4Jexy/ntLKIOwM7M8grENtBLbubl6vw5Vfanx+ZOJg1Gwp4+k/HCA3TMoTnK3yY+FBX/Pwuqq5xBMbntRKI2q2mdV2a3VFt2PV+/PcrUQzp78uh4zqqLDj6Ku87YUX37UxeXq/ww3GFH05pAWhcncC4q38vtBHVaG3XaDhjDI5MyvDQAfxX3/+gm08lWl2yif/L1z4o9A/qXVP/VvvDReV8WSWv/v00v2RrP0CrbSbe/WMUt8cFuHzXbm3LtjN16ozLrOV8eEjbhWxyz0date7OoDPQqV3N10nNd5Sm2FQr2/Ul2BQIVdsxIeQu3h42n06+EZyrzOf3P77MX/a+Q5n1Qlb4SMkxzpad5X9/XEug6ksVVjazlzT2Ox7b2EcquymgFCN6bqQHw+lDV0KdHmEEOvrqXqwHEcRyHWEENhgUA47uGj/l/8yu/D146bz4ff/pzf49tDP6cW/X0TwQNcalDK5BpyfSJxy4UE6xp6D2xrvmbz4M8Q7m8Z4Trpi+uL8WekXvuKn2WOkJvjyeytnKc3QwtadHTWbzaOkxpzGOXe+uoK4Urqn9d65mF1LHb8xap5QCcGzQk3pqk9OmLr/U9C/u7h+FQdd4YuDOTrcD8OXxjY6NVyRj3HKjR4/mqaee4uTJk82fXGPDhg1MnTqVHj2a3lK9LZw6dYqVK1cSEHC1/b/VPAmM20JwL1TvQBSzjcg3DjNyiHZT2MK5qfx74UqGPf88m7POsjNTq5X7fw8MBKBLlyC+++4posP9OHK6lCf++C12u53gQAOJw/35d5Y/J4pMnC7RsgidfL0x+lahqgoEasHZ6fPlhPq144m+WuZazdNuhPp44xmsVpWY6wNZt7WS99ae5ZHR5Tx+t1ZbG+jfSM1S3Yyxraa2Twl0eUe19gEGXpsRydMPhZF96sI/slmZ7VGKIknPVfjTFj0LPsrjTL6V/kF9uL/rXUzpOZF2Rn/tpj1tATX/bSQwrjmeEN6d/+hU8+seXRgYBjjatGn1xdSUXmg/YBZ+cIwtO88TGap9Sr89LoSOwY1do2ENtWz7POcrSqvL6OrXmfjIW9yazyWKLyg1rexs2j+kGRymSFHxUmEIvVDQsqrv/+Zv3N9Vy1j/M2c94zdN5pOjn2OxWR03nPVsF80tygCC8ceKjRPkOR4nyceOSkeCSOAGoghrNABuSjQdubmRoBggyq+LtplLjUk9HiLCp/Fdly6F4wa80pPYVXudG+8GtMn1ROuozWAeKjnC/9R88Hyk+4P0qrlJLPu8842mV2pXiubVJihUalr41DxvvQ/YcaE34mfw5VxlvlN9dm19cS//+vXFdY0KH4FRZ+BoaQ7VajU+BjMdW3hzsdDMmDGDzp0bztI3ZNq0abz99tttuKLGJSQkkJiY6JFrtzW5+a4tKDpodwNqwWZ0AdXcfWt7vtlWxIa0Ul6Njyc8Joa1s7UG74P7R9El6sInri5R7Vn7wYMMG7OSDf8+zMKFW5k1ayTj7mjP+q3FfJhmpltEMT5GBT9vLctZaQjl4LlTDOxopLDcyrM3346fOQjbuTLHvP/zTy07/djELth9z/PylGpGxNSUJ+gitCCywfdSW19rBbUmO613/X9c0H7tfc9tQZwvCQS0Otyfq36mZ6LKH0Y+zBspp8k6XMmCFbnMf7YTz/av86sZxfdCfTPQaGCseDli5+zSPN7M+pI3hvwZP52O3flafXFtYGytVjlzVkenUOjQs4zRN4Glj5UfdTZQzgFFbr2/zlG9iG9vxGb2ppgyvG1G1hz9JwATuj3gaOd1ngoOcQprM718FaAzIXSkgR0FAQvV/MIJKvTVoFYDZ7CrVRxXtL+fG+2BmOvcBGg2ePNs/2mM6HgTf81YRk7ZCRZn/TefHv0cX4P2wWNQUD+MGLiZfpwgH4vTjXXgizfhBLUoIHaVoigMCurHljNpRPt1abX2Zg2p28v4yPlsSqvLMOvNbveYFpdXbWC85sg/Ka0uI9jUnjFdEvk85ysAjtYJjFVVrdOV4irLaik6tLyVHe03ZrUZ49YLjL30Rm6LGMG/cjbw9cnvGBys1c4fKKm98a7pG6r8vdrxm7Cb+O60dhNXt3ZRrdYbVwhPksC4jdiLTFS+3Q3vh0+Q8B8x8NoRcuhEv98+hk1V+X69dgf8nSMHYrjo37qY+D689bd7eOqpz0hO/oqbhnUh16+Q3jdWYK/UgsROgTp8OlSj2lVeytjHfYPCgPZcFxLBDZ26oNpVMOih2kZWQRW7fjqFXq8w4aEutO9QgV4HoIA+GnRN3OGq6AEfqL0pSwmpk8V1Tzs/f7Dlo6oqewM+54Goe4kI9eL5J8KZ9ko2u/eV8/l3Rdw3qk5AqPgBWvmG1WbAaGzkH15de7AXgi6QV35eyaHSHH7K+5kufp0otGj1xX0CenE818Lr757izpurORVeTVi89uHgwn3uDfeSbIrR35c+/lrQ/Q3pKCWVFFQVEuodTHzkSFRUjnKGdI402yGiVjZn6UZHBhGNgQuZ9rMU8SMHqaBKi6AdXw5t3d1tOiKUhrM2scHX88HNb7P+RCrLD3zkuGENLmzsoUdPVzyX9XnkugepVquZ0utRjDr3Mvfu6Ox3ITBOr6kvHtC+T5O/OhaeV7vJR2m19u/gI9c9iEnvRXRN79y6PY5Lq8uoVrUPeIFXXcYYtCRAVU2pVO1vzFq3FVpi5K38K2cDm3N/IKn/NEw6U52OFM13GrgjcpQjMJYyCnGtkMC4jah5dqp3B1JeFMzpAe8QyjnOEkJWWRj5h4s49LNW23jHyH4N9mufMmUo3357mDVr9nD/gx/Qf1YA3r46hoSGATo6B2iDfsgvZ29+MdP8tE1Fbuqq3ZGv6BR0HQOwnyjgw++yAYjuHUlISG2NmgH0PVwridD5gb0cLZCObPb0Rin+gMKB82cpra5yZH86hXkxZWwIiz86y3trz3FjP186dfSivNLOR/9bzuR7tOEnz0B4uB2TVwMVQIoPGLXg9PrggRwqPcaOvJ/Ir9JqrvsH9iH1hzKWfnyWwC4WKm6s4JhOBRW6E4KvPV97f7pOzdZOX+x42Sm+yNlAj9BehHWIhCAT9w4ZT+eKQOw62MY+TqGtI4QAwhvJBNc6TwVHlih4+QAAnBJJREFUOcMRcjlLMUPpSQC+ZHKMX9DKJnzxphsdUVQL2LU2PkZVIUpVwND436lBp+fuLneQEHkL/zj6BasO/4MgUyB9Ans2OuZy6hPYk/k3/rHNr1NbSnGi7BTe+gsbe4grW1Sdm8FCvDvwH521X+XWdhI5WdOZwktvdGSLfQ0+V1RvXZcpBq2EwvEbM6OjZWZr6R/Uh3BzGKcrzvDDmR/pF9ibEut5DIqB6JqfKU0ZEnID7U2BFFQVSWAsrhkSGLcRe56WGawOqODHxYvpRR/OEsIXX2RBznlUFWL6dqVTuH+DcZiiKLz77gPs2HmcI4cLyFxpZ9Lz1+Gl6Ci12/ihsJRRJj8+zC7kvv7X062DP9qv2y5k2XTdO2IPC+CDh9YC4B/Zk/JKIz7eBjD0vNC2rDlKMHAOdJ0v7eYPxRsMg/jDnqcAnHZkG3NLINvSS9mVVc4b75/mdw+HMu+905w+a+H/JYLZG87kw+b0Ah67J7jJy8QGx/CP7C/4pSIbQ0A7Bna6ifbnbmPj2WxuuN9G/9sqUHTgo8JQmx/BujCwFwHebpeJAJhVhZ+O/Mi+Yz8zM24mRX5WuoREY1T1fM1PVGFFh0J/utKTSJfKEToTwg4OUEoF3/Izvpgorem1HE0Y19NNyyQr1OwMWFQz0gtXtoz11nvzyHUP8lC3+1Gxt2l29kpU28v4dMUZztdkH69vpe2wRdvp5BuBXtFhU+080v1BR8DbwdTesWtfTtkJrvOPptCi/RblSuth7LqaH8+1gXErllHU0ik6EiJv4YNDa/j65HcYa3Y4jG7XFa8G28hdtEKdnhl9n2LDyW8ZFVG/e4wQVyMJjNuImqfVkWae+JiK/HxiIyrYegq++uoXvA9q2cM7Rg5Ab1QbncPf35vfvT6E30/YwNn0SrqfbweBVo6e8+PfO/L5VHeOh2OHMTpuEFTv0AbV+cdzV8EeXv/gc86dLcNgMnH/ff3wqQ1G3cmK6tqBcqPbmdSGFFkrya3ZPrnuLms6ncKsSR2Z/Mds9h+p5HevabWCIe2N2NC2OM4v0fHxVwXcNtSfzh0b/yER02EAgeYgbo65A2+jN5FduqPV6l1oQ9ZVbU9MdQnGuje2uPpB4SKhZq1bSIWtklW7P6SEcv7fTY+Btwmw4Y8PQ+lJYCM3nTUkjEASiGEXhzlBHqVU4oWBWHoQyUU7ZekiwVZU8x783fp70koHfn3lA8GmDnjrTVTaqii2lOCl86J3wJWRNReNM+qMTOrxMDmlJ7mrc4LjuKIoRLfryt7CLLLP52iBsaO+uOnf0Fy5agPj2i4ybZP1Toi8lQ8OreHHc7sI9db+bXGljKLWbREjuC1iRJusTQhPkMC4jdjz7djVanbu1O4YHT/7CT56NY8zZ0o5v1trbXPnzQMwmOoHMdbyaqzlNrzaG/ipOpueYwM48lkJXl6VgB5LcSixa3XoVRj2dA/AxsVdG6x2K6+nv8UPK3oCZXTrdx3PTopseXDbSjdV5NS09eloDsVscA5EQ9ob+d2EUOanaKUBw2P8+P1jHfEznwZ7GSreWKtV3vrwDG/+vpPTjR5ZhytY/VUB5RXa1yLhgSl4G3UUn9GRl2PEbFLo291MO18DnelAJEHATrR2SLUZmZYFxt56bwKM/hRbS8gpO4FJZyJBN5hzlGLDTi86oW9BAxgvjNxEL07QgXzO05tOeDf0w1HnB/ZALWusC2zRe/i1URSFzr6Rjo0M+gX2cilDJjxvUo+HGzwe3a4LewuzOFqqfai+0MP4Ks0YK8aaf9Zbv1VbXV38OtEnoAf7ig/yv8c3AtCrkY09hPg18Hhg/M477/Dmm29y+vRp+vXrx6JFixgxouFPn5MmTeKDDz6od7xv375kZma29VKbZLfZKDp6lLxffiFv/37OfLiHMwcyKC7PwSckhBueeJz/2P2/pKRomd3BfcKJCAtC713/Zqwvn9rF6V2FRKSEcbb0PINGh5B02xB8fArJy7Pw9rwvGOMdRUxQJMkfnCWsg405T0F5pcLv/6r9UCi2lpBX8DB5+74D4NWXhuPj7fnufLU3x9Qto6jr9pv8sdnA5KVwy43ttOBXjQDFnxv6eeFlzCF9fzn//r8Sbo8LwGZX+Xh9AR/8K4+avugMiC+nYzcd1ipY/1YA+qCjrHxmNGZTnfevgPbtXw1qcc3Blv/gCTWHUGzVdtob0yWB9l6BtCewxfPVUlDoTAidaWYLUP11WoCvtLvka/5a1A2MB3WQ+uKrXW398dHzWi/joqu2h3Gti388t12ddELkrewrPoitZidIdzLGQlxrPBoYr1mzhpkzZ/LOO+8wfPhw/v73v3PnnXeSlZVFly71t2V96623eOONNxzPq6urGTRoEA8++ODlXHaD8g8c4J2+fRt8bdhzz2E0m7n77r6OwPium/sAoPd2zsTaq+2cSMvHVm3nk4xdAIwdNJjOFVZycgo5ftxGWbmFj8sP8L3lHNX/k0OQv8rhtGrKKiDt5wtZr6rycuw2GwHh3jx4z5XxD11txrixHZUUReGO31z0g0zRgeJPeAg8MqYD73+Wx7JPztGtszdvrz7Dnl+0DS5uHdKOocP0FPbVSjW+355BXp89TI671TkodszrXbOjn+XC8xYKMwdzsOQwekXH+Oi2azPWKEVfc3OjcFXtDXjg2sYe4soW3U67Waw2Y1xQExhfnR0pqL+ZURvUGNcaFXEzS/a9h021o0NHd9nB7rLLz8+nT58+/Pjjj0RFRXl6Oa1i1qxZWCwW/va3v3l6KW7xaApx4cKFPPnkk0yePJk+ffqwaNEiOnfuzNKlSxs8PyAggI4dOzoeO3fupLCwkMcff/wyr7y+9t274+XnR9igQfQbN46b+vyeO6KWMPl/fmTYrFkADL7lOvR+JnQGHXeO1H4QX1xKcf5UJXaryuk+peSpZbQzeXNHz76cOqV1sXj22Tt5fMhA9CicKC0k9/Bh9u0+wocf5bBuXQ65hw87HoWntZ3uet9XfsX0lzxWkzHu6ttwxrg5Dya0p0u4F0XnbUydk82eXyrwNik8/3hH/mtKGLb+J0Gn0lEN4njVVtT2xxncYVAjs12UIb6EX1V2qumLe3vESDr6SJP7q0Ht35le0dMvsLeHVyMuVVRNy7ZTZblU2SyOzT3amwI9t6hLcnHeqm1KKQCCTIHcGKxtChXVrjPe+pYnCUTLzJs3jzFjxjiC4j179vDwww/TuXNnzGYzffr04a233mrR3GvXrqVv376YTCb69u3LunXrmh2zd+9eRo4cidlsJjIykrlz5zptCX369GkmTJhAr1690Ol0zJw5s94czz//PMuXL+fo0aMtWreneCxjbLFY2LVrFy+88ILT8YSEBLZt2+bSHCkpKdx+++107dp4W5mqqiqqqqocz0tKSlq24Gbovbz4r6IiSixVBJp9KLk1F7VExW9YsCMo3V2tY/CiBHqdLyIiLBgrcHEXoaKjZaioHBqu3VF9T79BlBYVUV1djdlsJjg4mDhrGOHhJv4Vt4myoPPcFXkT0X7tAF9UXQdWH/mMgqpCovy6cNyeTfjoK6d28lgzGePmGA0KMyeGkfRnLcDu2dXE7KkRdArzIp0jlFCOCSM3Kj14I/YlTpafpl9Qr4YnU7wvlGYDl/KDZ0K3++lgCuI/6twQJK5sg9r3w6QzcVPo4Hr17uLq08EURDujH+etpeSUnqCotsb4WgmM2zBjDDA2agzbz+1iWOiQNr2OqK+iooKUlBTWr1/vOLZr1y5CQkL48MMP6dy5M9u2bWPq1Kno9Xp+97vfuTx3Wloa48eP59VXX+W+++5j3bp1jBs3ju+//56hQ4c2OKakpIT4+HhuvfVWduzYwYEDB5g0aRK+vr78/ve/B7TYKiQkhBdffJG//vWvDc4TGhpKQkICy5YtY/78+W58RTzLY4FxXl4eNpuNsDDnHdfCwsLIzc1tdvzp06f56quv+Oijj5o8b968ebzyyiuXtFZXHMk/x2vfrNfarN39CGqJFnHpgi/c8f9dXhkB9nTO+Ngpsqv46qm3uUfR0TLO9CzjfKgFQ5XCb/TdOHNGyxaHh4dTnF1ORb6FYLMX7SceJ9Bo56Yelfy/6MGg68iWcyf5567D9DT4sHTYFB7d8jSFdj121Y6ulXtgNqfKVsWhkqPYaz5l2lSbY1OJro3UGLuif09vfvdmJVa/MgwGhZ3KaXaCY0e5WHrgjRf9gnrTL6iJTKBThtjrknqEBpkC23SnNtH6wn3CWHf7B5h0bZeJE5ePoihE+3Xh58IssktzHF0pAq/am+/q/nhWaHTXz1YyNHQwn9/+If5ernfPEa3jq6++wmAwEBcX5zj2xBNPOJ3TrVs30tLS+Oyzz9wKjBctWkR8fDzJyckAJCcns3nzZhYtWsTq1asbHLNq1SoqKytZsWIFJpOJ/v37c+DAARYuXEhSUhKKohAVFeXIYL///vuNXv/uu+/mpZdeksDYHRf/il9VVZd+7b9ixQoCAwO59957mzwvOTmZpKQkx/OSkhK39iJ3VVg7f86Unsdqs3H46Blt7zAvoJ32Xs7bVPaeOIKi2lFQMOu0DNXec8eJbaetJ6+slM/zf2bv6JrgcWcAhV7nyYvWnoeGhnL6/7RMckHXc9iNduIjRtLepP1DZrHDBwfXAHB/1/+gs28ndOiwqTYKq4rp4H152xa99NMbpJ3dUe+4v7HdJf2w2sdxrEHnAS7auBiuI5wI2rs4U50sYRvd8S2ubO2MEgRcS6LbaYHx0fM5FFTV9jEO9OyiWqxuIOzVap2BmnL13qjYMFVVqa6weeTaBrPe5RLGLVu2EBsb2+x5xcXFtG/v6s83TVpaGs8++6zTscTERBYtWtTkmJEjR2IymZzGJCcnk52dTXR0tMvXHzJkCMePH+fYsWNN/nb/SuKxwDg4OBi9Xl8vO3z27Nl6WeSLqarK+++/z8SJE/HyavrXSyaTyekvt634epm4qUs0W48e4rvDBxhPT5QOF/7H2Ha+GjXvKAowJrQHOkWHXVV56Zt13NV3AEUV5fyQfRh7Oy272q7ERPSPQeQYz2IJKgIgJCSEAzsPApDfLRcfg5nf93+ag4Xar19WHf4nB0oO46038WD0PRh0eoJMgeRXFZBXlX9ZA+PDJdmknd2BDh0RPnX+PhWFuzvf0eKa5wLOs69mA+fBXEcIF/4h16Hg4045hFMwLL9KF+JqF1WzW9vBksOObaOviRrjNi6juFZVV9hY2udrj1z7t/sSMfq4FmJlZ2cTERHR5DlpaWl88sknfPnll26tIzc31+3fzOfm5ta7AbB2jtzcXLcC48hI7V6O7OxsCYyb4+XlxeDBg0lNTeW++y78Cjo1NZV77rmnybGbN2/m0KFDPPnkk229TLfccl0vth49xOazB3mQHhg7XPjV/Hd5ZShF2na+o9t3w24DKxbsqHyR9bPjvNAzvnT6vh1jx8XyQ/l+8gvyaAf4+/tjNps5vVPbHCSvey6BXgH4Gn3o5d8FO3aK/Lzp3rEng819HJ/8Q7w7kF9VwNmKPHoFXHfZvhb/yP4XADd3jOPVwcmtMmc1NrZzABXoTDDd6HiJMxrR7j+1S8ZYiGtA7dbQPxdmAdqNlX5GX08uqeUUBUdLyTZs1SY8r6KiAm/vxpMzmZmZ3HPPPbz88svEx8e7PX9LfjPf0JiGjjfHbDYDUF5e3syZVw6PllIkJSUxceJEYmNjiYuL49133yUnJ4dp06YBWhnEyZMnWblypdO4lJQUhg4dSv/+V1bv0SGdo/AxepFnLWN/eB4Dg7U62jKbyu6cIyiodA4KpoNq5hzQztfIy/F38dFPP9IzNIy7eg7gq7idqDaVnndGsGvJEXSdtJKB0NBQKgotFB7WsiD53XK5zkv79GXW69mnq6ZTp36ER/RmqPVCABzs3QGKD5JXmX/Zvg6FVcVsPKn1T34wuukPOe7YSzalVOCNFzfQCu3nFAUtU1x+Sa3ahBBXhtrAuLxaa+EY6BVw2e+taF01gbF8cG8Rg1nPb/cleuzargoODqawsLDB17KysrjtttuYMmUKf/jDH9xeR8eOHd3+zXxjY4Bmf6N/sYICLZkXEtJML/4riEcD4/Hjx5Ofn8/cuXM5ffo0/fv3Z/369Y50++nTp8nJyXEaU1xczNq1a1vctqQteRkM/Cb6OjYeyOKH7jlcH6y9j+2lNux5R9ABt0V3x3Ze+x9Gb1IYHn0dw6O1QLboaBmqTcXgrcOvozed4jpQeF0RoAXGuT9p/+MYuoDFr1Lb0UlVKcVKlk5rzK7X6TlgOkMXwtGjI6Rmi89zlzEw/iJnAxa7ld4BPRgQ1KdV5jxDIYfQ2s/dSA+8WutGFH0nsBeCEtg68wkhPCbIKxB/YztKrFpC4aqvmVUMNZ1zJGPcEoqiuFzO4EkxMTF8+OGH9Y5nZmZy22238dhjj/Haa6+1aO64uDhSU1Od6ow3btzIsGHDmhwze/ZsLBaLo1x148aNREREuN1jOSMjA6PRSL9+V0+veI9/x0yfPp3p06c3+NqKFSvqHQsICLiiU/K3XNeTjQeySOt+nKe8tV89/DuvFKVI6yxxc0Q0tl+0cy/uYVx0VMsGB0T5ougUwof5U+qlzRESEsLOVVovQF1fK6BlQ1Qs7NLbsCsQrPpzXqmghHIyOcZAorWMMXCuquHA2IadfErogH+Lti2+mNVuZd0xrQZqbNTd9X7tkk8J5VQ1NLRJe9Dee3fC6Ugr1krrgrSHEOKqpygK0e26sKdA2wn16r3xrobSAVQr6K7yAF80qfbGtsLCQoKCtJ9HmZmZ3HrrrSQkJJCUlOTI4Or1ereyrzNmzODmm29m/vz53HPPPXz++ed88803fP/9945zlixZwrp16/j3v/8NwIQJE3jllVeYNGkSs2fP5uDBg7z++uu8/PLLTj/T09PTASgtLeXcuXOkp6fj5eVF3zqbnW3dupURI0Y4SiquBh4PjK8110d0JrDamyLvSn72z2WwPYCfjh1GQaVTUDARJh/O1ey0Vq+HcbYWGAdGaTVx3r3tcASqT+vQqwZO79QyxpZepdp5pgByOMtZnYpOhRuVHhRTzjb28QsniaCDI2PcUClFCeWksZ8SygnAh5vojT8+rDr8DwqqCpne5wn0iuu/DgLYdPoH8qoKaG8K4raI3ziOV2NjN4fJ5qxb89XlhzcDiWrxeCHEtS/Kr05gfNXeeFdD31F7iGvagAEDiI2N5ZNPPuGpp54C4NNPP+XcuXOsWrWKVatWOc7t2rUr2dnZjueKorB8+XImTZrU4NzDhg3j448/5g9/+AMvvfQS3bt3Z82aNU49jPPy8jh8+LDjeUBAAKmpqTz99NPExsYSFBREUlKSU4cv0DLdtXbt2sVHH31Ub32rV6++LC1zW5MExq3oo3MWepv1DDvTlfWRv7CFw9hLr6M67yg64PbreqBWWrHXfNn1F5WN1WaMA6O1wLgMbTOSqoM6TqTlc2ZPEQDFPbQgN9A7kHS0DTP62k346c34YaYroRzjLD9ygGBvrbVL3VIKFZWjnCGdI9jQSjCKKecb0ulp7ciy/SsACDOHMs6NGmFVVfn06OcA3N/1Low6rdyhiFL+j184j1b3F4w/Cu4V8OvRMYCuGHAvUBdC/LrU1hkDWrmZEFeBl156iVmzZjFlyhR0Oh1z5sxhzpw5TY7Jzs7GYDAwfPjwJs8bO3YsY8eObfT1hq41YMAAtmzZ0uS8dXfCa8iXX36JXq9v8tpXIgmMW8n+Chvvn7WiYuWPv3RifeQv/F9pNhVnCi+UUXTrSf62PGze4UADm3s4MsY+wIVid8sRPbu2HUIfo2DMMXI05Bzkg3dIeyyKDX8VeqkX+rHG0I2zFFNGJb7+2vHajLGVanZxiOPkARBGIAOJYg/ZnKWIfcZTJFw/hu/2fs1//7KS34QNJcLHtYxFZtF+9hUfxEtn5O4ud6Kicphc9nAEOyreeHETvZxarAkhRGuK9rvQEuqqzxiLX43Ro0dz8OBBTp486fJeCxs2bGDq1Kn06NGjjVfXMmVlZSxfvhyD4eoKNa+u1V7BOnnpuKe9gX/lWel7pD2hsb6c9S/jx92bUFCJDAomwj+AfekH8L1J+6ZvaDto0DLG5eXllJZqJRO+z/lhv9VOB/zADv3Lb6J9cWesvlpN8GCbHl2d/r1GDNxID7aQwVmvUn43+nkAPlW/pzZRqwD9iaIXkSgo3Ew/9nOCvWo2vSP70TuyH3bVzvccRFEP4UqCVw1U+d3o51FQ+EbZ6/RaOEHcSE9Mbbx7kxDi1805YxzouYUI4aYZM2a4dX5tB68r1bhx4zy9hBa5mvvYXFH89Ar/GW7i7Q4mjDaF4Ye0f5zVmmxx/HU9sJbb8A3UY6stpagTGNssds6frGkxFOXLuXPnAFCCvDDdakKtULGdsoMO/P0C6R2p3eHZze5LsKoDxTngDCOQnmiNtXWKTmtZVBPc+mLiVgbSm06OkgYFhT50ZuvurykuL3KMUxTFpaAYtFonx5gaOhQGEc1w+kpQLIRoc0GmQAK8/Gv+LL+dEkK4RzLGrax7GZQCQ3O7so59juM3d+uJtbQa3w5GimvqZOuWUhTnlKPaweirxxzqxYEdWhcGNdQL9ZhK/uRSqg/YGfPPwcy1LyA0IIy7o+5kIEbAAg0EnYOIpjedmL7teU6Un2JuzAsM7NAPb4wN1vjmVeaTfjqdn0//zD8SPuDbU1t4/+BH+OjN/O2mNwg219+K0mKrYvWRz/j82Abs2InpMIA/xjzveN2IXuqChRCX1b1d7mRLbhr9W6ldpBDi10Myxq3MnqfdzHadqT1dgrSOEN06hBAZEEh1QRnmDtpGEjZLNYr+QuF6bX1xQFdf0pWjFJ7TaoJDQ0PokOJP9QE7OqNC4HVmDuXuZ9svm7lR6YWRmn3glYazsSaMtNP5UF5VRmFFIWa8Gr3xLT0/A4Du/tGEGIMY2+U/iDJ3Iq88jyUZf8dbNWLGy/E4VHCY6VufY9WBTymtOs/wDjcyu98Mp3MkKBZCXG6Te01k5ch3aGf0a/5kIYSoQzLGrUzN0wJVXbCOsQNjWLj5G+7tNwi12obp7DmsOq0WuLKwioIDdjr0agfU6WHc04fDpSegzAaKwvDg68kZlk/WBycIHxzEeaWm7tjgg5feCFZrzZUbL1NoqmVbXT/la1tT39BhAKBtp/rCwGd4YusMtp3dweTvZ2LUad8ydtXO/uJDqKh0MLVn1oCn+U3Y0EbnFkIIIYS40klg3MpqM8ZKBz2Jvfrxm+jr8DF6Ycs8gd5uo7AYCICq4ipObCt2BMbFNRlj8zAjZWe1DTA6tG+P0WikW2IYd75zA2GDAsi2aCUWgY42RFpPZJTGd0YKdnH3u90F2g1zMR0GOo5Ft+vK4z0e5r8P/A8HSg7XG3NHp1E803eKZGaEEEIIcdWTwLiVqfkXMsYAvl4mbCcLUM+VoKqwb1sVXe/UAuMzh/IZ9Hg0cCFjrAxS4JwWGIeGhmrHFIUed2kt3opyi4Ga/pyqDWr6EF9qxvhcZR4nyk6hQ8eg9s5bN068bhz9gnpTYat0Oh7qHUzPgO5Nfj2EEEIIIa4WEhi3MrU2Yxys1daq5yuwH9K2csyv9MZardUVVxVXcfL/ClDtKopOoShb2+b6PPlwXOtOERYWVm/+Iou26UegKQCoLaPQ0VS5eHPbQgP8lKdli3sGdMfP6Ov0mqIoDA4e1OhYIYQQQohrgdx818rs+bWBsQ612kZ15gmwqygd/Mgr0GMK0GqMreUWqoqtnMsqobrSxvlT5fjdZaHy57Ngh4gukQ3uh15YVQRAgFcAqHXqi5XGe6q5kjG+UEYxwN23LIQQQohLkJ+fT2hoqNN2yr8GY8eOZeHChZ5ehhMJjFtZ3Zvv7CcLoMICJiP6PpFYSm2YArXA2KeDlqw/kZZPYXYpAeMt+N2iBbrG3oEMHzrMqR9wrSJLnVKK2oxxIx0patUGxgVVhVTbbQ2es9tx493ABl8XQgghRNuYN28eY8aMISoqCoA9e/bw8MMP07lzZ8xmM3369OGtt95q0dxr166lb9++mEwm+vbty7p165ods3fvXkaOHInZbCYyMpK5c+fW2wJ68+bNDB48GG9vb7p168ayZcucXs/MzOSBBx4gKioKRVFYtGhRveu8/PLLvPbaa5SUlLTovbUFCYxbmSNj3EEPlVrgqusYiGI0YC2rdmSMA6PMABzffo4dmf+HeXA1KkBsAJ0HRjcYFAMU1gTGgV4BoNbceNfMxhlBpkD0ig6baqfQUljv9TMVZzlVnote0TGwfV8337EQQgghWqqiooKUlBQmT57sOLZr1y5CQkL48MMPyczM5MUXXyQ5OZklS5a4NXdaWhrjx49n4sSJ7Nmzh4kTJzJu3Di2b9/e6JiSkhLi4+OJiIhgx44dLF68mAULFjhldo8ePcro0aMZMWIEu3fvZvbs2TzzzDOsXbvWcU55eTndunXjjTfeoGPHjg1ea+DAgURFRbFq1Sq33ldbkhrjVqRW2KFM+0SlC9ZhO1ZzY5xB+/xhKbPRrpsWGIf007o4FNjO4GurxF4JhuuDUbt5EUrjuzUVVdVkjOvWGDfRkQK0tmvtTUGcq8znXGU+Id7BTq/vztfKKHoF9MDH4OP6GxZCCCHEJfnqq68wGAzExcU5jj3xxBNO53Tr1o20tDQ+++wzfve737k896JFi4iPjyc5ORmA5ORkNm/ezKJFi1i9enWDY1atWkVlZSUrVqzAZDLRv39/Dhw4wMKFC0lKSkJRFJYtW0aXLl0cWeA+ffqwc+dOFixYwAMPPADAjTfeyI033gjACy+80Oga7777blavXs1vf/tbl99XW5KMcWtR7diLzmMYUQ7eCvgoUF2TPa4NjEur8WqnBbEdevlh8jegC9OC2/I0I+oA7bUQAhu9jHPGuPkexrWCm6gz/ilf6ouFEEJcW1RVpcLumcfFZQdN2bJlC7Gxsc2eV1xcTPv29XegbUpaWhoJCQlOxxITE9m2bVuTY0aOHInJZHIac+rUKUcNdGPz7ty5E6tjfwXXDBkyhB9//JGqqiq3xrUVyRi3mir0wfvxeUWh9DE/rRTCVlPPq9c6VFjLq9HptSBZb1SIvKkDJZFaXY0aYAQF2mHGTOMZ4As1xoG4WmMMEGLqwD4a7mVcW18sgbEQQohrRaUK/7Gv3CPX/t8+PpgbvyfeSXZ2NhEREU2ek5aWxieffMKXX37p1jpyc3PrdbgKCwsjNze3yTG1tc51x9S+Fh0d3ei81dXV5OXlER4e7vIaIyMjqaqqIjc3l65du7o8rq1IxrjVeKPaFRQfFV1PLVOsVjuXUlSX2x1nKzqIiAtEH6J9qtT30j6ZNVVGYVftFDvatflzoV2b6xnjiwPj0+VnyK04i17RMyBI6ouFEEKIy6miogJvb+9GX8/MzOSee+7h5ZdfJj4+3u35L75nSVXVRu9jamrMxcddOccVZrN2z1V5uWc+xFxMMsatRVFQi00oQZXo+1Rrx2w1gXBNlri6yjkwDhhoRDkCtmIFr980X0ZRai3DpmpZ6ABjANhzal5xIWPcSClF7TbQfQJ74mMwNzuPEEIIcTXwVrTMraeu7arg4GAKC+vfGA+QlZXFbbfdxpQpU/jDH/7g9jo6duxYLzt89uzZBvdJaG4MXMgcN3aOwWCgQ4cObq2xoKAAoMEWtZ4gGeNWpJ7Vsr76bjXdImy1NcZaKYXNUltzpKIoYPfXzqs+q8PYRzunyRvvasoo/Ay+eOkMQE0A7kopRc0NdxdnjLfmpgEwWNq0CSGEuIYoioJZ55mHO1nTmJgYsrKy6h3PzMzk1ltv5bHHHuO1115r0dcgLi6O1NRUp2MbN25k2LBhTY7ZsmULFovFaUxERISjxKKxeWNjYzEam49J6srIyKBTp04EBwc3f/JlIIFxK7Id17K+usiab6bq2hrj+hljgMIi7ROiatAS9wH4YGoi+1toKQIg0MsfLSiuDbTdyRgXOI7lVxbyf+d2AhAfeUuzcwghhBCidSUmJpKZmemUNa4NiuPj40lKSiI3N5fc3FzOnTvn1twzZsxg48aNzJ8/n/379zN//ny++eYbZs6c6ThnyZIljBo1yvF8woQJmEwmJk2aREZGBuvWreP11193dKQAmDZtGseOHSMpKYl9+/bx/vvvk5KSwqxZsxzzWCwW0tPTSU9Px2KxcPLkSdLT0zl06JDTGrdu3VrvRj5PksC4FdkPaQGqrkMVql0Fe03gWhMY22oTvDrteFFRkfa8kxZQhzZRRgFQVFVbXxzIhfpig1aX0YyGaoy/PvktNtVOv8BedPXr3OwcQgghhGhdAwYMIDY2lk8++cRx7NNPP+XcuXOsWrWK8PBwx6O2/VktRVFYsWJFo3MPGzaMjz/+mOXLlzNw4EBWrFjBmjVrGDp0qOOcvLw8Dh8+7HgeEBBAamoqJ06cIDY2lunTp5OUlERSUpLjnOjoaNavX8+mTZu4/vrrefXVV/nb3/7maNUGcOrUKWJiYoiJieH06dMsWLCAmJgYp37NlZWVrFu3jilTprToa9cWpMa4FVVn1nw5fasuRMHguPnObq0pTNeBzWajuFgrjQi4M4Aq7ITUllGoFlBLuZARBlAotbasVRtcyBhX2Coos5bjYzCz/sQ3AIzu7H4xvxBCCCFax0svvcSsWbOYMmUKOp2OOXPmMGfOnCbHZGdnYzAYGD58eJPnjR07lrFjxzb6ekPXGjBgAFu2bGly3pEjR/LTTz81+npUVFSzbetSUlIYOnQoN910U5PnXU4SGLci+xEFe5EOXaAd1VamHVQUFJ0Om+VCGYVOr1BcXISqqhi9vKgMsqGgaIGxqkL1PqCy3vwjQ9rxkU+Hmu2ga8o1XKgvBjAbvPEz+FJaXca5ynzKqss5Vnock87EbeEjLvGdCyGEEKKlRo8ezcGDBzl58iSdO7v2G9wNGzYwdepUevTo0caraztGo5HFixd7ehlOJDBuJWq1ilqgYj9kRBdbBfaatiOOXe+q0Ru1G+wUPY5aInOQL9WKQhB+eGEAtQQtKFZA8atzgUr8DPD2kEl8d/ac2xlj0MopSkvLyKvKZ9Pp7wEYGT4MP6Pvpbx1IYQQQlyiGTNmuHX+tGnT2mgll8/UqVM9vYR6pMa4laiFdlDBdqQ2UK0JjGvqi62l1eiM2p91esVRX0yQdr6jG4W9prBeCQZD3zqPAZwoLyHQy4cxEZ1BrSnSb2Y76LpqyylOlJ3i36e2AjC60+3uv1khhBBCiGuQBMatxaBgesIXpX1NllepKYWoadVmKatGV5M9VnQXMsYVQVqJRUeCQK0GtaZrhO6ifn6Kkbd+2cKPeYcx6HQ1NcjgbsYYYN2xLymtLiPcHCa73QkhhBBC1JDAuJXognR4P+2PV2JNY2udFhgrdTLGtaUUqmJ3ZIytgTr06AjGvyYotgPezmUUNc5WFvBfuz8m31Lnr83FGmO4kDE+cv4YAHd0ug2dCx0thBBCCCF+DSQqam2KtnucorOB0V6nxtjmKKWotJZgt9vRGfXgpyeMQHToLpRR6EKggebgRZZiqlU7hbb2oIsAxReUxjcEuVhtxrjWHZ1GNXKmEEIIIcSvj9x819oUPWACqlB87I4aY0udGuPSmo069IFeqIpSU0ZRcaE8Qld/9xe7aqfYUtPH2CsQ9B0A93oPh9QJjG/oMJAIn45ujRdCCCGEuJZJxrgtKNre7Iqv3bEdtLVOV4qyKq2+2BqkffnDCKpz011ggzfUnbeWYlO1euQAL/8WLatuYHyn3HQnhBBCCOFEAuO2UCcwdmSMy+pkjCtqOkoEGvHDjJ9qAnueduzim+5qFFm0zT38DL4Yde7tQ14r0iccH4OZIK9AbglvfJ90IYQQQohfIwmM20JNYEzdUorzWmCsqiqllUXa60FGOhIIahHaFs8GLWPcgMKqml3vTK7XFF/Mz+jLfw//K+8OX4i33rvF8wghhBCi9eTn5xMaGkp2dranl3LFufHGG/nss88u2/UkMG4LtTfg+Vy4+a62lKLKdh6bvRr0CrQzaPXFjpvugrVebg2ozRgHeQVe0tK6+HWio0/oJc0hhBBCiNYzb948xowZQ1RUFAB79uzh4YcfpnPnzpjNZvr06cNbb73VornXrl1L3759MZlM9O3bl3Xr1jU7Zu/evYwcORKz2UxkZCRz586tt73z5s2bGTx4MN7e3nTr1o1ly5a5fe0tW7YwZswYIiIiUBSFf/7zn/XmeOmll3jhhRew2+31XmsLEhi3CW9Uu3YfnuJlAy7cfFdeXaSdEmhAr9MRovrUZIxptIwCoLAmMA5sYX2xEEIIIa48FRUVpKSkMHnyZMexXbt2ERISwocffkhmZiYvvvgiycnJLFmyxK2509LSGD9+PBMnTmTPnj1MnDiRcePGsX379kbHlJSUEB8fT0REBDt27GDx4sUsWLCAhQsXOs45evQoo0ePZsSIEezevZvZs2fzzDPPsHbtWreuXVZWxqBBg5p8X3fddRfFxcV8/fXXbr33FlM97O2331ajoqJUk8mk3nDDDeqWLVuaPL+yslKdPXu22qVLF9XLy0vt1q2bmpKS4vL1iouLVUAtLi6+1KU3yV60U1Ut/6faCnJUVVXVDTN2q9/+8Zi66V/p6po1a9Q1O79QN6t7VbX6mKpa/k9VrXubnO/9Ax+pv/nfu9Q//7y4TdcthBBCXIma+vldUVGhZmVlqRUVFR5Y2aVZu3atGhwc3Ox506dPV2+99Va35h43bpx6xx13OB1LTExUH3rooUbHvPPOO2pAQIBaWVnpODZv3jw1IiJCtdvtqqqq6vPPP6/27t3badxTTz2l3nTTTS2+NqCuW7euwdcmTZqkTpw4sdE1N8ed7w+PZozXrFnDzJkzefHFF9m9ezcjRozgzjvvJCcnp9Ex48aN49///jcpKSn88ssvrF69mt69e1/GVbtGrdA6UChGK6CVUmgZ45ob74KMdLSbwX5ae66LbHK+oqoiAAK9Wl5jLIQQQvxaqKqKWmH3zOOisoOmbNmyhdjY2GbPKy4upn379m59DdLS0khISHA6lpiYyLZt25ocM3LkSEwmk9OYU6dOOWqgG5t3586dWK3WFl+7MUOGDGHr1q1uj2sJj/YxXrhwIU8++aTj1weLFi3i66+/ZunSpcybN6/e+Rs2bGDz5s0cOXLE8c1RW4/TmKqqKqqqqhzPS0pKWu8NNEEt10EHQK9d+0IpRW1g7EVHW82fdaGgC2pyvqKaHsZBEhgLIYQQzatUKfnNGY9c2v/7MDDX36irIdnZ2URERDR5TlpaGp988glffvmlW+vIzc0lLCzM6VhYWBi5ublNjrk4tqqdIzc3l+jo6Ebnra6uJi8vj/Dw8BZduzGRkZHk5ORom6Pp2jan67GMscViYdeuXfU+TSQkJDT6aeJf//oXsbGx/PnPfyYyMpKePXsya9YsKioqGr3OvHnzCAgIcDw6d3ZvU4yWUktrvrQ1W0Nby6pRvOzYVO2TlE87L9pRDXiDrkuz8xU5aowlMBZCCCGuFRUVFXh7N94pKjMzk3vuuYeXX36Z+Ph4t+dXLtpJV1XVesdcGXPx8Zae09y1G2I2m7Hb7U6JzrbisYxxXl4eNpvNrU8TR44c4fvvv8fb25t169aRl5fH9OnTKSgo4P33329wTHJyMklJSY7nJSUllyU4Vs/X/EGxgGrDUlqN3WTRjpl0hCsKiqoDw3U1u+U1rbC2lOIS2rUJIYQQvxreipa59dC1XRUcHExhYWGDr2VlZXHbbbcxZcoU/vCHP7i9jI4dO9aLqc6ePVsv9nJlDFzIHDd2jsFgoEOHDi2+dmMKCgrw8fHBbDa7PdZdHu9K4c6nCbvdjqIorFq1iiFDhjB69GgWLlzIihUrGs0am0wm/P39nR5tTbXbwaKgWhQUBVArtMDYqyYw9tXTUVVA1wkUX5fmLHJsBy2BsRBCCNEcRVFQzDrPPNzIisbExJCVlVXveGZmJrfeeiuPPfYYr732Wou+BnFxcaSmpjod27hxI8OGNb7JV1xcHFu2bMFisTiNiYiIcJRYNDZvbGwsRqOxxdduTEZGBjfccIPb41rCY4FxcHAwer3erU8T4eHhREZGEhBwITjs06cPqqpy4sSJNl2vW6q1XntqWc2X157NHW+ZaX/DKe25j54Q/EEX7tJ0dtVOsQTGQgghxDUnMTGRzMxMp6xxbVAcHx9PUlISubm55Obmcu7cObfmnjFjBhs3bmT+/Pns37+f+fPn88033zBz5kzHOUuWLGHUqFGO5xMmTMBkMjFp0iQyMjJYt24dr7/+OklJSY6Af9q0aRw7doykpCT27dvH+++/T0pKCrNmzXLr2qWlpaSnp5Oeng5obeDS09PrNWHYunVrvdLbtuKxwNjLy4vBgwfX+zSRmpra6KeJ4cOHc+rUKUpLSx3HDhw4gE6no1OnTm26XrfYagPjmhIJtYzIWAPldq02Ru+rx0t/Hbj4ibLEeh472pzSx1gIIYS4dgwYMIDY2Fg++eQTx7FPP/2Uc+fOsWrVKsLDwx2PG2+80WmsoiisWLGi0bmHDRvGxx9/zPLlyxk4cCArVqxgzZo1DB061HFOXl4ehw8fdjwPCAggNTWVEydOEBsby/Tp00lKSnIqS42Ojmb9+vVs2rSJ66+/nldffZW//e1vPPDAA25de+fOncTExBATEwNAUlISMTExvPzyy45zTp48ybZt23j88cfd+Kq2nKK601Okla1Zs4aJEyeybNky4uLiePfdd/nv//5vMjMz6dq1K8nJyZw8eZKVK1cC2ieLPn36cNNNN/HKK6+Ql5fH5MmTGTlyJP/93//t0jVLSkoICAiguLi4zcoq1NJKqnccBrMO442BVFtUUn+fie0/7JSXFuMzKJT/6HWLy/MdPZ/Do1um087ox/qEj9tkzUIIIcSVrKmf35WVlRw9epTo6Ogmb2S7Uq1fv55Zs2aRkZHhcteF7OxsevToQVZWFj169GjjFXrOc889R3FxMe+++26L53Dn+8Oj7drGjx9Pfn4+c+fO5fTp0/Tv35/169fTtWtXAE6fPu2UTvfz8yM1NZX//M//JDY2lg4dOjBu3Dj+9Kc/eeotNEitttX8yQD6cKpKKjn4pYVOidpnEB/zhbriKpuFz7L/l1vDf9PoVs2ttR20EEIIIa48o0eP5uDBg5w8edLlBgEbNmxg6tSp13RQDBAaGupUotHWPBoYA0yfPp3p06c3+FpDvx7o3bt3vfKLK05NKQV67VOfpaxaO1ytlVK082nnOPUf2f9i2f4V7C8+yCs3/FeD052rzAMgSDpSCCGEENekGTNmuHX+tGnT2mglV5bnnnvusl7P410prkk1N98pBu3Lay2zoZhUVJuWSQ70vvAroB3ndgOwr+hAo9MdLDkKQLRf1zZZrhBCCCGEkMC4bdQEwBi0m++qzlvRB9aUcnspBBq1jHGVzcLewn0AnK44Q4nlfL2pAA4Wa0XxPQO6t+GihRBCCCF+3SQwbgNqtXMphbXMhj685piPAT9Fa1CdUbgPi/1Cn8CDJUfqz6WqjuMSGAshhBBCtB0JjNtCTY2xUltjXFqNV3etNZtiNmDSaaXdu/L2OA07WHKYi52pOEeJ9Tx6RS+lFEIIIYQQbUgC47ZQ7VxKYS2rxljTZlnvZUKp+arvytcC406+EQAcKK4fGB+oCZaj23XBS29sw0ULIYQQQvy6SWDcBtSLu1KUVqNrr9UYexl8UHRQai1jf9FBAMZH3wvAgQZKKWrLKHr4SxmFEEIIIURbksC4LdTWGDu6UlSj89GyyCad1sM4vSADO3Y6+Ubwm7CbADheepKK6kqnqRw33vl3uxwrF0IIIYT41ZLAuC1cXGNcZkPRa8d80Fq17cpLB2Bwh0EEe7envSkQO3YOnz/qNFVtKYXceCeEEEJcm/Lz8wkNDSU7O9vTS3HJkiVLuPvuuz29jDYhgXFbuKjGuKq0CqUmWPZD26Sj9sa7wcGDgAulEgeLL5RTFFYVc64yHwWF6/yjL8vShRBCCHF5zZs3jzFjxhAVFVXvtfz8fDp16oSiKBQVFbk999q1a+nbty8mk4m+ffuybt26Js+vrKxk0qRJDBgwAIPBwL333lvvnClTprBjxw6+//57t9dzpZPAuA1cXGNcqaspjzAo+FT7k19ZyNHSHBQUbugwEICeNYHxgTqdKWq7VET6huNj8LlMqxdCCCHE5VJRUUFKSgqTJ09u8PUnn3ySgQMHtmjutLQ0xo8fz8SJE9mzZw8TJ05k3LhxbN++vdExNpsNs9nMM888w+23397gOSaTiQkTJrB48eIWretKJoFxW7j45jv/msDYx4CX3chPNd0orvPvRoCXVlrRI0CrIa7bmeKAo75YyiiEEEKIa9FXX32FwWAgLi6u3mtLly6lqKiIWbNmtWjuRYsWER8fT3JyMr179yY5OZlRo0axaNGiRsf4+vqydOlSpkyZQseOHRs97+677+af//wnFRUVLVrblUoC47bg2BJaK6WwBVgB0Ju80OmUemUUAL0CrgPgaOkxqu3VALKxhxBCCNFCqqpiUys88lBV1eV1btmyhdjY2HrHs7KymDt3LitXrkSna1m4lpaWRkJCgtOxxMREtm3b1qL56oqNjcVqtfLjjz9e8lxXEoOnF3CtUVW1zpbQ2jey2s6KAhiM3ig61dG/OLbDhcA43ByGn8GX0uoysktzuM6/m6Osood0pBBCCCHcYqeSrcX3eOTaIwI+R4/ZpXOzs7OJiIhwOlZVVcXDDz/Mm2++SZcuXThypH47V1fk5uYSFhbmdCwsLIzc3NwWzVeXr68vgYGBZGdnM3LkyEue70ohGePWZleh9oNiTSmFatYCZS+9D1Ys5FacxaAYGNi+n2OYoly4we6X4sOUWcs5UXYKkB7GQgghxLWqoqICb29vp2PJycn06dOHRx555JLnVxTF6bmqqvWOtZTZbKa8vLxV5rpSSMa4tdXWF4MjMFa8bFAF3vhRXF0MQL+gXpgNzv8j9AzoTnpBBgdLjtDJNxyAUO9ggkwBl2ftQgghxDVChzcjAj732LVdFRwcTGFhodOxb7/9lr179/KPf/wDwFGaERwczIsvvsgrr7zi0twdO3aslx0+e/ZsvSxySxUUFBASEtIqc10pJDBubbWt2vS6C5/IVO2YWQ2gwKJ98w+uU0ZR60LLtsN08gmvOSZlFEIIIYS7FEVxuZzBk2JiYvjwww+djq1du9bpprYdO3bwxBNPsHXrVrp3d/23yHFxcaSmpvLss886jm3cuJFhw4Zd8roPHz5MZWUlMTExlzzXlUQC49Z2cau2SguKRTvmaw0kp/o4ADcE12+90rOmM8XBkqOE+2if5nrIjXdCCCHENSsxMZHk5GQKCwsJCgoCqBf85uXlAdCnTx8CAwNdnnvGjBncfPPNzJ8/n3vuuYfPP/+cb775xqn/8JIlS1i3bh3//ve/HceysrKwWCwUFBRw/vx50tPTAbj++usd52zdupVu3bq5FahfDaTGuJWpF20HfbYwX3uuA2+bH2X2MgCi/LrUG9vFtzNeOi8qbBX8cEa7y1NatQkhhBDXrgEDBhAbG8snn3zi9lhFUVixYkWjrw8bNoyPP/6Y5cuXM3DgQFasWMGaNWsYOnSo45y8vDwOHz7sNG706NHExMTwxRdfsGnTJmJiYuplhlevXs2UKVPcXvOVTgLj1ubYDlpr1ZZ/vkg77mVAp+iwqhYAvPX1648MOj3d/aMAKK3WAujaLLIQQgghrk0vvfQSb731Fna7vcHXb7nlFlRVdcoWZ2dnYzAYGD58eJNzjx07lv3792OxWNi3bx/333+/0+tz5syptxV1dnY2qqrWe9TKyMggPT2d3/72t+690avAJQXGhw4d4uuvv3bUwbjTt++aVe3cqq24ogQARW8EwIoVBQUvnbHB4T3r1BT7G9sR6n1tFbULIYQQwtno0aN56qmnOHnypMtjNmzYwNSpU+nRo0cbrqxhp06dYuXKlQQEXHvNAVpUY5yfn8/48eP59ttvURSFgwcP0q1bNyZPnkxgYCB/+ctfWnudV42Lt4Mur9TamOhVL0ALjL313o22SulZs9GH9ufurdZSRQghhBBXrhkzZrh1/rRp09poJc27eNOQa0mLMsbPPvssBoOBnJwcfHx8HMfHjx/Phg0bWm1xV6WLaoyrLNp20Aa7dmesVbXgrTc1OrxuFwrpSCGEEEIIcfm0KGO8ceNGvv76azp16uR0vEePHhw7dqxVFnbVqtn1rrbGuLpKqyk2WbUPEFrGuPHAuFu7KPSKDptqlxvvhBBCCCEuoxZljMvKypwyxbXy8vIwmRoP+n4V6mSM7dhRq6oBMFvaAWDFUm9jj7pMei+GhQ7B39iOmA71W7oJIYQQQoi20aLA+Oabb2blypWO54qiYLfbefPNN7n11ltbbXFXo7o1xqX2Siiv2dzD7g9opRSmJjLGAHNvSOazUR/QwTuoTdcqhBBCCCEuaFEpxZtvvsktt9zCzp07sVgsPP/882RmZlJQUMAPP/zQ2mu8uthqu1LoKagsAhVUwNvoC2ilFOYGWrXVZdDpMaBv23UKIYQQQggnLcoY9+3bl59//pkhQ4YQHx9PWVkZ999/P7t3777mdkBxW3VtH2MdhWXFAKiKDr1RC3StNJ8xFkIIIYQQl5/bGWOr1UpCQgJ///vfeeWVV9piTVe3OqUU58tLAVAtOnRm7TOIFQvtmskYCyGEEEKIy8/tjLHRaCQjI0P66zbiwpbQeqrKtI1P7JU6dDV9ja1q010phBBCCPHrkp+fT2hoaL0d6K5ms2bN4plnnvH0MtzWolKKRx99lJSUlNZey7WhtsZYr6OyWAuMbSU6FMOFjLEExkIIIYSoNW/ePMaMGUNUVFS91/Lz8+nUqROKolBUVOT23GvXrqVv376YTCb69u3LunXrmh2zd+9eRo4cidlsJjIykrlz5zrtbnz69GkmTJhAr1690Ol0zJw5s94czz//PMuXL+fo0aNur9mTWnTzncVi4b333iM1NZXY2Fh8fX2dXl+4cGGrLO6qVFtjbNBRVaDteld9Toei0zLs1TU73wkhhBBCVFRUkJKSwvr16xt8/cknn2TgwIFubRddKy0tjfHjx/Pqq69y3333sW7dOsaNG8f333/P0KFDGxxTUlJCfHw8t956Kzt27ODAgQNMmjQJX19ffv/73wNQVVVFSEgIL774In/9618bnCc0NJSEhASWLVvG/Pnz3V67p7QoY5yRkcENN9yAv78/Bw4cYPfu3Y5Henp6Ky/x6qGqqqPGuMpmxV5mBcB6Uu8oPZFSCiGEEELU+uqrrzAYDMTFxdV7benSpRQVFTFr1qwWzb1o0SLi4+NJTk6md+/eJCcnM2rUKBYtWtTomFWrVlFZWcmKFSvo378/999/P7Nnz2bhwoWOrHFUVBRvvfUWjz76KAEBAY3Odffdd7N69eoWrd1TWpQx/u6771p7HdeG2hvvgMKSEu0Pfnps54DawBiLZIyFEEKINqaqKtjV5k9sCzrF5XuxtmzZQmxsbL3jWVlZzJ07l+3bt3PkyJEWLSMtLY1nn33W6VhiYmKTgXFaWhojR4502rAtMTGR5ORksrOziY6Odvn6Q4YM4fjx4xw7doyuXbu6vX5PaFFgXNeJEydQFIXIyMjWWM/VrU5gXFBUqP2hvRdqkQrUCYyb2PlOCCGEEK3ArlK9ZZ9HLm24uQ/oXQuMs7OziYiIcDpWVVXFww8/zJtvvkmXLl1aHBjn5uYSFhbmdCwsLIzc3Nwmx1xc61w7R25urluBcW1smJ2dfdUExi0qpbDb7cydO5eAgAC6du1Kly5dCAwM5NVXX8Vutzc/QR3vvPMO0dHReHt7M3jwYLZu3drouZs2bUJRlHqP/fv3t+RttL4620EXFBZof25vxF5cJzCWUgohhBBC1KioqMDb2zlhlpycTJ8+fXjkkUcuef6LM9eqqjabzW5oTEPHm2M2mwEoLy93a5wntShj/OKLL5KSksIbb7zB8OHDUVWVH374gTlz5lBZWclrr73m0jxr1qxh5syZvPPOOwwfPpy///3v3HnnnWRlZdGlS5dGx/3yyy/4+/s7noeEhLTkbbS62u2gVZ2OgvyawDjAiFJ54Vc50pVCCCGEuAx0ipa59dC1XRUcHExhYaHTsW+//Za9e/fyj3/8A7gQmAYHB/Piiy+6vI9Ex44d62WHz549Wy+L7MoYoMlxDSko0GKhKyVOc0WLAuMPPviA9957j7vvvttxbNCgQURGRjJ9+nSXA+OFCxfy5JNPMnnyZEArEv/6669ZunQp8+bNa3RcaGgogYGBLVl626rWWrVVKjaqKqtAATsGdMZqxykSGAshhBBtT1EUl8sZPCkmJoYPP/zQ6djatWupqKhwPN+xYwdPPPEEW7dudWuH4bi4OFJTU53qjDdu3MiwYcOaHDN79mwsFgteXl6OMREREQ22k2tKRkYGRqORfv36uTXOk1pUSlFQUEDv3r3rHe/du7fj00FzLBYLu3btIiEhwel4QkIC27Zta3JsTEwM4eHhjBo1qtkbAauqqigpKXF6tJmajHGhteab2d+AWgp604UvczXVcvOdEEIIIQDtxrbMzEynrHH37t3p37+/41Fb19unTx9CQ0NdnnvGjBls3LiR+fPns3//fubPn88333zj1Hd4yZIljBo1yvF8woQJmEwmJk2aREZGBuvWreP1118nKSnJqZQiPT2d9PR0SktLOXfuHOnp6WRlZTldf+vWrYwYMcJRUnE1aFFgPGjQIJYsWVLv+JIlSxg0aJBLc+Tl5WGz2dwqCg8PD+fdd99l7dq1fPbZZ/Tq1YtRo0axZcuWRq8zb948AgICHI/OnTu7tL4WcQTGNbU07b2wF6uYArRPXFbVAoBZAmMhhBBCAAMGDCA2NpZPPvnE7bGKorBixYpGXx82bBgff/wxy5cvZ+DAgaxYsYI1a9Y49TDOy8vj8OHDjucBAQGkpqZy4sQJYmNjmT59OklJSSQlJTnNHRMTQ0xMDLt27eKjjz4iJiaG0aNHO52zevVqpkyZ4vb78qQWlVL8+c9/5q677uKbb74hLi4ORVHYtm0bx48fb7RBdWPcKQrv1asXvXr1cjyPi4vj+PHjLFiwgJtvvrnBMcnJyU5/mSUlJW0WHKs1pRSFVbWBsRH7MRWTv1Y6YUULjE1SSiGEEEKIGi+99BKzZs1iypQp6HT1c5a33HKL085zoHV6MBgMDB8+vMm5x44dy9ixYxt9fc6cOcyZM8fp2IABA5pMOgL11nOxL7/8Er1e3+S1r0QtyhiPHDmSX375hfvuu4+ioiIKCgq4//77+eWXXxgxYoRLcwQHB6PX690uCr/YTTfdxMGDBxt93WQy4e/v7/RoMzY7qqpSVFGqPW/vhVqs4tXOCFwIjCVjLIQQQohao0eP5qmnnnJrd7sNGzYwdepUevTo0YYra7mysjKWL1+OwXDJnYEvqxavNjIy0uWb7Bri5eXF4MGDSU1N5b777nMcT01N5Z577nF5nt27dxMeHt7idbSqajulNgtWuw1Fr6AGGLAXWTDVBsaqthOeZIyFEEIIUdeMGTPcOn/atGlttJLWMW7cOE8voUVaFBgvX74cPz8/HnzwQafjn376KeXl5Tz22GMuzZOUlMTEiROJjY0lLi6Od999l5ycHMdfdnJyMidPnmTlypWA1rUiKiqKfv36YbFY+PDDD1m7di1r165tydtofTYbRdXajXdegT5YdAr2IhUvP+3L7MgYGyQwFkIIIYS40rQoMH7jjTdYtmxZveOhoaFMnTrV5cB4/Pjx5OfnM3fuXE6fPk3//v1Zv369Y3eU06dPk5OT4zjfYrEwa9YsTp48idlspl+/fnz55Zf1ir09Ra22U1gTGBuDvLEA9mIVo19tKUVNxlgngbEQQgghxJWmRYHxsWPHGtwSsGvXrk6BrCumT5/O9OnTG3zt4jstn3/+eZ5//nm35r+sbHZHqzZ9ey34VYtUjOE1GWNV62Hs7s4xQgghhBCi7bXo5rvQ0FB+/vnnesf37NlDhw4dLnlRVyu7tZqi6krtSXutRZu9WMXoU1tKYZUexkIIIYQQV6gWBcYPPfQQzzzzDN999x02mw2bzca3337LjBkzeOihh1p7jVeNkooy7KgY9Aaq22lZYefAWHa9E0IIIYS4UrWolOJPf/oTx44dY9SoUY42HHa7nUcffZTXX3+9VRd4NSmoadMWFBBAsaJtA20vUjH61nalsEjGWAghhBDiCtWiwNjLy4s1a9bwpz/9ifT0dMxmMwMGDHDcNPdrVVRZBkD7wEDy0GqN1SIVL98LpRRmyRgLIYQQQlyRWlRKUatHjx48+OCD3HnnnRQWFjrt8/1rVGjRdrzzDwp0HLMXqxjMF0oppIexEEIIIerKz88nNDSU7OxsTy/lsho7diwLFy709DKctCgwnjlzJikpKQDYbDZGjhzJDTfcQOfOndm0aVNrru+qYbVaKam58c63g7a7nlquQjUYvPXaOarcfCeEEEIIZ/PmzWPMmDFERUXVey0/P59OnTqhKApFRUVuz7127Vr69u2LyWSib9++rFu3rtkxe/fuZeTIkZjNZiIjI5k7d269LaA3b97M4MGD8fb2plu3bvXa+GZmZvLAAw8QFRWFoigsWrSo3nVefvllXnvtNUpKStx+X22lRYHxP/7xDwYNGgTAF198wZEjR9i/fz8zZ87kxRdfbNUFXi3KSs6jQ4dJMaCr6VtsL9a+ifSmmsAYK2aDBMZCCCGE0FRUVJCSksLkyZMbfP3JJ59k4MCBLZo7LS2N8ePHM3HiRPbs2cPEiRMZN24c27dvb3RMSUkJ8fHxREREsGPHDhYvXsyCBQucMrtHjx5l9OjRjBgxgt27dzN79myeeeYZpw3XysvL6datG2+88QYdO3Zs8FoDBw4kKiqKVatWtej9tYUWBcZ5eXmON7l+/XrGjRtHz549efLJJ9m7d2+rLvBqEeDbjjHBvbmlfTesejsA9sKawNirNjCWUgohhBBCXPDVV19hMBiIi4ur99rSpUspKipi1qxZLZp70aJFxMfHk5ycTO/evUlOTmbUqFENZm9rrVq1isrKSlasWEH//v25//77mT17NgsXLnRkjZctW0aXLl1YtGgRffr0YfLkyTzxxBMsWLDAMc+NN97Im2++yUMPPYTJ1Hjsc/fdd7N69eoWvb+20KLAOCwsjKysLGw2Gxs2bOD2228HtE8Her2+VRd41TDqMcRE0+767lgVG6B1pADQGbUvsxULZimlEEIIIdqcqqpUWq0eeVxcdtCULVu2EBsbW+94VlYWc+fOZeXKleh0LbslLC0tjYSEBKdjiYmJbNu2rckxI0eOdApmExMTOXXqlKMGurF5d+7cidVqdWuNQ4YM4ccff6SqqsqtcW2lRV0pHn/8ccaNG0d4eDiKohAfHw/A9u3b6d27d6su8Gqh6HUoQb4AWDgPaIGxwaxHqfmGtqpW2knGWAghhGhzVdXV3LP8HY9c+/PHp+NtNLp0bnZ2NhEREU7HqqqqePjhh3nzzTfp0qULR44cadE6cnNzCQsLczoWFhZGbm5uk2MurnWunSM3N5fo6OhG562uriYvL4/w8HCX1xgZGUlVVRW5ublXRHezFgXGc+bMoX///hw/fpwHH3zQ8alCr9fzwgsvtOoCr0YWtB7GarGKd6ARVausqMkY+3hwZUIIIYS4klRUVODt7fzb5OTkZPr06cMjjzxyyfMriuL0XFXVesdcGXPxcVfOcYXZbAa0qoMrQYsCY9BabACcOHECu92OTqfjsccea7WFXc1qA2N7Uf3A2Fvf3oMrE0IIIX4dTAYDnz8+3WPXdlVwcHC9drfffvste/fu5R//+AdwIegMDg7mxRdf5JVXXnFp7o4dO9bLDp89e7ZetteVMXAhc9zYOQaDgQ4dOri0tloFBQUAhISEuDWurbQ4MK7Vt29f0tPT6datW2us55pwITC2YwowomolxzXt2qSUQgghhGhriqK4XM7gSTExMXz44YdOx9auXUtFRYXj+Y4dO3jiiSfYunUr3bt3d3nuuLg4UlNTefbZZx3HNm7cyLBhw5ocM3v2bCwWC15eXo4xERERjhKLuLg4vvjiC6dxGzduJDY2FqObX/OMjAw6depEcHCwW+PayiVt8AG4VWD+a2GtDYyLVbwDvS7KGMvNd0IIIYTQJCYmkpmZ6ZQ17t69O/3793c8oqOjAejTpw+hoaEuzz1jxgw2btzI/Pnz2b9/P/Pnz+ebb75h5syZjnOWLFnCqFGjHM8nTJiAyWRi0qRJZGRksG7dOl5//XWSkpIcZRLTpk3j2LFjJCUlsW/fPt5//31SUlKcumdYLBbS09NJT0/HYrFw8uRJ0tPTOXTokNMat27dWu9GPk+65MBY1Nd4jbFkjIUQQghxwYABA4iNjeWTTz5xe6yiKKxYsaLR14cNG8bHH3/M8uXLGThwICtWrGDNmjUMHTrUcU5eXh6HDx92PA8ICCA1NZUTJ04QGxvL9OnTSUpKIikpyXFOdHQ069evZ9OmTVx//fW8+uqr/O1vf+OBBx5wnHPq1CliYmKIiYnh9OnTLFiwgJiYGKd+zZWVlaxbt44pU6a4/d7biqJeYsp33rx5/Pa3vyUwMLCVltS2SkpKCAgIoLi4GH9//za5xtf8RAnl5D9cyoCBXeka34eq8/CXyj/yyA3/wbCwG9vkukIIIcS1qqmf35WVlRw9epTo6Oh6N7JdDdavX8+sWbPIyMhwuTVbdnY2PXr0ICsrix49erTxCtvG22+/zeeff87GjRvb9DrufH9cco1xcnLypU5xzbHUKaUwBXphr8kYV2PFbJCMsRBCCCEuGD16NAcPHuTkyZN07tzZpTEbNmxg6tSpV21QDGA0Glm8eLGnl+HkkgPjuo4fP84f//hH3n///dac9qqiomJBa26tNtCVQna+E0IIIcTFZsyY4db506ZNa6OVXD5Tp0719BLqadUa44KCAj744IPWnPKqY8OOHa06xV6k4h1QJzBWrbLznRBCCCHEFcqtjPG//vWvJl9v6c4s15LajhSqTUUtA1OgkWrJGAshhBBCXPHcCozvvfdeFEVpskWbuzueXGsudKTQnnsHenH+nAooNTvfScZYCCGEEOJK5FYpRXh4OGvXrsVutzf4+Omnn9pqnVcNx413hVqauH67NgmMhRBCCCGuRG4FxoMHD24y+G0um/xrULcjBYApwAhoWXSrasGk9/LU0oQQQgghRBPcKqV47rnnKCsra/T16667ju++++6SF3U1q+1IYS9S0Xnp0HvpHa8pOgWdInuqCCGEEEJcidwKjCMjIx3bEjbE19eXkSNHXvKirmaOjHFNRwrUCzXXBr0ExUIIIYQQVyq3IrUePXpw7tw5x/Px48dz5syZVl/U1azedtA1lSXVqhWTQcoohBBCCOEsPz+f0NBQsrOzPb2UK86NN97IZ599dtmu51ZgfHH98Pr165ssrfg1csoYy413QgghhGjGvHnzGDNmDFFRUfVey8/Pp1OnTiiKQlFRkdtzr127lr59+2Iymejbty/r1q1rdszevXsZOXIkZrOZyMhI5s6dWy8G3Lx5M4MHD8bb25tu3bqxbNkyt6+9ZcsWxowZQ0REBIqi8M9//rPeHC+99BIvvPAC9tpthNuY/G6/lVnrBMamQK+LAmPpYSyEEEKICyoqKkhJSWHy5MkNvv7kk08ycODAFs2dlpbG+PHjmThxInv27GHixImMGzeO7du3NzqmpKSE+Ph4IiIi2LFjB4sXL2bBggUsXLjQcc7Ro0cZPXo0I0aMYPfu3cyePZtnnnmGtWvXunXtsrIyBg0axJIlSxpdz1133UVxcTFff/11i74G7nKrxlhRlHp9in/tfYsvVq+UwrHrnUUyxkIIIcRloqo4fgZfbooOXA2PvvrqKwwGA3FxcfVeW7p0KUVFRbz88st89dVXbq9j0aJFxMfHk5ycDEBycjKbN29m0aJFrF69usExq1atorKykhUrVmAymejfvz8HDhxg4cKFJCUloSgKy5Yto0uXLixatAiAPn36sHPnThYsWMADDzzg8rXvvPNO7rzzzibfg16vZ/To0axevbrZc1uDW4GxqqpMmjQJk0nLfFZWVjJt2jR8fX2dzructSBXmrrt2ry7GbHbtOOSMRZCCCEuH9UOR7d45trRN4Oib/480MoJYmNj6x3Pyspi7ty5bN++vcU7C6elpfHss886HUtMTHQEtI2NGTlypCPWqx2TnJxMdnY20dHRpKWlkZCQUG/elJQUrFYrRqOxRdduzJAhQ/jzn//s9riWcCswfuyxx5yeP/LII626mGtB4zXGFgmMhRBCCOEkOzubiIgIp2NVVVU8/PDDvPnmm3Tp0qXFgXFubi5hYWFOx8LCwsjNzW1yzMW1zrVz5ObmEh0d3ei81dXV5OXlER4e3qJrNyYyMpKcnBzsdjs6XdtWAbsVGC9fvryt1nHNcPQxLr6oxliV7aCFEEKIy0XRaZlbT13bVRUVFXh7O8cHycnJ9OnTp1USkBeXvKqq2mwZbENjLj7e0nNaUoJrNpux2+1UVVVhNpvdHu8OufmuFamoWNFqJ9QGulKYJGMshBBCXBaKAjq9Zx7uxH7BwcEUFhY6Hfv222/59NNPMRgMGAwGRo0a5Tj3j3/8o8tzd+zYsV6G9uzZs/Uyua6MgQuZ48bOMRgMdOjQocXXbkxBQQE+Pj5tHhSDBMatqrYjBdTUGF9USiEZYyGEEELUFRMTQ1ZWltOxtWvXsmfPHtLT00lPT+e9994DYOvWrTz99NMuzx0XF0dqaqrTsY0bNzJs2LAmx2zZsgWLxeI0JiIiwlFi0di8sbGxGI3GFl+7MRkZGdxwww1uj2sJCYxbkaMjRZkK1eBdp5SiWjLGQgghhLhIYmIimZmZTlnj7t27079/f8ejdtfhPn36EBoa6vLcM2bMYOPGjcyfP5/9+/czf/58vvnmG2bOnOk4Z8mSJY6MNMCECRMwmUxMmjSJjIwM1q1bx+uvv+7oSAEwbdo0jh07RlJSEvv27eP9998nJSWFWbNmuXXt0tJSR/APWhu49PR0cnJynN7H1q1b693s11Y8Hhi/8847REdH4+3tzeDBg9m6datL43744QcMBgPXX3992y7QDXVvvAMwBVzY+c6qWjAbJGMshBBCiAsGDBhAbGwsn3zyidtjFUVhxYoVjb4+bNgwPv74Y5YvX87AgQNZsWIFa9asYejQoY5z8vLyOHz4sON5QEAAqampnDhxgtjYWKZPn05SUhJJSUmOc6Kjo1m/fj2bNm3i+uuv59VXX+Vvf/ubo1Wbq9feuXMnMTExxMTEAJCUlERMTAwvv/yy45yTJ0+ybds2Hn/8cbe/Pi2hqBdvZXIZrVmzhokTJ/LOO+8wfPhw/v73v/Pee++RlZVFly5dGh1XXFzMDTfcwHXXXceZM2ccnzRcUVJSQkBAAMXFxfj7+7fCu7ggl0K2kok100be6FKe2ptARZGR/MOwrfo7fHqU8kDUmFa9phBCCPFr0NTP78rKSo4ePepItF1t1q9fz6xZs8jIyHC560J2djY9evQgKyuLHj16tPEKPee5556juLiYd999t8VzuPP94dGM8cKFC3nyySeZPHkyffr0YdGiRXTu3JmlS5c2Oe6pp55iwoQJDTbD9qS6PYwVvYJXO4O0axNCCCFEk0aPHs1TTz3FyZMnXR6zYcMGpk6dek0HxQChoaG8+uqrl+16brVra00Wi4Vdu3bxwgsvOB1PSEhg27ZtjY5bvnw5hw8f5sMPP+RPf/pTs9epqqqiqqrK8bykpKTli26Go1VbkYopwIiiKHXatVnx1rduhloIIYQQ14YZM2a4df60adPaaCVXlueee+6yXs9jGeO8vDxsNptbzZ8PHjzICy+8wKpVqzAYXIvp582bR0BAgOPRuXPnS157Yy7eDhqQjLEQQgghxFXC4zffudr82WazMWHCBF555RV69uzp8vzJyckUFxc7HsePH7/kNTfGade7gIYC46uv7kkIIYQQ4tfCY6UUwcHB6PV6l5s/nz9/np07d7J7925+97vfAWC321FVFYPBwMaNG7ntttvqjTOZTE77fbelC4GxHVNNYGx3KqWQwFgIIYQQ4krlsYyxl5cXgwcPrtf8OTU1tcHmz/7+/uzdu9fR7y49PZ1p06bRq1cv0tPTndp/eIq1zs13UkohhBBCCHF18VjGGLR+dRMnTiQ2Npa4uDjeffddcnJyHAXlycnJnDx5kpUrV6LT6ejfv7/T+NDQULy9vesd9xSnGuNQL+3PdbaElj7GQgghhBBXLo8GxuPHjyc/P5+5c+dy+vRp+vfvz/r16+natSsAp0+frrf7yZWsbo2xqWdtxlgFFKyqBZNOMsZCCCGEEFcqjwbGANOnT2f69OkNvtbUbi4Ac+bMYc6cOa2/qBayNFBKYbPbAT1WLJgNEhgLIYQQQlypPN6V4lqhojr6GKt1ulLYbNrGglasmKTGWAghhBAXyc/PJzQ0lOzsbE8vxSVLlizh7rvv9vQy2oQExq3Ehh07WhBsL1LxDtRqjO01gTGKHb2i99TyhBBCCHGFmjdvHmPGjCEqKspxbMeOHYwaNYrAwECCgoJISEggPT3d7bnXrl1L3759MZlM9O3bl3Xr1jV5fmVlJZMmTWLAgAEYDAbuvffeeudMmTKFHTt28P3337u9niudBMatpLYjhVqtopaBKbC2XZsWGCu6+r2ZhRBCCPHrVlFRQUpKCpMnT3YcO3/+PImJiXTp0oXt27fz/fff4+/vT2JiIlar1eW509LSGD9+PBMnTmTPnj1MnDiRcePGsX379kbH2Gw2zGYzzzzzDLfffnuD55hMJiZMmMDixYtdf6NXCY/XGF8rDOi5ge5s/WsWgFO7NgVQ5COIEEIIcdmoqkq1pcIj1zZ4mRvcrKwhX331FQaDgbi4OMexX375hcLCQubOnevYsfePf/wjAwcOJCcnh+7du7s096JFi4iPjyc5ORnQun1t3ryZRYsWsXr16gbH+Pr6snTpUgB++OEHioqKGjzv7rvvJiEhgYqKCsxms0vruRpIYNxKjBiIsobx5ZKfABylFLWBsU4yxkIIIcRlU22pYMXTgzxy7Ulv78Fo8nHp3C1bthAbG+t0rFevXgQHB5OSksLs2bOx2WykpKTQr18/R+cuV6SlpfHss886HUtMTGTRokUuz9GY2NhYrFYrP/74IyNHjrzk+a4UksdsRVUlF369YfKv+cxh1wJivV4CYyGEEEI4y87OJiIiwulYu3bt2LRpEx9++CFmsxk/Pz++/vpr1q9fj8Hgek4zNze33m7CYWFh9XYdbglfX18CAwOvmhsGXSUZ41ZUVaQFxl7+BnSGms8cak1grJPPIEIIIcTlYvAyM+ntPR67tqsqKirw9vaud+yJJ55g+PDhrF69GpvNxoIFCxg9ejQ7duxwq3Th4pIOVVVdLvNojtlspry8vFXmulJIYNyKKmsC49pWbQCoWkBsMEhgLIQQQlwuiqK4XM7gScHBwRQWFjod++ijj8jOziYtLQ1dTWLto48+IigoiM8//5yHHnrIpbk7duxYLzt89uzZelnkliooKCAkJKRV5rpSSLTWiiqLLECd+mIVdLWBsU5atQkhhBDCWUxMDFlZWU7HysvL0el0Tpnd2ud2u93luePi4khNTXU6tnHjRoYNG3ZpiwYOHz5MZWUlMTExlzzXlUQC41ZUWaxljE11OlLUMhglMBZCCCGEs8TERDIzM52yxvHx8RQWFvL000+zb98+MjMzefzxxzEYDNx6660uzz1jxgw2btzI/Pnz2b9/P/Pnz+ebb75h5syZjnOWLFnCqFGjnMZlZWWRnp5OQUEBxcXFpKen1+uhvHXrVrp16+Zyh4yrhQTGrai2xti7gcDYSy9VK0IIIYRwNmDAAGJjY/nkk08cx3r37s0XX3zBzz//TFxcHCNGjODUqVNs2LCB8PBwx3mKorBixYpG5x42bBgff/wxy5cvZ+DAgaxYsYI1a9YwdOhQxzl5eXkcPnzYadzo0aOJiYnhiy++YNOmTcTExNTLDK9evZopU6Zc4ru/8ki01oourjGuDYztqh0vvbGxYUIIIYT4FXvppZeYNWsWU6ZMcdQUx8fHEx8f3+iY7OxsDAYDw4cPb3LusWPHMnbs2EZfnzNnDnPmzKk3d1MyMjJIT093CuavFRIYt6J6NcY1gbEVC2aDd2PDhBBCCPErNnr0aA4ePMjJkycdG3o0Z8OGDUydOpUePXq08erqO3XqFCtXriQgIOCyX7utSWDcimpLKS6uMbZixaQ3eWpZQgghhLjCzZgxw63zp02b1kYraV5CQoLHrt3WpMa4FVU2UmNsVS2Y9ZIxFkIIIYS4kklg3Ipqu1LUL6Ww4i2BsRBCCCHEFU0C41Z0ocb44lIKC95SSiGEEEIIcUWTwLgVOWqMAxoIjOXmOyGEEEKIK5oExq1Etat1SikurjG2SsZYCCGEEOIKJ4FxK6k6Xw2q9ucGM8YSGAshhBBCXNGkXVsrsZRY0Xnp0BsUDCZt+2e70813/h5cnRBCCCGEaI5kjFuJf2cfnj5wB1N2X9ilpjZjXC2lFEIIIYRoRH5+PqGhoc3uOHc1mTVrFs8884ynl+E2CYxbkaIoGLz1jueqXaut0Eop5OY7IYQQQtQ3b948xowZQ1RUlOPYjh07GDVqFIGBgQQFBZGQkEB6errbc69du5a+fftiMpno27cv69ata3bM3r17GTlyJGazmcjISObOnYuqqo7XT58+zYQJE+jVqxc6nY6ZM2fWm+P5559n+fLlHD161O01e5IExm3IarNp/5UaYyGEEEI0oKKigpSUFCZPnuw4dv78eRITE+nSpQvbt2/n+++/x9/fn8TERKxWq8tzp6WlMX78eCZOnMiePXuYOHEi48aNY/v27Y2OKSkpIT4+noiICHbs2MHixYtZsGABCxcudJxTVVVFSEgIL774IoMGDWpwntDQUBISEli2bJnL670SSGDchqqrq4HarhSSMRZCCCEuG1UF1eahh9r8+mp89dVXGAwG4uLiHMd++eUXCgsLmTt3Lr169aJfv3788Y9/5OzZs+Tk5Lg896JFi4iPjyc5OZnevXuTnJzMqFGjWLRoUaNjVq1aRWVlJStWrKB///7cf//9zJ49m4ULFzqyxlFRUbz11ls8+uijBAQENDrX3XffzerVq11e75VAbr5rQ1abVmRsU6ox6PTNnC2EEEKI1mOH6p2eubQhFnDt5/6WLVuIjY11OtarVy+Cg4NJSUlh9uzZ2Gw2UlJS6NevH127dnV5GWlpaTz77LNOxxITE5sMjNPS0hg5ciQmk8lpTHJyMtnZ2URHR7t8/SFDhnD8+HGOHTvm1ro9STLGbai6WiulsCs2D69ECCGEEFei7OxsIiIinI61a9eOTZs28eGHH2I2m/Hz8+Prr79m/fr1GAyu5zRzc3MJCwtzOhYWFkZubq7bY2pfc0dkZCTAVXVToWSM25DNpqJDyxgLIYQQ4nLS1WRuPXRtF1VUVODt7V3v2BNPPMHw4cNZvXo1NpuNBQsWMHr0aHbs2IHZbHZ5fkVRnJ6rqlrvmCtjGjrenNp1lpeXuzXOkyQwbkO2ai0wtuskYyyEEEJcVoqCq+UMnhQcHExhYaHTsY8++ojs7GzS0tLQ6XSOY0FBQXz++ec89NBDLs3dsWPHelnes2fP1ssIuzIGaHJcQwoKCgAICQlxa5wnSSlFG1Jr4mFVAmMhhBBCNCAmJoasrCynY+Xl5eh0OqcMbe1ze+3uYS6Ii4sjNTXV6djGjRsZNmxYk2O2bNmCxWJxGhMREeHUTs4VGRkZGI1G+vXr59Y4T5LAuA3VBsboXP8mFkIIIcSvR2JiIpmZmU5Z4/j4eAoLC3n66afZt28fmZmZPP744xgMBm699VaX554xYwYbN25k/vz57N+/n/nz5/PNN9849R1esmQJo0aNcjyfMGECJpOJSZMmkZGRwbp163j99ddJSkpyCtTT09NJT0+ntLSUc+fOkZ6eXi/A37p1KyNGjHCr9MPTJDBuQ6q95surl8BYCCGEEPUNGDCA2NhYPvnkE8ex3r1788UXX/Dzzz8TFxfHiBEjOHXqFBs2bCA8PNxxnqIorFixotG5hw0bxscff8zy5csZOHAgK1asYM2aNQwdOtRxTl5eHocPH3Y8DwgIIDU1lRMnThAbG8v06dNJSkoiKSnJae6YmBhiYmLYtWsXH330ETExMYwePdrpnNWrVzNlypSWfmk8QlFVN5rtXQNKSkoICAiguLgYf3//Nr1W1vdlmKy+/K/5A2bc9FibXksIIYS4ljX187uyspKjR48SHR1d70a2q8H69euZNWsWGRkZjpri5mRnZ9OjRw+ysrLo0aNHG6/QfV9++SXPPfccP//8s1udNNqCO98fcvNdG1JqMsbSwlgIIYQQjRk9ejQHDx7k5MmTdO7c2aUxGzZsYOrUqVdkUAxQVlbG8uXLPR4Uu8vjpRTvvPOOI4IfPHgwW7dubfTc77//nuHDh9OhQwfMZjO9e/fmr3/962VcrXt0du2bQWdwr72JEEIIIX5dZsyY4XJQDDBt2jTefvvtNlzRpRk3bpxTycbVwqNh/Jo1a5g5cybvvPMOw4cP5+9//zt33nknWVlZdOnSpd75vr6+/O53v2PgwIH4+vry/fff89RTT+Hr68vUqVM98A4ap6qgV7Uvr0EvgbEQQgghxJXOoxnjhQsX8uSTTzJ58mT69OnDokWL6Ny5M0uXLm3w/JiYGB5++GH69etHVFQUjzzyCImJiU1mmT1FtYOCFhCH+Hbw8GqEEEIIIURzPBYYWywWdu3aRUJCgtPxhIQEtm3b5tIcu3fvZtu2bYwcObLRc6qqqigpKXF6XA5Wa8120KqdgcG9L8s1hRBCCCFEy3ksMM7Ly8Nms7m9hzdAp06dMJlMxMbG8vTTTzN58uRGz503bx4BAQGOhzv1O5fiaPFxACxUEe3f9bJcUwghhBBCtJzHb75ryR7eW7duZefOnSxbtoxFixaxevXqRs9NTk6muLjY8Th+/HirrLs5BwqPAGDTVaNXpC2FEEIIIcSVzmM33wUHB6PX693ewxsgOjoa0Jpinzlzhjlz5vDwww83eK7JZMJkMrXOot1wpCiHfkirNiGEEEKIq4XHMsZeXl4MHjy43h7eqampTe7hfTFVVamqqmrt5V0SVVU5cV4L+E1Go4dXI4QQQgghXOHRUoqkpCTee+893n//ffbt28ezzz5LTk4O06ZNA7QyiEcffdRx/ttvv80XX3zBwYMHOXjwIMuXL2fBggU88sgjnnoLDcouPY7Npm0DbTZ6eXg1QgghhLiS5efnExoaSnZ2tqeXclmNHTuWhQsXenoZTjwaGI8fP55FixYxd+5crr/+erZs2cL69evp2lW7We306dPk5OQ4zrfb7SQnJ3P99dcTGxvL4sWLeeONN5g7d66n3kKDfi7IxBszAHqDx8u4hRBCCHEFmzdvHmPGjCEqKspxbMeOHYwaNYrAwECCgoJISEggPT3d7bnXrl1L3759MZlM9O3bl3Xr1jU7Zu/evYwcORKz2UxkZCRz585FVVWnczZv3szgwYPx9vamW7duLFu2zOn1zMxMHnjgAaKiolAUhUWLFtW7zssvv8xrr7122TqGucLjUdv06dPJzs6mqqqKXbt2cfPNNzteW7FiBZs2bXI8/8///E8yMjIoKyujuLiYn376id/+9rcu7yt+uewpyMSkaIGx3HcnhBBCiMZUVFSQkpLi1GHr/PnzJCYm0qVLF7Zv387333+Pv78/iYmJWK1Wl+dOS0tj/PjxTJw4kT179jBx4kTGjRvH9u3bGx1TUlJCfHw8ERER7Nixg8WLF7NgwQKnzO7Ro0cZPXo0I0aMYPfu3cyePZtnnnmGtWvXOs4pLy+nW7duvPHGG3Ts2LHBaw0cOJCoqChWrVrl8ntqa4p68UeAa1xJSQkBAQEUFxfj7+/fJtd44N+Pc2P1SB70mkS7jhDap00uI4QQQvxqNPXzu7KykqNHjxIdHY23tzeg3e9jLS/3xFIx+vg022Gr1meffcZTTz3FuXPnHMd27tzJjTfeSE5OjqPN7N69exk4cCCHDh2ie/fuLs09fvx4SkpK+OqrrxzH7rjjDoKCghrt6LV06VKSk5M5c+aMo3nBG2+8weLFizlx4gSKovBf//Vf/Otf/2Lfvn2OcdOmTWPPnj2kpaXVmzMqKoqZM2cyc+bMeq+98sor/Pvf/2bLli0uvaeWaOj7ozEe3RL6WpRbfpazlecwG30A6UohhBBCeIK1vJx5fn4euXZyaSlevr4unbtlyxZiY2OdjvXq1Yvg4GBSUlKYPXs2NpuNlJQU+vXr5yg3dUVaWhrPPvus07HExMQGyxrqjhk5cqRTR6/ExESSk5PJzs4mOjqatLS0ehu0JSYmkpKSgtVqxehG44EhQ4Ywb948qqqqPNJF7GJXVg3CNSC9IAOAjibt1wZSSiGEEEKIxmRnZxMREeF0rF27dmzatIkPP/wQs9mMn58fX3/9NevXr8dgcD2nmZub6/ZGao2NqX2tqXOqq6vJy8tzeX0AkZGRVFVVNbu52+UiGeNW9nNBJgBhpjCokIyxEEII4QlGHx+SS0s9dm1XVVRU1Pv1fkVFBU888QTDhw9n9erV2Gw2FixYwOjRo9mxYwdms9nl+VuykVpDYy4+7so5rqh9L+UeKnu5mATGrWxPTWAcbAzWAmP5CgshhBCXnaIoLpczeFJwcDCFhYVOxz766COys7NJS0tzNBj46KOPCAoK4vPPP+ehhx5yae6OHTu6vZFaY2PgQua4sXMMBgMdOnRwaW21CgoKAAgJCXFrXFuRUopWVFhVRE7ZCQAC9AGAlFIIIYQQonExMTFkZWU5HSsvL0en0zllX2uf2+12l+eOi4urt5Haxo0bm9xILS4uji1btmCxWJzGREREONrJNTZvbGysW/XFABkZGXTq1Ing4GC3xrUVCYxbUW22uFu7rujsWqpYSimEEEII0ZjExEQyMzOdssbx8fEUFhby9NNPs2/fPjIzM3n88ccxGAzceuutLs89Y8YMNm7cyPz589m/fz/z58/nm2++ceoOsWTJEkaNGuV4PmHCBEwmE5MmTSIjI4N169bx+uuvk5SU5AjUp02bxrFjx0hKSmLfvn28//77pKSkMGvWLMc8FouF9PR00tPTsVgsnDx5kvT0dA4dOuS0xq1bt9a7kc+TJDBuRbX1xYPa98du045JxlgIIYQQjRkwYACxsbF88sknjmO9e/fmiy++4OeffyYuLo4RI0Zw6tQpNmzYQHh4uOM8RVFYsWJFo3MPGzaMjz/+mOXLlzNw4EBWrFjBmjVrGDp0qOOcvLw8Dh8+7HgeEBBAamoqJ06cIDY2lunTp5OUlERSUpLjnOjoaNavX8+mTZu4/vrrefXVV/nb3/7GAw884Djn1KlTxMTEEBMTw+nTp1mwYAExMTFO/ZorKytZt24dU6ZMafHXr7VJH+NW9OTWGRwoOcwfY56jZ85IrBUQEQPmwFa9jBBCCPGr424f46vJ+vXrmTVrFhkZGS5vWpadnU2PHj3IysqiR48ebbzCtvH222/z+eefs3Hjxja9jvQx9oAyazmHSo4CMKh9P8q0P0ophRBCCCGaNHr0aA4ePMjJkycdG3o0Z8OGDUydOvWqDYoBjEYjixcv9vQynEhg3ErOVebTzb8rldWVhHgHUyqlFEIIIYRw0YwZM9w6f9q0aW20kstn6tSpnl5CPRIYt5Kodp1ZPmIxFpsVVcVRYywZYyGEEEKIq4PcfNfKvPRG1DqdVCQwFkIIIYS4Okhg3AZqs8UgpRRCCCGEEFcLCYzbgFqnvtjNnRGFEEIIIYSHSGDcBqS+WAghhBDi6iOBcRtQpSOFEEIIIcRVRwLjNiAZYyGEEEKIq48Exm3AXq39VwJjIYQQQjQnPz+f0NBQsrOzPb2UK86NN97IZ599dtmuJ4FxG7BLKYUQQgghXDRv3jzGjBlDVFSU49iOHTsYNWoUgYGBBAUFkZCQQHp6uttzr127lr59+2Iymejbty/r1q1rdszevXsZOXIkZrOZyMhI5s6di6qqTuds3ryZwYMH4+3tTbdu3Vi2bJnb196yZQtjxowhIiICRVH45z//WW+Ol156iRdeeAG73V7vtbYggXEbUKWUQgghhBAuqKioICUlhcmTJzuOnT9/nsTERLp06cL27dv5/vvv8ff3JzExEavV6vLcaWlpjB8/nokTJ7Jnzx4mTpzIuHHj2L59e6NjSkpKiI+PJyIigh07drB48WIWLFjAwoULHeccPXqU0aNHM2LECHbv3s3s2bN55plnWLt2rVvXLisrY9CgQSxZsqTR9dx1110UFxfz9ddfu/y+L4WiXvwR4BpXUlJCQEAAxcXF+Pv7t8k1Co9BwRFo1xFC+7TJJYQQQohflaZ+fldWVnL06FGio6Px9vYGQEXFxuXJMl5Mjw4F1/q1fvbZZzz11FOcO3fOcWznzp3ceOON5OTk0LlzZ0DL4g4cOJBDhw7RvXt3l+YeP348JSUlfPXVV45jd9xxB0FBQaxevbrBMUuXLiU5OZkzZ85gMpkAeOONN1i8eDEnTpxAURT+67/+i3/961/s27fPMW7atGns2bOHtLS0Fl1bURTWrVvHvffeW++1xx9/HJvNxsqVK1163xdr6PujMbIldBuQrhRCCCGEZ9mws440j1z7PuIw4FoQsGXLFmJjY52O9erVi+DgYFJSUpg9ezY2m42UlBT69etH165dXV5HWloazz77rNOxxMREFi1a1OSYkSNHOoLi2jHJyclkZ2cTHR1NWloaCQkJ9eZNSUnBarViNBpbdO3GDBkyhD//+c9uj2sJKaVoA9KVQgghhBCuyM7OJiIiwulYu3bt2LRpEx9++CFmsxk/Pz++/vpr1q9fj8Hgek4zNzeXsLAwp2NhYWHk5ua6Pab2tabOqa6uJi8vr8XXbkxkZCQ5OTmXpc5YMsZtQAJjIYQQwrP06LiPOI9d21UVFRX1fr1fUVHBE088wfDhw1m9ejU2m40FCxYwevRoduzYgdlsdnl+5aIteFVVrXfMlTEXH2/pOc1duyFmsxm73U5VVZVb770lJDBuA45SCvnqCiGEEB6hoLhczuBJwcHBFBYWOh376KOPyM7OJi0tDZ1O5zgWFBTE559/zkMPPeTS3B07dqyXoT179my9TK4rY+BC5rixcwwGAx06dGjxtRtTUFCAj49PmwfFIKUUbUIyxkIIIYRwRUxMDFlZWU7HysvL0el0TtnV2ufulBPExcWRmprqdGzjxo0MGzasyTFbtmzBYrE4jYmIiHC0k2ts3tjYWIxGY4uv3ZiMjAxuuOEGt8e1hATGbUACYyGEEEK4IjExkczMTKescXx8PIWFhTz99NPs27ePzMxMHn/8cQwGA7feeqvLc8+YMYONGzcyf/589u/fz/z58/nmm2+YOXOm45wlS5YwatQox/MJEyZgMpmYNGkSGRkZrFu3jtdff52kpCRHoD5t2jSOHTtGUlIS+/bt4/333yclJYVZs2a5de3S0lLS09Md/ZmPHj1Keno6OTk5Tu9j69at9W72azPqr0xxcbEKqMXFxW12jeM7VPXQt6pamtdmlxBCCCF+VZr6+V1RUaFmZWWpFRUVHljZpbvpppvUZcuWOR3buHGjOnz4cDUgIEANCgpSb7vtNjUtLc3pHEBdvnx5k3N/+umnaq9evVSj0aj27t1bXbt2rdPrf/zjH9WuXbs6Hfv555/VESNGqCaTSe3YsaM6Z84c1W63O52zadMmNSYmRvXy8lKjoqLUpUuXun3t7777TgXqPR577DHHOSdOnFCNRqN6/PjxJt9nU9z5/pA+xm0gZztYyyEiBsyBbXIJIYQQ4lfF3T7GV5P169cza9YsMjIyHDXFzcnOzqZHjx5kZWXRo0ePNl6h5zz33HMUFxfz7rvvtngO6WPsYVJKIYQQQghXjR49moMHD3Ly5EnHhh7N2bBhA1OnTr2mg2KA0NBQpxKNtiaBcRtQq7X/ygYfQgghhHDFjBkz3Dp/2rRpbbSSK8tzzz13Wa8nN9+1MlWVjLEQQgghxNVIAuNWptbpoiKBsRBCCCHE1UMC41ZWu7kHSCmFEEIIIcTVxOOB8TvvvOO4S3Dw4MFs3bq10XM/++wz4uPjCQkJwd/fn7i4OL7++uvLuNrm1ZZRKDpowa6HQgghhBDCQzwaGK9Zs4aZM2fy4osvsnv3bkaMGMGdd95Zr7FzrS1bthAfH8/69evZtWsXt956K2PGjGH37t2XeeWNc9QXy22NQgghhBBXFY/2MR46dCg33HADS5cudRzr06cP9957L/PmzXNpjn79+jF+/Hhefvlll85v6z7GlcVw8icwmKHrTa0+vRBCCPGrdC33MRZty53vD49ljC0WC7t27aq3xV9CQgLbtm1zaQ673c758+dp3759o+dUVVVRUlLi9GhL0pFCCCGEEOLq5LHAOC8vD5vNRlhYmNPxsLAwcnNzXZrjL3/5C2VlZYwbN67Rc+bNm0dAQIDj4Wrj7JaSwFgIIYQQ7sjPzyc0NJTs7GxPL6XVzJo1i2eeecbTy3Cbx2++Uy66Q01V1XrHGrJ69WrmzJnDmjVrCA0NbfS85ORkiouLHY/jx49f8pqbUtuVQjpSCCGEEMIV8+bNY8yYMURFRTmOzZgxg8GDB2Mymbj++usbHKeqKgsWLKBnz56YTCY6d+7M66+/7vb13WmEAHD69GkmTJhAr1690Ol0zJw5s945zz//PMuXL+fo0aNur8eTPBYYBwcHo9fr62WHz549Wy+LfLE1a9bw5JNP8sknn3D77bc3ea7JZMLf39/p0ZYkYyyEEEIIV1VUVJCSksLkyZOdjquqyhNPPMH48eMbHTtjxgzee+89FixYwP79+/niiy8YMmSIW9d3txECaGWqISEhvPjiiwwaNKjBc0JDQ0lISGDZsmVurcfTPNY7wcvLi8GDB5Oamsp9993nOJ6amso999zT6LjVq1fzxBNPsHr1au66667LsVS32Gu2g5bAWAghhPAcVVWxWss9cm2j0cel334DfPXVVxgMBuLi4pyO/+1vfwPg3Llz/Pzzz/XG7du3j6VLl5KRkUGvXr1avNaFCxfy5JNPOgLzRYsW8fXXX7N06dJGGyFERUXx1ltvAfD+++83Ovfdd9/NSy+9xPz581u8vsvNo03FkpKSmDhxIrGxscTFxfHuu++Sk5Pj2P87OTmZkydPsnLlSkALih999FHeeustbrrpJke22Ww2ExAQ4LH3UZeUUgghhBCeZ7WWM2+en0eunZxcipeXr0vnbtmyhdjYWLev8cUXX9CtWzf+93//lzvuuANVVbn99tv585//3GRTgrpqGyG88MILTsfdaYTQlCFDhnD8+HGOHTtG165dL3m+y8GjNcbjx49n0aJFzJ07l+uvv54tW7awfv16xxfv9OnTTqn8v//971RXV/P0008THh7ueMyYMcNTb6EeKaUQQgghhKuys7OJiIhwe9yRI0c4duwYn376KStXrmTFihXs2rWLsWPHujxHazRCaEpkZCTAVXVToce3oZg+fTrTp09v8LUVK1Y4Pd+0aVPbL+gSSWAshBBCeJ7R6ENycqnHru2qioqKFvVettvtVFVVsXLlSnr27AlASkoKgwcP5pdffnGrvKKljRCaYzabASgv90xJS0t4PDC+1kgphRBCCOF5iqK4XM7gScHBwRQWFro9Ljw8HIPB4AiKQdskDSAnJ8elwPhSGiG4oqCgAICQkJBLnuty8Xi7tmuNZIyFEEII4aqYmBiysrLcHjd8+HCqq6s5fPiw49iBAwcAXK7nrdsIoa7U1FSGDRvm9poulpGRgdFopF+/fpc81+UigXErcwTGkosXQgghRDMSExPJzMyslzU+dOgQ6enp5ObmUlFRQXp6Ounp6VgsFgBuv/12brjhBp544gl2797Nrl27eOqpp4iPj3fKIjcnKSmJ9957j/fff599+/bx7LPPOjVCAK0ZwqOPPuo0rnY9paWlnDt3jvT09HoB/tatWxkxYoSjpOJqIOFbK5NSCiGEEEK4asCAAcTGxvLJJ5/w1FNPOY5PnjyZzZs3O57HxMQAcPToUaKiotDpdHzxxRf853/+JzfffDO+vr7ceeed/OUvf3GMyc7OJjo6mu+++45bbrmlweuPHz+e/Px85s6dy+nTp+nfv79TIwSo3wyh7noAdu3axUcffUTXrl2dbrRbvXo1r7zySou+Lp6iqKqqenoRl1NJyf9v796joqzzP4C/B4YZQI1UlIuiE7txyw1hkCOhsRWCUK6rsppripklqQmylBfWtTYF9bAu26aw5njhaOrhoCVm3vanaMlWEigEXhmBMI7XhZSR6/f3h+ucxgGcwUeG0ffrnDkr3+d7ez49Z+cz3/nO89TByckJtbW1D+VhH5XfAE31gHsA4PCk5N0TERE9ljp6/759+za0Wq3+6W3WZu/evUhKSkJJSQlsbKT7Mv/IkSMYN24cysvL0bt3b8n6NcUXX3yBd999F6dOnYJcbtl1WHOuD64YS4x7jImIiMgc0dHROHfuHKqrq+Hh4SFZv/v27cPixYu7PCkGgFu3bmHjxo0WT4rNZV2ztQLcSkFERETmehjPZFixYoXkfZpq4sSJFhv7QfDHdxISgivGRERERNaKibGERCuA/+3YZmJMREREZF2YGEvo7jYKgFspiIiIiKwNE2MJ3d1GIbMBJHiSIhERERF1ISbGEuL+YiIiIiLrxcRYQrwjBREREZH1YmIsIa4YExEREVkvJsYSYmJMRERE5rp27Rr69+9v8Djlx0FMTAxWr15t6WkYYGIsIf1WCj42hYiIiEyUmpqKMWPGQKVS6cvi4+OhVquhVCoxdOjQNtsJIZCWlgYvLy8olUp4eHggJSXF7PHXrl2rf1yyWq3GsWPH7tsmLy8ParUa9vb28PT0RGZmpsHxH374ARMmTIBKpYJMJkN6erpRH3/5y1+wfPly1NXVmT3nh4WJsYS4YkxERETm0Ol00Gg0mDlzpkG5EAIzZszApEmT2m0bHx+P9evXIy0tDadPn0Zubi6Cg4PNGn/Hjh1ISEhAcnIyCgsLMXLkSERFRaGysrLdNlqtFtHR0Rg5ciQKCwuxePFizJs3Dzk5Ofo69fX18PT0xIoVK+Dq6tpmP88++yxUKhW2bt1q1pwfJq5tSoiJMRERUTchhOEDBrqSzNbk+7Z++eWXkMvlCAkJMSj/6KOPAABXrlzBqVOnjNqVlZUhIyMDJSUl8Pb27vRUV69ejTfeeEOfmKenp2P//v3IyMhAampqm20yMzMxaNAg/Sqwr68vTpw4gbS0NEyYMAEAMGzYMAwbNgwAsHDhwnbH/93vfodt27bh7bff7vQ5SImJsYRE853/5V0piIiILEy0AOf2Wmbsp6NN3ld59OhRBAUFmT1Ebm4uPD09sWfPHowePRpCCISHh2PVqlXo06ePSX00NjaioKDAKHGNiIjA8ePH222Xn5+PiIgIg7LIyEhoNBo0NTXBzs7O5PMIDg5GamoqGhoaoFQqTW73sHArhYS4YkxERETmuHjxItzd3c1uV15ejoqKCmRnZyMrKwubNm1CQUEBYmJiTO7j6tWraGlpgYuLi0G5i4sLampq2m1XU1PTZpvm5mZcvXrVrPMYMGAAGhoaOhyvK3HFWEJMjImIiLoJme2dlVtLjW0inU4He3t7s4dobW1FQ0MDsrKy4OXlBQDQaDRQq9U4c+aMWdsrZPds+xBCGJWZ0qat8vtxcHAAcGdPcnfAxFhCfMAHERFRNyGTWcVtopydnXHjxg2z27m5uUEul+uTYuDOXl8AqKysNCkxdnZ2hq2trdFq7eXLl41WhH/J1dW1zTZyuRx9+/Y15zRw/fp1AEC/fv3MavewcCuFhLhiTEREROYICAhAaWmp2e1CQ0PR3NyMCxcu6MvOnj0LABg8eLBJfSgUCqjVahw8eNCg/ODBg3juuefabRcSEmLU5sCBAwgKCjJrfzEAlJSUYODAgXB2djar3cPCxFhCTIyJiIjIHJGRkfjhhx+MVo3Pnz+PoqIi1NTUQKfToaioCEVFRWhsbAQAhIeHIzAwEDNmzEBhYSEKCgowa9YsjBo1ymAV+X4SExOxfv16bNiwAWVlZZg/fz4qKysRFxenr7No0SJMmzZN/3dcXBwqKiqQmJiIsrIybNiwARqNBklJSfo6jY2NBnOurq5GUVERzp8/bzD+sWPHjH7IZ1HiMVNbWysAiNraWsn7rvpOiPP/J8TNK5J3TURE9Fjr6P1bp9OJ0tJSodPpLDCzBzd8+HCRmZlpUBYWFiYAGL20Wq2+TnV1tRg/frzo2bOncHFxEdOnTxfXrl3TH9dqtQKAOHz4cIfjr1mzRgwePFgoFAoRGBgo8vLyDI7HxsaKsLAwg7IjR46IgIAAoVAohEqlEhkZGQbH74597+uX/eh0OvHEE0+I/Pz8+wfpAZhzfciE+N9u6cdEXV0dnJycUFtbiyeeeELSviu/AZrqAfehgENvSbsmIiJ6rHX0/n379m1otVr909uszd69e5GUlISSkhLY2Ej3Zf6RI0cwbtw4lJeXo3fv7peYrFmzBp9//jkOHDjwUMcx5/ro/rvSrYh+KwWjSkRERCaKjo7GuXPnUF1dDQ8PD8n63bdvHxYvXtwtk2IAsLOzwz//+U9LT8MAUzgJ8a4URERE1Bnx8fGS97lixQrJ+5TSW2+9ZekpGOGP7yQiBH98R0RERGTNmBhL5e62cjAxJiIiIrJGTIwlcne1GOBWCiIiIiJrxD3GEhEtd1aKBe48bIeIiIiIrAsTY4nI7YGnnr+z15iIiIiIrA+3UkiMq8VERERE1sniifHatWv1N1xWq9U4duxYu3V/+ukn/PGPf4S3tzdsbGyQkJDQdRMlIiIiokeaRRPjHTt2ICEhAcnJySgsLMTIkSMRFRWFysrKNus3NDSgX79+SE5Ohr+/fxfPloiIiEh6165dQ//+/XHx4kVLT6XbGTZsGHbu3Nll41k0MV69ejXeeOMNzJw5E76+vkhPT4eHhwcyMjLarK9SqfCPf/wD06ZNg5OTUxfPloiIiEh6qampGDNmDFQqlb4sPj4earUaSqUSQ4cObbOdEAJpaWnw8vKCUqmEh4cHUlJSzB7fnG/v78rLy4NarYa9vT08PT2RmZlpVCcnJwd+fn5QKpXw8/PDrl27DI4fPXoUY8aMgbu7O2QyGT777DOjPpYsWYKFCxeitbXV7PPqDIslxo2NjSgoKEBERIRBeUREBI4fPy7ZOA0NDairqzN4EREREXUHOp0OGo0GM2fONCgXQmDGjBmYNGlSu23j4+Oxfv16pKWl4fTp08jNzUVwcLBZ45v77T0AaLVaREdHY+TIkSgsLMTixYsxb9485OTk6Ovk5+dj0qRJmDp1Kk6ePImpU6di4sSJ+Oabb/R1bt26BX9/f3z88cftjvXyyy+jtrYW+/fvN+u8Ostid6W4evUqWlpa4OLiYlDu4uKCmpoaycZJTU3FBx98IFl/RERE1P0JIVBf32SRsR0d7SAz8df4X375JeRyOUJCQgzKP/roIwDAlStXcOrUKaN2ZWVlyMjIQElJCby9vTs9119+ew8A6enp2L9/PzIyMpCamtpmm8zMTAwaNAjp6ekAAF9fX5w4cQJpaWmYMGGCvp9Ro0Zh0aJFAIBFixYhLy8P6enp2LZtGwAgKioKUVFRHc7P1tYW0dHR2LZt233rSsHit2u798IRQph8MZli0aJFSExM1P9dV1cHDw8PyfonIiKi7qe+vgk9e/7ZImPfvLkMPXooTKp79OhRBAUFmT1Gbm4uPD09sWfPHowePRpCCISHh2PVqlXo06ePSX3c/fZ+4cKFBuX3+/Y+Pz/f6Bv/yMhIaDQaNDU1wc7ODvn5+Zg/f75RnbvJtDmCg4OxatUqs9t1hsW2Ujg7O8PW1tZodfjy5ctGq8gPQqlU4oknnjB4EREREXUHFy9ehLu7u9ntysvLUVFRgezsbGRlZWHTpk0oKChATEyMyX109tv7mpqaNts0Nzfj6tWrHdbpzK6AAQMGoLKyskv2GVtsxVihUECtVuPgwYMYN26cvvzgwYMYO3aspaZFREREjwBHRzvcvLnMYmObSqfTwd7e3uwxWltb0dDQgKysLHh5eQEANBoN1Go1zpw5Y9b2is58e99Wm3vLpdoV4ODgoD9fBwcHs9ubw6JbKRITEzF16lQEBQUhJCQE69atQ2VlJeLi4gDc2QZRXV2NrKwsfZuioiIAwM2bN3HlyhUUFRVBoVDAz8/PEqdARERE3ZBMJjN5O4MlOTs748aNG2a3c3Nzg1wu1yfFwJ29vgBQWVlpUmLc2W/vXV1d22wjl8vRt2/fDut0ZlfA9evX4ejo+NCTYsDCt2ubNGkS0tPT8de//hVDhw7F0aNHsXfvXgwePBjAnQd63PuryICAAAQEBKCgoACffvopAgICEB0dbYnpExERET2QgIAAlJaWmt0uNDQUzc3NuHDhgr7s7NmzAKDPo+7nl9/e/9LBgwfx3HPPtdsuJCTEqM2BAwcQFBQEOzu7Dut01G97SkpKEBgYaHa7zrD4j+9mz56N2bNnt3ls06ZNRmV3l+qJiIiIrF1kZCQWLVqEGzduoHfv3vry8+fP4+bNm6ipqYFOp9N/Y+7n5weFQoHw8HAEBgZixowZSE9PR2trK+bMmYNRo0YZrCLfz/2+vQeMv8GPi4vDxx9/jMTERLz55pvIz8+HRqPR320CuHMrueeffx4rV67E2LFj8fnnn+PQoUP46quv9HVu3ryJ8+fP6//WarUoKipCnz59MGjQIH35sWPHjH7s99CIx0xtba0AIGpray09FSIiIjJRR+/fOp1OlJaWCp1OZ4GZPbjhw4eLzMxMg7KwsDABwOil1Wr1daqrq8X48eNFz549hYuLi5g+fbq4du2a/rhWqxUAxOHDhzscf82aNWLw4MFCoVCIwMBAkZeXZ3A8NjZWhIWFGZQdOXJEBAQECIVCIVQqlcjIyDDqNzs7W3h7ews7Ozvh4+MjcnJyDI4fPny4zXOMjY3V1/nxxx+FnZ2dqKqq6vAcOmLO9SET4vFagq2rq4OTkxNqa2t5hwoiIiIr0dH79+3bt6HVavVPb7M2e/fuRVJSEkpKSmBjI90u1yNHjmDcuHEoLy83WI22Ju+++y5qa2uxbt26TvdhzvVh8a0UXe3u5wA+AY+IiMh63H3ffhTX86Kjo3Hu3DlUV1dL+qyFffv2YfHixVabFANA//79kZSU1GXjPXYrxj/++CMf8EFERGSlqqqqMHDgQIMya18xpoeLK8YdcHd3R1VVFXr16vVAT9i7+wS9qqoqbsl4yBjrrsV4dx3Guusw1l3nYcVaCIGff/65Uw/DIDLVY5cY29jYGH3SfBB8ml7XYay7FuPddRjrrsNYd52HEWsnJydJ+yO6l0XvY0xERERE1F0wMSYiIiIiAhPjTlMqlVi6dCmUSqWlp/LIY6y7FuPddRjrrsNYdx3GmqzZY3dXCiIiInq08K4U1BFzrg+uGBMRERERgYkxERERkUVdu3YN/fv3x8WLFy09FavT0NCAQYMGoaCgQJL+mBgTERERWVBqairGjBkDlUqlL4uPj4darYZSqcTQoUPbbCeEQFpaGry8vKBUKuHh4YGUlBSzx1+7dq1+m4FarcaxY8fu2yYvLw9qtRr29vbw9PREZmamUZ2cnBz4+flBqVTCz88Pu3btMnvsnTt3IjIyEs7OzpDJZCgqKjI4rlQqkZSUhAULFph30u1gYkxERERkITqdDhqNBjNnzjQoF0JgxowZmDRpUrtt4+PjsX79eqSlpeH06dPIzc1FcHCwWePv2LEDCQkJSE5ORmFhIUaOHImoqChUVla220ar1SI6OhojR45EYWEhFi9ejHnz5iEnJ0dfJz8/H5MmTcLUqVNx8uRJTJ06FRMnTsQ333xj1ti3bt1CaGgoVqxY0e58pkyZgmPHjqGsrMysc2+ToE5Zs2aNUKlUQqlUisDAQHH06FFLT8nqpaSkiKCgINGzZ0/Rr18/MXbsWHH69GmDOq2trWLp0qXCzc1N2Nvbi7CwMFFSUmKhGT8aUlJSBAARHx+vL2OcpfXjjz+KKVOmiD59+ggHBwfh7+8vTpw4oT/OeEujqalJJCcnC5VKJezt7cVTTz0lPvjgA9HS0qKvw1h3Tl5ennjllVeEm5ubACB27dplcNyUuN6+fVvMnTtX9O3bVzg6OooxY8aIqqoqSean0+lEaWmp0Ol0BnNqamqyyKu1tdXkuefk5AhnZ+d2jy9dulT4+/sblZeWlgq5XG70Pmmu4OBgERcXZ1Dm4+MjFi5c2G6b9957T/j4+BiUzZo1SwwfPlz/98SJE8Xo0aMN6kRGRopXX321U2NrtVoBQBQWFrY5p9/+9rdiyZIlbR5r6/poz2P35Dsp3P2Es3btWoSGhuJf//oXoqKiUFpaikGDBll6elYrLy8Pc+bMwbBhw9Dc3Izk5GRERESgtLQUPXr0AACsWrUKq1evxqZNm+Dl5YVly5Zh1KhROHPmDHr16mXhM7A+3333HdatW4dnn33WoJxxls6NGzcQGhqKF154AV9++SX69++PCxcu4Mknn9TXYbylsXLlSmRmZmLz5s145plncOLECbz++utwcnJCfHw8AMa6s27dugV/f3+8/vrrmDBhgtFxU+KakJCA3NxcbN++HX379sWf/vQnvPLKKygoKICtra3kc25pacHOnTsl79cU48ePh1xuWop19OhRBAUFmT1Gbm4uPD09sWfPHowePRpCCISHh2PVqlXo06ePSX00NjaioKAACxcuNCiPiIjA8ePH222Xn5+PiIgIg7LIyEhoNBo0NTXBzs4O+fn5mD9/vlGd9PT0Bxq7PcHBwSZtAbkfbqXohNWrV+ONN97AzJkz4evri/T0dHh4eCAjI8PSU7Nq+/btw/Tp0/HMM8/A398fGzduRGVlpX5DvRAC6enpSE5Oxvjx4zFkyBBs3rwZ9fX1+PTTTy08e+tz8+ZNTJkyBZ988gl69+6tL2ecpbVy5Up4eHhg48aNCA4OhkqlwksvvYRf/epXABhvKeXn52Ps2LF4+eWXoVKpEBMTg4iICJw4cQIAY/0goqKisGzZMowfP97omClxra2thUajwd/+9jeEh4cjICAAW7ZsQXFxMQ4dOtTVp9OtXLx4Ee7u7ma3Ky8vR0VFBbKzs5GVlYVNmzahoKAAMTExJvdx9epVtLS0wMXFxaDcxcUFNTU17barqalps01zczOuXr3aYZ27/XZ27PYMGDBAkh8vcsXYTFJ/wqH21dbWAoD+k69Wq0VNTY3Bp1SlUomwsDAcP34cs2bNssg8rdWcOXPw8ssvIzw8HMuWLdOXM87S2r17NyIjI/GHP/wBeXl5GDBgAGbPno0333wTAOMtpREjRiAzMxNnz56Fl5cXTp48ia+++kq/QsVYPxymxLWgoABNTU0Gddzd3TFkyBAcP34ckZGRks/L1ta2zUS+K5izAq7T6Tp17+XW1lY0NDQgKysLXl5eAACNRgO1Wo0zZ87A29vb5L5kMpnB30IIozJT2txbbkq/nRm7LQ4ODqivrze73b2YGJtJ6k841DYhBBITEzFixAgMGTIEAPTxbSv2FRUVXT5Ha7Z9+3YUFBToV9J+iXGWVnl5OTIyMpCYmIjFixfj22+/xbx586BUKjFt2jTGW0ILFixAbW0tfHx8YGtri5aWFixfvhyTJ08GwGv7YTElrjU1NVAoFAbfTt2t87DeO2UymcnbGSzJ2dkZN27cMLudm5sb5HK5PikGAF9fXwBAZWWlSYmxs7MzbG1tjf4bXL582ei/5y+5urq22UYul6Nv374d1rnbb2fHbs/169fRr18/s9vdi1spOkmqTzjUtrlz5+LUqVPYtm2b0THG/sFUVVUhPj4eW7du7XCVgnGWRmtrKwIDA5GSkoKAgADMmjULb775ptHWK8b7we3YsQNbtmzBp59+iu+//x6bN29GWloaNm/ebFCPsX44OhNXxh4ICAhAaWmp2e1CQ0PR3NyMCxcu6MvOnj0LABg8eLBJfSgUCqjVahw8eNCg/ODBg3juuefabRcSEmLU5sCBAwgKCoKdnV2Hde7229mx21NSUoKAgACz292LibGZpP6EQ8beeecd7N69G4cPH8bAgQP15a6urgDA2D+ggoICXL58GWq1GnK5HHK5HHl5efjoo48gl8v1sWScpeHm5gY/Pz+DMl9fX/3tiHhdS+fdd9/FwoUL8eqrr+I3v/kNpk6divnz5yM1NRUAY/2wmBJXV1dXNDY2Gq2MMvZ3fpD2ww8/GMXm/PnzKCoqQk1NDXQ6HYqKilBUVITGxkYAQHh4OAIDAzFjxgwUFhaioKAAs2bNwqhRowxWke8nMTER69evx4YNG1BWVob58+ejsrIScXFx+jqLFi3CtGnT9H/HxcWhoqICiYmJKCsrw4YNG6DRaJCUlKSvEx8fjwMHDmDlypU4ffo0Vq5ciUOHDiEhIcGssa9fv46ioiL9h4czZ87o4/JLx44dM/pBYKfc974VZCQ4OFi8/fbbBmW+vr4d3tqE7q+1tVXMmTNHuLu7i7Nnz7Z53NXVVaxcuVJf1tDQIJycnERmZmZXTtWq1dXVieLiYoNXUFCQeO2110RxcTHjLLHJkyeLESNGGJQlJCSIkJAQIQSvayn16dNHrF271qAsJSVFPP3000IIxloquOd2babE9b///a+ws7MTO3bs0Ne5dOmSsLGxEfv27XvgOZlzO67uaPjw4UbXYFhYmABg9NJqtfo61dXVYvz48aJnz57CxcVFTJ8+XVy7dk1//O4tzg4fPtzh+GvWrBGDBw8WCoVCBAYGiry8PIPjsbGxIiwszKDsyJEjIiAgQCgUCqFSqURGRoZRv9nZ2cLb21vY2dkJHx8fkZOTY/bYGzdubDMOS5cu1dc5fvy4ePLJJ0V9fX2b52fO9cHEuBO2b98u7OzshEajEaWlpSIhIUH06NFDXLx40dJTs2pvv/22cHJyEkeOHBE//fST/vXLC33FihXCyclJ7Ny5UxQXF4vJkycLNzc3UVdXZ8GZW7+wsDCD+xgzztL59ttvhVwuF8uXLxfnzp0TW7duFY6OjmLLli36Ooy3NGJjY8WAAQPEnj17hFarFTt37hTOzs7ivffe09dhrDvn559/FoWFhaKwsFAAEKtXrxaFhYWioqJCCGFaXOPi4sTAgQPFoUOHxPfffy9efPFF4e/vL5qbmx94ftaeGH/xxRfC19fX4J7bUjh8+LB48sknxfXr1yXtt7uJiYkRy5cvb/c4E+MucL9POGS+tj4RAhAbN27U17l7E3lXV1ehVCrF888/L4qLiy036UfEvYkx4yyt3NxcMWTIEKFUKoWPj49Yt26dwXHGWxp1dXUiPj5eDBo0SNjb2wtPT0+RnJwsGhoa9HUY6845fPhwm///HBsbK4QwLa46nU7MnTtX/6CbV155RVRWVkoyP2tPjIUQIj09XbJ43LVgwQKxatUqSfvsbm7fvi0+/PDDdleLhTDv+pAJ8b/7axARERFZodu3b0Or1eKpp57q1K3P6NFmzvXBH98REREREYGJMRERERERACbGRERE9IhobW219BSoGzJn13D3fyQMERERUQcUCgVsbGxw6dIl9OvXDwqF4rF/cAjdIYTAlStXIJPJ9A8f6Qh/fEdERERWr7GxET/99BPq6+stPRXqZmQyGQYOHIiePXvevy4TYyIiInoUCCHQ3NyMlpYWS0+FuhE7OzvY2tqaVJeJMRERERER+OM7IiIiIiIATIyJiADc2YP22WefWXoaRERkQUyMicjipk+fDplMZvQaPXq0padGRESPEd6ujYi6hdGjR2Pjxo0GZUql0kKzISKixxFXjImoW1AqlXB1dTV49e7dG8CdbQ4ZGRmIioqCg4MDnnrqKWRnZxu0Ly4uxosvvggHBwf07dsXb731Fm7evGlQZ8OGDXjmmWegVCrh5uaGuXPnGhy/evUqxo0bB0dHRzz99NPYvXv3wz1pIiLqVpgYE5FVWLJkCSZMmICTJ0/itddew+TJk1FWVgYAqK+vx+jRo9G7d2989913yM7OxqFDhwwS34yMDMyZMwdvvfUWiouLsXv3bvz61782GOODDz7AxIkTcerUKURHR2PKlCm4fv16l54nERFZDm/XRkQWN336dGzZsgX29vYG5QsWLMCSJUsgk8kQFxeHjIwM/bHhw4cjMDAQa9euxSeffIIFCxagqqoKPXr0AADs3bsXY8aMwaVLl+Di4oIBAwbg9ddfx7Jly9qcg0wmw5///Gd8+OGHAIBbt26hV69e2Lt3L/c6ExE9JrjHmIi6hRdeeMEg8QWAPn366P8dEhJicCwkJARFRUUAgLKyMvj7++uTYgAIDQ1Fa2srzpw5A5lMhkuXLuGll17qcA7PPvus/t89evRAr169cPny5c6eEhERWRkmxkTULfTo0cNoa8P9yGQyAHeednX3323VcXBwMKk/Ozs7o7atra1mzYmIiKwX9xgTkVX4z3/+Y/S3j48PAMDPzw9FRUW4deuW/vjXX38NGxsbeHl5oVevXlCpVPj3v//dpXMmIiLrwhVjIuoWGhoaUFNTY1Aml8vh7OwMAMjOzkZQUBBGjBiBrVu34ttvv4VGowEATJkyBUuXLkVsbCzef/99XLlyBe+88w6mTp0KFxcXAMD777+PuLg49O/fH1FRUfj555/x9ddf45133unaEyUiom6LiTERdQv79u2Dm5ubQZm3tzdOnz4N4M4dI7Zv347Zs2fD1dUVW7duhZ+fHwDA0dER+/fvR3x8PIYNGwZHR0dMmDABq1ev1vcVGxuL27dv4+9//zuSkpLg7OyMmJiYrjtBIiLq9nhXCiLq9mQyGXbt2oXf//73lp4KERE9wrjHmIiIiIgITIyJiIiIiABwjzERWQHu+CIioq7AFWMiIiIiIjAxJiIiIiICwMSYiIiIiAgAE2MiIiIiIgBMjImIiIiIADAxJiIiIiICwMSYiIiIiAgAE2MiIiIiIgDA/wPjcLJpNEt0SQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#By looking this graph we can say that which model gives a good accuracy. We are aware of that this plot not good at differentiate the every value.\n",
    "#However, we are not using this graph to differentiate every value from the each other. Excluding straight lines using the same reasoning that is explained before.\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "x = np.arange(NO_EPOCH)+1\n",
    "\n",
    "colors = ['#e6194B', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#42d4f4', '#f032e6', '#bfef45', '#fabed4', '#469990', '#dcbeff', '#9A6324', '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1', '#000075', '#a9a9a9', '#ffffff', '#000000']\n",
    "best_idx_cvs = []\n",
    "for idx in range(final_stat_s.shape[0]):\n",
    "    best_idx_cvs.append(np.argmax(final_stat_e[idx][2]))\n",
    "    ax.plot(x, epoch_stat_e[idx][2][best_idx_cvs[-1]], label=f'{combinations[idx]}',color=colors[idx]);\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.title('F1-score vs epoch for each different parameters(for best fold)\\n with all features')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"F1-score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean results for each combination(validation accuracy, training accuracy, f1 score, matthews_corrcoef):\n",
      "[[ 0.70031136  0.5         0.62971656 -0.00711718]\n",
      " [ 0.72161172  0.9654629   0.73954937  0.00207676]\n",
      " [ 0.77734432  0.99888889  0.77561811  0.06028804]\n",
      " [ 0.77153846  0.99776442  0.77228368  0.0558397 ]\n",
      " [ 0.44391941  0.5         0.35490236  0.        ]\n",
      " [ 0.77738095  0.97398015  0.78123732  0.11057242]\n",
      " [ 0.76197802  0.99528069  0.7676754   0.05019313]\n",
      " [ 0.77357143  0.99387142  0.77415824  0.06301681]\n",
      " [ 0.44391941  0.5         0.35490236  0.        ]\n",
      " [ 0.75813187  0.97013239  0.76772899  0.08475486]\n",
      " [ 0.78509158  0.99944444  0.78403386  0.1000147 ]\n",
      " [ 0.76393773  0.98603495  0.77216518  0.09282096]\n",
      " [ 0.58684982  0.5         0.50576805  0.        ]\n",
      " [ 0.78117216  0.99832942  0.77731333  0.06073263]\n",
      " [ 0.76003663  0.99944516  0.76418622  0.03169973]\n",
      " [ 0.75043956  0.96731883  0.76524205  0.09621166]\n",
      " [ 0.55031136  0.50056259  0.47320362  0.00677745]\n",
      " [ 0.77728938  0.99887324  0.77817327  0.08706751]\n",
      " [ 0.74860806  0.99469485  0.75853054  0.05085563]\n",
      " [ 0.72364469  0.93803421  0.74436786  0.03787684]]\n"
     ]
    }
   ],
   "source": [
    "#Calculate mean result for the each different hyper parameter combination overall is 20\n",
    "final_mean_e = np.mean(final_stat_e,axis=2)\n",
    "print(f'Mean results for each combination(validation accuracy, training accuracy, f1 score, matthews_corrcoef):\\n{final_mean_e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14aa5a71070>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#we are selecting the overall best model by looking the graph(excluding straight lines)\n",
    "overall_best_e = 18\n",
    "#We are ploting the best fold result with the best parameters\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "#found best fold result\n",
    "best_val_e =np.argmax(final_stat_e[overall_best_e][0])\n",
    "y_v = epoch_stat_e[overall_best_e][0][best_val_e]\n",
    "y_t = epoch_stat_e[overall_best_e][1][best_val_e]\n",
    "x = np.arange(len(y_v))+1\n",
    "\n",
    "ax.plot(x, y_v, label='validation');\n",
    "ax.plot(x, y_t, label='training');\n",
    "\n",
    "plt.title('Accuracy vs epoch for best fold of model with best parameters\\n with all features')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the best epoch result\n",
    "maxIndx_e = np.argmax(epoch_stat_e[overall_best_e][0][best_val_e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our best result epoch(#48)(validation accuracy, training accuracy, f1 score, matthews_corrcoef):[0.85576923 0.99579832 0.85327869 0.31851103]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Our best result epoch(#{maxIndx_e})(validation accuracy, training accuracy, f1 score, matthews_corrcoef):{epoch_stat_e[overall_best_e,:,best_val_e,maxIndx_e]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our mean result(validation accuracy, training accuracy, f1 score, matthews_corrcoef):[0.78509158 0.99944516 0.78403386 0.11057242]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Our mean result(validation accuracy, training accuracy, f1 score, matthews_corrcoef):{np.amax(final_mean_e, axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Recurrent Neural Network(Experimental)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We experimented the RNN and we see that it does not work as we wanted so we experiment on it. Here the feature extraction is different from what we did before. This is just for experiment. We are including both friendship games and betrayal games. We are not excluding any game according to lasted friendship. We are just exclude the seasons that does not have any messages from both parties. We are labelling seasons 1 if it is the last season and if there is a betrayal, otherwise 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = []\n",
    "victim_items = []\n",
    "betrayer_items = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "for entry in diplomacy:\n",
    "    \n",
    "    seasons = seasons_before_betrayal(entry)\n",
    "    vic_game = []\n",
    "    bet_game = []\n",
    "    label_game = []\n",
    "    for i,season in enumerate(seasons):\n",
    "        \n",
    "        if len(season['messages']['victim']) == 0 or len(season['messages']['betrayer']) == 0:\n",
    "            continue\n",
    "        if len(seasons) == i+1 and entry[\"betrayal\"]:\n",
    "            label_item = 1\n",
    "        else:\n",
    "            label_item = 0\n",
    "        label_game.append(label_item)\n",
    "        for who in [\"victim\",\"betrayer\"]:\n",
    "            #politness\n",
    "            politness = [message[\"politeness\"] for message in season[\"messages\"][who]]           \n",
    "            politness_item = np.mean(politness) if len(politness)>=1 else 0\n",
    "            #sentiment\n",
    "            positive_sentiment = [message[\"sentiment\"][\"positive\"] for message in season[\"messages\"][who]]\n",
    "            negative_sentiment = [message[\"sentiment\"][\"negative\"] for message in season[\"messages\"][who]]\n",
    "            neutral_sentiment = [message[\"sentiment\"][\"neutral\"] for message in season[\"messages\"][who]]\n",
    "            positive_item = np.mean(positive_sentiment) if len(positive_sentiment)>=1 else 0\n",
    "            negative_item = np.mean(negative_sentiment) if len(negative_sentiment)>=1 else 0\n",
    "            neutral_item = np.mean(neutral_sentiment) if len(neutral_sentiment)>=1 else 0\n",
    "            #nb_requests\n",
    "            nb_requests = [message[\"n_requests\"] for message in season[\"messages\"][who]]\n",
    "            requests_item = np.mean(nb_requests) if len(nb_requests)>=1 else 0\n",
    "            #nb_words\n",
    "            nb_words = [message[\"n_words\"] for message in season[\"messages\"][who]]\n",
    "            words_item = np.mean(nb_words) if len(nb_words)>=1 else 0\n",
    "            #nb_sentences\n",
    "            nb_sentences = [message[\"n_sentences\"] for message in season[\"messages\"][who]]\n",
    "            sentences_item = np.mean(nb_sentences) if len(nb_sentences)>=1 else 0\n",
    "            #premise\n",
    "            premise = [len(message[\"lexicon_words\"][\"premise\"]) for message in season[\"messages\"][who] if \"premise\" in message[\"lexicon_words\"].keys()]\n",
    "            premise_item = np.mean(premise) if len(premise)>=1 else 0\n",
    "            #claim\n",
    "            claim = [len(message[\"lexicon_words\"][\"claim\"]) for message in season[\"messages\"][who] if \"claim\" in message[\"lexicon_words\"].keys()]\n",
    "            claim_item = np.mean(claim) if len(claim)>=1 else 0\n",
    "            #disc_comparison\n",
    "            disc_comparison = [len(message[\"lexicon_words\"][\"disc_comparison\"]) for message in season[\"messages\"][who] if \"disc_comparison\" in message[\"lexicon_words\"].keys()]\n",
    "            comparison_item = np.mean(disc_comparison) if len(disc_comparison)>=1 else 0\n",
    "            #disc_expansion\n",
    "            disc_expansion = [len(message[\"lexicon_words\"][\"disc_expansion\"]) for message in season[\"messages\"][who] if \"disc_expansion\" in message[\"lexicon_words\"].keys()]\n",
    "            expansion_item = np.mean(disc_expansion) if len(disc_expansion)>=1 else 0\n",
    "            #disc_contingency\n",
    "            disc_contingency = [len(message[\"lexicon_words\"][\"disc_contingency\"]) for message in season[\"messages\"][who] if \"disc_contingency\" in message[\"lexicon_words\"].keys()]\n",
    "            contingency_item = np.mean(disc_contingency) if len(disc_contingency)>=1 else 0\n",
    "            #disc_temporal_future\n",
    "            disc_temporal_future = [len(message[\"lexicon_words\"][\"disc_temporal_future\"]) for message in season[\"messages\"][who] if \"disc_temporal_future\" in message[\"lexicon_words\"].keys()]\n",
    "            temporal_future_item = np.mean(disc_temporal_future) if len(disc_temporal_future)>=1 else 0\n",
    "            #disc_temporal_rest\n",
    "            disc_temporal_rest = [len(message[\"lexicon_words\"][\"disc_temporal_rest\"]) for message in season[\"messages\"][who] if \"disc_temporal_rest\" in message[\"lexicon_words\"].keys()]\n",
    "            temporal_rest_item = np.mean(disc_temporal_rest) if len(disc_temporal_rest)>=1 else 0\n",
    "            \n",
    "            item = [politness_item,positive_item,negative_item,neutral_item,requests_item,words_item,sentences_item,\\\n",
    "                    premise_item,claim_item,comparison_item,expansion_item,contingency_item,temporal_future_item,temporal_rest_item]\n",
    "            \n",
    "            if who == \"victim\":\n",
    "                vic_game.append(item)\n",
    "            else:\n",
    "                bet_game.append(item)\n",
    "          \n",
    "            \n",
    "    if len(vic_game) != 0:\n",
    "        victim_items.append(vic_game)\n",
    "        betrayer_items.append(bet_game)\n",
    "        labels.append(label_game)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need successive seasons information in order to feed it into an RNN.\n",
    "\n",
    "We manage that by creating a list of list and then transforming into an array of objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformation from lists to numpy arrays\n",
    "betrayer_feature = np.array(betrayer_items, dtype=object)\n",
    "betrayer_feature = np.expand_dims(betrayer_feature, axis = 1)\n",
    "\n",
    "victim_feature = np.array(victim_items,dtype=object)\n",
    "victim_feature = np.expand_dims(victim_feature, axis = 1)\n",
    "\n",
    "features =np.concatenate((betrayer_feature,victim_feature), axis =1)\n",
    "labels = np.array(labels, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = 64\n",
    "        self.input_size = 28\n",
    "        \n",
    "        #Simply two linear layers that uses the hidden layer as part of their input\n",
    "        self.hidden_layer = nn.Linear(self.input_size + self.hidden_size, self.hidden_size)\n",
    "        self.output_layer = nn.Linear(self.input_size + self.hidden_size, 2)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = x.view(1,-1)\n",
    "        combined = torch.cat((x, hidden), 1).cuda()\n",
    "        hidden = self.hidden_layer(combined)\n",
    "        output = self.output_layer(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    #Initialize the hidden layer to all zeros\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda_is_available:\n",
    "    model = RNN().cuda()\n",
    "else:\n",
    "    model = RNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a balance array where the number corrsespond to how much the class at that index should be amplified in weight.\n",
    "#In our case, 0 labels are untouched and 1 labels are weighted almost 10 times\n",
    "temp = np.array((1,9.713178294573643 ))\n",
    "balance = torch.from_numpy(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifiy the training hyper-parameters such as the loss function, learning rate and the optimizer\n",
    "criterion = nn.CrossEntropyLoss(weight = balance.float().cuda())\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)#, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_rnn(input_label_size,model, org_labels, org_features, no_epoch, optimizer, criterion, verbose = True):\n",
    "    model.train()\n",
    "    for epoch in range(NO_EPOCH):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        k = 0\n",
    "        \n",
    "        # Shuffle the dataset and seperate it into training and test set.\n",
    "        rand_idx=np.random.permutation(len(org_features))\n",
    "        features = org_features[rand_idx]\n",
    "        labels = np.array(org_labels)[rand_idx]\n",
    "        train_features = features[0:200]\n",
    "        train_labels = labels[0:200]\n",
    "        \n",
    "        \n",
    "        test_features = features[200:-1]\n",
    "        test_labels = labels[200:-1]\n",
    "        #Performed for each game in the training set\n",
    "        for i in range(len(train_features)):\n",
    "            \n",
    "            ft_1 = np.array(train_features[i,0])      \n",
    "            ft_2 = np.array(train_features[i,1])\n",
    "            ft = np.concatenate(( (ft_1 +ft_2) /2.0 ,np.absolute(ft_1 - ft_2)), axis=1)\n",
    "            lb =  np.array(train_labels[i])           \n",
    "            \n",
    "            if cuda_is_available:\n",
    "                sample = torch.from_numpy(ft).float().cuda()\n",
    "                target = torch.from_numpy(lb).long().cuda()\n",
    "                \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            hidden = model.initHidden().cuda()\n",
    "            \n",
    "            # Forward pass and calculate the loss\n",
    "            for j in range(sample.shape[0]):\n",
    "                truth = target[j].view(1)\n",
    "                #Calculate the running mean for the season\n",
    "                current_sample = torch.mean(sample[0:j+1],axis = 0)\n",
    "                out,hidden = model(current_sample.view(1,-1),hidden)\n",
    "                loss = criterion(out, truth)\n",
    "\n",
    "            # Backward pass + optimize\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            hidden = hidden.detach()\n",
    "\n",
    "           # print statistics\n",
    "            if verbose:\n",
    "                running_loss += loss.item()\n",
    "                if k % 100 == 99:\n",
    "                    print('[%d, %5d] loss: %f' %\n",
    "                          (epoch + 1, k, running_loss/100))\n",
    "                    running_loss = 0.0\n",
    "                k += 1\n",
    "    \n",
    "        #validation\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        accuracy_v = []\n",
    "        matthews_corrcoefs = []\n",
    "        f1_scores = []\n",
    "        #Perfrom the same forward pass without calculating gradients\n",
    "        with torch.no_grad():\n",
    "            hidden = model.initHidden().cuda()\n",
    "            for i in range(len(test_features)):\n",
    "                ft_1 = np.array(test_features[i,0])      \n",
    "                ft_2 = np.array(test_features[i,1])\n",
    "                ft = np.concatenate(( (ft_1 +ft_2) /2.0 ,np.absolute(ft_1 - ft_2)), axis=1)\n",
    "                lb =  np.array(test_labels[i])\n",
    "\n",
    "                sample = torch.from_numpy(ft).float().cuda()\n",
    "                target = torch.from_numpy(lb).long().cuda()\n",
    "                \n",
    "                hidden = model.initHidden().cuda()\n",
    "                \n",
    "                # forward + backward + optimize\n",
    "                for j in range(sample.shape[0]):\n",
    "                    truth = target[j].view(1)\n",
    "                    #Calculate the running mean for the season\n",
    "                    current_sample = torch.mean(sample[0:j+1],axis = 0)\n",
    "                    out,hidden = model(current_sample.view(1,-1),hidden)\n",
    "                    \n",
    "                    prediction_v = predict_label_rnn(out)\n",
    "                    #print(prediction_v)\n",
    "                    accuracy_v.append(np.mean(prediction_v == truth.detach().cpu().numpy()))\n",
    "                    matthews_corrcoefs.append(matthews_corrcoef(truth.detach().cpu().numpy(), prediction_v))\n",
    "                    f1_scores.append(f1_score(truth.detach().cpu().numpy(), prediction_v, average='weighted'))\n",
    "\n",
    "    print('Finished Training')\n",
    "    return np.mean(np.array(accuracy_v)) ,np.mean(np.array(f1_scores)),np.mean(np.array(matthews_corrcoefs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label_rnn(output):\n",
    "    output = output.detach().cpu().numpy()\n",
    "    return np.array([1 if label[1]>=label[0] else 0 for label in output ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    99] loss: 1.182764\n",
      "[1,   199] loss: 0.994846\n",
      "[2,    99] loss: 0.974633\n",
      "[2,   199] loss: 0.817621\n",
      "[3,    99] loss: 0.867998\n",
      "[3,   199] loss: 0.915052\n",
      "[4,    99] loss: 0.947105\n",
      "[4,   199] loss: 0.840241\n",
      "[5,    99] loss: 0.670109\n",
      "[5,   199] loss: 0.781437\n",
      "[6,    99] loss: 0.697694\n",
      "[6,   199] loss: 0.793016\n",
      "[7,    99] loss: 0.777367\n",
      "[7,   199] loss: 0.992036\n",
      "[8,    99] loss: 0.849156\n",
      "[8,   199] loss: 0.669905\n",
      "[9,    99] loss: 0.725323\n",
      "[9,   199] loss: 0.707600\n",
      "[10,    99] loss: 0.614473\n",
      "[10,   199] loss: 0.738845\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "mean_accuracy,mean_f1_score, mean_matthews_corrcoef = train_model_rnn(24,model, labels, features, NO_EPOCH,optimizer,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7625570776255708, F1-score:0.7625570776255708, Matthews correlation coefficient: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {mean_accuracy}, F1-score:{mean_f1_score}, Matthews correlation coefficient: {mean_matthews_corrcoef}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
